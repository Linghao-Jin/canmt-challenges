wandb_version: 1

_wandb:
  desc: null
  value:
    python_version: 3.9.16
    cli_version: 0.14.2
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1686523725.254073
    t:
      1:
      - 1
      - 50
      - 53
      - 55
      - 64
      2:
      - 1
      - 50
      - 53
      - 55
      - 64
      3:
      - 13
      - 23
      - 24
      4: 3.9.16
      5: 0.14.2
      8:
      - 5
_name:
  desc: null
  value: null
common:
  desc: null
  value:
    _name: null
    no_progress_bar: false
    log_interval: 100
    log_format: null
    log_file: null
    aim_repo: null
    aim_run_hash: null
    tensorboard_logdir: null
    wandb_project: reproduce-p2p
    azureml_logging: false
    seed: 1
    cpu: false
    tpu: false
    bf16: false
    memory_efficient_bf16: false
    fp16: true
    memory_efficient_fp16: false
    fp16_no_flatten_grads: false
    fp16_init_scale: 128
    fp16_scale_window: null
    fp16_scale_tolerance: 0.0
    on_cpu_convert_precision: false
    min_loss_scale: 0.0001
    threshold_loss_scale: null
    amp: false
    amp_batch_retries: 2
    amp_init_scale: 128
    amp_scale_window: null
    user_dir: null
    empty_cache_freq: 0
    all_gather_list_size: 16384
    model_parallel_size: 1
    quantization_config_path: null
    profile: false
    reset_logging: false
    suppress_crashes: false
    use_plasma_view: false
    plasma_path: /tmp/plasma
common_eval:
  desc: null
  value:
    _name: null
    path: null
    post_process: null
    quiet: false
    model_overrides: '{}'
    results_path: null
distributed_training:
  desc: null
  value:
    _name: null
    distributed_world_size: 1
    distributed_num_procs: 1
    distributed_rank: 0
    distributed_backend: nccl
    distributed_init_method: null
    distributed_port: -1
    device_id: 0
    distributed_no_spawn: false
    ddp_backend: pytorch_ddp
    ddp_comm_hook: none
    bucket_cap_mb: 25
    fix_batches_to_gpus: false
    find_unused_parameters: false
    gradient_as_bucket_view: false
    fast_stat_sync: false
    heartbeat_timeout: -1
    broadcast_buffers: false
    slowmo_momentum: null
    slowmo_base_algorithm: localsgd
    localsgd_frequency: 3
    nprocs_per_node: 1
    pipeline_model_parallel: false
    pipeline_balance: null
    pipeline_devices: null
    pipeline_chunks: 0
    pipeline_encoder_balance: null
    pipeline_encoder_devices: null
    pipeline_decoder_balance: null
    pipeline_decoder_devices: null
    pipeline_checkpoint: never
    zero_sharding: none
    fp16: true
    memory_efficient_fp16: false
    tpu: false
    no_reshard_after_forward: false
    fp32_reduce_scatter: false
    cpu_offload: false
    use_sharded_state: false
    not_fsdp_flatten_parameters: false
dataset:
  desc: null
  value:
    _name: null
    num_workers: 1
    skip_invalid_size_inputs_valid_test: false
    max_tokens: 4000
    batch_size: null
    required_batch_size_multiple: 8
    required_seq_len_multiple: 1
    dataset_impl: null
    data_buffer_size: 10
    train_subset: train
    valid_subset: valid
    combine_valid_subsets: null
    ignore_unused_valid_subsets: false
    validate_interval: 1
    validate_interval_updates: 0
    validate_after_updates: 0
    fixed_validation_seed: null
    disable_validation: false
    max_tokens_valid: 4000
    batch_size_valid: null
    max_valid_steps: null
    curriculum: 0
    gen_subset: test
    num_shards: 1
    shard_id: 0
    grouped_shuffling: false
    update_epoch_batch_itr: false
    update_ordered_indices_seed: false
optimization:
  desc: null
  value:
    _name: null
    max_epoch: 0
    max_update: 2000000
    stop_time_hours: 0.0
    clip_norm: 0.0
    sentence_avg: false
    update_freq:
    - 16
    lr:
    - 0.001
    stop_min_lr: -1.0
    use_bmuf: false
    skip_remainder_batch: false
checkpoint:
  desc: null
  value:
    _name: null
    save_dir: /project/jonmay_231/linghaoj/reproduce/data/p2p/wmt17/ckpt/xfmr-wmt17-big
    restore_file: checkpoint_last.pt
    continue_once: null
    finetune_from_model: null
    reset_dataloader: false
    reset_lr_scheduler: false
    reset_meters: false
    reset_optimizer: false
    optimizer_overrides: '{}'
    save_interval: 1
    save_interval_updates: 0
    keep_interval_updates: -1
    keep_interval_updates_pattern: -1
    keep_last_epochs: 20
    keep_best_checkpoints: -1
    no_save: false
    no_epoch_checkpoints: false
    no_last_checkpoints: false
    no_save_optimizer_state: false
    best_checkpoint_metric: loss
    maximize_best_checkpoint_metric: false
    patience: -1
    checkpoint_suffix: ''
    checkpoint_shard_count: 1
    load_checkpoint_on_all_dp_ranks: false
    write_checkpoints_asynchronously: false
    model_parallel_size: 1
bmuf:
  desc: null
  value:
    _name: null
    block_lr: 1.0
    block_momentum: 0.875
    global_sync_iter: 50
    warmup_iterations: 500
    use_nbm: false
    average_sync: false
    distributed_world_size: 1
generation:
  desc: null
  value:
    _name: null
    beam: 5
    nbest: 1
    max_len_a: 0.0
    max_len_b: 200
    min_len: 1
    match_source_len: false
    unnormalized: false
    no_early_stop: false
    no_beamable_mm: false
    lenpen: 1.0
    unkpen: 0.0
    replace_unk: null
    sacrebleu: false
    score_reference: false
    prefix_size: 0
    no_repeat_ngram_size: 0
    sampling: false
    sampling_topk: -1
    sampling_topp: -1.0
    constraints: null
    temperature: 1.0
    diverse_beam_groups: -1
    diverse_beam_strength: 0.5
    diversity_rate: -1.0
    print_alignment: null
    print_step: false
    lm_path: null
    lm_weight: 0.0
    iter_decode_eos_penalty: 0.0
    iter_decode_max_iter: 10
    iter_decode_force_max_iter: false
    iter_decode_with_beam: 1
    iter_decode_with_external_reranker: false
    retain_iter_history: false
    retain_dropout: false
    retain_dropout_modules: null
    decoding_format: null
    no_seed_provided: false
    eos_token: null
eval_lm:
  desc: null
  value:
    _name: null
    output_word_probs: false
    output_word_stats: false
    context_window: 0
    softmax_batch: 9223372036854775807
interactive:
  desc: null
  value:
    _name: null
    buffer_size: 0
    input: '-'
task:
  desc: null
  value:
    _name: translation
    data: /project/jonmay_231/linghaoj/reproduce/data/p2p/wmt17/bin-wmt17
    source_lang: zh
    target_lang: en
    load_alignments: false
    left_pad_source: true
    left_pad_target: false
    max_source_positions: 1024
    max_target_positions: 1024
    upsample_primary: -1
    truncate_source: false
    num_batch_buckets: 0
    train_subset: train
    dataset_impl: null
    required_seq_len_multiple: 1
    eval_bleu: true
    eval_bleu_args: '{"beam": 5}'
    eval_bleu_detok: moses
    eval_bleu_detok_args: '{}'
    eval_tokenized_bleu: false
    eval_bleu_remove_bpe: '@@ '
    eval_bleu_print_samples: false
criterion:
  desc: null
  value:
    _name: label_smoothed_cross_entropy
    label_smoothing: 0.1
    report_accuracy: false
    ignore_prefix_size: 0
    sentence_avg: false
optimizer:
  desc: null
  value:
    _name: adam
    adam_betas: (0.9, 0.98)
    adam_eps: 1.0e-08
    weight_decay: 0.0001
    use_old_adam: false
    fp16_adam_stats: false
    tpu: false
    lr:
    - 0.001
lr_scheduler:
  desc: null
  value:
    _name: inverse_sqrt
    warmup_updates: 10000
    warmup_init_lr: 1.0e-07
    lr:
    - 0.001
scoring:
  desc: null
  value:
    _name: bleu
    pad: 1
    eos: 2
    unk: 3
bpe:
  desc: null
  value: null
tokenizer:
  desc: null
  value: null
ema:
  desc: null
  value:
    _name: null
    store_ema: false
    ema_decay: 0.9999
    ema_start_update: 0
    ema_seed_model: null
    ema_update_freq: 1
    ema_fp32: false
args:
  desc: null
  value:
    no_progress_bar: false
    log_interval: 100
    log_format: null
    log_file: null
    aim_repo: null
    aim_run_hash: null
    tensorboard_logdir: null
    wandb_project: reproduce-p2p
    azureml_logging: false
    seed: 1
    cpu: false
    tpu: false
    bf16: false
    memory_efficient_bf16: false
    fp16: true
    memory_efficient_fp16: false
    fp16_no_flatten_grads: false
    fp16_init_scale: 128
    fp16_scale_window: null
    fp16_scale_tolerance: 0.0
    on_cpu_convert_precision: false
    min_loss_scale: 0.0001
    threshold_loss_scale: null
    amp: false
    amp_batch_retries: 2
    amp_init_scale: 128
    amp_scale_window: null
    user_dir: null
    empty_cache_freq: 0
    all_gather_list_size: 16384
    model_parallel_size: 1
    quantization_config_path: null
    profile: false
    reset_logging: false
    suppress_crashes: false
    use_plasma_view: false
    plasma_path: /tmp/plasma
    criterion: label_smoothed_cross_entropy
    tokenizer: null
    bpe: null
    optimizer: adam
    lr_scheduler: inverse_sqrt
    scoring: bleu
    task: translation
    num_workers: 1
    skip_invalid_size_inputs_valid_test: false
    max_tokens: 4000
    batch_size: null
    required_batch_size_multiple: 8
    required_seq_len_multiple: 1
    dataset_impl: null
    data_buffer_size: 10
    train_subset: train
    valid_subset: valid
    combine_valid_subsets: null
    ignore_unused_valid_subsets: false
    validate_interval: 1
    validate_interval_updates: 0
    validate_after_updates: 0
    fixed_validation_seed: null
    disable_validation: false
    max_tokens_valid: 4000
    batch_size_valid: null
    max_valid_steps: null
    curriculum: 0
    gen_subset: test
    num_shards: 1
    shard_id: 0
    grouped_shuffling: false
    update_epoch_batch_itr: false
    update_ordered_indices_seed: false
    distributed_world_size: 1
    distributed_num_procs: 1
    distributed_rank: 0
    distributed_backend: nccl
    distributed_init_method: null
    distributed_port: -1
    device_id: 0
    distributed_no_spawn: false
    ddp_backend: pytorch_ddp
    ddp_comm_hook: none
    bucket_cap_mb: 25
    fix_batches_to_gpus: false
    find_unused_parameters: false
    gradient_as_bucket_view: false
    fast_stat_sync: false
    heartbeat_timeout: -1
    broadcast_buffers: false
    slowmo_momentum: null
    slowmo_base_algorithm: localsgd
    localsgd_frequency: 3
    nprocs_per_node: 1
    pipeline_model_parallel: false
    pipeline_balance: null
    pipeline_devices: null
    pipeline_chunks: 0
    pipeline_encoder_balance: null
    pipeline_encoder_devices: null
    pipeline_decoder_balance: null
    pipeline_decoder_devices: null
    pipeline_checkpoint: never
    zero_sharding: none
    no_reshard_after_forward: false
    fp32_reduce_scatter: false
    cpu_offload: false
    use_sharded_state: false
    not_fsdp_flatten_parameters: false
    arch: transformer_wmt_en_de_big
    max_epoch: 0
    max_update: 2000000
    stop_time_hours: 0
    clip_norm: 0.0
    sentence_avg: false
    update_freq:
    - 16
    lr:
    - 0.001
    stop_min_lr: -1.0
    use_bmuf: false
    skip_remainder_batch: false
    save_dir: /project/jonmay_231/linghaoj/reproduce/data/p2p/wmt17/ckpt/xfmr-wmt17-big
    restore_file: checkpoint_last.pt
    continue_once: null
    finetune_from_model: null
    reset_dataloader: false
    reset_lr_scheduler: false
    reset_meters: false
    reset_optimizer: false
    optimizer_overrides: '{}'
    save_interval: 1
    save_interval_updates: 0
    keep_interval_updates: -1
    keep_interval_updates_pattern: -1
    keep_last_epochs: 20
    keep_best_checkpoints: -1
    no_save: false
    no_epoch_checkpoints: false
    no_last_checkpoints: false
    no_save_optimizer_state: false
    best_checkpoint_metric: loss
    maximize_best_checkpoint_metric: false
    patience: -1
    checkpoint_suffix: ''
    checkpoint_shard_count: 1
    load_checkpoint_on_all_dp_ranks: false
    write_checkpoints_asynchronously: false
    store_ema: false
    ema_decay: 0.9999
    ema_start_update: 0
    ema_seed_model: null
    ema_update_freq: 1
    ema_fp32: false
    data: /project/jonmay_231/linghaoj/reproduce/data/p2p/wmt17/bin-wmt17
    source_lang: zh
    target_lang: en
    load_alignments: false
    left_pad_source: true
    left_pad_target: false
    upsample_primary: -1
    truncate_source: false
    num_batch_buckets: 0
    eval_bleu: true
    eval_bleu_args: '{"beam": 5}'
    eval_bleu_detok: moses
    eval_bleu_detok_args: '{}'
    eval_tokenized_bleu: false
    eval_bleu_remove_bpe: '@@ '
    eval_bleu_print_samples: false
    label_smoothing: 0.1
    report_accuracy: false
    ignore_prefix_size: 0
    adam_betas: (0.9, 0.98)
    adam_eps: 1.0e-08
    weight_decay: 0.0001
    use_old_adam: false
    fp16_adam_stats: false
    warmup_updates: 10000
    warmup_init_lr: 1.0e-07
    pad: 1
    eos: 2
    unk: 3
    dropout: 0.3
    max_source_positions: 1024
    max_target_positions: 1024
    no_seed_provided: false
    attention_dropout: 0.1
    encoder_embed_dim: 1024
    encoder_ffn_embed_dim: 4096
    encoder_attention_heads: 16
    encoder_normalize_before: false
    decoder_embed_dim: 1024
    decoder_ffn_embed_dim: 4096
    decoder_attention_heads: 16
    encoder_embed_path: null
    encoder_layers: 6
    encoder_learned_pos: false
    decoder_embed_path: null
    decoder_layers: 6
    decoder_normalize_before: false
    decoder_learned_pos: false
    activation_dropout: 0.0
    activation_fn: relu
    adaptive_softmax_cutoff: null
    adaptive_softmax_dropout: 0
    share_decoder_input_output_embed: false
    share_all_embeddings: false
    no_token_positional_embeddings: false
    adaptive_input: false
    no_cross_attention: false
    cross_self_attention: false
    decoder_output_dim: 1024
    decoder_input_dim: 1024
    no_scale_embedding: false
    layernorm_embedding: false
    tie_adaptive_weights: false
    checkpoint_activations: false
    offload_activations: false
    encoder_layers_to_keep: null
    decoder_layers_to_keep: null
    encoder_layerdrop: 0
    decoder_layerdrop: 0
    quant_noise_pq: 0
    quant_noise_pq_block_size: 8
    quant_noise_scalar: 0
    _name: transformer_wmt_en_de_big
    min_params_to_wrap: 100000000
