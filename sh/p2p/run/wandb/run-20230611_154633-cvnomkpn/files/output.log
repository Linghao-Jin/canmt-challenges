2023-06-11 15:46:39 | INFO | fairseq.trainer | begin training epoch 1
2023-06-11 15:46:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-11 15:46:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-06-11 15:46:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-06-11 15:46:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-06-11 15:46:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-06-11 15:46:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-06-11 15:48:16 | INFO | train_inner | epoch 001:    105 / 11284 loss=14.283, nll_loss=14.098, ppl=17539.3, wps=66705.7, ups=1.13, wpb=59293.9, bsz=2227.4, num_updates=100, lr=1.0099e-05, gnorm=3.311, loss_scale=4, train_wall=85, gb_free=39.5, wall=116
2023-06-11 15:49:44 | INFO | train_inner | epoch 001:    205 / 11284 loss=12.554, nll_loss=12.173, ppl=4617.55, wps=67743.1, ups=1.14, wpb=59471.6, bsz=2273.9, num_updates=200, lr=2.0098e-05, gnorm=1.243, loss_scale=4, train_wall=81, gb_free=39.6, wall=204
2023-06-11 15:51:11 | INFO | train_inner | epoch 001:    305 / 11284 loss=11.317, nll_loss=10.769, ppl=1745.14, wps=67964.6, ups=1.14, wpb=59678.3, bsz=2190.5, num_updates=300, lr=3.0097e-05, gnorm=1.186, loss_scale=4, train_wall=82, gb_free=39.6, wall=292
2023-06-11 15:52:41 | INFO | train_inner | epoch 001:    405 / 11284 loss=10.532, nll_loss=9.837, ppl=914.52, wps=66908.4, ups=1.12, wpb=59682.2, bsz=2236.7, num_updates=400, lr=4.0096e-05, gnorm=1.207, loss_scale=4, train_wall=84, gb_free=39.6, wall=381
2023-06-11 15:54:09 | INFO | train_inner | epoch 001:    505 / 11284 loss=10.127, nll_loss=9.341, ppl=648.47, wps=67171.1, ups=1.13, wpb=59511.7, bsz=2192.5, num_updates=500, lr=5.0095e-05, gnorm=1.28, loss_scale=4, train_wall=84, gb_free=39.4, wall=470
2023-06-11 15:55:37 | INFO | train_inner | epoch 001:    605 / 11284 loss=9.791, nll_loss=8.947, ppl=493.46, wps=68048.1, ups=1.14, wpb=59540.2, bsz=2200.3, num_updates=600, lr=6.0094e-05, gnorm=1.342, loss_scale=4, train_wall=82, gb_free=39.5, wall=557
2023-06-11 15:57:03 | INFO | train_inner | epoch 001:    705 / 11284 loss=9.484, nll_loss=8.592, ppl=385.87, wps=68751.7, ups=1.16, wpb=59435.2, bsz=2234.7, num_updates=700, lr=7.0093e-05, gnorm=1.392, loss_scale=4, train_wall=82, gb_free=39.6, wall=644
2023-06-11 15:58:31 | INFO | train_inner | epoch 001:    805 / 11284 loss=9.193, nll_loss=8.257, ppl=305.93, wps=67407.2, ups=1.13, wpb=59556.5, bsz=2300.8, num_updates=800, lr=8.0092e-05, gnorm=1.163, loss_scale=4, train_wall=83, gb_free=39.6, wall=732
2023-06-11 15:59:59 | INFO | train_inner | epoch 001:    905 / 11284 loss=8.944, nll_loss=7.969, ppl=250.48, wps=67977.6, ups=1.15, wpb=59354.5, bsz=2211.5, num_updates=900, lr=9.0091e-05, gnorm=1.238, loss_scale=4, train_wall=83, gb_free=39.2, wall=819
2023-06-11 16:01:22 | INFO | train_inner | epoch 001:   1005 / 11284 loss=8.713, nll_loss=7.7, ppl=207.95, wps=70900, ups=1.19, wpb=59356.7, bsz=2129, num_updates=1000, lr=0.00010009, gnorm=1.187, loss_scale=4, train_wall=79, gb_free=39.6, wall=903
2023-06-11 16:02:48 | INFO | train_inner | epoch 001:   1105 / 11284 loss=8.542, nll_loss=7.502, ppl=181.24, wps=69187.1, ups=1.17, wpb=59338.2, bsz=2348, num_updates=1100, lr=0.000110089, gnorm=1.175, loss_scale=8, train_wall=81, gb_free=39.6, wall=989
2023-06-11 16:04:15 | INFO | train_inner | epoch 001:   1205 / 11284 loss=8.345, nll_loss=7.273, ppl=154.69, wps=68658.7, ups=1.16, wpb=59290.3, bsz=2234.5, num_updates=1200, lr=0.000120088, gnorm=1.183, loss_scale=8, train_wall=82, gb_free=39.6, wall=1075
2023-06-11 16:05:42 | INFO | train_inner | epoch 001:   1305 / 11284 loss=8.178, nll_loss=7.079, ppl=135.2, wps=67695.5, ups=1.14, wpb=59465.1, bsz=2298.8, num_updates=1300, lr=0.000130087, gnorm=1.169, loss_scale=8, train_wall=84, gb_free=39.6, wall=1163
2023-06-11 16:07:09 | INFO | train_inner | epoch 001:   1405 / 11284 loss=8.01, nll_loss=6.883, ppl=118.03, wps=68598.3, ups=1.15, wpb=59667.6, bsz=2245.7, num_updates=1400, lr=0.000140086, gnorm=1.064, loss_scale=8, train_wall=83, gb_free=39.5, wall=1250
2023-06-11 16:08:36 | INFO | train_inner | epoch 001:   1505 / 11284 loss=7.849, nll_loss=6.697, ppl=103.78, wps=68423.9, ups=1.15, wpb=59440.6, bsz=2227, num_updates=1500, lr=0.000150085, gnorm=1.109, loss_scale=8, train_wall=83, gb_free=39.5, wall=1337
2023-06-11 16:10:02 | INFO | train_inner | epoch 001:   1605 / 11284 loss=7.695, nll_loss=6.519, ppl=91.68, wps=69595.4, ups=1.17, wpb=59697.3, bsz=2226.3, num_updates=1600, lr=0.000160084, gnorm=1.049, loss_scale=8, train_wall=82, gb_free=39.6, wall=1423
2023-06-11 16:11:29 | INFO | train_inner | epoch 001:   1705 / 11284 loss=7.522, nll_loss=6.318, ppl=79.77, wps=68062.9, ups=1.15, wpb=59393.1, bsz=2269, num_updates=1700, lr=0.000170083, gnorm=1.032, loss_scale=8, train_wall=83, gb_free=39.6, wall=1510
2023-06-11 16:12:57 | INFO | train_inner | epoch 001:   1805 / 11284 loss=7.356, nll_loss=6.126, ppl=69.82, wps=68107.7, ups=1.15, wpb=59386.9, bsz=2301.2, num_updates=1800, lr=0.000180082, gnorm=1.008, loss_scale=8, train_wall=83, gb_free=39.6, wall=1597
2023-06-11 16:14:23 | INFO | train_inner | epoch 001:   1905 / 11284 loss=7.213, nll_loss=5.959, ppl=62.22, wps=69273.7, ups=1.16, wpb=59717.9, bsz=2255.6, num_updates=1900, lr=0.000190081, gnorm=1.049, loss_scale=8, train_wall=82, gb_free=39.5, wall=1683
2023-06-11 16:15:48 | INFO | train_inner | epoch 001:   2005 / 11284 loss=7.055, nll_loss=5.777, ppl=54.84, wps=70051.7, ups=1.18, wpb=59461.6, bsz=2141.8, num_updates=2000, lr=0.00020008, gnorm=0.958, loss_scale=8, train_wall=81, gb_free=39.6, wall=1768
2023-06-11 16:17:13 | INFO | train_inner | epoch 001:   2105 / 11284 loss=6.915, nll_loss=5.615, ppl=49.02, wps=70327.5, ups=1.18, wpb=59711, bsz=2264.2, num_updates=2100, lr=0.000210079, gnorm=1.019, loss_scale=16, train_wall=81, gb_free=39.6, wall=1853
2023-06-11 16:18:38 | INFO | train_inner | epoch 001:   2205 / 11284 loss=6.779, nll_loss=5.458, ppl=43.95, wps=69863.2, ups=1.17, wpb=59482.8, bsz=2230.9, num_updates=2200, lr=0.000220078, gnorm=0.983, loss_scale=16, train_wall=81, gb_free=39.4, wall=1938
2023-06-11 16:20:03 | INFO | train_inner | epoch 001:   2305 / 11284 loss=6.657, nll_loss=5.316, ppl=39.83, wps=69903, ups=1.18, wpb=59294.9, bsz=2227.3, num_updates=2300, lr=0.000230077, gnorm=0.966, loss_scale=16, train_wall=81, gb_free=39.5, wall=2023
2023-06-11 16:21:28 | INFO | train_inner | epoch 001:   2405 / 11284 loss=6.554, nll_loss=5.198, ppl=36.7, wps=69798.6, ups=1.18, wpb=59377.6, bsz=2258.3, num_updates=2400, lr=0.000240076, gnorm=0.972, loss_scale=16, train_wall=81, gb_free=39.6, wall=2108
2023-06-11 16:22:53 | INFO | train_inner | epoch 001:   2505 / 11284 loss=6.438, nll_loss=5.063, ppl=33.43, wps=69533.4, ups=1.17, wpb=59411.9, bsz=2132.5, num_updates=2500, lr=0.000250075, gnorm=0.929, loss_scale=16, train_wall=82, gb_free=39.5, wall=2194
2023-06-11 16:24:18 | INFO | train_inner | epoch 001:   2605 / 11284 loss=6.32, nll_loss=4.927, ppl=30.42, wps=69946.1, ups=1.18, wpb=59444.9, bsz=2188.7, num_updates=2600, lr=0.000260074, gnorm=0.914, loss_scale=16, train_wall=81, gb_free=39.4, wall=2279
2023-06-11 16:25:44 | INFO | train_inner | epoch 001:   2705 / 11284 loss=6.16, nll_loss=4.743, ppl=26.77, wps=69215.3, ups=1.16, wpb=59479.5, bsz=2286.4, num_updates=2700, lr=0.000270073, gnorm=0.854, loss_scale=16, train_wall=82, gb_free=39.6, wall=2365
2023-06-11 16:27:10 | INFO | train_inner | epoch 001:   2805 / 11284 loss=6.063, nll_loss=4.631, ppl=24.77, wps=68839.5, ups=1.16, wpb=59440.5, bsz=2267.9, num_updates=2800, lr=0.000280072, gnorm=0.85, loss_scale=16, train_wall=82, gb_free=39.6, wall=2451
2023-06-11 16:28:37 | INFO | train_inner | epoch 001:   2905 / 11284 loss=5.94, nll_loss=4.49, ppl=22.47, wps=68911.6, ups=1.16, wpb=59429.8, bsz=2134.3, num_updates=2900, lr=0.000290071, gnorm=0.817, loss_scale=16, train_wall=82, gb_free=39.6, wall=2537
2023-06-11 16:30:00 | INFO | train_inner | epoch 001:   3005 / 11284 loss=5.782, nll_loss=4.308, ppl=19.8, wps=71771.2, ups=1.2, wpb=59695.6, bsz=2192.8, num_updates=3000, lr=0.00030007, gnorm=0.829, loss_scale=16, train_wall=79, gb_free=39.6, wall=2620
2023-06-11 16:31:21 | INFO | train_inner | epoch 001:   3105 / 11284 loss=5.69, nll_loss=4.203, ppl=18.41, wps=72787.3, ups=1.22, wpb=59498.1, bsz=2195.8, num_updates=3100, lr=0.000310069, gnorm=0.727, loss_scale=32, train_wall=78, gb_free=39.6, wall=2702
2023-06-11 16:31:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-06-11 16:32:44 | INFO | train_inner | epoch 001:   3206 / 11284 loss=5.579, nll_loss=4.075, ppl=16.86, wps=71667.5, ups=1.21, wpb=59421.9, bsz=2205.4, num_updates=3200, lr=0.000320068, gnorm=0.722, loss_scale=16, train_wall=79, gb_free=39.6, wall=2785
2023-06-11 16:34:07 | INFO | train_inner | epoch 001:   3306 / 11284 loss=5.513, nll_loss=3.999, ppl=15.99, wps=71658.9, ups=1.21, wpb=59412.2, bsz=2125.8, num_updates=3300, lr=0.000330067, gnorm=0.759, loss_scale=16, train_wall=79, gb_free=39.5, wall=2868
2023-06-11 16:35:30 | INFO | train_inner | epoch 001:   3406 / 11284 loss=5.402, nll_loss=3.873, ppl=14.66, wps=71396.1, ups=1.2, wpb=59399.8, bsz=2227.4, num_updates=3400, lr=0.000340066, gnorm=0.682, loss_scale=16, train_wall=79, gb_free=39.6, wall=2951
2023-06-11 16:36:53 | INFO | train_inner | epoch 001:   3506 / 11284 loss=5.315, nll_loss=3.775, ppl=13.69, wps=72645.1, ups=1.22, wpb=59712.6, bsz=2159.3, num_updates=3500, lr=0.000350065, gnorm=0.676, loss_scale=16, train_wall=78, gb_free=39.6, wall=3033
2023-06-11 16:38:16 | INFO | train_inner | epoch 001:   3606 / 11284 loss=5.226, nll_loss=3.674, ppl=12.76, wps=71610.2, ups=1.2, wpb=59452.7, bsz=2266.1, num_updates=3600, lr=0.000360064, gnorm=0.638, loss_scale=16, train_wall=79, gb_free=39.3, wall=3116
2023-06-11 16:38:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-06-11 16:39:40 | INFO | train_inner | epoch 001:   3707 / 11284 loss=5.171, nll_loss=3.612, ppl=12.23, wps=70837.2, ups=1.19, wpb=59495.3, bsz=2227.2, num_updates=3700, lr=0.000370063, gnorm=0.629, loss_scale=8, train_wall=80, gb_free=39.6, wall=3200
2023-06-11 16:41:02 | INFO | train_inner | epoch 001:   3807 / 11284 loss=5.109, nll_loss=3.543, ppl=11.65, wps=72338.6, ups=1.22, wpb=59469.1, bsz=2327.7, num_updates=3800, lr=0.000380062, gnorm=0.592, loss_scale=8, train_wall=78, gb_free=39.5, wall=3282
2023-06-11 16:42:24 | INFO | train_inner | epoch 001:   3907 / 11284 loss=5.046, nll_loss=3.471, ppl=11.09, wps=72705.2, ups=1.22, wpb=59573.9, bsz=2133.5, num_updates=3900, lr=0.000390061, gnorm=0.606, loss_scale=8, train_wall=78, gb_free=39.5, wall=3364
2023-06-11 16:43:46 | INFO | train_inner | epoch 001:   4007 / 11284 loss=4.984, nll_loss=3.402, ppl=10.57, wps=72712.9, ups=1.22, wpb=59622.9, bsz=2161.7, num_updates=4000, lr=0.00040006, gnorm=0.574, loss_scale=8, train_wall=78, gb_free=39.6, wall=3446
2023-06-11 16:45:09 | INFO | train_inner | epoch 001:   4107 / 11284 loss=4.928, nll_loss=3.339, ppl=10.12, wps=71874.9, ups=1.21, wpb=59542.1, bsz=2197, num_updates=4100, lr=0.000410059, gnorm=0.577, loss_scale=8, train_wall=79, gb_free=39.6, wall=3529
2023-06-11 16:46:32 | INFO | train_inner | epoch 001:   4207 / 11284 loss=4.897, nll_loss=3.305, ppl=9.89, wps=71319.6, ups=1.2, wpb=59561.1, bsz=2238.6, num_updates=4200, lr=0.000420058, gnorm=0.535, loss_scale=8, train_wall=80, gb_free=39.5, wall=3613
2023-06-11 16:47:57 | INFO | train_inner | epoch 001:   4307 / 11284 loss=4.856, nll_loss=3.259, ppl=9.57, wps=69874.8, ups=1.17, wpb=59584.3, bsz=2321.8, num_updates=4300, lr=0.000430057, gnorm=0.537, loss_scale=8, train_wall=81, gb_free=39.6, wall=3698
2023-06-11 16:49:22 | INFO | train_inner | epoch 001:   4407 / 11284 loss=4.797, nll_loss=3.194, ppl=9.15, wps=70585.2, ups=1.19, wpb=59560.2, bsz=2179, num_updates=4400, lr=0.000440056, gnorm=0.526, loss_scale=8, train_wall=80, gb_free=39.5, wall=3782
2023-06-11 16:50:46 | INFO | train_inner | epoch 001:   4507 / 11284 loss=4.773, nll_loss=3.167, ppl=8.98, wps=70764.3, ups=1.19, wpb=59510.2, bsz=2257.3, num_updates=4500, lr=0.000450055, gnorm=0.523, loss_scale=8, train_wall=80, gb_free=39.6, wall=3867
2023-06-11 16:52:11 | INFO | train_inner | epoch 001:   4607 / 11284 loss=4.734, nll_loss=3.125, ppl=8.72, wps=70381.7, ups=1.18, wpb=59752.9, bsz=2255.8, num_updates=4600, lr=0.000460054, gnorm=0.514, loss_scale=8, train_wall=81, gb_free=39.6, wall=3951
2023-06-11 16:53:33 | INFO | train_inner | epoch 001:   4707 / 11284 loss=4.697, nll_loss=3.084, ppl=8.48, wps=72249.2, ups=1.22, wpb=59455.7, bsz=2173.5, num_updates=4700, lr=0.000470053, gnorm=0.487, loss_scale=16, train_wall=78, gb_free=39.5, wall=4034
2023-06-11 16:54:56 | INFO | train_inner | epoch 001:   4807 / 11284 loss=4.661, nll_loss=3.045, ppl=8.25, wps=71979.1, ups=1.21, wpb=59525.8, bsz=2129.5, num_updates=4800, lr=0.000480052, gnorm=0.485, loss_scale=16, train_wall=79, gb_free=39.6, wall=4116
2023-06-11 16:56:18 | INFO | train_inner | epoch 001:   4907 / 11284 loss=4.646, nll_loss=3.029, ppl=8.16, wps=72544.3, ups=1.22, wpb=59658.7, bsz=2259.1, num_updates=4900, lr=0.000490051, gnorm=0.495, loss_scale=16, train_wall=78, gb_free=39.6, wall=4199
2023-06-11 16:56:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-06-11 16:57:42 | INFO | train_inner | epoch 001:   5008 / 11284 loss=4.611, nll_loss=2.99, ppl=7.94, wps=70823.5, ups=1.19, wpb=59350.7, bsz=2186.1, num_updates=5000, lr=0.00050005, gnorm=0.475, loss_scale=8, train_wall=80, gb_free=39.6, wall=4282
2023-06-11 16:59:05 | INFO | train_inner | epoch 001:   5108 / 11284 loss=4.597, nll_loss=2.975, ppl=7.86, wps=71279.9, ups=1.2, wpb=59398.2, bsz=2269.8, num_updates=5100, lr=0.000510049, gnorm=0.47, loss_scale=8, train_wall=79, gb_free=39.5, wall=4366
2023-06-11 17:00:28 | INFO | train_inner | epoch 001:   5208 / 11284 loss=4.579, nll_loss=2.956, ppl=7.76, wps=71900.4, ups=1.21, wpb=59519.1, bsz=2268.3, num_updates=5200, lr=0.000520048, gnorm=0.48, loss_scale=8, train_wall=79, gb_free=39.5, wall=4449
2023-06-11 17:01:51 | INFO | train_inner | epoch 001:   5308 / 11284 loss=4.538, nll_loss=2.91, ppl=7.52, wps=71700.8, ups=1.21, wpb=59488.9, bsz=2325.1, num_updates=5300, lr=0.000530047, gnorm=0.473, loss_scale=8, train_wall=78, gb_free=39.6, wall=4532
2023-06-11 17:03:14 | INFO | train_inner | epoch 001:   5408 / 11284 loss=4.524, nll_loss=2.896, ppl=7.44, wps=72036.4, ups=1.2, wpb=59798.9, bsz=2355.2, num_updates=5400, lr=0.000540046, gnorm=0.449, loss_scale=8, train_wall=79, gb_free=39.6, wall=4615
2023-06-11 17:04:37 | INFO | train_inner | epoch 001:   5508 / 11284 loss=4.51, nll_loss=2.88, ppl=7.36, wps=71252.9, ups=1.2, wpb=59444.1, bsz=2265.3, num_updates=5500, lr=0.000550045, gnorm=0.47, loss_scale=8, train_wall=79, gb_free=39.6, wall=4698
2023-06-11 17:06:00 | INFO | train_inner | epoch 001:   5608 / 11284 loss=4.476, nll_loss=2.843, ppl=7.18, wps=71874.8, ups=1.21, wpb=59588.3, bsz=2179.8, num_updates=5600, lr=0.000560044, gnorm=0.452, loss_scale=8, train_wall=79, gb_free=39.6, wall=4781
2023-06-11 17:07:24 | INFO | train_inner | epoch 001:   5708 / 11284 loss=4.448, nll_loss=2.812, ppl=7.02, wps=71433.3, ups=1.2, wpb=59604.2, bsz=2317.9, num_updates=5700, lr=0.000570043, gnorm=0.452, loss_scale=8, train_wall=79, gb_free=39.6, wall=4864
2023-06-11 17:08:47 | INFO | train_inner | epoch 001:   5808 / 11284 loss=4.447, nll_loss=2.812, ppl=7.02, wps=71740.7, ups=1.2, wpb=59612.6, bsz=2257.7, num_updates=5800, lr=0.000580042, gnorm=0.446, loss_scale=8, train_wall=79, gb_free=39.6, wall=4947
2023-06-11 17:10:10 | INFO | train_inner | epoch 001:   5908 / 11284 loss=4.415, nll_loss=2.777, ppl=6.85, wps=71549.7, ups=1.2, wpb=59624, bsz=2253.2, num_updates=5900, lr=0.000590041, gnorm=0.431, loss_scale=8, train_wall=79, gb_free=39.6, wall=5031
2023-06-11 17:11:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-06-11 17:11:34 | INFO | train_inner | epoch 001:   6009 / 11284 loss=4.432, nll_loss=2.797, ppl=6.95, wps=70968.3, ups=1.2, wpb=59256.5, bsz=2234.1, num_updates=6000, lr=0.00060004, gnorm=0.44, loss_scale=8, train_wall=80, gb_free=39.6, wall=5114
2023-06-11 17:12:57 | INFO | train_inner | epoch 001:   6109 / 11284 loss=4.387, nll_loss=2.747, ppl=6.71, wps=71575, ups=1.2, wpb=59470.4, bsz=2250.9, num_updates=6100, lr=0.000610039, gnorm=0.43, loss_scale=8, train_wall=79, gb_free=39.6, wall=5197
2023-06-11 17:14:20 | INFO | train_inner | epoch 001:   6209 / 11284 loss=4.382, nll_loss=2.743, ppl=6.69, wps=71717, ups=1.2, wpb=59585.6, bsz=2182.1, num_updates=6200, lr=0.000620038, gnorm=0.425, loss_scale=8, train_wall=79, gb_free=39.6, wall=5280
2023-06-11 17:15:44 | INFO | train_inner | epoch 001:   6309 / 11284 loss=4.384, nll_loss=2.745, ppl=6.7, wps=70979.6, ups=1.2, wpb=59364.2, bsz=2290.2, num_updates=6300, lr=0.000630037, gnorm=0.424, loss_scale=8, train_wall=79, gb_free=39.6, wall=5364
2023-06-11 17:17:05 | INFO | train_inner | epoch 001:   6409 / 11284 loss=4.349, nll_loss=2.707, ppl=6.53, wps=72386.1, ups=1.22, wpb=59286.6, bsz=2211, num_updates=6400, lr=0.000640036, gnorm=0.44, loss_scale=8, train_wall=78, gb_free=39.6, wall=5446
2023-06-11 17:18:28 | INFO | train_inner | epoch 001:   6509 / 11284 loss=4.34, nll_loss=2.697, ppl=6.48, wps=72427.4, ups=1.21, wpb=59615.7, bsz=2194.4, num_updates=6500, lr=0.000650035, gnorm=0.413, loss_scale=8, train_wall=78, gb_free=39.6, wall=5528
2023-06-11 17:19:51 | INFO | train_inner | epoch 001:   6609 / 11284 loss=4.325, nll_loss=2.68, ppl=6.41, wps=71679.2, ups=1.2, wpb=59601.5, bsz=2225.1, num_updates=6600, lr=0.000660034, gnorm=0.435, loss_scale=8, train_wall=79, gb_free=39.5, wall=5611
2023-06-11 17:21:14 | INFO | train_inner | epoch 001:   6709 / 11284 loss=4.318, nll_loss=2.673, ppl=6.38, wps=71468.3, ups=1.2, wpb=59434.7, bsz=2319.5, num_updates=6700, lr=0.000670033, gnorm=0.419, loss_scale=8, train_wall=79, gb_free=39.6, wall=5695
2023-06-11 17:22:38 | INFO | train_inner | epoch 001:   6809 / 11284 loss=4.313, nll_loss=2.668, ppl=6.36, wps=71446.5, ups=1.2, wpb=59720.7, bsz=2244.4, num_updates=6800, lr=0.000680032, gnorm=0.438, loss_scale=8, train_wall=80, gb_free=39.6, wall=5778
2023-06-11 17:24:01 | INFO | train_inner | epoch 001:   6909 / 11284 loss=4.297, nll_loss=2.65, ppl=6.28, wps=71497.6, ups=1.2, wpb=59357.3, bsz=2263.7, num_updates=6900, lr=0.000690031, gnorm=0.448, loss_scale=8, train_wall=79, gb_free=39.6, wall=5861
2023-06-11 17:25:24 | INFO | train_inner | epoch 001:   7009 / 11284 loss=4.281, nll_loss=2.633, ppl=6.2, wps=71221.1, ups=1.2, wpb=59340.6, bsz=2284.7, num_updates=7000, lr=0.00070003, gnorm=0.416, loss_scale=8, train_wall=79, gb_free=39.6, wall=5945
2023-06-11 17:26:48 | INFO | train_inner | epoch 001:   7109 / 11284 loss=4.264, nll_loss=2.614, ppl=6.12, wps=71518.3, ups=1.2, wpb=59747.7, bsz=2268.1, num_updates=7100, lr=0.000710029, gnorm=0.417, loss_scale=16, train_wall=80, gb_free=39.4, wall=6028
2023-06-11 17:28:11 | INFO | train_inner | epoch 001:   7209 / 11284 loss=4.264, nll_loss=2.616, ppl=6.13, wps=71776.4, ups=1.2, wpb=59678.2, bsz=2140.2, num_updates=7200, lr=0.000720028, gnorm=0.418, loss_scale=16, train_wall=79, gb_free=39.5, wall=6111
2023-06-11 17:28:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-06-11 17:29:36 | INFO | train_inner | epoch 001:   7310 / 11284 loss=4.267, nll_loss=2.619, ppl=6.14, wps=69816.2, ups=1.17, wpb=59513.8, bsz=2275.5, num_updates=7300, lr=0.000730027, gnorm=0.435, loss_scale=8, train_wall=81, gb_free=39.6, wall=6196
2023-06-11 17:30:59 | INFO | train_inner | epoch 001:   7410 / 11284 loss=4.266, nll_loss=2.619, ppl=6.14, wps=71202, ups=1.2, wpb=59493.4, bsz=2224.1, num_updates=7400, lr=0.000740026, gnorm=0.418, loss_scale=8, train_wall=80, gb_free=39.6, wall=6280
2023-06-11 17:32:24 | INFO | train_inner | epoch 001:   7510 / 11284 loss=4.255, nll_loss=2.606, ppl=6.09, wps=70642.5, ups=1.19, wpb=59368.9, bsz=2166.2, num_updates=7500, lr=0.000750025, gnorm=0.43, loss_scale=8, train_wall=80, gb_free=39.6, wall=6364
2023-06-11 17:33:46 | INFO | train_inner | epoch 001:   7610 / 11284 loss=4.229, nll_loss=2.578, ppl=5.97, wps=72618.4, ups=1.22, wpb=59550.6, bsz=2116.7, num_updates=7600, lr=0.000760024, gnorm=0.426, loss_scale=8, train_wall=78, gb_free=39.6, wall=6446
2023-06-11 17:35:08 | INFO | train_inner | epoch 001:   7710 / 11284 loss=4.223, nll_loss=2.572, ppl=5.95, wps=72122.8, ups=1.21, wpb=59688.6, bsz=2180.8, num_updates=7700, lr=0.000770023, gnorm=0.432, loss_scale=8, train_wall=79, gb_free=39.6, wall=6529
2023-06-11 17:36:31 | INFO | train_inner | epoch 001:   7810 / 11284 loss=4.215, nll_loss=2.563, ppl=5.91, wps=72377.4, ups=1.21, wpb=59591, bsz=2284.3, num_updates=7800, lr=0.000780022, gnorm=0.416, loss_scale=8, train_wall=78, gb_free=39.6, wall=6611
2023-06-11 17:37:52 | INFO | train_inner | epoch 001:   7910 / 11284 loss=4.221, nll_loss=2.57, ppl=5.94, wps=72626.3, ups=1.23, wpb=59197.6, bsz=2143.3, num_updates=7900, lr=0.000790021, gnorm=0.446, loss_scale=8, train_wall=77, gb_free=39.6, wall=6693
2023-06-11 17:39:15 | INFO | train_inner | epoch 001:   8010 / 11284 loss=4.213, nll_loss=2.561, ppl=5.9, wps=72202.8, ups=1.21, wpb=59486.5, bsz=2191.8, num_updates=8000, lr=0.00080002, gnorm=0.438, loss_scale=8, train_wall=79, gb_free=39.6, wall=6775
2023-06-11 17:40:37 | INFO | train_inner | epoch 001:   8110 / 11284 loss=4.216, nll_loss=2.565, ppl=5.92, wps=71688.3, ups=1.21, wpb=59444.7, bsz=2202.1, num_updates=8100, lr=0.000810019, gnorm=0.424, loss_scale=8, train_wall=79, gb_free=39.6, wall=6858
2023-06-11 17:42:01 | INFO | train_inner | epoch 001:   8210 / 11284 loss=4.191, nll_loss=2.537, ppl=5.8, wps=71461.1, ups=1.2, wpb=59494.1, bsz=2177.4, num_updates=8200, lr=0.000820018, gnorm=0.446, loss_scale=8, train_wall=79, gb_free=39.6, wall=6941
2023-06-11 17:43:24 | INFO | train_inner | epoch 001:   8310 / 11284 loss=4.206, nll_loss=2.555, ppl=5.87, wps=71913.5, ups=1.21, wpb=59583.9, bsz=2225.6, num_updates=8300, lr=0.000830017, gnorm=0.429, loss_scale=16, train_wall=79, gb_free=39.5, wall=7024
2023-06-11 17:44:47 | INFO | train_inner | epoch 001:   8410 / 11284 loss=4.198, nll_loss=2.546, ppl=5.84, wps=71529.2, ups=1.2, wpb=59637.2, bsz=2203.6, num_updates=8400, lr=0.000840016, gnorm=0.419, loss_scale=16, train_wall=79, gb_free=39.6, wall=7108
2023-06-11 17:46:09 | INFO | train_inner | epoch 001:   8510 / 11284 loss=4.203, nll_loss=2.552, ppl=5.87, wps=72017.5, ups=1.21, wpb=59394.1, bsz=2174.7, num_updates=8500, lr=0.000850015, gnorm=0.452, loss_scale=16, train_wall=78, gb_free=39.5, wall=7190
2023-06-11 17:46:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-06-11 17:47:33 | INFO | train_inner | epoch 001:   8611 / 11284 loss=4.177, nll_loss=2.522, ppl=5.75, wps=71119.3, ups=1.2, wpb=59450.8, bsz=2215.1, num_updates=8600, lr=0.000860014, gnorm=0.428, loss_scale=8, train_wall=79, gb_free=39.6, wall=7274
2023-06-11 17:48:56 | INFO | train_inner | epoch 001:   8711 / 11284 loss=4.177, nll_loss=2.523, ppl=5.75, wps=71917.6, ups=1.21, wpb=59660.8, bsz=2218.5, num_updates=8700, lr=0.000870013, gnorm=0.433, loss_scale=8, train_wall=79, gb_free=39.6, wall=7357
2023-06-11 17:50:19 | INFO | train_inner | epoch 001:   8811 / 11284 loss=4.177, nll_loss=2.523, ppl=5.75, wps=71345.1, ups=1.2, wpb=59487.3, bsz=2191.7, num_updates=8800, lr=0.000880012, gnorm=0.437, loss_scale=8, train_wall=79, gb_free=39.6, wall=7440
2023-06-11 17:51:42 | INFO | train_inner | epoch 001:   8911 / 11284 loss=4.179, nll_loss=2.526, ppl=5.76, wps=71605.4, ups=1.2, wpb=59518.6, bsz=2185.1, num_updates=8900, lr=0.000890011, gnorm=0.45, loss_scale=8, train_wall=79, gb_free=39.6, wall=7523
2023-06-11 17:53:06 | INFO | train_inner | epoch 001:   9011 / 11284 loss=4.169, nll_loss=2.515, ppl=5.72, wps=71292.3, ups=1.2, wpb=59230.6, bsz=2145.8, num_updates=9000, lr=0.00090001, gnorm=0.446, loss_scale=8, train_wall=79, gb_free=39.6, wall=7606
2023-06-11 17:54:29 | INFO | train_inner | epoch 001:   9111 / 11284 loss=4.161, nll_loss=2.506, ppl=5.68, wps=71889.4, ups=1.2, wpb=59663.7, bsz=2209.3, num_updates=9100, lr=0.000910009, gnorm=0.438, loss_scale=8, train_wall=79, gb_free=39.6, wall=7689
2023-06-11 17:55:52 | INFO | train_inner | epoch 001:   9211 / 11284 loss=4.183, nll_loss=2.532, ppl=5.78, wps=71074.4, ups=1.2, wpb=59238.6, bsz=2239.6, num_updates=9200, lr=0.000920008, gnorm=0.452, loss_scale=8, train_wall=79, gb_free=39.6, wall=7772
2023-06-11 17:57:15 | INFO | train_inner | epoch 001:   9311 / 11284 loss=4.176, nll_loss=2.523, ppl=5.75, wps=71353.5, ups=1.2, wpb=59425.3, bsz=2288.7, num_updates=9300, lr=0.000930007, gnorm=0.465, loss_scale=8, train_wall=79, gb_free=39.6, wall=7856
2023-06-11 17:58:38 | INFO | train_inner | epoch 001:   9411 / 11284 loss=4.159, nll_loss=2.504, ppl=5.67, wps=71525.1, ups=1.2, wpb=59552.9, bsz=2248.5, num_updates=9400, lr=0.000940006, gnorm=0.442, loss_scale=8, train_wall=79, gb_free=39.5, wall=7939
2023-06-11 18:00:02 | INFO | train_inner | epoch 001:   9511 / 11284 loss=4.175, nll_loss=2.522, ppl=5.75, wps=71586.9, ups=1.2, wpb=59514.7, bsz=2300.5, num_updates=9500, lr=0.000950005, gnorm=0.468, loss_scale=8, train_wall=79, gb_free=39.6, wall=8022
2023-06-11 18:00:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-06-11 18:01:25 | INFO | train_inner | epoch 001:   9612 / 11284 loss=4.142, nll_loss=2.486, ppl=5.6, wps=71179.4, ups=1.2, wpb=59544.9, bsz=2234.6, num_updates=9600, lr=0.000960004, gnorm=0.435, loss_scale=8, train_wall=80, gb_free=39.6, wall=8106
2023-06-11 18:02:48 | INFO | train_inner | epoch 001:   9712 / 11284 loss=4.174, nll_loss=2.522, ppl=5.74, wps=71695.2, ups=1.2, wpb=59604.8, bsz=2194.7, num_updates=9700, lr=0.000970003, gnorm=0.468, loss_scale=8, train_wall=79, gb_free=39.6, wall=8189
2023-06-11 18:04:12 | INFO | train_inner | epoch 001:   9812 / 11284 loss=4.155, nll_loss=2.5, ppl=5.66, wps=71703, ups=1.2, wpb=59688.6, bsz=2187.9, num_updates=9800, lr=0.000980002, gnorm=0.447, loss_scale=8, train_wall=79, gb_free=39.6, wall=8272
2023-06-11 18:05:35 | INFO | train_inner | epoch 001:   9912 / 11284 loss=4.15, nll_loss=2.496, ppl=5.64, wps=71581, ups=1.21, wpb=59403.2, bsz=2323.9, num_updates=9900, lr=0.000990001, gnorm=0.459, loss_scale=8, train_wall=79, gb_free=39.6, wall=8355
2023-06-11 18:06:57 | INFO | train_inner | epoch 001:  10012 / 11284 loss=4.146, nll_loss=2.492, ppl=5.62, wps=71641.4, ups=1.21, wpb=59354.6, bsz=2244.5, num_updates=10000, lr=0.001, gnorm=0.437, loss_scale=8, train_wall=79, gb_free=39.6, wall=8438
2023-06-11 18:08:21 | INFO | train_inner | epoch 001:  10112 / 11284 loss=4.124, nll_loss=2.467, ppl=5.53, wps=71336.1, ups=1.2, wpb=59384, bsz=2266.7, num_updates=10100, lr=0.000995037, gnorm=0.459, loss_scale=8, train_wall=79, gb_free=39.6, wall=8521
2023-06-11 18:09:44 | INFO | train_inner | epoch 001:  10212 / 11284 loss=4.133, nll_loss=2.477, ppl=5.57, wps=71432.8, ups=1.2, wpb=59539.4, bsz=2235.8, num_updates=10200, lr=0.000990148, gnorm=0.464, loss_scale=8, train_wall=79, gb_free=39.6, wall=8605
2023-06-11 18:11:07 | INFO | train_inner | epoch 001:  10312 / 11284 loss=4.115, nll_loss=2.457, ppl=5.49, wps=71266.9, ups=1.2, wpb=59223.5, bsz=2302.9, num_updates=10300, lr=0.000985329, gnorm=0.446, loss_scale=8, train_wall=79, gb_free=39.6, wall=8688
2023-06-11 18:12:31 | INFO | train_inner | epoch 001:  10412 / 11284 loss=4.113, nll_loss=2.455, ppl=5.48, wps=71370.6, ups=1.2, wpb=59492.5, bsz=2216.7, num_updates=10400, lr=0.000980581, gnorm=0.425, loss_scale=8, train_wall=79, gb_free=39.6, wall=8771
2023-06-11 18:13:54 | INFO | train_inner | epoch 001:  10512 / 11284 loss=4.11, nll_loss=2.452, ppl=5.47, wps=71563.7, ups=1.2, wpb=59606.2, bsz=2258.5, num_updates=10500, lr=0.0009759, gnorm=0.461, loss_scale=8, train_wall=79, gb_free=39.6, wall=8854
2023-06-11 18:14:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-06-11 18:15:18 | INFO | train_inner | epoch 001:  10613 / 11284 loss=4.106, nll_loss=2.448, ppl=5.46, wps=70932.8, ups=1.19, wpb=59539.8, bsz=2258.2, num_updates=10600, lr=0.000971286, gnorm=0.446, loss_scale=8, train_wall=80, gb_free=39.6, wall=8938
2023-06-11 18:16:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-06-11 18:16:42 | INFO | train_inner | epoch 001:  10714 / 11284 loss=4.102, nll_loss=2.443, ppl=5.44, wps=70622.8, ups=1.19, wpb=59388.7, bsz=2158.7, num_updates=10700, lr=0.000966736, gnorm=0.453, loss_scale=4, train_wall=80, gb_free=39.6, wall=9022
2023-06-11 18:18:05 | INFO | train_inner | epoch 001:  10814 / 11284 loss=4.096, nll_loss=2.437, ppl=5.41, wps=71518.4, ups=1.2, wpb=59454, bsz=2206.8, num_updates=10800, lr=0.00096225, gnorm=0.44, loss_scale=4, train_wall=79, gb_free=39.5, wall=9106
2023-06-11 18:19:28 | INFO | train_inner | epoch 001:  10914 / 11284 loss=4.089, nll_loss=2.43, ppl=5.39, wps=71574.4, ups=1.2, wpb=59544, bsz=2286.2, num_updates=10900, lr=0.000957826, gnorm=0.439, loss_scale=4, train_wall=79, gb_free=39.6, wall=9189
2023-06-11 18:20:51 | INFO | train_inner | epoch 001:  11014 / 11284 loss=4.107, nll_loss=2.45, ppl=5.47, wps=71446.3, ups=1.2, wpb=59388.5, bsz=2182.7, num_updates=11000, lr=0.000953463, gnorm=0.444, loss_scale=4, train_wall=79, gb_free=39.6, wall=9272
2023-06-11 18:22:14 | INFO | train_inner | epoch 001:  11114 / 11284 loss=4.081, nll_loss=2.421, ppl=5.36, wps=71797.4, ups=1.2, wpb=59640.7, bsz=2189.6, num_updates=11100, lr=0.000949158, gnorm=0.421, loss_scale=4, train_wall=79, gb_free=39.6, wall=9355
2023-06-11 18:23:37 | INFO | train_inner | epoch 001:  11214 / 11284 loss=4.088, nll_loss=2.429, ppl=5.39, wps=71816.1, ups=1.2, wpb=59598.8, bsz=2246.5, num_updates=11200, lr=0.000944911, gnorm=0.439, loss_scale=4, train_wall=79, gb_free=39.6, wall=9438
2023-06-11 18:24:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-11 18:24:55 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.945 | nll_loss 3.304 | ppl 9.88 | bleu 17.46 | wps 3498.8 | wpb 2397.5 | bsz 71.5 | num_updates 11270
2023-06-11 18:24:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 11270 updates
2023-06-11 18:24:55 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint1.pt
2023-06-11 18:24:56 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint1.pt
2023-06-11 18:25:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint1.pt (epoch 1 @ 11270 updates, score 4.945) (writing took 6.380784255452454 seconds)
2023-06-11 18:25:01 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-06-11 18:25:01 | INFO | train | epoch 001 | loss 5.442 | nll_loss 3.955 | ppl 15.51 | wps 70629.1 | ups 1.19 | wpb 59499.6 | bsz 2227.5 | num_updates 11270 | lr 0.000941972 | gnorm 0.656 | loss_scale 4 | train_wall 9007 | gb_free 39.6 | wall 9522
2023-06-11 18:25:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-11 18:25:01 | INFO | fairseq.trainer | begin training epoch 2
2023-06-11 18:25:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-11 18:25:26 | INFO | train_inner | epoch 002:     30 / 11284 loss=4.083, nll_loss=2.423, ppl=5.36, wps=54496.9, ups=0.92, wpb=59257.8, bsz=2201.3, num_updates=11300, lr=0.000940721, gnorm=0.43, loss_scale=4, train_wall=79, gb_free=39.4, wall=9547
2023-06-11 18:26:49 | INFO | train_inner | epoch 002:    130 / 11284 loss=4.058, nll_loss=2.396, ppl=5.26, wps=72248.1, ups=1.21, wpb=59662.7, bsz=2234.2, num_updates=11400, lr=0.000936586, gnorm=0.421, loss_scale=4, train_wall=78, gb_free=39.6, wall=9629
2023-06-11 18:28:12 | INFO | train_inner | epoch 002:    230 / 11284 loss=4.041, nll_loss=2.377, ppl=5.19, wps=71280.1, ups=1.2, wpb=59461.1, bsz=2329.1, num_updates=11500, lr=0.000932505, gnorm=0.434, loss_scale=4, train_wall=80, gb_free=39.6, wall=9713
2023-06-11 18:29:35 | INFO | train_inner | epoch 002:    330 / 11284 loss=4.042, nll_loss=2.378, ppl=5.2, wps=71454.5, ups=1.2, wpb=59595.4, bsz=2187.9, num_updates=11600, lr=0.000928477, gnorm=0.424, loss_scale=4, train_wall=79, gb_free=39.6, wall=9796
2023-06-11 18:30:59 | INFO | train_inner | epoch 002:    430 / 11284 loss=4.055, nll_loss=2.392, ppl=5.25, wps=71028.3, ups=1.2, wpb=59351.7, bsz=2209.8, num_updates=11700, lr=0.0009245, gnorm=0.427, loss_scale=8, train_wall=80, gb_free=39.6, wall=9880
2023-06-11 18:31:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-06-11 18:32:22 | INFO | train_inner | epoch 002:    531 / 11284 loss=4.057, nll_loss=2.396, ppl=5.26, wps=71715.3, ups=1.21, wpb=59374.1, bsz=2306.3, num_updates=11800, lr=0.000920575, gnorm=0.454, loss_scale=4, train_wall=79, gb_free=39.6, wall=9962
2023-06-11 18:33:44 | INFO | train_inner | epoch 002:    631 / 11284 loss=4.03, nll_loss=2.365, ppl=5.15, wps=72108.9, ups=1.21, wpb=59562.7, bsz=2319.9, num_updates=11900, lr=0.000916698, gnorm=0.399, loss_scale=4, train_wall=78, gb_free=39.6, wall=10045
2023-06-11 18:35:08 | INFO | train_inner | epoch 002:    731 / 11284 loss=4.046, nll_loss=2.383, ppl=5.22, wps=70814.3, ups=1.19, wpb=59415.7, bsz=2264.8, num_updates=12000, lr=0.000912871, gnorm=0.423, loss_scale=4, train_wall=80, gb_free=39.5, wall=10129
2023-06-11 18:36:31 | INFO | train_inner | epoch 002:    831 / 11284 loss=4.037, nll_loss=2.373, ppl=5.18, wps=71996.8, ups=1.21, wpb=59454.2, bsz=2180, num_updates=12100, lr=0.000909091, gnorm=0.435, loss_scale=4, train_wall=79, gb_free=39.6, wall=10212
2023-06-11 18:37:53 | INFO | train_inner | epoch 002:    931 / 11284 loss=4.02, nll_loss=2.355, ppl=5.12, wps=72348, ups=1.21, wpb=59581.7, bsz=2244.5, num_updates=12200, lr=0.000905357, gnorm=0.405, loss_scale=4, train_wall=78, gb_free=39.6, wall=10294
2023-06-11 18:39:17 | INFO | train_inner | epoch 002:   1031 / 11284 loss=4.031, nll_loss=2.367, ppl=5.16, wps=71174.1, ups=1.2, wpb=59482.9, bsz=2172.1, num_updates=12300, lr=0.00090167, gnorm=0.412, loss_scale=4, train_wall=80, gb_free=39.5, wall=10377
2023-06-11 18:40:41 | INFO | train_inner | epoch 002:   1131 / 11284 loss=4.017, nll_loss=2.351, ppl=5.1, wps=70341.9, ups=1.18, wpb=59438.2, bsz=2275.7, num_updates=12400, lr=0.000898027, gnorm=0.422, loss_scale=4, train_wall=80, gb_free=39.6, wall=10462
2023-06-11 18:42:05 | INFO | train_inner | epoch 002:   1231 / 11284 loss=4.005, nll_loss=2.339, ppl=5.06, wps=71514.4, ups=1.2, wpb=59695.4, bsz=2177.7, num_updates=12500, lr=0.000894427, gnorm=0.407, loss_scale=4, train_wall=80, gb_free=39.6, wall=10545
2023-06-11 18:43:28 | INFO | train_inner | epoch 002:   1331 / 11284 loss=4.011, nll_loss=2.346, ppl=5.08, wps=71446, ups=1.2, wpb=59607.3, bsz=2196.1, num_updates=12600, lr=0.000890871, gnorm=0.405, loss_scale=4, train_wall=79, gb_free=39.5, wall=10629
2023-06-11 18:44:52 | INFO | train_inner | epoch 002:   1431 / 11284 loss=3.987, nll_loss=2.318, ppl=4.99, wps=71821, ups=1.2, wpb=59833.8, bsz=2307.8, num_updates=12700, lr=0.000887357, gnorm=0.43, loss_scale=4, train_wall=79, gb_free=39.6, wall=10712
2023-06-11 18:45:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-06-11 18:46:15 | INFO | train_inner | epoch 002:   1532 / 11284 loss=4.019, nll_loss=2.354, ppl=5.11, wps=71074.2, ups=1.2, wpb=59417.7, bsz=2208.7, num_updates=12800, lr=0.000883883, gnorm=0.417, loss_scale=4, train_wall=80, gb_free=39.5, wall=10796
2023-06-11 18:47:39 | INFO | train_inner | epoch 002:   1632 / 11284 loss=3.985, nll_loss=2.317, ppl=4.98, wps=70922.5, ups=1.19, wpb=59407, bsz=2200, num_updates=12900, lr=0.000880451, gnorm=0.409, loss_scale=4, train_wall=80, gb_free=39.6, wall=10880
2023-06-11 18:49:02 | INFO | train_inner | epoch 002:   1732 / 11284 loss=3.994, nll_loss=2.327, ppl=5.02, wps=71385.3, ups=1.2, wpb=59451.3, bsz=2201.7, num_updates=13000, lr=0.000877058, gnorm=0.423, loss_scale=4, train_wall=79, gb_free=39.6, wall=10963
2023-06-11 18:50:25 | INFO | train_inner | epoch 002:   1832 / 11284 loss=4.009, nll_loss=2.344, ppl=5.08, wps=71823.2, ups=1.2, wpb=59713.3, bsz=2204.7, num_updates=13100, lr=0.000873704, gnorm=0.417, loss_scale=4, train_wall=79, gb_free=39.5, wall=11046
2023-06-11 18:51:47 | INFO | train_inner | epoch 002:   1932 / 11284 loss=3.98, nll_loss=2.312, ppl=4.96, wps=72822, ups=1.22, wpb=59547.1, bsz=2239.4, num_updates=13200, lr=0.000870388, gnorm=0.388, loss_scale=4, train_wall=78, gb_free=39.6, wall=11128
2023-06-11 18:53:10 | INFO | train_inner | epoch 002:   2032 / 11284 loss=3.983, nll_loss=2.315, ppl=4.98, wps=71587.3, ups=1.2, wpb=59663.7, bsz=2282.3, num_updates=13300, lr=0.00086711, gnorm=0.4, loss_scale=4, train_wall=79, gb_free=39.6, wall=11211
2023-06-11 18:54:34 | INFO | train_inner | epoch 002:   2132 / 11284 loss=3.985, nll_loss=2.318, ppl=4.99, wps=71689.7, ups=1.2, wpb=59598.5, bsz=2266.1, num_updates=13400, lr=0.000863868, gnorm=0.392, loss_scale=4, train_wall=79, gb_free=39.5, wall=11294
2023-06-11 18:55:57 | INFO | train_inner | epoch 002:   2232 / 11284 loss=3.981, nll_loss=2.313, ppl=4.97, wps=71539.2, ups=1.2, wpb=59624.2, bsz=2257.4, num_updates=13500, lr=0.000860663, gnorm=0.406, loss_scale=4, train_wall=80, gb_free=39.6, wall=11378
2023-06-11 18:57:19 | INFO | train_inner | epoch 002:   2332 / 11284 loss=4.004, nll_loss=2.339, ppl=5.06, wps=72303.3, ups=1.21, wpb=59644.4, bsz=2201.2, num_updates=13600, lr=0.000857493, gnorm=0.385, loss_scale=4, train_wall=78, gb_free=39.5, wall=11460
2023-06-11 18:58:43 | INFO | train_inner | epoch 002:   2432 / 11284 loss=3.987, nll_loss=2.32, ppl=4.99, wps=71356.6, ups=1.2, wpb=59507.6, bsz=2185.9, num_updates=13700, lr=0.000854358, gnorm=0.401, loss_scale=4, train_wall=79, gb_free=39.6, wall=11543
2023-06-11 19:00:06 | INFO | train_inner | epoch 002:   2532 / 11284 loss=3.969, nll_loss=2.3, ppl=4.92, wps=71785.5, ups=1.21, wpb=59439.6, bsz=2149.7, num_updates=13800, lr=0.000851257, gnorm=0.397, loss_scale=8, train_wall=79, gb_free=39.6, wall=11626
2023-06-11 19:00:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-06-11 19:01:29 | INFO | train_inner | epoch 002:   2633 / 11284 loss=3.969, nll_loss=2.301, ppl=4.93, wps=71025.9, ups=1.19, wpb=59505.3, bsz=2154.1, num_updates=13900, lr=0.000848189, gnorm=0.398, loss_scale=4, train_wall=80, gb_free=39.6, wall=11710
2023-06-11 19:02:53 | INFO | train_inner | epoch 002:   2733 / 11284 loss=3.953, nll_loss=2.282, ppl=4.86, wps=71380.8, ups=1.2, wpb=59402.9, bsz=2125.6, num_updates=14000, lr=0.000845154, gnorm=0.385, loss_scale=4, train_wall=79, gb_free=39.6, wall=11793
2023-06-11 19:04:16 | INFO | train_inner | epoch 002:   2833 / 11284 loss=3.966, nll_loss=2.297, ppl=4.91, wps=71481.8, ups=1.21, wpb=59238.7, bsz=2206.8, num_updates=14100, lr=0.000842152, gnorm=0.407, loss_scale=4, train_wall=79, gb_free=39.5, wall=11876
2023-06-11 19:05:38 | INFO | train_inner | epoch 002:   2933 / 11284 loss=3.961, nll_loss=2.292, ppl=4.9, wps=71841.7, ups=1.21, wpb=59505.6, bsz=2295.4, num_updates=14200, lr=0.000839181, gnorm=0.392, loss_scale=4, train_wall=79, gb_free=39.6, wall=11959
2023-06-11 19:07:01 | INFO | train_inner | epoch 002:   3033 / 11284 loss=3.956, nll_loss=2.286, ppl=4.88, wps=71791.8, ups=1.2, wpb=59617.4, bsz=2205.3, num_updates=14300, lr=0.000836242, gnorm=0.384, loss_scale=4, train_wall=79, gb_free=39.5, wall=12042
2023-06-11 19:08:24 | INFO | train_inner | epoch 002:   3133 / 11284 loss=3.955, nll_loss=2.285, ppl=4.87, wps=72378.5, ups=1.22, wpb=59564.2, bsz=2320.2, num_updates=14400, lr=0.000833333, gnorm=0.384, loss_scale=4, train_wall=78, gb_free=39.6, wall=12124
2023-06-11 19:09:47 | INFO | train_inner | epoch 002:   3233 / 11284 loss=3.962, nll_loss=2.293, ppl=4.9, wps=71899.4, ups=1.21, wpb=59545.7, bsz=2294.1, num_updates=14500, lr=0.000830455, gnorm=0.396, loss_scale=4, train_wall=78, gb_free=39.6, wall=12207
2023-06-11 19:11:09 | INFO | train_inner | epoch 002:   3333 / 11284 loss=3.941, nll_loss=2.27, ppl=4.82, wps=72460.1, ups=1.22, wpb=59615.1, bsz=2217.3, num_updates=14600, lr=0.000827606, gnorm=0.379, loss_scale=4, train_wall=78, gb_free=39.6, wall=12289
2023-06-11 19:12:31 | INFO | train_inner | epoch 002:   3433 / 11284 loss=3.954, nll_loss=2.285, ppl=4.87, wps=72786.6, ups=1.22, wpb=59661.7, bsz=2162.3, num_updates=14700, lr=0.000824786, gnorm=0.382, loss_scale=4, train_wall=78, gb_free=39.6, wall=12371
2023-06-11 19:13:54 | INFO | train_inner | epoch 002:   3533 / 11284 loss=3.952, nll_loss=2.282, ppl=4.86, wps=71425.2, ups=1.2, wpb=59499.3, bsz=2342.2, num_updates=14800, lr=0.000821995, gnorm=0.391, loss_scale=4, train_wall=79, gb_free=39.6, wall=12455
2023-06-11 19:15:17 | INFO | train_inner | epoch 002:   3633 / 11284 loss=3.947, nll_loss=2.276, ppl=4.84, wps=71746.6, ups=1.2, wpb=59616.1, bsz=2304.2, num_updates=14900, lr=0.000819232, gnorm=0.368, loss_scale=8, train_wall=79, gb_free=39.6, wall=12538
2023-06-11 19:16:40 | INFO | train_inner | epoch 002:   3733 / 11284 loss=3.934, nll_loss=2.262, ppl=4.8, wps=71505.2, ups=1.21, wpb=59287.6, bsz=2225.6, num_updates=15000, lr=0.000816497, gnorm=0.374, loss_scale=8, train_wall=79, gb_free=39.6, wall=12621
2023-06-11 19:16:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-06-11 19:18:03 | INFO | train_inner | epoch 002:   3834 / 11284 loss=3.923, nll_loss=2.25, ppl=4.76, wps=71779, ups=1.21, wpb=59419.8, bsz=2279, num_updates=15100, lr=0.000813788, gnorm=0.379, loss_scale=4, train_wall=79, gb_free=39.6, wall=12703
2023-06-11 19:19:26 | INFO | train_inner | epoch 002:   3934 / 11284 loss=3.927, nll_loss=2.255, ppl=4.77, wps=71641.4, ups=1.21, wpb=59387.2, bsz=2237.5, num_updates=15200, lr=0.000811107, gnorm=0.369, loss_scale=4, train_wall=79, gb_free=39.5, wall=12786
2023-06-11 19:20:49 | INFO | train_inner | epoch 002:   4034 / 11284 loss=3.946, nll_loss=2.276, ppl=4.84, wps=71538.7, ups=1.2, wpb=59467, bsz=2249.4, num_updates=15300, lr=0.000808452, gnorm=0.377, loss_scale=4, train_wall=79, gb_free=39.6, wall=12869
2023-06-11 19:22:12 | INFO | train_inner | epoch 002:   4134 / 11284 loss=3.913, nll_loss=2.238, ppl=4.72, wps=71709.7, ups=1.21, wpb=59433, bsz=2242.4, num_updates=15400, lr=0.000805823, gnorm=0.373, loss_scale=4, train_wall=79, gb_free=39.6, wall=12952
2023-06-11 19:23:35 | INFO | train_inner | epoch 002:   4234 / 11284 loss=3.929, nll_loss=2.257, ppl=4.78, wps=71387.1, ups=1.2, wpb=59367.7, bsz=2195.9, num_updates=15500, lr=0.000803219, gnorm=0.387, loss_scale=4, train_wall=79, gb_free=39.6, wall=13036
2023-06-11 19:24:58 | INFO | train_inner | epoch 002:   4334 / 11284 loss=3.913, nll_loss=2.239, ppl=4.72, wps=71769.3, ups=1.2, wpb=59560.2, bsz=2199.5, num_updates=15600, lr=0.000800641, gnorm=0.362, loss_scale=4, train_wall=79, gb_free=39.6, wall=13118
2023-06-11 19:26:21 | INFO | train_inner | epoch 002:   4434 / 11284 loss=3.914, nll_loss=2.241, ppl=4.73, wps=71510.2, ups=1.2, wpb=59556.7, bsz=2288, num_updates=15700, lr=0.000798087, gnorm=0.366, loss_scale=4, train_wall=79, gb_free=39.6, wall=13202
2023-06-11 19:27:45 | INFO | train_inner | epoch 002:   4534 / 11284 loss=3.924, nll_loss=2.252, ppl=4.76, wps=71416.7, ups=1.2, wpb=59656.2, bsz=2342, num_updates=15800, lr=0.000795557, gnorm=0.365, loss_scale=4, train_wall=80, gb_free=39.5, wall=13285
2023-06-11 19:29:08 | INFO | train_inner | epoch 002:   4634 / 11284 loss=3.927, nll_loss=2.255, ppl=4.77, wps=71372.9, ups=1.2, wpb=59578.3, bsz=2220.6, num_updates=15900, lr=0.000793052, gnorm=0.38, loss_scale=4, train_wall=79, gb_free=39.5, wall=13369
2023-06-11 19:30:32 | INFO | train_inner | epoch 002:   4734 / 11284 loss=3.914, nll_loss=2.241, ppl=4.73, wps=71574.2, ups=1.2, wpb=59664.7, bsz=2272.8, num_updates=16000, lr=0.000790569, gnorm=0.354, loss_scale=4, train_wall=79, gb_free=39.5, wall=13452
2023-06-11 19:31:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-06-11 19:31:55 | INFO | train_inner | epoch 002:   4835 / 11284 loss=3.914, nll_loss=2.241, ppl=4.73, wps=70873.9, ups=1.19, wpb=59352.9, bsz=2226.9, num_updates=16100, lr=0.00078811, gnorm=0.353, loss_scale=4, train_wall=80, gb_free=39.6, wall=13536
2023-06-11 19:33:17 | INFO | train_inner | epoch 002:   4935 / 11284 loss=3.909, nll_loss=2.236, ppl=4.71, wps=72286.2, ups=1.22, wpb=59290.4, bsz=2246.8, num_updates=16200, lr=0.000785674, gnorm=0.367, loss_scale=4, train_wall=78, gb_free=39.5, wall=13618
2023-06-11 19:34:40 | INFO | train_inner | epoch 002:   5035 / 11284 loss=3.914, nll_loss=2.241, ppl=4.73, wps=71506.6, ups=1.21, wpb=59233.3, bsz=2148.9, num_updates=16300, lr=0.00078326, gnorm=0.377, loss_scale=4, train_wall=79, gb_free=39.4, wall=13701
2023-06-11 19:36:04 | INFO | train_inner | epoch 002:   5135 / 11284 loss=3.906, nll_loss=2.232, ppl=4.7, wps=71334.7, ups=1.2, wpb=59615, bsz=2253.6, num_updates=16400, lr=0.000780869, gnorm=0.359, loss_scale=4, train_wall=80, gb_free=39.6, wall=13784
2023-06-11 19:37:27 | INFO | train_inner | epoch 002:   5235 / 11284 loss=3.887, nll_loss=2.211, ppl=4.63, wps=71345.8, ups=1.2, wpb=59356.9, bsz=2297, num_updates=16500, lr=0.000778499, gnorm=0.353, loss_scale=4, train_wall=79, gb_free=39.6, wall=13868
2023-06-11 19:38:50 | INFO | train_inner | epoch 002:   5335 / 11284 loss=3.899, nll_loss=2.224, ppl=4.67, wps=71271.3, ups=1.2, wpb=59361.6, bsz=2278.7, num_updates=16600, lr=0.000776151, gnorm=0.372, loss_scale=4, train_wall=79, gb_free=39.6, wall=13951
2023-06-11 19:40:13 | INFO | train_inner | epoch 002:   5435 / 11284 loss=3.893, nll_loss=2.218, ppl=4.65, wps=71679.7, ups=1.2, wpb=59619.4, bsz=2263.9, num_updates=16700, lr=0.000773823, gnorm=0.352, loss_scale=4, train_wall=79, gb_free=39.6, wall=14034
2023-06-11 19:41:37 | INFO | train_inner | epoch 002:   5535 / 11284 loss=3.898, nll_loss=2.224, ppl=4.67, wps=71440.6, ups=1.2, wpb=59534.4, bsz=2262.4, num_updates=16800, lr=0.000771517, gnorm=0.345, loss_scale=4, train_wall=79, gb_free=39.6, wall=14117
2023-06-11 19:42:59 | INFO | train_inner | epoch 002:   5635 / 11284 loss=3.892, nll_loss=2.217, ppl=4.65, wps=72715.3, ups=1.22, wpb=59474, bsz=2174.2, num_updates=16900, lr=0.000769231, gnorm=0.378, loss_scale=4, train_wall=78, gb_free=39.6, wall=14199
2023-06-11 19:44:22 | INFO | train_inner | epoch 002:   5735 / 11284 loss=3.91, nll_loss=2.237, ppl=4.72, wps=71330.7, ups=1.2, wpb=59477.5, bsz=2270.2, num_updates=17000, lr=0.000766965, gnorm=0.349, loss_scale=4, train_wall=79, gb_free=39.6, wall=14283
2023-06-11 19:45:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-06-11 19:45:46 | INFO | train_inner | epoch 002:   5836 / 11284 loss=3.892, nll_loss=2.217, ppl=4.65, wps=70442.7, ups=1.19, wpb=59284.8, bsz=2151.3, num_updates=17100, lr=0.000764719, gnorm=0.352, loss_scale=4, train_wall=80, gb_free=39.6, wall=14367
2023-06-11 19:47:10 | INFO | train_inner | epoch 002:   5936 / 11284 loss=3.876, nll_loss=2.199, ppl=4.59, wps=71376.1, ups=1.2, wpb=59623.4, bsz=2219.4, num_updates=17200, lr=0.000762493, gnorm=0.347, loss_scale=4, train_wall=80, gb_free=38.6, wall=14450
2023-06-11 19:48:33 | INFO | train_inner | epoch 002:   6036 / 11284 loss=3.892, nll_loss=2.218, ppl=4.65, wps=71666.4, ups=1.2, wpb=59730.3, bsz=2275.7, num_updates=17300, lr=0.000760286, gnorm=0.355, loss_scale=4, train_wall=80, gb_free=39.3, wall=14534
2023-06-11 19:49:56 | INFO | train_inner | epoch 002:   6136 / 11284 loss=3.892, nll_loss=2.218, ppl=4.65, wps=71737.8, ups=1.2, wpb=59555.1, bsz=2225.4, num_updates=17400, lr=0.000758098, gnorm=0.346, loss_scale=4, train_wall=79, gb_free=39.6, wall=14617
2023-06-11 19:51:19 | INFO | train_inner | epoch 002:   6236 / 11284 loss=3.88, nll_loss=2.204, ppl=4.61, wps=71489.1, ups=1.2, wpb=59554.1, bsz=2201.2, num_updates=17500, lr=0.000755929, gnorm=0.36, loss_scale=4, train_wall=79, gb_free=39.6, wall=14700
2023-06-11 19:52:43 | INFO | train_inner | epoch 002:   6336 / 11284 loss=3.902, nll_loss=2.229, ppl=4.69, wps=71601.7, ups=1.2, wpb=59625.2, bsz=2270.4, num_updates=17600, lr=0.000753778, gnorm=0.368, loss_scale=4, train_wall=79, gb_free=39.6, wall=14783
2023-06-11 19:54:05 | INFO | train_inner | epoch 002:   6436 / 11284 loss=3.88, nll_loss=2.205, ppl=4.61, wps=71892.6, ups=1.21, wpb=59543.1, bsz=2235.7, num_updates=17700, lr=0.000751646, gnorm=0.363, loss_scale=4, train_wall=79, gb_free=39.6, wall=14866
2023-06-11 19:55:29 | INFO | train_inner | epoch 002:   6536 / 11284 loss=3.903, nll_loss=2.23, ppl=4.69, wps=71356.1, ups=1.2, wpb=59500.7, bsz=2251.2, num_updates=17800, lr=0.000749532, gnorm=0.364, loss_scale=4, train_wall=80, gb_free=39.6, wall=14949
2023-06-11 19:56:52 | INFO | train_inner | epoch 002:   6636 / 11284 loss=3.882, nll_loss=2.206, ppl=4.61, wps=71644.9, ups=1.2, wpb=59640.8, bsz=2261.1, num_updates=17900, lr=0.000747435, gnorm=0.357, loss_scale=4, train_wall=79, gb_free=39.6, wall=15033
2023-06-11 19:58:15 | INFO | train_inner | epoch 002:   6736 / 11284 loss=3.885, nll_loss=2.21, ppl=4.63, wps=71475.2, ups=1.21, wpb=59303.7, bsz=2262, num_updates=18000, lr=0.000745356, gnorm=0.349, loss_scale=4, train_wall=79, gb_free=39.5, wall=15116
2023-06-11 19:59:37 | INFO | train_inner | epoch 002:   6836 / 11284 loss=3.865, nll_loss=2.187, ppl=4.55, wps=72855.3, ups=1.22, wpb=59498.7, bsz=2178, num_updates=18100, lr=0.000743294, gnorm=0.355, loss_scale=8, train_wall=78, gb_free=39.6, wall=15197
2023-06-11 20:01:00 | INFO | train_inner | epoch 002:   6936 / 11284 loss=3.881, nll_loss=2.206, ppl=4.61, wps=71772.4, ups=1.21, wpb=59467.7, bsz=2270.4, num_updates=18200, lr=0.000741249, gnorm=0.347, loss_scale=8, train_wall=79, gb_free=39.5, wall=15280
2023-06-11 20:01:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-06-11 20:02:22 | INFO | train_inner | epoch 002:   7037 / 11284 loss=3.882, nll_loss=2.207, ppl=4.62, wps=71868.5, ups=1.21, wpb=59448.5, bsz=2128.5, num_updates=18300, lr=0.000739221, gnorm=0.345, loss_scale=4, train_wall=79, gb_free=39.5, wall=15363
2023-06-11 20:03:45 | INFO | train_inner | epoch 002:   7137 / 11284 loss=3.883, nll_loss=2.208, ppl=4.62, wps=71783.2, ups=1.21, wpb=59496.5, bsz=2214.9, num_updates=18400, lr=0.00073721, gnorm=0.347, loss_scale=4, train_wall=79, gb_free=39.5, wall=15446
2023-06-11 20:05:08 | INFO | train_inner | epoch 002:   7237 / 11284 loss=3.852, nll_loss=2.173, ppl=4.51, wps=72162.8, ups=1.21, wpb=59536.4, bsz=2172.2, num_updates=18500, lr=0.000735215, gnorm=0.331, loss_scale=4, train_wall=79, gb_free=39.6, wall=15528
2023-06-11 20:06:31 | INFO | train_inner | epoch 002:   7337 / 11284 loss=3.862, nll_loss=2.185, ppl=4.55, wps=71653.5, ups=1.2, wpb=59603, bsz=2247, num_updates=18600, lr=0.000733236, gnorm=0.347, loss_scale=4, train_wall=79, gb_free=39.6, wall=15611
2023-06-11 20:07:54 | INFO | train_inner | epoch 002:   7437 / 11284 loss=3.852, nll_loss=2.174, ppl=4.51, wps=72062, ups=1.21, wpb=59706.4, bsz=2199.4, num_updates=18700, lr=0.000731272, gnorm=0.337, loss_scale=4, train_wall=79, gb_free=39.6, wall=15694
2023-06-11 20:09:17 | INFO | train_inner | epoch 002:   7537 / 11284 loss=3.866, nll_loss=2.189, ppl=4.56, wps=71655.6, ups=1.2, wpb=59474.9, bsz=2170.4, num_updates=18800, lr=0.000729325, gnorm=0.346, loss_scale=4, train_wall=79, gb_free=39.6, wall=15777
2023-06-11 20:10:40 | INFO | train_inner | epoch 002:   7637 / 11284 loss=3.871, nll_loss=2.195, ppl=4.58, wps=71686.1, ups=1.21, wpb=59398.2, bsz=2247.1, num_updates=18900, lr=0.000727393, gnorm=0.345, loss_scale=4, train_wall=79, gb_free=39.5, wall=15860
2023-06-11 20:12:03 | INFO | train_inner | epoch 002:   7737 / 11284 loss=3.863, nll_loss=2.186, ppl=4.55, wps=71336.8, ups=1.2, wpb=59517.7, bsz=2176.6, num_updates=19000, lr=0.000725476, gnorm=0.343, loss_scale=4, train_wall=79, gb_free=39.6, wall=15944
2023-06-11 20:13:26 | INFO | train_inner | epoch 002:   7837 / 11284 loss=3.86, nll_loss=2.182, ppl=4.54, wps=71351.8, ups=1.2, wpb=59499.1, bsz=2240.4, num_updates=19100, lr=0.000723575, gnorm=0.345, loss_scale=4, train_wall=79, gb_free=39.5, wall=16027
2023-06-11 20:14:49 | INFO | train_inner | epoch 002:   7937 / 11284 loss=3.862, nll_loss=2.184, ppl=4.55, wps=71824.7, ups=1.21, wpb=59566.2, bsz=2165.9, num_updates=19200, lr=0.000721688, gnorm=0.354, loss_scale=4, train_wall=79, gb_free=39.6, wall=16110
2023-06-11 20:16:13 | INFO | train_inner | epoch 002:   8037 / 11284 loss=3.845, nll_loss=2.166, ppl=4.49, wps=71498.3, ups=1.2, wpb=59514.7, bsz=2190.7, num_updates=19300, lr=0.000719816, gnorm=0.33, loss_scale=8, train_wall=79, gb_free=39.6, wall=16193
2023-06-11 20:17:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-06-11 20:17:36 | INFO | train_inner | epoch 002:   8138 / 11284 loss=3.86, nll_loss=2.183, ppl=4.54, wps=70925.5, ups=1.19, wpb=59489.7, bsz=2146.2, num_updates=19400, lr=0.000717958, gnorm=0.343, loss_scale=4, train_wall=80, gb_free=39.6, wall=16277
2023-06-11 20:18:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-11 20:18:59 | INFO | train_inner | epoch 002:   8239 / 11284 loss=3.86, nll_loss=2.183, ppl=4.54, wps=71415.5, ups=1.2, wpb=59303.6, bsz=2184.4, num_updates=19500, lr=0.000716115, gnorm=0.361, loss_scale=2, train_wall=79, gb_free=39.6, wall=16360
2023-06-11 20:20:21 | INFO | train_inner | epoch 002:   8339 / 11284 loss=3.868, nll_loss=2.192, ppl=4.57, wps=72524.3, ups=1.22, wpb=59371.8, bsz=2199.6, num_updates=19600, lr=0.000714286, gnorm=0.35, loss_scale=2, train_wall=78, gb_free=39.6, wall=16442
2023-06-11 20:21:43 | INFO | train_inner | epoch 002:   8439 / 11284 loss=3.855, nll_loss=2.177, ppl=4.52, wps=72965.6, ups=1.23, wpb=59421.9, bsz=2213.7, num_updates=19700, lr=0.00071247, gnorm=0.386, loss_scale=2, train_wall=77, gb_free=39.6, wall=16523
2023-06-11 20:23:05 | INFO | train_inner | epoch 002:   8539 / 11284 loss=3.867, nll_loss=2.191, ppl=4.57, wps=71737.3, ups=1.21, wpb=59329.5, bsz=2210.4, num_updates=19800, lr=0.000710669, gnorm=0.331, loss_scale=2, train_wall=79, gb_free=39.6, wall=16606
2023-06-11 20:24:29 | INFO | train_inner | epoch 002:   8639 / 11284 loss=3.863, nll_loss=2.187, ppl=4.55, wps=71749.3, ups=1.2, wpb=59674.2, bsz=2229.9, num_updates=19900, lr=0.000708881, gnorm=0.327, loss_scale=2, train_wall=79, gb_free=39.6, wall=16689
2023-06-11 20:25:52 | INFO | train_inner | epoch 002:   8739 / 11284 loss=3.833, nll_loss=2.152, ppl=4.44, wps=71729, ups=1.21, wpb=59456.9, bsz=2155.7, num_updates=20000, lr=0.000707107, gnorm=0.334, loss_scale=2, train_wall=79, gb_free=39.5, wall=16772
2023-06-11 20:27:14 | INFO | train_inner | epoch 002:   8839 / 11284 loss=3.846, nll_loss=2.167, ppl=4.49, wps=71883.4, ups=1.21, wpb=59557.6, bsz=2169.2, num_updates=20100, lr=0.000705346, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.6, wall=16855
2023-06-11 20:28:37 | INFO | train_inner | epoch 002:   8939 / 11284 loss=3.851, nll_loss=2.174, ppl=4.51, wps=72315.1, ups=1.22, wpb=59392.5, bsz=2191.1, num_updates=20200, lr=0.000703598, gnorm=0.33, loss_scale=2, train_wall=78, gb_free=39.5, wall=16937
2023-06-11 20:29:58 | INFO | train_inner | epoch 002:   9039 / 11284 loss=3.824, nll_loss=2.143, ppl=4.42, wps=72849.1, ups=1.22, wpb=59667.8, bsz=2236.1, num_updates=20300, lr=0.000701862, gnorm=0.336, loss_scale=2, train_wall=78, gb_free=39.6, wall=17019
2023-06-11 20:31:21 | INFO | train_inner | epoch 002:   9139 / 11284 loss=3.868, nll_loss=2.192, ppl=4.57, wps=72298.9, ups=1.21, wpb=59570.8, bsz=2200.8, num_updates=20400, lr=0.00070014, gnorm=0.336, loss_scale=2, train_wall=78, gb_free=39.6, wall=17101
2023-06-11 20:32:44 | INFO | train_inner | epoch 002:   9239 / 11284 loss=3.839, nll_loss=2.159, ppl=4.47, wps=71933.5, ups=1.21, wpb=59616.5, bsz=2121.3, num_updates=20500, lr=0.00069843, gnorm=0.335, loss_scale=4, train_wall=79, gb_free=39.6, wall=17184
2023-06-11 20:34:06 | INFO | train_inner | epoch 002:   9339 / 11284 loss=3.845, nll_loss=2.167, ppl=4.49, wps=71634.3, ups=1.21, wpb=59300.5, bsz=2258.7, num_updates=20600, lr=0.000696733, gnorm=0.332, loss_scale=4, train_wall=79, gb_free=39.6, wall=17267
2023-06-11 20:35:30 | INFO | train_inner | epoch 002:   9439 / 11284 loss=3.854, nll_loss=2.176, ppl=4.52, wps=71311.7, ups=1.2, wpb=59458, bsz=2229.8, num_updates=20700, lr=0.000695048, gnorm=0.339, loss_scale=4, train_wall=79, gb_free=39.6, wall=17350
2023-06-11 20:36:53 | INFO | train_inner | epoch 002:   9539 / 11284 loss=3.83, nll_loss=2.15, ppl=4.44, wps=71721.5, ups=1.21, wpb=59414.1, bsz=2238.5, num_updates=20800, lr=0.000693375, gnorm=0.338, loss_scale=4, train_wall=79, gb_free=39.5, wall=17433
2023-06-11 20:38:16 | INFO | train_inner | epoch 002:   9639 / 11284 loss=3.841, nll_loss=2.162, ppl=4.47, wps=71295.7, ups=1.2, wpb=59392.2, bsz=2264.8, num_updates=20900, lr=0.000691714, gnorm=0.348, loss_scale=4, train_wall=79, gb_free=39.6, wall=17517
2023-06-11 20:39:39 | INFO | train_inner | epoch 002:   9739 / 11284 loss=3.826, nll_loss=2.145, ppl=4.42, wps=72326.4, ups=1.21, wpb=59672.8, bsz=2249.9, num_updates=21000, lr=0.000690066, gnorm=0.313, loss_scale=4, train_wall=79, gb_free=39.5, wall=17599
2023-06-11 20:41:02 | INFO | train_inner | epoch 002:   9839 / 11284 loss=3.823, nll_loss=2.142, ppl=4.41, wps=71584.8, ups=1.2, wpb=59516.9, bsz=2250, num_updates=21100, lr=0.000688428, gnorm=0.323, loss_scale=4, train_wall=79, gb_free=39.5, wall=17682
2023-06-11 20:42:25 | INFO | train_inner | epoch 002:   9939 / 11284 loss=3.841, nll_loss=2.163, ppl=4.48, wps=71450.7, ups=1.2, wpb=59576.8, bsz=2191.6, num_updates=21200, lr=0.000686803, gnorm=0.356, loss_scale=4, train_wall=80, gb_free=39.6, wall=17766
2023-06-11 20:43:49 | INFO | train_inner | epoch 002:  10039 / 11284 loss=3.854, nll_loss=2.178, ppl=4.52, wps=70396.7, ups=1.19, wpb=59034.6, bsz=2194, num_updates=21300, lr=0.000685189, gnorm=0.33, loss_scale=4, train_wall=80, gb_free=39.3, wall=17849
2023-06-11 20:45:14 | INFO | train_inner | epoch 002:  10139 / 11284 loss=3.829, nll_loss=2.149, ppl=4.44, wps=70163.3, ups=1.18, wpb=59712.5, bsz=2260.5, num_updates=21400, lr=0.000683586, gnorm=0.331, loss_scale=4, train_wall=81, gb_free=39.6, wall=17935
2023-06-11 20:46:39 | INFO | train_inner | epoch 002:  10239 / 11284 loss=3.82, nll_loss=2.139, ppl=4.4, wps=69573.2, ups=1.17, wpb=59337.3, bsz=2228.8, num_updates=21500, lr=0.000681994, gnorm=0.321, loss_scale=4, train_wall=81, gb_free=39.6, wall=18020
2023-06-11 20:47:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-06-11 20:48:08 | INFO | train_inner | epoch 002:  10340 / 11284 loss=3.813, nll_loss=2.131, ppl=4.38, wps=67429.4, ups=1.13, wpb=59507.4, bsz=2268.8, num_updates=21600, lr=0.000680414, gnorm=0.316, loss_scale=4, train_wall=84, gb_free=39.6, wall=18108
2023-06-11 20:49:34 | INFO | train_inner | epoch 002:  10440 / 11284 loss=3.841, nll_loss=2.163, ppl=4.48, wps=68796.2, ups=1.15, wpb=59609.1, bsz=2214.9, num_updates=21700, lr=0.000678844, gnorm=0.326, loss_scale=4, train_wall=83, gb_free=39.6, wall=18195
2023-06-11 20:51:01 | INFO | train_inner | epoch 002:  10540 / 11284 loss=3.823, nll_loss=2.142, ppl=4.41, wps=68224.3, ups=1.15, wpb=59554.8, bsz=2217.5, num_updates=21800, lr=0.000677285, gnorm=0.322, loss_scale=4, train_wall=83, gb_free=39.6, wall=18282
2023-06-11 20:52:29 | INFO | train_inner | epoch 002:  10640 / 11284 loss=3.83, nll_loss=2.15, ppl=4.44, wps=67918.3, ups=1.15, wpb=59216, bsz=2252.9, num_updates=21900, lr=0.000675737, gnorm=0.334, loss_scale=4, train_wall=83, gb_free=39.5, wall=18369
2023-06-11 20:53:56 | INFO | train_inner | epoch 002:  10740 / 11284 loss=3.837, nll_loss=2.158, ppl=4.46, wps=68268.8, ups=1.15, wpb=59490.6, bsz=2259.8, num_updates=22000, lr=0.0006742, gnorm=0.33, loss_scale=4, train_wall=83, gb_free=39.6, wall=18456
2023-06-11 20:55:23 | INFO | train_inner | epoch 002:  10840 / 11284 loss=3.817, nll_loss=2.136, ppl=4.4, wps=68514.4, ups=1.15, wpb=59487.7, bsz=2135.2, num_updates=22100, lr=0.000672673, gnorm=0.325, loss_scale=4, train_wall=83, gb_free=39.5, wall=18543
2023-06-11 20:56:50 | INFO | train_inner | epoch 002:  10940 / 11284 loss=3.833, nll_loss=2.154, ppl=4.45, wps=68375.4, ups=1.15, wpb=59542.9, bsz=2204, num_updates=22200, lr=0.000671156, gnorm=0.317, loss_scale=4, train_wall=83, gb_free=39.6, wall=18630
2023-06-11 20:58:16 | INFO | train_inner | epoch 002:  11040 / 11284 loss=3.834, nll_loss=2.156, ppl=4.46, wps=68886.2, ups=1.16, wpb=59298.6, bsz=2226.7, num_updates=22300, lr=0.00066965, gnorm=0.343, loss_scale=4, train_wall=82, gb_free=39.6, wall=18716
2023-06-11 20:59:41 | INFO | train_inner | epoch 002:  11140 / 11284 loss=3.813, nll_loss=2.132, ppl=4.38, wps=69635.9, ups=1.17, wpb=59609, bsz=2248.5, num_updates=22400, lr=0.000668153, gnorm=0.305, loss_scale=4, train_wall=82, gb_free=39.6, wall=18802
2023-06-11 21:01:06 | INFO | train_inner | epoch 002:  11240 / 11284 loss=3.809, nll_loss=2.127, ppl=4.37, wps=70004.9, ups=1.18, wpb=59464.6, bsz=2184.5, num_updates=22500, lr=0.000666667, gnorm=0.335, loss_scale=4, train_wall=81, gb_free=39.5, wall=18887
2023-06-11 21:01:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-11 21:02:02 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.591 | nll_loss 2.935 | ppl 7.65 | bleu 19.74 | wps 3647.1 | wpb 2397.5 | bsz 71.5 | num_updates 22544 | best_loss 4.591
2023-06-11 21:02:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 22544 updates
2023-06-11 21:02:02 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint2.pt
2023-06-11 21:02:03 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint2.pt
2023-06-11 21:02:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint2.pt (epoch 2 @ 22544 updates, score 4.591) (writing took 5.926612164825201 seconds)
2023-06-11 21:02:08 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-06-11 21:02:08 | INFO | train | epoch 002 | loss 3.911 | nll_loss 2.237 | ppl 4.72 | wps 71161.5 | ups 1.2 | wpb 59500.2 | bsz 2227.5 | num_updates 22544 | lr 0.000666016 | gnorm 0.366 | loss_scale 4 | train_wall 8953 | gb_free 39.6 | wall 18948
2023-06-11 21:02:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-11 21:02:08 | INFO | fairseq.trainer | begin training epoch 3
2023-06-11 21:02:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-11 21:02:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-06-11 21:02:56 | INFO | train_inner | epoch 003:     57 / 11284 loss=3.801, nll_loss=2.118, ppl=4.34, wps=53927.4, ups=0.91, wpb=59337.9, bsz=2251.1, num_updates=22600, lr=0.00066519, gnorm=0.33, loss_scale=4, train_wall=81, gb_free=39.6, wall=18997
2023-06-11 21:04:22 | INFO | train_inner | epoch 003:    157 / 11284 loss=3.785, nll_loss=2.1, ppl=4.29, wps=69336.5, ups=1.16, wpb=59548.7, bsz=2236.2, num_updates=22700, lr=0.000663723, gnorm=0.327, loss_scale=4, train_wall=82, gb_free=39.5, wall=19083
2023-06-11 21:05:45 | INFO | train_inner | epoch 003:    257 / 11284 loss=3.794, nll_loss=2.11, ppl=4.32, wps=72053.8, ups=1.21, wpb=59621.9, bsz=2172.1, num_updates=22800, lr=0.000662266, gnorm=0.32, loss_scale=4, train_wall=79, gb_free=39.6, wall=19166
2023-06-11 21:07:08 | INFO | train_inner | epoch 003:    357 / 11284 loss=3.81, nll_loss=2.127, ppl=4.37, wps=71647.8, ups=1.2, wpb=59490.5, bsz=2253.6, num_updates=22900, lr=0.000660819, gnorm=0.337, loss_scale=4, train_wall=79, gb_free=39.5, wall=19249
2023-06-11 21:08:30 | INFO | train_inner | epoch 003:    457 / 11284 loss=3.787, nll_loss=2.102, ppl=4.29, wps=72777.1, ups=1.22, wpb=59411, bsz=2196.6, num_updates=23000, lr=0.00065938, gnorm=0.341, loss_scale=4, train_wall=78, gb_free=39.6, wall=19330
2023-06-11 21:09:53 | INFO | train_inner | epoch 003:    557 / 11284 loss=3.807, nll_loss=2.124, ppl=4.36, wps=71560.8, ups=1.21, wpb=59374.4, bsz=2229.8, num_updates=23100, lr=0.000657952, gnorm=0.331, loss_scale=4, train_wall=79, gb_free=39.6, wall=19413
2023-06-11 21:11:14 | INFO | train_inner | epoch 003:    657 / 11284 loss=3.798, nll_loss=2.114, ppl=4.33, wps=72621.5, ups=1.22, wpb=59343, bsz=2298.4, num_updates=23200, lr=0.000656532, gnorm=0.321, loss_scale=4, train_wall=78, gb_free=39.6, wall=19495
2023-06-11 21:12:36 | INFO | train_inner | epoch 003:    757 / 11284 loss=3.797, nll_loss=2.113, ppl=4.33, wps=72895.9, ups=1.23, wpb=59433.6, bsz=2164.3, num_updates=23300, lr=0.000655122, gnorm=0.328, loss_scale=4, train_wall=78, gb_free=39, wall=19577
2023-06-11 21:13:58 | INFO | train_inner | epoch 003:    857 / 11284 loss=3.81, nll_loss=2.129, ppl=4.37, wps=72784.1, ups=1.22, wpb=59668.4, bsz=2261.8, num_updates=23400, lr=0.00065372, gnorm=0.319, loss_scale=4, train_wall=78, gb_free=39.6, wall=19658
2023-06-11 21:15:20 | INFO | train_inner | epoch 003:    957 / 11284 loss=3.799, nll_loss=2.115, ppl=4.33, wps=72069.1, ups=1.21, wpb=59329.2, bsz=2206.6, num_updates=23500, lr=0.000652328, gnorm=0.31, loss_scale=4, train_wall=78, gb_free=39.6, wall=19741
2023-06-11 21:16:43 | INFO | train_inner | epoch 003:   1057 / 11284 loss=3.782, nll_loss=2.097, ppl=4.28, wps=72455.2, ups=1.21, wpb=59913.2, bsz=2213, num_updates=23600, lr=0.000650945, gnorm=0.315, loss_scale=4, train_wall=78, gb_free=39.6, wall=19823
2023-06-11 21:16:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-06-11 21:18:07 | INFO | train_inner | epoch 003:   1158 / 11284 loss=3.784, nll_loss=2.099, ppl=4.28, wps=70970.9, ups=1.19, wpb=59503.6, bsz=2242.4, num_updates=23700, lr=0.00064957, gnorm=0.325, loss_scale=4, train_wall=80, gb_free=39.5, wall=19907
2023-06-11 21:19:29 | INFO | train_inner | epoch 003:   1258 / 11284 loss=3.794, nll_loss=2.111, ppl=4.32, wps=71944.6, ups=1.21, wpb=59380, bsz=2181.7, num_updates=23800, lr=0.000648204, gnorm=0.323, loss_scale=4, train_wall=79, gb_free=39.6, wall=19990
2023-06-11 21:20:53 | INFO | train_inner | epoch 003:   1358 / 11284 loss=3.801, nll_loss=2.118, ppl=4.34, wps=71481.7, ups=1.2, wpb=59610.6, bsz=2241, num_updates=23900, lr=0.000646846, gnorm=0.309, loss_scale=4, train_wall=79, gb_free=39.6, wall=20073
2023-06-11 21:22:15 | INFO | train_inner | epoch 003:   1458 / 11284 loss=3.806, nll_loss=2.124, ppl=4.36, wps=71630, ups=1.21, wpb=59253.2, bsz=2286.1, num_updates=24000, lr=0.000645497, gnorm=0.32, loss_scale=4, train_wall=79, gb_free=39.6, wall=20156
2023-06-11 21:23:37 | INFO | train_inner | epoch 003:   1558 / 11284 loss=3.785, nll_loss=2.1, ppl=4.29, wps=72655, ups=1.22, wpb=59512.1, bsz=2265.6, num_updates=24100, lr=0.000644157, gnorm=0.321, loss_scale=4, train_wall=78, gb_free=39.6, wall=20238
2023-06-11 21:24:59 | INFO | train_inner | epoch 003:   1658 / 11284 loss=3.783, nll_loss=2.097, ppl=4.28, wps=72643.7, ups=1.22, wpb=59607.3, bsz=2227, num_updates=24200, lr=0.000642824, gnorm=0.311, loss_scale=4, train_wall=78, gb_free=39.6, wall=20320
2023-06-11 21:26:22 | INFO | train_inner | epoch 003:   1758 / 11284 loss=3.789, nll_loss=2.104, ppl=4.3, wps=72233.9, ups=1.21, wpb=59493, bsz=2288.2, num_updates=24300, lr=0.0006415, gnorm=0.315, loss_scale=4, train_wall=78, gb_free=39.6, wall=20402
2023-06-11 21:27:44 | INFO | train_inner | epoch 003:   1858 / 11284 loss=3.771, nll_loss=2.085, ppl=4.24, wps=71779.5, ups=1.21, wpb=59386.6, bsz=2201.5, num_updates=24400, lr=0.000640184, gnorm=0.316, loss_scale=4, train_wall=78, gb_free=39.6, wall=20485
2023-06-11 21:28:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-11 21:29:09 | INFO | train_inner | epoch 003:   1959 / 11284 loss=3.792, nll_loss=2.108, ppl=4.31, wps=70018.9, ups=1.18, wpb=59502.8, bsz=2265.3, num_updates=24500, lr=0.000638877, gnorm=0.318, loss_scale=2, train_wall=81, gb_free=39.6, wall=20570
2023-06-11 21:30:32 | INFO | train_inner | epoch 003:   2059 / 11284 loss=3.789, nll_loss=2.105, ppl=4.3, wps=72167.9, ups=1.22, wpb=59275.3, bsz=2224.7, num_updates=24600, lr=0.000637577, gnorm=0.313, loss_scale=2, train_wall=78, gb_free=39.6, wall=20652
2023-06-11 21:31:54 | INFO | train_inner | epoch 003:   2159 / 11284 loss=3.786, nll_loss=2.102, ppl=4.29, wps=72521.3, ups=1.22, wpb=59623.7, bsz=2269.6, num_updates=24700, lr=0.000636285, gnorm=0.318, loss_scale=2, train_wall=78, gb_free=39.6, wall=20734
2023-06-11 21:33:17 | INFO | train_inner | epoch 003:   2259 / 11284 loss=3.789, nll_loss=2.105, ppl=4.3, wps=71067.2, ups=1.2, wpb=59291.7, bsz=2268.1, num_updates=24800, lr=0.000635001, gnorm=0.319, loss_scale=2, train_wall=79, gb_free=39.6, wall=20818
2023-06-11 21:34:40 | INFO | train_inner | epoch 003:   2359 / 11284 loss=3.755, nll_loss=2.067, ppl=4.19, wps=72412.7, ups=1.22, wpb=59589.5, bsz=2172.5, num_updates=24900, lr=0.000633724, gnorm=0.321, loss_scale=2, train_wall=79, gb_free=39.5, wall=20900
2023-06-11 21:36:02 | INFO | train_inner | epoch 003:   2459 / 11284 loss=3.78, nll_loss=2.095, ppl=4.27, wps=71649.1, ups=1.21, wpb=59199.4, bsz=2124, num_updates=25000, lr=0.000632456, gnorm=0.309, loss_scale=2, train_wall=79, gb_free=39.6, wall=20983
2023-06-11 21:37:26 | INFO | train_inner | epoch 003:   2559 / 11284 loss=3.789, nll_loss=2.106, ppl=4.3, wps=71023.6, ups=1.2, wpb=59385.8, bsz=2335.5, num_updates=25100, lr=0.000631194, gnorm=0.321, loss_scale=2, train_wall=79, gb_free=39.5, wall=21066
2023-06-11 21:38:49 | INFO | train_inner | epoch 003:   2659 / 11284 loss=3.788, nll_loss=2.104, ppl=4.3, wps=71905.4, ups=1.21, wpb=59510.5, bsz=2172.4, num_updates=25200, lr=0.000629941, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.6, wall=21149
2023-06-11 21:40:12 | INFO | train_inner | epoch 003:   2759 / 11284 loss=3.788, nll_loss=2.104, ppl=4.3, wps=71895, ups=1.2, wpb=59668.7, bsz=2246.5, num_updates=25300, lr=0.000628695, gnorm=0.323, loss_scale=2, train_wall=79, gb_free=39.6, wall=21232
2023-06-11 21:41:34 | INFO | train_inner | epoch 003:   2859 / 11284 loss=3.769, nll_loss=2.083, ppl=4.24, wps=71574.4, ups=1.21, wpb=59328.3, bsz=2248.8, num_updates=25400, lr=0.000627456, gnorm=0.314, loss_scale=2, train_wall=79, gb_free=39.6, wall=21315
2023-06-11 21:42:58 | INFO | train_inner | epoch 003:   2959 / 11284 loss=3.785, nll_loss=2.101, ppl=4.29, wps=71156.3, ups=1.2, wpb=59432.4, bsz=2292.9, num_updates=25500, lr=0.000626224, gnorm=0.329, loss_scale=4, train_wall=79, gb_free=39.6, wall=21399
2023-06-11 21:44:21 | INFO | train_inner | epoch 003:   3059 / 11284 loss=3.793, nll_loss=2.11, ppl=4.32, wps=71600.3, ups=1.2, wpb=59640.6, bsz=2379.4, num_updates=25600, lr=0.000625, gnorm=0.323, loss_scale=4, train_wall=79, gb_free=39.6, wall=21482
2023-06-11 21:45:44 | INFO | train_inner | epoch 003:   3159 / 11284 loss=3.795, nll_loss=2.112, ppl=4.32, wps=71718.3, ups=1.21, wpb=59476.8, bsz=2282.4, num_updates=25700, lr=0.000623783, gnorm=0.328, loss_scale=4, train_wall=79, gb_free=39.6, wall=21565
2023-06-11 21:47:07 | INFO | train_inner | epoch 003:   3259 / 11284 loss=3.772, nll_loss=2.086, ppl=4.25, wps=72199.2, ups=1.21, wpb=59665.3, bsz=2089.7, num_updates=25800, lr=0.000622573, gnorm=0.314, loss_scale=4, train_wall=79, gb_free=39.5, wall=21647
2023-06-11 21:48:30 | INFO | train_inner | epoch 003:   3359 / 11284 loss=3.774, nll_loss=2.089, ppl=4.25, wps=71785.6, ups=1.2, wpb=59645.3, bsz=2161.1, num_updates=25900, lr=0.00062137, gnorm=0.312, loss_scale=4, train_wall=79, gb_free=39.6, wall=21731
2023-06-11 21:49:53 | INFO | train_inner | epoch 003:   3459 / 11284 loss=3.782, nll_loss=2.097, ppl=4.28, wps=71618.9, ups=1.2, wpb=59458.5, bsz=2192, num_updates=26000, lr=0.000620174, gnorm=0.311, loss_scale=4, train_wall=79, gb_free=39.5, wall=21814
2023-06-11 21:51:16 | INFO | train_inner | epoch 003:   3559 / 11284 loss=3.783, nll_loss=2.099, ppl=4.29, wps=71697.1, ups=1.2, wpb=59642.2, bsz=2164.5, num_updates=26100, lr=0.000618984, gnorm=0.316, loss_scale=4, train_wall=79, gb_free=39.6, wall=21897
2023-06-11 21:52:39 | INFO | train_inner | epoch 003:   3659 / 11284 loss=3.786, nll_loss=2.102, ppl=4.29, wps=72150.9, ups=1.21, wpb=59496.2, bsz=2265.9, num_updates=26200, lr=0.000617802, gnorm=0.314, loss_scale=4, train_wall=78, gb_free=39.6, wall=21979
2023-06-11 21:54:01 | INFO | train_inner | epoch 003:   3759 / 11284 loss=3.765, nll_loss=2.079, ppl=4.22, wps=72820.5, ups=1.22, wpb=59644, bsz=2130.2, num_updates=26300, lr=0.000616626, gnorm=0.31, loss_scale=4, train_wall=78, gb_free=39.6, wall=22061
2023-06-11 21:55:24 | INFO | train_inner | epoch 003:   3859 / 11284 loss=3.771, nll_loss=2.086, ppl=4.25, wps=71856.6, ups=1.2, wpb=59756.2, bsz=2258, num_updates=26400, lr=0.000615457, gnorm=0.314, loss_scale=4, train_wall=79, gb_free=39.5, wall=22144
2023-06-11 21:56:47 | INFO | train_inner | epoch 003:   3959 / 11284 loss=3.786, nll_loss=2.102, ppl=4.29, wps=71452.9, ups=1.2, wpb=59391, bsz=2227.6, num_updates=26500, lr=0.000614295, gnorm=0.308, loss_scale=8, train_wall=79, gb_free=39.6, wall=22227
2023-06-11 21:56:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-06-11 21:58:09 | INFO | train_inner | epoch 003:   4060 / 11284 loss=3.776, nll_loss=2.091, ppl=4.26, wps=72226.9, ups=1.21, wpb=59523.9, bsz=2303.8, num_updates=26600, lr=0.000613139, gnorm=0.332, loss_scale=4, train_wall=78, gb_free=39.5, wall=22310
2023-06-11 21:59:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-11 21:59:32 | INFO | train_inner | epoch 003:   4161 / 11284 loss=3.779, nll_loss=2.095, ppl=4.27, wps=72174.5, ups=1.21, wpb=59558.4, bsz=2268.2, num_updates=26700, lr=0.00061199, gnorm=0.339, loss_scale=2, train_wall=78, gb_free=39.5, wall=22392
2023-06-11 22:00:54 | INFO | train_inner | epoch 003:   4261 / 11284 loss=3.775, nll_loss=2.091, ppl=4.26, wps=72541.8, ups=1.22, wpb=59466.4, bsz=2192.9, num_updates=26800, lr=0.000610847, gnorm=0.307, loss_scale=2, train_wall=78, gb_free=39.6, wall=22474
2023-06-11 22:02:16 | INFO | train_inner | epoch 003:   4361 / 11284 loss=3.777, nll_loss=2.092, ppl=4.26, wps=72914.9, ups=1.22, wpb=59762.5, bsz=2230.1, num_updates=26900, lr=0.000609711, gnorm=0.331, loss_scale=2, train_wall=78, gb_free=39.6, wall=22556
2023-06-11 22:03:39 | INFO | train_inner | epoch 003:   4461 / 11284 loss=3.782, nll_loss=2.098, ppl=4.28, wps=71731, ups=1.21, wpb=59453.1, bsz=2253.8, num_updates=27000, lr=0.000608581, gnorm=0.317, loss_scale=2, train_wall=79, gb_free=39.6, wall=22639
2023-06-11 22:05:02 | INFO | train_inner | epoch 003:   4561 / 11284 loss=3.758, nll_loss=2.071, ppl=4.2, wps=71299.1, ups=1.2, wpb=59434, bsz=2258.2, num_updates=27100, lr=0.000607457, gnorm=0.308, loss_scale=2, train_wall=79, gb_free=39.5, wall=22722
2023-06-11 22:06:25 | INFO | train_inner | epoch 003:   4661 / 11284 loss=3.774, nll_loss=2.089, ppl=4.26, wps=71545.4, ups=1.2, wpb=59748.1, bsz=2279.4, num_updates=27200, lr=0.000606339, gnorm=0.323, loss_scale=2, train_wall=79, gb_free=39.6, wall=22806
2023-06-11 22:07:48 | INFO | train_inner | epoch 003:   4761 / 11284 loss=3.78, nll_loss=2.097, ppl=4.28, wps=71359.5, ups=1.2, wpb=59230.2, bsz=2173.6, num_updates=27300, lr=0.000605228, gnorm=0.291, loss_scale=2, train_wall=79, gb_free=39.6, wall=22889
2023-06-11 22:09:12 | INFO | train_inner | epoch 003:   4861 / 11284 loss=3.762, nll_loss=2.076, ppl=4.22, wps=71468.5, ups=1.2, wpb=59467.5, bsz=2201.3, num_updates=27400, lr=0.000604122, gnorm=0.327, loss_scale=2, train_wall=79, gb_free=39.6, wall=22972
2023-06-11 22:10:35 | INFO | train_inner | epoch 003:   4961 / 11284 loss=3.791, nll_loss=2.108, ppl=4.31, wps=71419.5, ups=1.2, wpb=59295.4, bsz=2231.8, num_updates=27500, lr=0.000603023, gnorm=0.309, loss_scale=2, train_wall=79, gb_free=39.4, wall=23055
2023-06-11 22:11:59 | INFO | train_inner | epoch 003:   5061 / 11284 loss=3.764, nll_loss=2.078, ppl=4.22, wps=70409.7, ups=1.18, wpb=59581.5, bsz=2156.4, num_updates=27600, lr=0.000601929, gnorm=0.323, loss_scale=2, train_wall=81, gb_free=39.5, wall=23140
2023-06-11 22:13:22 | INFO | train_inner | epoch 003:   5161 / 11284 loss=3.765, nll_loss=2.079, ppl=4.23, wps=72228, ups=1.22, wpb=59393, bsz=2304, num_updates=27700, lr=0.000600842, gnorm=0.307, loss_scale=2, train_wall=78, gb_free=39.5, wall=23222
2023-06-11 22:14:44 | INFO | train_inner | epoch 003:   5261 / 11284 loss=3.782, nll_loss=2.099, ppl=4.28, wps=72427.4, ups=1.22, wpb=59439.5, bsz=2245.2, num_updates=27800, lr=0.00059976, gnorm=0.319, loss_scale=4, train_wall=78, gb_free=39.5, wall=23304
2023-06-11 22:16:06 | INFO | train_inner | epoch 003:   5361 / 11284 loss=3.757, nll_loss=2.07, ppl=4.2, wps=72465.6, ups=1.22, wpb=59472.5, bsz=2149.3, num_updates=27900, lr=0.000598684, gnorm=0.331, loss_scale=4, train_wall=78, gb_free=39.6, wall=23386
2023-06-11 22:17:27 | INFO | train_inner | epoch 003:   5461 / 11284 loss=3.776, nll_loss=2.092, ppl=4.26, wps=72830.4, ups=1.22, wpb=59532.5, bsz=2244.9, num_updates=28000, lr=0.000597614, gnorm=0.318, loss_scale=4, train_wall=78, gb_free=38.7, wall=23468
2023-06-11 22:18:50 | INFO | train_inner | epoch 003:   5561 / 11284 loss=3.771, nll_loss=2.086, ppl=4.25, wps=72358.5, ups=1.22, wpb=59439.1, bsz=2232.5, num_updates=28100, lr=0.00059655, gnorm=0.312, loss_scale=4, train_wall=78, gb_free=39.6, wall=23550
2023-06-11 22:20:13 | INFO | train_inner | epoch 003:   5661 / 11284 loss=3.782, nll_loss=2.099, ppl=4.28, wps=71587.6, ups=1.2, wpb=59534.4, bsz=2265.9, num_updates=28200, lr=0.000595491, gnorm=0.316, loss_scale=4, train_wall=79, gb_free=39.6, wall=23633
2023-06-11 22:21:36 | INFO | train_inner | epoch 003:   5761 / 11284 loss=3.761, nll_loss=2.075, ppl=4.21, wps=71734.5, ups=1.2, wpb=59620.7, bsz=2231, num_updates=28300, lr=0.000594438, gnorm=0.306, loss_scale=4, train_wall=79, gb_free=39.5, wall=23716
2023-06-11 22:22:59 | INFO | train_inner | epoch 003:   5861 / 11284 loss=3.759, nll_loss=2.073, ppl=4.21, wps=71955.3, ups=1.2, wpb=59798.9, bsz=2297, num_updates=28400, lr=0.000593391, gnorm=0.304, loss_scale=4, train_wall=79, gb_free=39.6, wall=23800
2023-06-11 22:24:22 | INFO | train_inner | epoch 003:   5961 / 11284 loss=3.762, nll_loss=2.076, ppl=4.22, wps=71664.5, ups=1.2, wpb=59611.1, bsz=2293.6, num_updates=28500, lr=0.000592349, gnorm=0.308, loss_scale=4, train_wall=79, gb_free=39.5, wall=23883
2023-06-11 22:25:45 | INFO | train_inner | epoch 003:   6061 / 11284 loss=3.744, nll_loss=2.056, ppl=4.16, wps=71610.3, ups=1.21, wpb=59315.3, bsz=2125.9, num_updates=28600, lr=0.000591312, gnorm=0.306, loss_scale=4, train_wall=79, gb_free=39.5, wall=23966
2023-06-11 22:27:08 | INFO | train_inner | epoch 003:   6161 / 11284 loss=3.769, nll_loss=2.084, ppl=4.24, wps=71587.3, ups=1.21, wpb=59395, bsz=2241.6, num_updates=28700, lr=0.000590281, gnorm=0.309, loss_scale=4, train_wall=79, gb_free=39.6, wall=24048
2023-06-11 22:27:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-06-11 22:28:32 | INFO | train_inner | epoch 003:   6262 / 11284 loss=3.741, nll_loss=2.053, ppl=4.15, wps=71266.6, ups=1.2, wpb=59636.1, bsz=2243.8, num_updates=28800, lr=0.000589256, gnorm=0.303, loss_scale=4, train_wall=80, gb_free=39.6, wall=24132
2023-06-11 22:29:53 | INFO | train_inner | epoch 003:   6362 / 11284 loss=3.758, nll_loss=2.071, ppl=4.2, wps=73086.5, ups=1.23, wpb=59538.2, bsz=2228.3, num_updates=28900, lr=0.000588235, gnorm=0.301, loss_scale=4, train_wall=78, gb_free=39.6, wall=24214
2023-06-11 22:31:16 | INFO | train_inner | epoch 003:   6462 / 11284 loss=3.759, nll_loss=2.073, ppl=4.21, wps=71589.2, ups=1.2, wpb=59418.4, bsz=2347.4, num_updates=29000, lr=0.00058722, gnorm=0.329, loss_scale=4, train_wall=79, gb_free=39.6, wall=24297
2023-06-11 22:32:39 | INFO | train_inner | epoch 003:   6562 / 11284 loss=3.751, nll_loss=2.064, ppl=4.18, wps=71443.4, ups=1.2, wpb=59369, bsz=2233.3, num_updates=29100, lr=0.00058621, gnorm=0.308, loss_scale=4, train_wall=79, gb_free=39.6, wall=24380
2023-06-11 22:33:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-11 22:34:03 | INFO | train_inner | epoch 003:   6663 / 11284 loss=3.759, nll_loss=2.073, ppl=4.21, wps=71340.9, ups=1.19, wpb=59704.6, bsz=2279.4, num_updates=29200, lr=0.000585206, gnorm=0.297, loss_scale=2, train_wall=80, gb_free=39.6, wall=24463
2023-06-11 22:35:26 | INFO | train_inner | epoch 003:   6763 / 11284 loss=3.756, nll_loss=2.07, ppl=4.2, wps=71585, ups=1.2, wpb=59667.2, bsz=2191.2, num_updates=29300, lr=0.000584206, gnorm=0.31, loss_scale=2, train_wall=79, gb_free=39.6, wall=24547
2023-06-11 22:36:50 | INFO | train_inner | epoch 003:   6863 / 11284 loss=3.74, nll_loss=2.052, ppl=4.15, wps=71400.8, ups=1.2, wpb=59578.1, bsz=2233.4, num_updates=29400, lr=0.000583212, gnorm=0.309, loss_scale=2, train_wall=79, gb_free=39.6, wall=24630
2023-06-11 22:38:13 | INFO | train_inner | epoch 003:   6963 / 11284 loss=3.749, nll_loss=2.062, ppl=4.18, wps=71439.8, ups=1.2, wpb=59572.3, bsz=2361.4, num_updates=29500, lr=0.000582223, gnorm=0.318, loss_scale=2, train_wall=79, gb_free=39.6, wall=24714
2023-06-11 22:39:36 | INFO | train_inner | epoch 003:   7063 / 11284 loss=3.754, nll_loss=2.068, ppl=4.19, wps=71614.8, ups=1.2, wpb=59469.4, bsz=2274.3, num_updates=29600, lr=0.000581238, gnorm=0.32, loss_scale=2, train_wall=79, gb_free=39.5, wall=24797
2023-06-11 22:40:59 | INFO | train_inner | epoch 003:   7163 / 11284 loss=3.747, nll_loss=2.059, ppl=4.17, wps=71641.9, ups=1.2, wpb=59649.5, bsz=2141.8, num_updates=29700, lr=0.000580259, gnorm=0.317, loss_scale=2, train_wall=79, gb_free=39.6, wall=24880
2023-06-11 22:42:23 | INFO | train_inner | epoch 003:   7263 / 11284 loss=3.755, nll_loss=2.069, ppl=4.2, wps=71327.1, ups=1.2, wpb=59511.9, bsz=2293.8, num_updates=29800, lr=0.000579284, gnorm=0.3, loss_scale=2, train_wall=79, gb_free=39.6, wall=24963
2023-06-11 22:43:46 | INFO | train_inner | epoch 003:   7363 / 11284 loss=3.753, nll_loss=2.067, ppl=4.19, wps=71842, ups=1.2, wpb=59780.3, bsz=2208.2, num_updates=29900, lr=0.000578315, gnorm=0.3, loss_scale=2, train_wall=79, gb_free=39.6, wall=25047
2023-06-11 22:45:08 | INFO | train_inner | epoch 003:   7463 / 11284 loss=3.75, nll_loss=2.063, ppl=4.18, wps=72139.7, ups=1.22, wpb=59265.8, bsz=2188.7, num_updates=30000, lr=0.00057735, gnorm=0.298, loss_scale=2, train_wall=78, gb_free=39.6, wall=25129
2023-06-11 22:46:31 | INFO | train_inner | epoch 003:   7563 / 11284 loss=3.767, nll_loss=2.082, ppl=4.23, wps=71573.7, ups=1.2, wpb=59461.4, bsz=2294.8, num_updates=30100, lr=0.00057639, gnorm=0.31, loss_scale=2, train_wall=79, gb_free=39.6, wall=25212
2023-06-11 22:47:54 | INFO | train_inner | epoch 003:   7663 / 11284 loss=3.735, nll_loss=2.046, ppl=4.13, wps=71833.5, ups=1.21, wpb=59525.8, bsz=2116.4, num_updates=30200, lr=0.000575435, gnorm=0.302, loss_scale=2, train_wall=79, gb_free=39.6, wall=25295
2023-06-11 22:49:17 | INFO | train_inner | epoch 003:   7763 / 11284 loss=3.75, nll_loss=2.063, ppl=4.18, wps=71743.6, ups=1.2, wpb=59556.8, bsz=2193.2, num_updates=30300, lr=0.000574485, gnorm=0.309, loss_scale=4, train_wall=79, gb_free=39.6, wall=25378
2023-06-11 22:50:40 | INFO | train_inner | epoch 003:   7863 / 11284 loss=3.748, nll_loss=2.061, ppl=4.17, wps=71570.8, ups=1.2, wpb=59494.4, bsz=2242, num_updates=30400, lr=0.000573539, gnorm=0.311, loss_scale=4, train_wall=79, gb_free=38.9, wall=25461
2023-06-11 22:51:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-11 22:52:04 | INFO | train_inner | epoch 003:   7964 / 11284 loss=3.753, nll_loss=2.067, ppl=4.19, wps=71138.7, ups=1.19, wpb=59796.2, bsz=2258, num_updates=30500, lr=0.000572598, gnorm=0.31, loss_scale=2, train_wall=80, gb_free=39.6, wall=25545
2023-06-11 22:53:26 | INFO | train_inner | epoch 003:   8064 / 11284 loss=3.738, nll_loss=2.05, ppl=4.14, wps=72933.8, ups=1.22, wpb=59654, bsz=2193.8, num_updates=30600, lr=0.000571662, gnorm=0.295, loss_scale=2, train_wall=78, gb_free=39.5, wall=25627
2023-06-11 22:54:49 | INFO | train_inner | epoch 003:   8164 / 11284 loss=3.749, nll_loss=2.062, ppl=4.18, wps=71607.4, ups=1.2, wpb=59521.7, bsz=2264.7, num_updates=30700, lr=0.00057073, gnorm=0.305, loss_scale=2, train_wall=79, gb_free=39.7, wall=25710
2023-06-11 22:56:12 | INFO | train_inner | epoch 003:   8264 / 11284 loss=3.734, nll_loss=2.045, ppl=4.13, wps=71426.4, ups=1.2, wpb=59441.6, bsz=2165.4, num_updates=30800, lr=0.000569803, gnorm=0.306, loss_scale=2, train_wall=79, gb_free=39.5, wall=25793
2023-06-11 22:57:35 | INFO | train_inner | epoch 003:   8364 / 11284 loss=3.732, nll_loss=2.044, ppl=4.12, wps=71918.4, ups=1.21, wpb=59397.5, bsz=2175.3, num_updates=30900, lr=0.00056888, gnorm=0.3, loss_scale=2, train_wall=79, gb_free=39.6, wall=25876
2023-06-11 22:58:58 | INFO | train_inner | epoch 003:   8464 / 11284 loss=3.739, nll_loss=2.052, ppl=4.15, wps=71611.5, ups=1.2, wpb=59574.7, bsz=2218.8, num_updates=31000, lr=0.000567962, gnorm=0.312, loss_scale=2, train_wall=79, gb_free=39.3, wall=25959
2023-06-11 23:00:21 | INFO | train_inner | epoch 003:   8564 / 11284 loss=3.737, nll_loss=2.049, ppl=4.14, wps=71503.9, ups=1.21, wpb=59292.3, bsz=2161.4, num_updates=31100, lr=0.000567048, gnorm=0.318, loss_scale=2, train_wall=79, gb_free=39.6, wall=26042
2023-06-11 23:01:44 | INFO | train_inner | epoch 003:   8664 / 11284 loss=3.764, nll_loss=2.079, ppl=4.23, wps=71794.2, ups=1.21, wpb=59386.8, bsz=2261.2, num_updates=31200, lr=0.000566139, gnorm=0.297, loss_scale=2, train_wall=78, gb_free=39.5, wall=26124
2023-06-11 23:03:06 | INFO | train_inner | epoch 003:   8764 / 11284 loss=3.747, nll_loss=2.06, ppl=4.17, wps=72504.1, ups=1.22, wpb=59355.2, bsz=2078.2, num_updates=31300, lr=0.000565233, gnorm=0.308, loss_scale=2, train_wall=78, gb_free=39.6, wall=26206
2023-06-11 23:04:27 | INFO | train_inner | epoch 003:   8864 / 11284 loss=3.735, nll_loss=2.046, ppl=4.13, wps=73127.3, ups=1.23, wpb=59659.6, bsz=2216, num_updates=31400, lr=0.000564333, gnorm=0.301, loss_scale=2, train_wall=78, gb_free=39.6, wall=26288
2023-06-11 23:05:49 | INFO | train_inner | epoch 003:   8964 / 11284 loss=3.753, nll_loss=2.067, ppl=4.19, wps=72581.4, ups=1.22, wpb=59560.7, bsz=2252.4, num_updates=31500, lr=0.000563436, gnorm=0.301, loss_scale=4, train_wall=78, gb_free=39.6, wall=26370
2023-06-11 23:07:12 | INFO | train_inner | epoch 003:   9064 / 11284 loss=3.735, nll_loss=2.047, ppl=4.13, wps=72174.9, ups=1.21, wpb=59701.8, bsz=2215.5, num_updates=31600, lr=0.000562544, gnorm=0.303, loss_scale=4, train_wall=79, gb_free=39.6, wall=26453
2023-06-11 23:08:35 | INFO | train_inner | epoch 003:   9164 / 11284 loss=3.731, nll_loss=2.042, ppl=4.12, wps=71838.5, ups=1.2, wpb=59642.6, bsz=2221, num_updates=31700, lr=0.000561656, gnorm=0.296, loss_scale=4, train_wall=79, gb_free=39.6, wall=26536
2023-06-11 23:09:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-11 23:09:59 | INFO | train_inner | epoch 003:   9265 / 11284 loss=3.744, nll_loss=2.057, ppl=4.16, wps=71140.1, ups=1.2, wpb=59392.2, bsz=2119.3, num_updates=31800, lr=0.000560772, gnorm=0.316, loss_scale=2, train_wall=80, gb_free=39.6, wall=26619
2023-06-11 23:11:22 | INFO | train_inner | epoch 003:   9365 / 11284 loss=3.719, nll_loss=2.029, ppl=4.08, wps=71427.6, ups=1.2, wpb=59354.8, bsz=2178.2, num_updates=31900, lr=0.000559893, gnorm=0.307, loss_scale=2, train_wall=79, gb_free=39.5, wall=26702
2023-06-11 23:12:44 | INFO | train_inner | epoch 003:   9465 / 11284 loss=3.738, nll_loss=2.051, ppl=4.14, wps=71780.7, ups=1.21, wpb=59304.3, bsz=2230.5, num_updates=32000, lr=0.000559017, gnorm=0.313, loss_scale=2, train_wall=79, gb_free=39.5, wall=26785
2023-06-11 23:14:07 | INFO | train_inner | epoch 003:   9565 / 11284 loss=3.744, nll_loss=2.057, ppl=4.16, wps=72011.9, ups=1.21, wpb=59463, bsz=2205.7, num_updates=32100, lr=0.000558146, gnorm=0.314, loss_scale=2, train_wall=79, gb_free=39.5, wall=26867
2023-06-11 23:15:29 | INFO | train_inner | epoch 003:   9665 / 11284 loss=3.713, nll_loss=2.022, ppl=4.06, wps=72454.4, ups=1.21, wpb=59674.2, bsz=2252.5, num_updates=32200, lr=0.000557278, gnorm=0.297, loss_scale=2, train_wall=78, gb_free=39.6, wall=26950
2023-06-11 23:16:52 | INFO | train_inner | epoch 003:   9765 / 11284 loss=3.736, nll_loss=2.048, ppl=4.14, wps=71723.5, ups=1.2, wpb=59608.5, bsz=2277.5, num_updates=32300, lr=0.000556415, gnorm=0.33, loss_scale=2, train_wall=79, gb_free=39.5, wall=27033
2023-06-11 23:18:15 | INFO | train_inner | epoch 003:   9865 / 11284 loss=3.751, nll_loss=2.065, ppl=4.19, wps=71752.9, ups=1.21, wpb=59470.4, bsz=2228.5, num_updates=32400, lr=0.000555556, gnorm=0.316, loss_scale=2, train_wall=79, gb_free=39.6, wall=27116
2023-06-11 23:19:38 | INFO | train_inner | epoch 003:   9965 / 11284 loss=3.723, nll_loss=2.033, ppl=4.09, wps=71663.7, ups=1.2, wpb=59548.1, bsz=2276.7, num_updates=32500, lr=0.0005547, gnorm=0.306, loss_scale=2, train_wall=79, gb_free=39.6, wall=27199
2023-06-11 23:21:01 | INFO | train_inner | epoch 003:  10065 / 11284 loss=3.73, nll_loss=2.042, ppl=4.12, wps=71737, ups=1.21, wpb=59440.6, bsz=2158.8, num_updates=32600, lr=0.000553849, gnorm=0.296, loss_scale=2, train_wall=79, gb_free=39.2, wall=27282
2023-06-11 23:22:24 | INFO | train_inner | epoch 003:  10165 / 11284 loss=3.726, nll_loss=2.036, ppl=4.1, wps=71789.3, ups=1.2, wpb=59596.4, bsz=2120.4, num_updates=32700, lr=0.000553001, gnorm=0.333, loss_scale=2, train_wall=79, gb_free=39.6, wall=27365
2023-06-11 23:23:47 | INFO | train_inner | epoch 003:  10265 / 11284 loss=3.73, nll_loss=2.042, ppl=4.12, wps=71699.9, ups=1.21, wpb=59352.6, bsz=2257.1, num_updates=32800, lr=0.000552158, gnorm=0.304, loss_scale=2, train_wall=79, gb_free=39.6, wall=27448
2023-06-11 23:25:10 | INFO | train_inner | epoch 003:  10365 / 11284 loss=3.713, nll_loss=2.022, ppl=4.06, wps=71884.4, ups=1.21, wpb=59477.7, bsz=2152.8, num_updates=32900, lr=0.000551318, gnorm=0.302, loss_scale=4, train_wall=79, gb_free=39.5, wall=27530
2023-06-11 23:26:33 | INFO | train_inner | epoch 003:  10465 / 11284 loss=3.728, nll_loss=2.039, ppl=4.11, wps=71526.9, ups=1.2, wpb=59363.9, bsz=2223.9, num_updates=33000, lr=0.000550482, gnorm=0.308, loss_scale=4, train_wall=79, gb_free=39.5, wall=27613
2023-06-11 23:27:56 | INFO | train_inner | epoch 003:  10565 / 11284 loss=3.737, nll_loss=2.05, ppl=4.14, wps=71411.6, ups=1.2, wpb=59480.9, bsz=2258.7, num_updates=33100, lr=0.00054965, gnorm=0.296, loss_scale=4, train_wall=79, gb_free=39.6, wall=27697
2023-06-11 23:28:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-11 23:29:19 | INFO | train_inner | epoch 003:  10666 / 11284 loss=3.744, nll_loss=2.057, ppl=4.16, wps=71479.6, ups=1.2, wpb=59474.6, bsz=2287.7, num_updates=33200, lr=0.000548821, gnorm=0.319, loss_scale=2, train_wall=79, gb_free=39.5, wall=27780
2023-06-11 23:30:42 | INFO | train_inner | epoch 003:  10766 / 11284 loss=3.744, nll_loss=2.057, ppl=4.16, wps=71816.9, ups=1.21, wpb=59545.3, bsz=2268.3, num_updates=33300, lr=0.000547997, gnorm=0.316, loss_scale=2, train_wall=79, gb_free=39, wall=27863
2023-06-11 23:32:05 | INFO | train_inner | epoch 003:  10866 / 11284 loss=3.722, nll_loss=2.032, ppl=4.09, wps=71543.8, ups=1.2, wpb=59531.9, bsz=2293.7, num_updates=33400, lr=0.000547176, gnorm=0.288, loss_scale=2, train_wall=79, gb_free=39.5, wall=27946
2023-06-11 23:33:29 | INFO | train_inner | epoch 003:  10966 / 11284 loss=3.735, nll_loss=2.047, ppl=4.13, wps=71245, ups=1.2, wpb=59237.8, bsz=2206.8, num_updates=33500, lr=0.000546358, gnorm=0.308, loss_scale=2, train_wall=79, gb_free=39.6, wall=28029
2023-06-11 23:34:51 | INFO | train_inner | epoch 003:  11066 / 11284 loss=3.749, nll_loss=2.063, ppl=4.18, wps=71831.5, ups=1.21, wpb=59454.3, bsz=2198.1, num_updates=33600, lr=0.000545545, gnorm=0.308, loss_scale=2, train_wall=79, gb_free=39.6, wall=28112
2023-06-11 23:36:14 | INFO | train_inner | epoch 003:  11166 / 11284 loss=3.72, nll_loss=2.031, ppl=4.09, wps=71523.9, ups=1.21, wpb=59296.2, bsz=2185.1, num_updates=33700, lr=0.000544735, gnorm=0.304, loss_scale=2, train_wall=79, gb_free=39.5, wall=28195
2023-06-11 23:37:37 | INFO | train_inner | epoch 003:  11266 / 11284 loss=3.725, nll_loss=2.036, ppl=4.1, wps=71579.7, ups=1.2, wpb=59559.1, bsz=2242, num_updates=33800, lr=0.000543928, gnorm=0.298, loss_scale=2, train_wall=79, gb_free=39.6, wall=28278
2023-06-11 23:37:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-11 23:38:10 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.515 | nll_loss 2.856 | ppl 7.24 | bleu 19.7 | wps 3645.9 | wpb 2397.5 | bsz 71.5 | num_updates 33818 | best_loss 4.515
2023-06-11 23:38:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 33818 updates
2023-06-11 23:38:10 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint3.pt
2023-06-11 23:38:12 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint3.pt
2023-06-11 23:38:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint3.pt (epoch 3 @ 33818 updates, score 4.515) (writing took 6.500546094030142 seconds)
2023-06-11 23:38:17 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-06-11 23:38:17 | INFO | train | epoch 003 | loss 3.763 | nll_loss 2.077 | ppl 4.22 | wps 71596.7 | ups 1.2 | wpb 59500.9 | bsz 2227.3 | num_updates 33818 | lr 0.000543784 | gnorm 0.313 | loss_scale 2 | train_wall 8894 | gb_free 39.6 | wall 28317
2023-06-11 23:38:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-11 23:38:17 | INFO | fairseq.trainer | begin training epoch 4
2023-06-11 23:38:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-11 23:39:28 | INFO | train_inner | epoch 004:     82 / 11284 loss=3.717, nll_loss=2.026, ppl=4.07, wps=53560.1, ups=0.9, wpb=59248.9, bsz=2181.8, num_updates=33900, lr=0.000543125, gnorm=0.314, loss_scale=2, train_wall=81, gb_free=39.5, wall=28389
2023-06-11 23:40:51 | INFO | train_inner | epoch 004:    182 / 11284 loss=3.721, nll_loss=2.031, ppl=4.09, wps=71794.6, ups=1.21, wpb=59534.9, bsz=2258, num_updates=34000, lr=0.000542326, gnorm=0.304, loss_scale=2, train_wall=79, gb_free=39.5, wall=28472
2023-06-11 23:42:15 | INFO | train_inner | epoch 004:    282 / 11284 loss=3.709, nll_loss=2.017, ppl=4.05, wps=71267.6, ups=1.19, wpb=59670.1, bsz=2314.3, num_updates=34100, lr=0.00054153, gnorm=0.298, loss_scale=2, train_wall=80, gb_free=39.6, wall=28555
2023-06-11 23:43:38 | INFO | train_inner | epoch 004:    382 / 11284 loss=3.722, nll_loss=2.032, ppl=4.09, wps=71384.7, ups=1.2, wpb=59293.2, bsz=2238.1, num_updates=34200, lr=0.000540738, gnorm=0.315, loss_scale=4, train_wall=79, gb_free=39.6, wall=28638
2023-06-11 23:44:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-11 23:45:01 | INFO | train_inner | epoch 004:    483 / 11284 loss=3.716, nll_loss=2.025, ppl=4.07, wps=71274.9, ups=1.2, wpb=59443, bsz=2284.4, num_updates=34300, lr=0.000539949, gnorm=0.311, loss_scale=2, train_wall=79, gb_free=39.6, wall=28722
2023-06-11 23:46:23 | INFO | train_inner | epoch 004:    583 / 11284 loss=3.701, nll_loss=2.008, ppl=4.02, wps=72785.2, ups=1.22, wpb=59701.1, bsz=2261.5, num_updates=34400, lr=0.000539164, gnorm=0.293, loss_scale=2, train_wall=78, gb_free=39.6, wall=28804
2023-06-11 23:47:45 | INFO | train_inner | epoch 004:    683 / 11284 loss=3.72, nll_loss=2.03, ppl=4.08, wps=72881, ups=1.22, wpb=59671.4, bsz=2220, num_updates=34500, lr=0.000538382, gnorm=0.298, loss_scale=2, train_wall=78, gb_free=39.6, wall=28886
2023-06-11 23:49:08 | INFO | train_inner | epoch 004:    783 / 11284 loss=3.706, nll_loss=2.014, ppl=4.04, wps=71780.3, ups=1.21, wpb=59511.2, bsz=2226.8, num_updates=34600, lr=0.000537603, gnorm=0.29, loss_scale=2, train_wall=79, gb_free=39.6, wall=28969
2023-06-11 23:50:31 | INFO | train_inner | epoch 004:    883 / 11284 loss=3.714, nll_loss=2.023, ppl=4.06, wps=71491.3, ups=1.2, wpb=59565.3, bsz=2330.6, num_updates=34700, lr=0.000536828, gnorm=0.328, loss_scale=2, train_wall=79, gb_free=39.6, wall=29052
2023-06-11 23:51:54 | INFO | train_inner | epoch 004:    983 / 11284 loss=3.695, nll_loss=2.002, ppl=4, wps=71789.7, ups=1.21, wpb=59304.1, bsz=2243.1, num_updates=34800, lr=0.000536056, gnorm=0.303, loss_scale=2, train_wall=79, gb_free=39.6, wall=29134
2023-06-11 23:53:16 | INFO | train_inner | epoch 004:   1083 / 11284 loss=3.706, nll_loss=2.015, ppl=4.04, wps=72278.5, ups=1.21, wpb=59677, bsz=2242.3, num_updates=34900, lr=0.000535288, gnorm=0.314, loss_scale=2, train_wall=78, gb_free=39.6, wall=29217
2023-06-11 23:54:38 | INFO | train_inner | epoch 004:   1183 / 11284 loss=3.708, nll_loss=2.016, ppl=4.05, wps=72511.4, ups=1.22, wpb=59391.7, bsz=2208.4, num_updates=35000, lr=0.000534522, gnorm=0.302, loss_scale=2, train_wall=78, gb_free=39.4, wall=29299
2023-06-11 23:56:02 | INFO | train_inner | epoch 004:   1283 / 11284 loss=3.714, nll_loss=2.024, ppl=4.07, wps=71422.5, ups=1.2, wpb=59568.4, bsz=2242.7, num_updates=35100, lr=0.000533761, gnorm=0.302, loss_scale=2, train_wall=79, gb_free=39.6, wall=29382
2023-06-11 23:57:25 | INFO | train_inner | epoch 004:   1383 / 11284 loss=3.709, nll_loss=2.018, ppl=4.05, wps=71570.3, ups=1.2, wpb=59505.2, bsz=2284.2, num_updates=35200, lr=0.000533002, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.6, wall=29465
2023-06-11 23:58:48 | INFO | train_inner | epoch 004:   1483 / 11284 loss=3.714, nll_loss=2.024, ppl=4.07, wps=71548, ups=1.21, wpb=59272.5, bsz=2181.8, num_updates=35300, lr=0.000532246, gnorm=0.3, loss_scale=4, train_wall=79, gb_free=39.5, wall=29548
2023-06-11 23:59:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 00:00:12 | INFO | train_inner | epoch 004:   1584 / 11284 loss=3.722, nll_loss=2.032, ppl=4.09, wps=70669.6, ups=1.19, wpb=59467.8, bsz=2231.1, num_updates=35400, lr=0.000531494, gnorm=0.314, loss_scale=2, train_wall=80, gb_free=39.6, wall=29632
2023-06-12 00:01:35 | INFO | train_inner | epoch 004:   1684 / 11284 loss=3.714, nll_loss=2.023, ppl=4.06, wps=71520.5, ups=1.21, wpb=59337, bsz=2167.6, num_updates=35500, lr=0.000530745, gnorm=0.295, loss_scale=2, train_wall=79, gb_free=39.6, wall=29715
2023-06-12 00:02:58 | INFO | train_inner | epoch 004:   1784 / 11284 loss=3.721, nll_loss=2.032, ppl=4.09, wps=71709.9, ups=1.2, wpb=59530.2, bsz=2204.2, num_updates=35600, lr=0.000529999, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.5, wall=29798
2023-06-12 00:04:21 | INFO | train_inner | epoch 004:   1884 / 11284 loss=3.72, nll_loss=2.03, ppl=4.08, wps=72021.2, ups=1.2, wpb=59772.2, bsz=2172.8, num_updates=35700, lr=0.000529256, gnorm=0.289, loss_scale=2, train_wall=79, gb_free=39.5, wall=29881
2023-06-12 00:05:44 | INFO | train_inner | epoch 004:   1984 / 11284 loss=3.709, nll_loss=2.018, ppl=4.05, wps=72036.1, ups=1.21, wpb=59644.5, bsz=2214.4, num_updates=35800, lr=0.000528516, gnorm=0.286, loss_scale=2, train_wall=79, gb_free=39.5, wall=29964
2023-06-12 00:07:07 | INFO | train_inner | epoch 004:   2084 / 11284 loss=3.715, nll_loss=2.025, ppl=4.07, wps=71416.9, ups=1.2, wpb=59295.5, bsz=2179.5, num_updates=35900, lr=0.00052778, gnorm=0.303, loss_scale=2, train_wall=79, gb_free=39.6, wall=30047
2023-06-12 00:08:30 | INFO | train_inner | epoch 004:   2184 / 11284 loss=3.714, nll_loss=2.024, ppl=4.07, wps=71479.8, ups=1.2, wpb=59814.5, bsz=2313.4, num_updates=36000, lr=0.000527046, gnorm=0.306, loss_scale=2, train_wall=80, gb_free=38.2, wall=30131
2023-06-12 00:09:54 | INFO | train_inner | epoch 004:   2284 / 11284 loss=3.721, nll_loss=2.032, ppl=4.09, wps=71549.6, ups=1.2, wpb=59535.6, bsz=2205, num_updates=36100, lr=0.000526316, gnorm=0.296, loss_scale=2, train_wall=79, gb_free=39.6, wall=30214
2023-06-12 00:11:17 | INFO | train_inner | epoch 004:   2384 / 11284 loss=3.71, nll_loss=2.019, ppl=4.05, wps=71706.6, ups=1.2, wpb=59565.4, bsz=2254.4, num_updates=36200, lr=0.000525588, gnorm=0.3, loss_scale=2, train_wall=79, gb_free=39.6, wall=30297
2023-06-12 00:12:39 | INFO | train_inner | epoch 004:   2484 / 11284 loss=3.714, nll_loss=2.024, ppl=4.07, wps=72132, ups=1.21, wpb=59465.8, bsz=2265.3, num_updates=36300, lr=0.000524864, gnorm=0.295, loss_scale=2, train_wall=78, gb_free=39.6, wall=30380
2023-06-12 00:14:02 | INFO | train_inner | epoch 004:   2584 / 11284 loss=3.713, nll_loss=2.022, ppl=4.06, wps=71876.2, ups=1.21, wpb=59422.9, bsz=2213.7, num_updates=36400, lr=0.000524142, gnorm=0.309, loss_scale=2, train_wall=78, gb_free=39.6, wall=30462
2023-06-12 00:15:24 | INFO | train_inner | epoch 004:   2684 / 11284 loss=3.703, nll_loss=2.011, ppl=4.03, wps=72102.5, ups=1.21, wpb=59398, bsz=2261.2, num_updates=36500, lr=0.000523424, gnorm=0.301, loss_scale=4, train_wall=78, gb_free=39.6, wall=30545
2023-06-12 00:16:47 | INFO | train_inner | epoch 004:   2784 / 11284 loss=3.713, nll_loss=2.023, ppl=4.06, wps=71454.8, ups=1.2, wpb=59480.5, bsz=2280.5, num_updates=36600, lr=0.000522708, gnorm=0.291, loss_scale=4, train_wall=79, gb_free=39.4, wall=30628
2023-06-12 00:18:11 | INFO | train_inner | epoch 004:   2884 / 11284 loss=3.7, nll_loss=2.007, ppl=4.02, wps=71447, ups=1.2, wpb=59390.5, bsz=2140.7, num_updates=36700, lr=0.000521996, gnorm=0.307, loss_scale=4, train_wall=79, gb_free=39.5, wall=30711
2023-06-12 00:19:34 | INFO | train_inner | epoch 004:   2984 / 11284 loss=3.701, nll_loss=2.01, ppl=4.03, wps=71597.7, ups=1.2, wpb=59702, bsz=2235, num_updates=36800, lr=0.000521286, gnorm=0.299, loss_scale=4, train_wall=79, gb_free=39.5, wall=30794
2023-06-12 00:20:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 00:20:58 | INFO | train_inner | epoch 004:   3085 / 11284 loss=3.703, nll_loss=2.012, ppl=4.03, wps=70686.9, ups=1.19, wpb=59472.6, bsz=2254.4, num_updates=36900, lr=0.000520579, gnorm=0.301, loss_scale=2, train_wall=80, gb_free=39.6, wall=30879
2023-06-12 00:22:21 | INFO | train_inner | epoch 004:   3185 / 11284 loss=3.704, nll_loss=2.013, ppl=4.04, wps=71776, ups=1.21, wpb=59491.4, bsz=2188.9, num_updates=37000, lr=0.000519875, gnorm=0.302, loss_scale=2, train_wall=79, gb_free=39.6, wall=30962
2023-06-12 00:23:44 | INFO | train_inner | epoch 004:   3285 / 11284 loss=3.713, nll_loss=2.023, ppl=4.06, wps=71766, ups=1.2, wpb=59596.2, bsz=2240, num_updates=37100, lr=0.000519174, gnorm=0.302, loss_scale=2, train_wall=79, gb_free=39.6, wall=31045
2023-06-12 00:25:07 | INFO | train_inner | epoch 004:   3385 / 11284 loss=3.696, nll_loss=2.003, ppl=4.01, wps=71602.1, ups=1.2, wpb=59542.6, bsz=2227.8, num_updates=37200, lr=0.000518476, gnorm=0.289, loss_scale=2, train_wall=79, gb_free=39.5, wall=31128
2023-06-12 00:26:31 | INFO | train_inner | epoch 004:   3485 / 11284 loss=3.704, nll_loss=2.012, ppl=4.03, wps=71343.2, ups=1.2, wpb=59470.6, bsz=2195.8, num_updates=37300, lr=0.00051778, gnorm=0.301, loss_scale=2, train_wall=79, gb_free=39.6, wall=31211
2023-06-12 00:27:54 | INFO | train_inner | epoch 004:   3585 / 11284 loss=3.707, nll_loss=2.016, ppl=4.05, wps=71323.5, ups=1.2, wpb=59362.5, bsz=2192.3, num_updates=37400, lr=0.000517088, gnorm=0.288, loss_scale=2, train_wall=79, gb_free=39.4, wall=31294
2023-06-12 00:29:17 | INFO | train_inner | epoch 004:   3685 / 11284 loss=3.708, nll_loss=2.018, ppl=4.05, wps=71665.6, ups=1.2, wpb=59536.2, bsz=2280.8, num_updates=37500, lr=0.000516398, gnorm=0.31, loss_scale=2, train_wall=79, gb_free=39.6, wall=31377
2023-06-12 00:30:40 | INFO | train_inner | epoch 004:   3785 / 11284 loss=3.711, nll_loss=2.021, ppl=4.06, wps=71381.9, ups=1.2, wpb=59328.9, bsz=2181.2, num_updates=37600, lr=0.000515711, gnorm=0.307, loss_scale=2, train_wall=79, gb_free=39.6, wall=31461
2023-06-12 00:32:03 | INFO | train_inner | epoch 004:   3885 / 11284 loss=3.699, nll_loss=2.008, ppl=4.02, wps=71768.9, ups=1.21, wpb=59356.7, bsz=2258.3, num_updates=37700, lr=0.000515026, gnorm=0.289, loss_scale=2, train_wall=79, gb_free=39.6, wall=31543
2023-06-12 00:33:26 | INFO | train_inner | epoch 004:   3985 / 11284 loss=3.709, nll_loss=2.018, ppl=4.05, wps=71276.3, ups=1.2, wpb=59418, bsz=2222.1, num_updates=37800, lr=0.000514344, gnorm=0.32, loss_scale=2, train_wall=79, gb_free=39.6, wall=31627
2023-06-12 00:34:49 | INFO | train_inner | epoch 004:   4085 / 11284 loss=3.697, nll_loss=2.005, ppl=4.01, wps=71716.8, ups=1.21, wpb=59427.8, bsz=2143.9, num_updates=37900, lr=0.000513665, gnorm=0.306, loss_scale=4, train_wall=79, gb_free=39.6, wall=31709
2023-06-12 00:35:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 00:36:13 | INFO | train_inner | epoch 004:   4186 / 11284 loss=3.699, nll_loss=2.007, ppl=4.02, wps=70904.6, ups=1.19, wpb=59536.3, bsz=2244.6, num_updates=38000, lr=0.000512989, gnorm=0.299, loss_scale=2, train_wall=80, gb_free=39.6, wall=31793
2023-06-12 00:37:36 | INFO | train_inner | epoch 004:   4286 / 11284 loss=3.702, nll_loss=2.011, ppl=4.03, wps=71704.3, ups=1.21, wpb=59470.6, bsz=2235.5, num_updates=38100, lr=0.000512316, gnorm=0.291, loss_scale=2, train_wall=79, gb_free=39.5, wall=31876
2023-06-12 00:38:59 | INFO | train_inner | epoch 004:   4386 / 11284 loss=3.717, nll_loss=2.028, ppl=4.08, wps=71725.6, ups=1.21, wpb=59521.1, bsz=2280.5, num_updates=38200, lr=0.000511645, gnorm=0.303, loss_scale=2, train_wall=79, gb_free=39.6, wall=31959
2023-06-12 00:40:21 | INFO | train_inner | epoch 004:   4486 / 11284 loss=3.689, nll_loss=1.996, ppl=3.99, wps=72772.8, ups=1.22, wpb=59582.5, bsz=2190.7, num_updates=38300, lr=0.000510976, gnorm=0.303, loss_scale=2, train_wall=78, gb_free=38.9, wall=32041
2023-06-12 00:41:43 | INFO | train_inner | epoch 004:   4586 / 11284 loss=3.71, nll_loss=2.02, ppl=4.05, wps=72388.6, ups=1.22, wpb=59424.6, bsz=2232.3, num_updates=38400, lr=0.00051031, gnorm=0.29, loss_scale=2, train_wall=78, gb_free=39.6, wall=32123
2023-06-12 00:43:05 | INFO | train_inner | epoch 004:   4686 / 11284 loss=3.708, nll_loss=2.017, ppl=4.05, wps=72100.6, ups=1.21, wpb=59397.6, bsz=2251.1, num_updates=38500, lr=0.000509647, gnorm=0.314, loss_scale=2, train_wall=78, gb_free=39.6, wall=32206
2023-06-12 00:44:28 | INFO | train_inner | epoch 004:   4786 / 11284 loss=3.692, nll_loss=1.999, ppl=4, wps=71966.5, ups=1.21, wpb=59383.7, bsz=2261.3, num_updates=38600, lr=0.000508987, gnorm=0.289, loss_scale=2, train_wall=78, gb_free=39.6, wall=32288
2023-06-12 00:45:50 | INFO | train_inner | epoch 004:   4886 / 11284 loss=3.701, nll_loss=2.009, ppl=4.03, wps=72414.1, ups=1.22, wpb=59413.1, bsz=2170.1, num_updates=38700, lr=0.000508329, gnorm=0.306, loss_scale=2, train_wall=78, gb_free=39.6, wall=32370
2023-06-12 00:47:12 | INFO | train_inner | epoch 004:   4986 / 11284 loss=3.713, nll_loss=2.024, ppl=4.07, wps=71737.6, ups=1.21, wpb=59336.3, bsz=2130, num_updates=38800, lr=0.000507673, gnorm=0.31, loss_scale=2, train_wall=79, gb_free=39.5, wall=32453
2023-06-12 00:48:35 | INFO | train_inner | epoch 004:   5086 / 11284 loss=3.708, nll_loss=2.017, ppl=4.05, wps=71674.8, ups=1.21, wpb=59475.1, bsz=2178.2, num_updates=38900, lr=0.00050702, gnorm=0.295, loss_scale=2, train_wall=79, gb_free=39.4, wall=32536
2023-06-12 00:49:58 | INFO | train_inner | epoch 004:   5186 / 11284 loss=3.698, nll_loss=2.007, ppl=4.02, wps=71499.8, ups=1.2, wpb=59367.7, bsz=2250.3, num_updates=39000, lr=0.00050637, gnorm=0.298, loss_scale=4, train_wall=79, gb_free=39.6, wall=32619
2023-06-12 00:51:21 | INFO | train_inner | epoch 004:   5286 / 11284 loss=3.689, nll_loss=1.996, ppl=3.99, wps=71883.1, ups=1.21, wpb=59434.2, bsz=2126.1, num_updates=39100, lr=0.000505722, gnorm=0.298, loss_scale=4, train_wall=79, gb_free=39.6, wall=32702
2023-06-12 00:52:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 00:52:45 | INFO | train_inner | epoch 004:   5387 / 11284 loss=3.696, nll_loss=2.005, ppl=4.01, wps=70813.7, ups=1.19, wpb=59567.8, bsz=2209.3, num_updates=39200, lr=0.000505076, gnorm=0.293, loss_scale=2, train_wall=80, gb_free=38.5, wall=32786
2023-06-12 00:54:08 | INFO | train_inner | epoch 004:   5487 / 11284 loss=3.703, nll_loss=2.012, ppl=4.03, wps=71582, ups=1.2, wpb=59540.4, bsz=2288.7, num_updates=39300, lr=0.000504433, gnorm=0.292, loss_scale=2, train_wall=79, gb_free=39.5, wall=32869
2023-06-12 00:55:31 | INFO | train_inner | epoch 004:   5587 / 11284 loss=3.713, nll_loss=2.024, ppl=4.07, wps=71490, ups=1.21, wpb=59317.8, bsz=2188, num_updates=39400, lr=0.000503793, gnorm=0.326, loss_scale=2, train_wall=79, gb_free=39.6, wall=32952
2023-06-12 00:56:55 | INFO | train_inner | epoch 004:   5687 / 11284 loss=3.698, nll_loss=2.006, ppl=4.02, wps=71471.6, ups=1.2, wpb=59503.2, bsz=2194.9, num_updates=39500, lr=0.000503155, gnorm=0.297, loss_scale=2, train_wall=80, gb_free=39.6, wall=33035
2023-06-12 00:58:18 | INFO | train_inner | epoch 004:   5787 / 11284 loss=3.719, nll_loss=2.03, ppl=4.08, wps=71762, ups=1.2, wpb=59635.9, bsz=2208.1, num_updates=39600, lr=0.000502519, gnorm=0.309, loss_scale=2, train_wall=79, gb_free=39.6, wall=33118
2023-06-12 00:59:41 | INFO | train_inner | epoch 004:   5887 / 11284 loss=3.71, nll_loss=2.02, ppl=4.06, wps=71545.5, ups=1.2, wpb=59524.3, bsz=2192, num_updates=39700, lr=0.000501886, gnorm=0.303, loss_scale=2, train_wall=79, gb_free=39.6, wall=33201
2023-06-12 01:01:03 | INFO | train_inner | epoch 004:   5987 / 11284 loss=3.697, nll_loss=2.006, ppl=4.02, wps=72634.8, ups=1.22, wpb=59662.2, bsz=2259.5, num_updates=39800, lr=0.000501255, gnorm=0.3, loss_scale=2, train_wall=78, gb_free=39.6, wall=33284
2023-06-12 01:02:26 | INFO | train_inner | epoch 004:   6087 / 11284 loss=3.719, nll_loss=2.03, ppl=4.08, wps=71224.3, ups=1.2, wpb=59310.8, bsz=2219.4, num_updates=39900, lr=0.000500626, gnorm=0.293, loss_scale=2, train_wall=79, gb_free=39.5, wall=33367
2023-06-12 01:03:49 | INFO | train_inner | epoch 004:   6187 / 11284 loss=3.687, nll_loss=1.994, ppl=3.98, wps=71717.7, ups=1.21, wpb=59505.1, bsz=2174.5, num_updates=40000, lr=0.0005, gnorm=0.294, loss_scale=2, train_wall=79, gb_free=39.6, wall=33450
2023-06-12 01:05:13 | INFO | train_inner | epoch 004:   6287 / 11284 loss=3.687, nll_loss=1.995, ppl=3.99, wps=70965.8, ups=1.19, wpb=59512.2, bsz=2266.6, num_updates=40100, lr=0.000499376, gnorm=0.302, loss_scale=2, train_wall=80, gb_free=39.6, wall=33534
2023-06-12 01:06:37 | INFO | train_inner | epoch 004:   6387 / 11284 loss=3.699, nll_loss=2.008, ppl=4.02, wps=71503, ups=1.2, wpb=59708.1, bsz=2303.5, num_updates=40200, lr=0.000498755, gnorm=0.319, loss_scale=4, train_wall=79, gb_free=39.6, wall=33617
2023-06-12 01:07:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 01:08:01 | INFO | train_inner | epoch 004:   6488 / 11284 loss=3.686, nll_loss=1.993, ppl=3.98, wps=70994.8, ups=1.19, wpb=59611.7, bsz=2233.7, num_updates=40300, lr=0.000498135, gnorm=0.308, loss_scale=2, train_wall=80, gb_free=39.5, wall=33701
2023-06-12 01:09:23 | INFO | train_inner | epoch 004:   6588 / 11284 loss=3.687, nll_loss=1.995, ppl=3.99, wps=71922.8, ups=1.21, wpb=59489.3, bsz=2150.7, num_updates=40400, lr=0.000497519, gnorm=0.301, loss_scale=2, train_wall=79, gb_free=39.6, wall=33784
2023-06-12 01:10:47 | INFO | train_inner | epoch 004:   6688 / 11284 loss=3.704, nll_loss=2.013, ppl=4.04, wps=71400.6, ups=1.2, wpb=59464.9, bsz=2263.3, num_updates=40500, lr=0.000496904, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.5, wall=33867
2023-06-12 01:12:10 | INFO | train_inner | epoch 004:   6788 / 11284 loss=3.701, nll_loss=2.01, ppl=4.03, wps=71534.4, ups=1.2, wpb=59553.8, bsz=2259.9, num_updates=40600, lr=0.000496292, gnorm=0.301, loss_scale=2, train_wall=79, gb_free=39.7, wall=33950
2023-06-12 01:13:33 | INFO | train_inner | epoch 004:   6888 / 11284 loss=3.704, nll_loss=2.014, ppl=4.04, wps=71939.2, ups=1.21, wpb=59662.5, bsz=2220.3, num_updates=40700, lr=0.000495682, gnorm=0.304, loss_scale=2, train_wall=79, gb_free=39.6, wall=34033
2023-06-12 01:14:56 | INFO | train_inner | epoch 004:   6988 / 11284 loss=3.698, nll_loss=2.007, ppl=4.02, wps=71577, ups=1.2, wpb=59735.1, bsz=2228.2, num_updates=40800, lr=0.000495074, gnorm=0.293, loss_scale=2, train_wall=80, gb_free=39.5, wall=34117
2023-06-12 01:16:20 | INFO | train_inner | epoch 004:   7088 / 11284 loss=3.69, nll_loss=1.998, ppl=3.99, wps=71239, ups=1.2, wpb=59385.1, bsz=2209.6, num_updates=40900, lr=0.000494468, gnorm=0.302, loss_scale=2, train_wall=80, gb_free=39.6, wall=34200
2023-06-12 01:17:42 | INFO | train_inner | epoch 004:   7188 / 11284 loss=3.677, nll_loss=1.983, ppl=3.95, wps=72274.2, ups=1.21, wpb=59586.7, bsz=2181.8, num_updates=41000, lr=0.000493865, gnorm=0.295, loss_scale=2, train_wall=78, gb_free=39.5, wall=34283
2023-06-12 01:19:04 | INFO | train_inner | epoch 004:   7288 / 11284 loss=3.698, nll_loss=2.007, ppl=4.02, wps=72512.5, ups=1.21, wpb=59742.6, bsz=2255.3, num_updates=41100, lr=0.000493264, gnorm=0.293, loss_scale=2, train_wall=78, gb_free=39.6, wall=34365
2023-06-12 01:20:27 | INFO | train_inner | epoch 004:   7388 / 11284 loss=3.685, nll_loss=1.993, ppl=3.98, wps=72354.1, ups=1.21, wpb=59664.6, bsz=2173.2, num_updates=41200, lr=0.000492665, gnorm=0.296, loss_scale=2, train_wall=78, gb_free=39.6, wall=34448
2023-06-12 01:21:49 | INFO | train_inner | epoch 004:   7488 / 11284 loss=3.69, nll_loss=1.997, ppl=3.99, wps=71947.9, ups=1.21, wpb=59369.7, bsz=2177.1, num_updates=41300, lr=0.000492068, gnorm=0.299, loss_scale=4, train_wall=79, gb_free=39.6, wall=34530
2023-06-12 01:22:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 01:23:13 | INFO | train_inner | epoch 004:   7589 / 11284 loss=3.702, nll_loss=2.011, ppl=4.03, wps=70800.9, ups=1.19, wpb=59284.1, bsz=2248, num_updates=41400, lr=0.000491473, gnorm=0.304, loss_scale=2, train_wall=80, gb_free=39.2, wall=34614
2023-06-12 01:24:36 | INFO | train_inner | epoch 004:   7689 / 11284 loss=3.688, nll_loss=1.995, ppl=3.99, wps=72329.5, ups=1.21, wpb=59540.7, bsz=2232.1, num_updates=41500, lr=0.000490881, gnorm=0.301, loss_scale=2, train_wall=78, gb_free=39.6, wall=34696
2023-06-12 01:25:59 | INFO | train_inner | epoch 004:   7789 / 11284 loss=3.695, nll_loss=2.003, ppl=4.01, wps=71449.9, ups=1.2, wpb=59710.9, bsz=2212.6, num_updates=41600, lr=0.00049029, gnorm=0.294, loss_scale=2, train_wall=80, gb_free=39.6, wall=34780
2023-06-12 01:27:22 | INFO | train_inner | epoch 004:   7889 / 11284 loss=3.686, nll_loss=1.994, ppl=3.98, wps=71753.5, ups=1.21, wpb=59510.4, bsz=2208, num_updates=41700, lr=0.000489702, gnorm=0.296, loss_scale=2, train_wall=79, gb_free=39.5, wall=34863
2023-06-12 01:28:44 | INFO | train_inner | epoch 004:   7989 / 11284 loss=3.697, nll_loss=2.006, ppl=4.02, wps=72263.4, ups=1.22, wpb=59425.1, bsz=2289.4, num_updates=41800, lr=0.000489116, gnorm=0.316, loss_scale=2, train_wall=78, gb_free=39.6, wall=34945
2023-06-12 01:30:06 | INFO | train_inner | epoch 004:   8089 / 11284 loss=3.674, nll_loss=1.981, ppl=3.95, wps=72445.1, ups=1.22, wpb=59566, bsz=2229.2, num_updates=41900, lr=0.000488532, gnorm=0.301, loss_scale=2, train_wall=78, gb_free=39.3, wall=35027
2023-06-12 01:31:30 | INFO | train_inner | epoch 004:   8189 / 11284 loss=3.663, nll_loss=1.967, ppl=3.91, wps=71397.2, ups=1.2, wpb=59628.8, bsz=2215.7, num_updates=42000, lr=0.00048795, gnorm=0.303, loss_scale=2, train_wall=80, gb_free=39.6, wall=35111
2023-06-12 01:32:53 | INFO | train_inner | epoch 004:   8289 / 11284 loss=3.689, nll_loss=1.997, ppl=3.99, wps=71563, ups=1.2, wpb=59711.7, bsz=2326.1, num_updates=42100, lr=0.00048737, gnorm=0.313, loss_scale=2, train_wall=80, gb_free=39.6, wall=35194
2023-06-12 01:34:17 | INFO | train_inner | epoch 004:   8389 / 11284 loss=3.68, nll_loss=1.986, ppl=3.96, wps=71452.8, ups=1.2, wpb=59397.5, bsz=2290.2, num_updates=42200, lr=0.000486792, gnorm=0.295, loss_scale=2, train_wall=79, gb_free=39.6, wall=35277
2023-06-12 01:35:39 | INFO | train_inner | epoch 004:   8489 / 11284 loss=3.685, nll_loss=1.992, ppl=3.98, wps=72504.6, ups=1.22, wpb=59642.4, bsz=2212.3, num_updates=42300, lr=0.000486217, gnorm=0.289, loss_scale=2, train_wall=78, gb_free=39.6, wall=35359
2023-06-12 01:37:02 | INFO | train_inner | epoch 004:   8589 / 11284 loss=3.676, nll_loss=1.983, ppl=3.95, wps=71762.6, ups=1.21, wpb=59394.7, bsz=2212.8, num_updates=42400, lr=0.000485643, gnorm=0.286, loss_scale=2, train_wall=79, gb_free=39.6, wall=35442
2023-06-12 01:37:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 01:38:26 | INFO | train_inner | epoch 004:   8690 / 11284 loss=3.677, nll_loss=1.983, ppl=3.95, wps=70262.5, ups=1.18, wpb=59385.7, bsz=2237.6, num_updates=42500, lr=0.000485071, gnorm=0.291, loss_scale=2, train_wall=80, gb_free=39.5, wall=35527
2023-06-12 01:39:49 | INFO | train_inner | epoch 004:   8790 / 11284 loss=3.669, nll_loss=1.974, ppl=3.93, wps=71445.2, ups=1.2, wpb=59420.8, bsz=2183.5, num_updates=42600, lr=0.000484502, gnorm=0.302, loss_scale=2, train_wall=79, gb_free=39.6, wall=35610
2023-06-12 01:41:12 | INFO | train_inner | epoch 004:   8890 / 11284 loss=3.671, nll_loss=1.977, ppl=3.94, wps=71603.6, ups=1.2, wpb=59526.6, bsz=2135.9, num_updates=42700, lr=0.000483934, gnorm=0.291, loss_scale=2, train_wall=79, gb_free=39.6, wall=35693
2023-06-12 01:42:36 | INFO | train_inner | epoch 004:   8990 / 11284 loss=3.692, nll_loss=2, ppl=4, wps=71559.9, ups=1.2, wpb=59494.6, bsz=2190, num_updates=42800, lr=0.000483368, gnorm=0.298, loss_scale=2, train_wall=79, gb_free=39.6, wall=35776
2023-06-12 01:43:59 | INFO | train_inner | epoch 004:   9090 / 11284 loss=3.678, nll_loss=1.985, ppl=3.96, wps=71488.5, ups=1.2, wpb=59335.4, bsz=2148.1, num_updates=42900, lr=0.000482805, gnorm=0.292, loss_scale=2, train_wall=79, gb_free=39.6, wall=35859
2023-06-12 01:45:21 | INFO | train_inner | epoch 004:   9190 / 11284 loss=3.676, nll_loss=1.983, ppl=3.95, wps=72043.9, ups=1.21, wpb=59591.5, bsz=2215.5, num_updates=43000, lr=0.000482243, gnorm=0.293, loss_scale=2, train_wall=79, gb_free=39.6, wall=35942
2023-06-12 01:46:45 | INFO | train_inner | epoch 004:   9290 / 11284 loss=3.688, nll_loss=1.996, ppl=3.99, wps=70982, ups=1.19, wpb=59406.5, bsz=2249.6, num_updates=43100, lr=0.000481683, gnorm=0.317, loss_scale=2, train_wall=80, gb_free=39.6, wall=36026
2023-06-12 01:48:10 | INFO | train_inner | epoch 004:   9390 / 11284 loss=3.691, nll_loss=2, ppl=4, wps=69826.1, ups=1.17, wpb=59548, bsz=2260.4, num_updates=43200, lr=0.000481125, gnorm=0.297, loss_scale=2, train_wall=81, gb_free=39.6, wall=36111
2023-06-12 01:49:34 | INFO | train_inner | epoch 004:   9490 / 11284 loss=3.672, nll_loss=1.978, ppl=3.94, wps=71477.1, ups=1.2, wpb=59635.8, bsz=2266.9, num_updates=43300, lr=0.000480569, gnorm=0.301, loss_scale=2, train_wall=79, gb_free=39.6, wall=36194
2023-06-12 01:50:57 | INFO | train_inner | epoch 004:   9590 / 11284 loss=3.687, nll_loss=1.995, ppl=3.99, wps=71358, ups=1.2, wpb=59418.9, bsz=2152.9, num_updates=43400, lr=0.000480015, gnorm=0.306, loss_scale=2, train_wall=79, gb_free=39.5, wall=36278
2023-06-12 01:52:20 | INFO | train_inner | epoch 004:   9690 / 11284 loss=3.684, nll_loss=1.992, ppl=3.98, wps=71389.9, ups=1.2, wpb=59360.2, bsz=2329.4, num_updates=43500, lr=0.000479463, gnorm=0.3, loss_scale=4, train_wall=79, gb_free=39.6, wall=36361
2023-06-12 01:52:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 01:53:44 | INFO | train_inner | epoch 004:   9791 / 11284 loss=3.688, nll_loss=1.996, ppl=3.99, wps=70721.4, ups=1.19, wpb=59513.8, bsz=2188.7, num_updates=43600, lr=0.000478913, gnorm=0.3, loss_scale=2, train_wall=80, gb_free=39.6, wall=36445
2023-06-12 01:55:07 | INFO | train_inner | epoch 004:   9891 / 11284 loss=3.681, nll_loss=1.988, ppl=3.97, wps=71359.5, ups=1.2, wpb=59288.9, bsz=2208.5, num_updates=43700, lr=0.000478365, gnorm=0.291, loss_scale=2, train_wall=79, gb_free=39.6, wall=36528
2023-06-12 01:56:30 | INFO | train_inner | epoch 004:   9991 / 11284 loss=3.686, nll_loss=1.994, ppl=3.98, wps=71901.8, ups=1.21, wpb=59510.4, bsz=2236.4, num_updates=43800, lr=0.000477818, gnorm=0.312, loss_scale=2, train_wall=79, gb_free=39.6, wall=36611
2023-06-12 01:57:53 | INFO | train_inner | epoch 004:  10091 / 11284 loss=3.681, nll_loss=1.988, ppl=3.97, wps=71924.3, ups=1.21, wpb=59491.4, bsz=2301.6, num_updates=43900, lr=0.000477274, gnorm=0.299, loss_scale=2, train_wall=79, gb_free=39.6, wall=36693
2023-06-12 01:59:16 | INFO | train_inner | epoch 004:  10191 / 11284 loss=3.684, nll_loss=1.991, ppl=3.98, wps=71487.7, ups=1.2, wpb=59505, bsz=2267.8, num_updates=44000, lr=0.000476731, gnorm=0.297, loss_scale=2, train_wall=79, gb_free=39.6, wall=36777
2023-06-12 02:00:40 | INFO | train_inner | epoch 004:  10291 / 11284 loss=3.694, nll_loss=2.003, ppl=4.01, wps=71000.2, ups=1.2, wpb=59408.4, bsz=2283, num_updates=44100, lr=0.00047619, gnorm=0.306, loss_scale=2, train_wall=80, gb_free=39.6, wall=36860
2023-06-12 02:02:02 | INFO | train_inner | epoch 004:  10391 / 11284 loss=3.694, nll_loss=2.002, ppl=4.01, wps=72404.9, ups=1.22, wpb=59483.1, bsz=2163.5, num_updates=44200, lr=0.000475651, gnorm=0.306, loss_scale=2, train_wall=78, gb_free=39.5, wall=36942
2023-06-12 02:03:24 | INFO | train_inner | epoch 004:  10491 / 11284 loss=3.685, nll_loss=1.992, ppl=3.98, wps=72185.1, ups=1.21, wpb=59543.1, bsz=2181, num_updates=44300, lr=0.000475114, gnorm=0.306, loss_scale=2, train_wall=79, gb_free=39.6, wall=37025
2023-06-12 02:04:48 | INFO | train_inner | epoch 004:  10591 / 11284 loss=3.693, nll_loss=2.002, ppl=4.01, wps=71671.5, ups=1.2, wpb=59576.4, bsz=2272.5, num_updates=44400, lr=0.000474579, gnorm=0.3, loss_scale=2, train_wall=79, gb_free=39.6, wall=37108
2023-06-12 02:06:10 | INFO | train_inner | epoch 004:  10691 / 11284 loss=3.688, nll_loss=1.997, ppl=3.99, wps=71784.7, ups=1.21, wpb=59410.1, bsz=2192.3, num_updates=44500, lr=0.000474045, gnorm=0.295, loss_scale=2, train_wall=79, gb_free=39.2, wall=37191
2023-06-12 02:07:34 | INFO | train_inner | epoch 004:  10791 / 11284 loss=3.686, nll_loss=1.994, ppl=3.98, wps=71652.9, ups=1.2, wpb=59628.5, bsz=2231.6, num_updates=44600, lr=0.000473514, gnorm=0.305, loss_scale=4, train_wall=79, gb_free=39.5, wall=37274
2023-06-12 02:08:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 02:08:57 | INFO | train_inner | epoch 004:  10892 / 11284 loss=3.683, nll_loss=1.991, ppl=3.97, wps=71073.1, ups=1.19, wpb=59620.4, bsz=2227.7, num_updates=44700, lr=0.000472984, gnorm=0.293, loss_scale=2, train_wall=80, gb_free=39.6, wall=37358
2023-06-12 02:10:21 | INFO | train_inner | epoch 004:  10992 / 11284 loss=3.665, nll_loss=1.971, ppl=3.92, wps=71397.4, ups=1.2, wpb=59565.4, bsz=2177.2, num_updates=44800, lr=0.000472456, gnorm=0.301, loss_scale=2, train_wall=80, gb_free=39.6, wall=37441
2023-06-12 02:11:44 | INFO | train_inner | epoch 004:  11092 / 11284 loss=3.691, nll_loss=2, ppl=4, wps=71205.6, ups=1.2, wpb=59421.2, bsz=2241.4, num_updates=44900, lr=0.000471929, gnorm=0.31, loss_scale=2, train_wall=79, gb_free=39.6, wall=37525
2023-06-12 02:13:07 | INFO | train_inner | epoch 004:  11192 / 11284 loss=3.682, nll_loss=1.989, ppl=3.97, wps=72254, ups=1.21, wpb=59691.1, bsz=2247, num_updates=45000, lr=0.000471405, gnorm=0.299, loss_scale=2, train_wall=78, gb_free=39.5, wall=37607
2023-06-12 02:14:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-12 02:14:41 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.469 | nll_loss 2.801 | ppl 6.97 | bleu 20.34 | wps 3695 | wpb 2397.5 | bsz 71.5 | num_updates 45092 | best_loss 4.469
2023-06-12 02:14:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 45092 updates
2023-06-12 02:14:41 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint4.pt
2023-06-12 02:14:42 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint4.pt
2023-06-12 02:14:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint4.pt (epoch 4 @ 45092 updates, score 4.469) (writing took 5.846774167381227 seconds)
2023-06-12 02:14:47 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-06-12 02:14:47 | INFO | train | epoch 004 | loss 3.698 | nll_loss 2.006 | ppl 4.02 | wps 71439.9 | ups 1.2 | wpb 59500.6 | bsz 2227.1 | num_updates 45092 | lr 0.000470923 | gnorm 0.301 | loss_scale 2 | train_wall 8917 | gb_free 39.6 | wall 37707
2023-06-12 02:14:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-12 02:14:47 | INFO | fairseq.trainer | begin training epoch 5
2023-06-12 02:14:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-12 02:14:54 | INFO | train_inner | epoch 005:      8 / 11284 loss=3.684, nll_loss=1.992, ppl=3.98, wps=55362, ups=0.94, wpb=59119.9, bsz=2323, num_updates=45100, lr=0.000470882, gnorm=0.288, loss_scale=2, train_wall=78, gb_free=39.6, wall=37714
2023-06-12 02:16:17 | INFO | train_inner | epoch 005:    108 / 11284 loss=3.668, nll_loss=1.973, ppl=3.93, wps=71890.4, ups=1.21, wpb=59649.6, bsz=2188.4, num_updates=45200, lr=0.00047036, gnorm=0.301, loss_scale=2, train_wall=79, gb_free=39.6, wall=37797
2023-06-12 02:17:40 | INFO | train_inner | epoch 005:    208 / 11284 loss=3.661, nll_loss=1.965, ppl=3.9, wps=71117.2, ups=1.2, wpb=59424.3, bsz=2279.9, num_updates=45300, lr=0.000469841, gnorm=0.295, loss_scale=2, train_wall=79, gb_free=39.6, wall=37881
2023-06-12 02:19:04 | INFO | train_inner | epoch 005:    308 / 11284 loss=3.671, nll_loss=1.977, ppl=3.94, wps=71464.6, ups=1.2, wpb=59518.5, bsz=2203.8, num_updates=45400, lr=0.000469323, gnorm=0.299, loss_scale=2, train_wall=79, gb_free=39.6, wall=37964
2023-06-12 02:20:26 | INFO | train_inner | epoch 005:    408 / 11284 loss=3.665, nll_loss=1.97, ppl=3.92, wps=71610.2, ups=1.21, wpb=59313.8, bsz=2076.2, num_updates=45500, lr=0.000468807, gnorm=0.296, loss_scale=2, train_wall=79, gb_free=39.5, wall=38047
2023-06-12 02:21:49 | INFO | train_inner | epoch 005:    508 / 11284 loss=3.658, nll_loss=1.962, ppl=3.9, wps=72167.2, ups=1.21, wpb=59844.4, bsz=2239.3, num_updates=45600, lr=0.000468293, gnorm=0.287, loss_scale=2, train_wall=79, gb_free=39.5, wall=38130
2023-06-12 02:23:12 | INFO | train_inner | epoch 005:    608 / 11284 loss=3.667, nll_loss=1.973, ppl=3.92, wps=72149.5, ups=1.21, wpb=59521.4, bsz=2240, num_updates=45700, lr=0.00046778, gnorm=0.298, loss_scale=4, train_wall=78, gb_free=39.6, wall=38212
2023-06-12 02:24:34 | INFO | train_inner | epoch 005:    708 / 11284 loss=3.673, nll_loss=1.979, ppl=3.94, wps=71682.2, ups=1.21, wpb=59262.6, bsz=2216.1, num_updates=45800, lr=0.000467269, gnorm=0.288, loss_scale=4, train_wall=79, gb_free=39.6, wall=38295
2023-06-12 02:24:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 02:25:58 | INFO | train_inner | epoch 005:    809 / 11284 loss=3.662, nll_loss=1.967, ppl=3.91, wps=71340.8, ups=1.2, wpb=59535.2, bsz=2201.1, num_updates=45900, lr=0.00046676, gnorm=0.301, loss_scale=2, train_wall=79, gb_free=39.6, wall=38378
2023-06-12 02:27:20 | INFO | train_inner | epoch 005:    909 / 11284 loss=3.672, nll_loss=1.977, ppl=3.94, wps=72921.2, ups=1.22, wpb=59693.3, bsz=2234.9, num_updates=46000, lr=0.000466252, gnorm=0.3, loss_scale=2, train_wall=78, gb_free=39.5, wall=38460
2023-06-12 02:28:43 | INFO | train_inner | epoch 005:   1009 / 11284 loss=3.662, nll_loss=1.967, ppl=3.91, wps=71736.8, ups=1.2, wpb=59590.9, bsz=2245.3, num_updates=46100, lr=0.000465746, gnorm=0.304, loss_scale=2, train_wall=79, gb_free=39.5, wall=38543
2023-06-12 02:30:06 | INFO | train_inner | epoch 005:   1109 / 11284 loss=3.648, nll_loss=1.95, ppl=3.87, wps=71624.6, ups=1.2, wpb=59605.5, bsz=2151.5, num_updates=46200, lr=0.000465242, gnorm=0.288, loss_scale=2, train_wall=79, gb_free=39.5, wall=38627
2023-06-12 02:31:28 | INFO | train_inner | epoch 005:   1209 / 11284 loss=3.669, nll_loss=1.974, ppl=3.93, wps=72212.8, ups=1.22, wpb=59228.7, bsz=2253.6, num_updates=46300, lr=0.000464739, gnorm=0.295, loss_scale=2, train_wall=78, gb_free=39.4, wall=38709
2023-06-12 02:32:50 | INFO | train_inner | epoch 005:   1309 / 11284 loss=3.662, nll_loss=1.966, ppl=3.91, wps=72374.3, ups=1.22, wpb=59329.2, bsz=2175.1, num_updates=46400, lr=0.000464238, gnorm=0.3, loss_scale=2, train_wall=78, gb_free=39.6, wall=38791
2023-06-12 02:34:11 | INFO | train_inner | epoch 005:   1409 / 11284 loss=3.652, nll_loss=1.956, ppl=3.88, wps=73060.6, ups=1.23, wpb=59461.9, bsz=2219.9, num_updates=46500, lr=0.000463739, gnorm=0.299, loss_scale=2, train_wall=77, gb_free=39.5, wall=38872
2023-06-12 02:35:33 | INFO | train_inner | epoch 005:   1509 / 11284 loss=3.662, nll_loss=1.967, ppl=3.91, wps=72815.2, ups=1.23, wpb=59394.2, bsz=2231.8, num_updates=46600, lr=0.000463241, gnorm=0.306, loss_scale=2, train_wall=77, gb_free=39.5, wall=38954
2023-06-12 02:36:56 | INFO | train_inner | epoch 005:   1609 / 11284 loss=3.665, nll_loss=1.97, ppl=3.92, wps=71479.3, ups=1.2, wpb=59496.5, bsz=2319.4, num_updates=46700, lr=0.000462745, gnorm=0.29, loss_scale=2, train_wall=79, gb_free=38.2, wall=39037
2023-06-12 02:38:19 | INFO | train_inner | epoch 005:   1709 / 11284 loss=3.667, nll_loss=1.972, ppl=3.92, wps=71555.6, ups=1.2, wpb=59437.7, bsz=2258.1, num_updates=46800, lr=0.00046225, gnorm=0.296, loss_scale=2, train_wall=79, gb_free=39.5, wall=39120
2023-06-12 02:39:43 | INFO | train_inner | epoch 005:   1809 / 11284 loss=3.673, nll_loss=1.979, ppl=3.94, wps=71632.7, ups=1.2, wpb=59683.4, bsz=2233, num_updates=46900, lr=0.000461757, gnorm=0.307, loss_scale=4, train_wall=79, gb_free=39.6, wall=39203
2023-06-12 02:40:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 02:41:07 | INFO | train_inner | epoch 005:   1910 / 11284 loss=3.664, nll_loss=1.968, ppl=3.91, wps=70574.3, ups=1.18, wpb=59634, bsz=2263.9, num_updates=47000, lr=0.000461266, gnorm=0.289, loss_scale=2, train_wall=80, gb_free=39.6, wall=39288
2023-06-12 02:42:30 | INFO | train_inner | epoch 005:   2010 / 11284 loss=3.661, nll_loss=1.966, ppl=3.91, wps=71575.8, ups=1.2, wpb=59609.3, bsz=2225.9, num_updates=47100, lr=0.000460776, gnorm=0.298, loss_scale=2, train_wall=79, gb_free=39.6, wall=39371
2023-06-12 02:43:53 | INFO | train_inner | epoch 005:   2110 / 11284 loss=3.661, nll_loss=1.966, ppl=3.91, wps=71756.5, ups=1.2, wpb=59590.4, bsz=2154.8, num_updates=47200, lr=0.000460287, gnorm=0.3, loss_scale=2, train_wall=79, gb_free=39.6, wall=39454
2023-06-12 02:45:17 | INFO | train_inner | epoch 005:   2210 / 11284 loss=3.679, nll_loss=1.986, ppl=3.96, wps=71466.7, ups=1.2, wpb=59537.6, bsz=2322.1, num_updates=47300, lr=0.0004598, gnorm=0.319, loss_scale=2, train_wall=79, gb_free=39.5, wall=39537
2023-06-12 02:46:40 | INFO | train_inner | epoch 005:   2310 / 11284 loss=3.672, nll_loss=1.978, ppl=3.94, wps=71321, ups=1.2, wpb=59323, bsz=2268.3, num_updates=47400, lr=0.000459315, gnorm=0.303, loss_scale=2, train_wall=79, gb_free=39.6, wall=39621
2023-06-12 02:48:03 | INFO | train_inner | epoch 005:   2410 / 11284 loss=3.651, nll_loss=1.955, ppl=3.88, wps=71839.6, ups=1.21, wpb=59511.1, bsz=2170, num_updates=47500, lr=0.000458831, gnorm=0.3, loss_scale=2, train_wall=79, gb_free=39.6, wall=39703
2023-06-12 02:49:25 | INFO | train_inner | epoch 005:   2510 / 11284 loss=3.662, nll_loss=1.967, ppl=3.91, wps=72797.3, ups=1.22, wpb=59668, bsz=2206.2, num_updates=47600, lr=0.000458349, gnorm=0.295, loss_scale=2, train_wall=78, gb_free=39.6, wall=39785
2023-06-12 02:50:47 | INFO | train_inner | epoch 005:   2610 / 11284 loss=3.654, nll_loss=1.958, ppl=3.89, wps=72364.9, ups=1.22, wpb=59491.4, bsz=2233.2, num_updates=47700, lr=0.000457869, gnorm=0.288, loss_scale=2, train_wall=78, gb_free=39.6, wall=39868
2023-06-12 02:52:10 | INFO | train_inner | epoch 005:   2710 / 11284 loss=3.655, nll_loss=1.959, ppl=3.89, wps=71703.4, ups=1.2, wpb=59530.8, bsz=2313, num_updates=47800, lr=0.000457389, gnorm=0.288, loss_scale=2, train_wall=79, gb_free=39.6, wall=39951
2023-06-12 02:53:33 | INFO | train_inner | epoch 005:   2810 / 11284 loss=3.656, nll_loss=1.96, ppl=3.89, wps=71506.1, ups=1.2, wpb=59503.3, bsz=2350.1, num_updates=47900, lr=0.000456912, gnorm=0.296, loss_scale=2, train_wall=79, gb_free=39.6, wall=40034
2023-06-12 02:54:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 02:54:57 | INFO | train_inner | epoch 005:   2911 / 11284 loss=3.655, nll_loss=1.959, ppl=3.89, wps=71104.5, ups=1.19, wpb=59580.3, bsz=2302, num_updates=48000, lr=0.000456435, gnorm=0.297, loss_scale=2, train_wall=80, gb_free=39.6, wall=40118
2023-06-12 02:56:20 | INFO | train_inner | epoch 005:   3011 / 11284 loss=3.659, nll_loss=1.964, ppl=3.9, wps=71404.5, ups=1.2, wpb=59452.6, bsz=2287.4, num_updates=48100, lr=0.000455961, gnorm=0.294, loss_scale=2, train_wall=79, gb_free=39.6, wall=40201
2023-06-12 02:57:43 | INFO | train_inner | epoch 005:   3111 / 11284 loss=3.659, nll_loss=1.964, ppl=3.9, wps=71720.3, ups=1.2, wpb=59680, bsz=2235.4, num_updates=48200, lr=0.000455488, gnorm=0.299, loss_scale=2, train_wall=80, gb_free=39.5, wall=40284
2023-06-12 02:59:07 | INFO | train_inner | epoch 005:   3211 / 11284 loss=3.654, nll_loss=1.958, ppl=3.89, wps=71224.7, ups=1.2, wpb=59416.5, bsz=2293.2, num_updates=48300, lr=0.000455016, gnorm=0.296, loss_scale=2, train_wall=79, gb_free=39.5, wall=40367
2023-06-12 03:00:30 | INFO | train_inner | epoch 005:   3311 / 11284 loss=3.669, nll_loss=1.975, ppl=3.93, wps=71495.7, ups=1.2, wpb=59477.7, bsz=2269.7, num_updates=48400, lr=0.000454545, gnorm=0.302, loss_scale=2, train_wall=79, gb_free=39.6, wall=40451
2023-06-12 03:01:53 | INFO | train_inner | epoch 005:   3411 / 11284 loss=3.663, nll_loss=1.968, ppl=3.91, wps=72266.5, ups=1.21, wpb=59617.3, bsz=2206.9, num_updates=48500, lr=0.000454077, gnorm=0.298, loss_scale=2, train_wall=78, gb_free=39.6, wall=40533
2023-06-12 03:03:15 | INFO | train_inner | epoch 005:   3511 / 11284 loss=3.662, nll_loss=1.967, ppl=3.91, wps=72329.3, ups=1.22, wpb=59465.2, bsz=2167, num_updates=48600, lr=0.000453609, gnorm=0.289, loss_scale=2, train_wall=78, gb_free=39.6, wall=40615
2023-06-12 03:04:37 | INFO | train_inner | epoch 005:   3611 / 11284 loss=3.664, nll_loss=1.969, ppl=3.91, wps=72661.6, ups=1.22, wpb=59420, bsz=2257.5, num_updates=48700, lr=0.000453143, gnorm=0.301, loss_scale=2, train_wall=78, gb_free=39.6, wall=40697
2023-06-12 03:05:58 | INFO | train_inner | epoch 005:   3711 / 11284 loss=3.654, nll_loss=1.959, ppl=3.89, wps=72538.8, ups=1.22, wpb=59378.2, bsz=2268, num_updates=48800, lr=0.000452679, gnorm=0.304, loss_scale=2, train_wall=78, gb_free=39.6, wall=40779
2023-06-12 03:07:21 | INFO | train_inner | epoch 005:   3811 / 11284 loss=3.673, nll_loss=1.979, ppl=3.94, wps=71744, ups=1.21, wpb=59525.5, bsz=2185.1, num_updates=48900, lr=0.000452216, gnorm=0.301, loss_scale=2, train_wall=79, gb_free=39.5, wall=40862
2023-06-12 03:08:44 | INFO | train_inner | epoch 005:   3911 / 11284 loss=3.662, nll_loss=1.966, ppl=3.91, wps=71572.7, ups=1.2, wpb=59414.5, bsz=2270, num_updates=49000, lr=0.000451754, gnorm=0.289, loss_scale=2, train_wall=79, gb_free=39.6, wall=40945
2023-06-12 03:09:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 03:10:07 | INFO | train_inner | epoch 005:   4012 / 11284 loss=3.668, nll_loss=1.974, ppl=3.93, wps=72010, ups=1.21, wpb=59691.3, bsz=2187.7, num_updates=49100, lr=0.000451294, gnorm=0.294, loss_scale=2, train_wall=79, gb_free=39.6, wall=41028
2023-06-12 03:11:29 | INFO | train_inner | epoch 005:   4112 / 11284 loss=3.663, nll_loss=1.968, ppl=3.91, wps=72445.9, ups=1.22, wpb=59528.2, bsz=2254, num_updates=49200, lr=0.000450835, gnorm=0.301, loss_scale=2, train_wall=78, gb_free=39.6, wall=41110
2023-06-12 03:12:52 | INFO | train_inner | epoch 005:   4212 / 11284 loss=3.677, nll_loss=1.984, ppl=3.96, wps=72250.9, ups=1.21, wpb=59611.2, bsz=2290.2, num_updates=49300, lr=0.000450377, gnorm=0.307, loss_scale=2, train_wall=79, gb_free=39.6, wall=41193
2023-06-12 03:14:14 | INFO | train_inner | epoch 005:   4312 / 11284 loss=3.656, nll_loss=1.961, ppl=3.89, wps=72875.9, ups=1.23, wpb=59483.4, bsz=2172.9, num_updates=49400, lr=0.000449921, gnorm=0.289, loss_scale=2, train_wall=78, gb_free=39.6, wall=41274
2023-06-12 03:15:36 | INFO | train_inner | epoch 005:   4412 / 11284 loss=3.664, nll_loss=1.969, ppl=3.92, wps=72599.4, ups=1.22, wpb=59509.7, bsz=2143.6, num_updates=49500, lr=0.000449467, gnorm=0.3, loss_scale=2, train_wall=78, gb_free=39.6, wall=41356
2023-06-12 03:16:58 | INFO | train_inner | epoch 005:   4512 / 11284 loss=3.677, nll_loss=1.984, ppl=3.96, wps=72250.9, ups=1.22, wpb=59329.9, bsz=2187.1, num_updates=49600, lr=0.000449013, gnorm=0.293, loss_scale=2, train_wall=78, gb_free=39.6, wall=41438
2023-06-12 03:18:20 | INFO | train_inner | epoch 005:   4612 / 11284 loss=3.656, nll_loss=1.96, ppl=3.89, wps=72631.3, ups=1.22, wpb=59731.9, bsz=2236, num_updates=49700, lr=0.000448561, gnorm=0.301, loss_scale=2, train_wall=78, gb_free=39.6, wall=41521
2023-06-12 03:19:42 | INFO | train_inner | epoch 005:   4712 / 11284 loss=3.668, nll_loss=1.974, ppl=3.93, wps=72464.3, ups=1.22, wpb=59583, bsz=2193.6, num_updates=49800, lr=0.000448111, gnorm=0.286, loss_scale=2, train_wall=78, gb_free=39.5, wall=41603
2023-06-12 03:21:05 | INFO | train_inner | epoch 005:   4812 / 11284 loss=3.663, nll_loss=1.969, ppl=3.91, wps=71941, ups=1.2, wpb=59760.2, bsz=2192.5, num_updates=49900, lr=0.000447661, gnorm=0.293, loss_scale=2, train_wall=79, gb_free=39.6, wall=41686
2023-06-12 03:22:28 | INFO | train_inner | epoch 005:   4912 / 11284 loss=3.659, nll_loss=1.964, ppl=3.9, wps=71425.3, ups=1.2, wpb=59364.9, bsz=2254.2, num_updates=50000, lr=0.000447214, gnorm=0.308, loss_scale=2, train_wall=79, gb_free=39.5, wall=41769
2023-06-12 03:23:52 | INFO | train_inner | epoch 005:   5012 / 11284 loss=3.66, nll_loss=1.965, ppl=3.91, wps=71485.9, ups=1.2, wpb=59446, bsz=2247.7, num_updates=50100, lr=0.000446767, gnorm=0.283, loss_scale=4, train_wall=79, gb_free=39.5, wall=41852
2023-06-12 03:24:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 03:25:15 | INFO | train_inner | epoch 005:   5113 / 11284 loss=3.652, nll_loss=1.957, ppl=3.88, wps=71711.9, ups=1.2, wpb=59680.5, bsz=2285.9, num_updates=50200, lr=0.000446322, gnorm=0.291, loss_scale=2, train_wall=79, gb_free=39.6, wall=41935
2023-06-12 03:26:37 | INFO | train_inner | epoch 005:   5213 / 11284 loss=3.672, nll_loss=1.978, ppl=3.94, wps=72294, ups=1.21, wpb=59543.1, bsz=2316.8, num_updates=50300, lr=0.000445878, gnorm=0.295, loss_scale=2, train_wall=78, gb_free=39.3, wall=42018
2023-06-12 03:28:00 | INFO | train_inner | epoch 005:   5313 / 11284 loss=3.639, nll_loss=1.942, ppl=3.84, wps=72032.6, ups=1.21, wpb=59458.8, bsz=2194.4, num_updates=50400, lr=0.000445435, gnorm=0.303, loss_scale=2, train_wall=79, gb_free=39.5, wall=42100
2023-06-12 03:29:23 | INFO | train_inner | epoch 005:   5413 / 11284 loss=3.668, nll_loss=1.974, ppl=3.93, wps=71438.1, ups=1.2, wpb=59354.4, bsz=2252.4, num_updates=50500, lr=0.000444994, gnorm=0.299, loss_scale=2, train_wall=79, gb_free=39.6, wall=42183
2023-06-12 03:30:46 | INFO | train_inner | epoch 005:   5513 / 11284 loss=3.668, nll_loss=1.974, ppl=3.93, wps=71310, ups=1.2, wpb=59367.7, bsz=2173.3, num_updates=50600, lr=0.000444554, gnorm=0.305, loss_scale=2, train_wall=80, gb_free=39.6, wall=42267
2023-06-12 03:32:08 | INFO | train_inner | epoch 005:   5613 / 11284 loss=3.655, nll_loss=1.959, ppl=3.89, wps=72034.2, ups=1.21, wpb=59421.3, bsz=2196.6, num_updates=50700, lr=0.000444116, gnorm=0.312, loss_scale=2, train_wall=79, gb_free=39.6, wall=42349
2023-06-12 03:33:32 | INFO | train_inner | epoch 005:   5713 / 11284 loss=3.644, nll_loss=1.947, ppl=3.86, wps=71598.1, ups=1.2, wpb=59505.1, bsz=2176.4, num_updates=50800, lr=0.000443678, gnorm=0.277, loss_scale=2, train_wall=79, gb_free=39.5, wall=42432
2023-06-12 03:34:54 | INFO | train_inner | epoch 005:   5813 / 11284 loss=3.658, nll_loss=1.963, ppl=3.9, wps=72290.5, ups=1.21, wpb=59777.6, bsz=2193.3, num_updates=50900, lr=0.000443242, gnorm=0.304, loss_scale=2, train_wall=79, gb_free=39.6, wall=42515
2023-06-12 03:36:17 | INFO | train_inner | epoch 005:   5913 / 11284 loss=3.655, nll_loss=1.959, ppl=3.89, wps=71968.1, ups=1.21, wpb=59589.2, bsz=2188.9, num_updates=51000, lr=0.000442807, gnorm=0.288, loss_scale=2, train_wall=79, gb_free=39.4, wall=42598
2023-06-12 03:37:40 | INFO | train_inner | epoch 005:   6013 / 11284 loss=3.673, nll_loss=1.98, ppl=3.95, wps=71542.4, ups=1.2, wpb=59601.8, bsz=2321.7, num_updates=51100, lr=0.000442374, gnorm=0.301, loss_scale=2, train_wall=79, gb_free=39.5, wall=42681
2023-06-12 03:39:03 | INFO | train_inner | epoch 005:   6113 / 11284 loss=3.646, nll_loss=1.95, ppl=3.86, wps=72294.2, ups=1.22, wpb=59490.9, bsz=2141.2, num_updates=51200, lr=0.000441942, gnorm=0.294, loss_scale=4, train_wall=79, gb_free=39.6, wall=42763
2023-06-12 03:40:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 03:40:26 | INFO | train_inner | epoch 005:   6214 / 11284 loss=3.661, nll_loss=1.966, ppl=3.91, wps=71241.4, ups=1.2, wpb=59394.8, bsz=2235.5, num_updates=51300, lr=0.000441511, gnorm=0.301, loss_scale=2, train_wall=79, gb_free=39.6, wall=42847
2023-06-12 03:41:49 | INFO | train_inner | epoch 005:   6314 / 11284 loss=3.651, nll_loss=1.955, ppl=3.88, wps=72030.4, ups=1.21, wpb=59510.7, bsz=2153.3, num_updates=51400, lr=0.000441081, gnorm=0.294, loss_scale=2, train_wall=79, gb_free=39.5, wall=42929
2023-06-12 03:43:11 | INFO | train_inner | epoch 005:   6414 / 11284 loss=3.661, nll_loss=1.967, ppl=3.91, wps=72101.2, ups=1.21, wpb=59635.6, bsz=2283.4, num_updates=51500, lr=0.000440653, gnorm=0.288, loss_scale=2, train_wall=78, gb_free=39.6, wall=43012
2023-06-12 03:44:34 | INFO | train_inner | epoch 005:   6514 / 11284 loss=3.654, nll_loss=1.959, ppl=3.89, wps=72180, ups=1.21, wpb=59586.4, bsz=2184.7, num_updates=51600, lr=0.000440225, gnorm=0.299, loss_scale=2, train_wall=79, gb_free=39.5, wall=43095
2023-06-12 03:45:56 | INFO | train_inner | epoch 005:   6614 / 11284 loss=3.662, nll_loss=1.968, ppl=3.91, wps=72304.2, ups=1.21, wpb=59510.6, bsz=2155.7, num_updates=51700, lr=0.000439799, gnorm=0.294, loss_scale=2, train_wall=78, gb_free=39.6, wall=43177
2023-06-12 03:47:19 | INFO | train_inner | epoch 005:   6714 / 11284 loss=3.665, nll_loss=1.971, ppl=3.92, wps=71439.7, ups=1.2, wpb=59401.2, bsz=2215.9, num_updates=51800, lr=0.000439375, gnorm=0.295, loss_scale=2, train_wall=79, gb_free=39.6, wall=43260
2023-06-12 03:48:42 | INFO | train_inner | epoch 005:   6814 / 11284 loss=3.655, nll_loss=1.96, ppl=3.89, wps=71651.5, ups=1.21, wpb=59393.3, bsz=2142.1, num_updates=51900, lr=0.000438951, gnorm=0.286, loss_scale=2, train_wall=79, gb_free=39.6, wall=43343
2023-06-12 03:50:06 | INFO | train_inner | epoch 005:   6914 / 11284 loss=3.655, nll_loss=1.959, ppl=3.89, wps=71086.7, ups=1.19, wpb=59646.9, bsz=2297.2, num_updates=52000, lr=0.000438529, gnorm=0.294, loss_scale=2, train_wall=80, gb_free=39.6, wall=43427
2023-06-12 03:51:29 | INFO | train_inner | epoch 005:   7014 / 11284 loss=3.663, nll_loss=1.969, ppl=3.92, wps=71601.3, ups=1.2, wpb=59463.1, bsz=2217.5, num_updates=52100, lr=0.000438108, gnorm=0.303, loss_scale=2, train_wall=79, gb_free=39.6, wall=43510
2023-06-12 03:52:54 | INFO | train_inner | epoch 005:   7114 / 11284 loss=3.649, nll_loss=1.953, ppl=3.87, wps=70116.9, ups=1.18, wpb=59547.8, bsz=2229, num_updates=52200, lr=0.000437688, gnorm=0.307, loss_scale=2, train_wall=81, gb_free=39.3, wall=43595
2023-06-12 03:54:19 | INFO | train_inner | epoch 005:   7214 / 11284 loss=3.662, nll_loss=1.968, ppl=3.91, wps=69965.3, ups=1.18, wpb=59479.9, bsz=2154.1, num_updates=52300, lr=0.000437269, gnorm=0.3, loss_scale=2, train_wall=81, gb_free=39.6, wall=43680
2023-06-12 03:54:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 03:55:46 | INFO | train_inner | epoch 005:   7315 / 11284 loss=3.656, nll_loss=1.96, ppl=3.89, wps=68617.2, ups=1.16, wpb=59391.7, bsz=2261.7, num_updates=52400, lr=0.000436852, gnorm=0.305, loss_scale=2, train_wall=82, gb_free=39.5, wall=43766
2023-06-12 03:57:11 | INFO | train_inner | epoch 005:   7415 / 11284 loss=3.672, nll_loss=1.978, ppl=3.94, wps=69468.6, ups=1.17, wpb=59338.6, bsz=2213.1, num_updates=52500, lr=0.000436436, gnorm=0.295, loss_scale=2, train_wall=82, gb_free=39.6, wall=43852
2023-06-12 03:58:37 | INFO | train_inner | epoch 005:   7515 / 11284 loss=3.672, nll_loss=1.979, ppl=3.94, wps=69782.5, ups=1.17, wpb=59720, bsz=2113.3, num_updates=52600, lr=0.000436021, gnorm=0.3, loss_scale=2, train_wall=82, gb_free=39.6, wall=43937
2023-06-12 04:00:02 | INFO | train_inner | epoch 005:   7615 / 11284 loss=3.666, nll_loss=1.973, ppl=3.92, wps=70391.3, ups=1.18, wpb=59830.9, bsz=2247.7, num_updates=52700, lr=0.000435607, gnorm=0.286, loss_scale=2, train_wall=81, gb_free=39.6, wall=44022
2023-06-12 04:01:28 | INFO | train_inner | epoch 005:   7715 / 11284 loss=3.645, nll_loss=1.949, ppl=3.86, wps=69445.4, ups=1.17, wpb=59589.9, bsz=2225.2, num_updates=52800, lr=0.000435194, gnorm=0.3, loss_scale=2, train_wall=82, gb_free=39.6, wall=44108
2023-06-12 04:02:52 | INFO | train_inner | epoch 005:   7815 / 11284 loss=3.654, nll_loss=1.959, ppl=3.89, wps=70328.5, ups=1.18, wpb=59628.2, bsz=2223.2, num_updates=52900, lr=0.000434783, gnorm=0.294, loss_scale=2, train_wall=81, gb_free=39.4, wall=44193
2023-06-12 04:04:17 | INFO | train_inner | epoch 005:   7915 / 11284 loss=3.655, nll_loss=1.96, ppl=3.89, wps=70689.8, ups=1.18, wpb=59805.1, bsz=2281.6, num_updates=53000, lr=0.000434372, gnorm=0.306, loss_scale=2, train_wall=80, gb_free=39.6, wall=44278
2023-06-12 04:05:42 | INFO | train_inner | epoch 005:   8015 / 11284 loss=3.648, nll_loss=1.952, ppl=3.87, wps=69672, ups=1.17, wpb=59452.5, bsz=2191.5, num_updates=53100, lr=0.000433963, gnorm=0.294, loss_scale=2, train_wall=81, gb_free=39.6, wall=44363
2023-06-12 04:07:07 | INFO | train_inner | epoch 005:   8115 / 11284 loss=3.639, nll_loss=1.943, ppl=3.84, wps=70381.8, ups=1.18, wpb=59537.4, bsz=2209.5, num_updates=53200, lr=0.000433555, gnorm=0.297, loss_scale=2, train_wall=81, gb_free=39.5, wall=44447
2023-06-12 04:08:28 | INFO | train_inner | epoch 005:   8215 / 11284 loss=3.663, nll_loss=1.969, ppl=3.92, wps=73022.1, ups=1.23, wpb=59511.7, bsz=2230.3, num_updates=53300, lr=0.000433148, gnorm=0.298, loss_scale=2, train_wall=78, gb_free=39.6, wall=44529
2023-06-12 04:09:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 04:09:52 | INFO | train_inner | epoch 005:   8316 / 11284 loss=3.658, nll_loss=1.963, ppl=3.9, wps=70936, ups=1.2, wpb=59357.8, bsz=2225.3, num_updates=53400, lr=0.000432742, gnorm=0.29, loss_scale=2, train_wall=80, gb_free=39.6, wall=44613
2023-06-12 04:11:14 | INFO | train_inner | epoch 005:   8416 / 11284 loss=3.65, nll_loss=1.954, ppl=3.87, wps=72288.8, ups=1.21, wpb=59567.7, bsz=2188.3, num_updates=53500, lr=0.000432338, gnorm=0.314, loss_scale=2, train_wall=79, gb_free=39.5, wall=44695
2023-06-12 04:12:38 | INFO | train_inner | epoch 005:   8516 / 11284 loss=3.653, nll_loss=1.958, ppl=3.89, wps=71681.6, ups=1.2, wpb=59537.3, bsz=2194, num_updates=53600, lr=0.000431934, gnorm=0.295, loss_scale=2, train_wall=79, gb_free=39.6, wall=44778
2023-06-12 04:14:01 | INFO | train_inner | epoch 005:   8616 / 11284 loss=3.665, nll_loss=1.971, ppl=3.92, wps=71285.4, ups=1.2, wpb=59314, bsz=2234.8, num_updates=53700, lr=0.000431532, gnorm=0.294, loss_scale=2, train_wall=79, gb_free=39.6, wall=44861
2023-06-12 04:15:24 | INFO | train_inner | epoch 005:   8716 / 11284 loss=3.679, nll_loss=1.987, ppl=3.96, wps=71089.2, ups=1.2, wpb=59454.6, bsz=2284.7, num_updates=53800, lr=0.000431131, gnorm=0.295, loss_scale=2, train_wall=79, gb_free=39.5, wall=44945
2023-06-12 04:16:48 | INFO | train_inner | epoch 005:   8816 / 11284 loss=3.65, nll_loss=1.954, ppl=3.88, wps=71377.3, ups=1.2, wpb=59371.9, bsz=2226.8, num_updates=53900, lr=0.00043073, gnorm=0.304, loss_scale=2, train_wall=79, gb_free=39.5, wall=45028
2023-06-12 04:18:10 | INFO | train_inner | epoch 005:   8916 / 11284 loss=3.659, nll_loss=1.965, ppl=3.9, wps=72104.7, ups=1.21, wpb=59456.7, bsz=2270.4, num_updates=54000, lr=0.000430331, gnorm=0.299, loss_scale=2, train_wall=78, gb_free=39.6, wall=45111
2023-06-12 04:19:32 | INFO | train_inner | epoch 005:   9016 / 11284 loss=3.652, nll_loss=1.957, ppl=3.88, wps=72494.4, ups=1.22, wpb=59474.6, bsz=2305.6, num_updates=54100, lr=0.000429934, gnorm=0.292, loss_scale=2, train_wall=78, gb_free=39.6, wall=45193
2023-06-12 04:20:55 | INFO | train_inner | epoch 005:   9116 / 11284 loss=3.645, nll_loss=1.949, ppl=3.86, wps=71456.6, ups=1.2, wpb=59485.8, bsz=2255.9, num_updates=54200, lr=0.000429537, gnorm=0.291, loss_scale=2, train_wall=79, gb_free=39.6, wall=45276
2023-06-12 04:22:18 | INFO | train_inner | epoch 005:   9216 / 11284 loss=3.656, nll_loss=1.961, ppl=3.89, wps=72110.6, ups=1.21, wpb=59595.1, bsz=2247.1, num_updates=54300, lr=0.000429141, gnorm=0.297, loss_scale=2, train_wall=78, gb_free=39.6, wall=45359
2023-06-12 04:23:39 | INFO | train_inner | epoch 005:   9316 / 11284 loss=3.656, nll_loss=1.961, ppl=3.89, wps=72882.6, ups=1.23, wpb=59439.7, bsz=2295.8, num_updates=54400, lr=0.000428746, gnorm=0.307, loss_scale=2, train_wall=77, gb_free=39.6, wall=45440
2023-06-12 04:25:02 | INFO | train_inner | epoch 005:   9416 / 11284 loss=3.654, nll_loss=1.959, ppl=3.89, wps=71757.8, ups=1.21, wpb=59405.8, bsz=2214, num_updates=54500, lr=0.000428353, gnorm=0.304, loss_scale=4, train_wall=79, gb_free=39.6, wall=45523
2023-06-12 04:25:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 04:26:26 | INFO | train_inner | epoch 005:   9517 / 11284 loss=3.663, nll_loss=1.969, ppl=3.92, wps=71036.9, ups=1.19, wpb=59790.2, bsz=2287.6, num_updates=54600, lr=0.00042796, gnorm=0.284, loss_scale=2, train_wall=80, gb_free=39.6, wall=45607
2023-06-12 04:27:49 | INFO | train_inner | epoch 005:   9617 / 11284 loss=3.652, nll_loss=1.957, ppl=3.88, wps=71834.5, ups=1.21, wpb=59167.5, bsz=2214, num_updates=54700, lr=0.000427569, gnorm=0.294, loss_scale=2, train_wall=78, gb_free=39.6, wall=45689
2023-06-12 04:29:11 | INFO | train_inner | epoch 005:   9717 / 11284 loss=3.648, nll_loss=1.952, ppl=3.87, wps=72384.8, ups=1.21, wpb=59599.2, bsz=2256.1, num_updates=54800, lr=0.000427179, gnorm=0.315, loss_scale=2, train_wall=78, gb_free=39.6, wall=45772
2023-06-12 04:30:33 | INFO | train_inner | epoch 005:   9817 / 11284 loss=3.648, nll_loss=1.953, ppl=3.87, wps=72643.7, ups=1.22, wpb=59499.5, bsz=2299.7, num_updates=54900, lr=0.00042679, gnorm=0.292, loss_scale=2, train_wall=78, gb_free=39.5, wall=45854
2023-06-12 04:31:57 | INFO | train_inner | epoch 005:   9917 / 11284 loss=3.651, nll_loss=1.956, ppl=3.88, wps=71050, ups=1.2, wpb=59397.2, bsz=2254.1, num_updates=55000, lr=0.000426401, gnorm=0.296, loss_scale=2, train_wall=79, gb_free=39.6, wall=45937
2023-06-12 04:33:20 | INFO | train_inner | epoch 005:  10017 / 11284 loss=3.638, nll_loss=1.941, ppl=3.84, wps=71390.1, ups=1.2, wpb=59641.5, bsz=2233.7, num_updates=55100, lr=0.000426014, gnorm=0.314, loss_scale=2, train_wall=80, gb_free=39.6, wall=46021
2023-06-12 04:34:43 | INFO | train_inner | epoch 005:  10117 / 11284 loss=3.644, nll_loss=1.948, ppl=3.86, wps=71487.9, ups=1.21, wpb=59170.1, bsz=2188.3, num_updates=55200, lr=0.000425628, gnorm=0.306, loss_scale=2, train_wall=79, gb_free=39.6, wall=46104
2023-06-12 04:36:06 | INFO | train_inner | epoch 005:  10217 / 11284 loss=3.663, nll_loss=1.969, ppl=3.92, wps=71355, ups=1.2, wpb=59413.3, bsz=2232.3, num_updates=55300, lr=0.000425243, gnorm=0.306, loss_scale=2, train_wall=79, gb_free=39.6, wall=46187
2023-06-12 04:37:29 | INFO | train_inner | epoch 005:  10317 / 11284 loss=3.652, nll_loss=1.957, ppl=3.88, wps=71350.5, ups=1.2, wpb=59273.6, bsz=2170.7, num_updates=55400, lr=0.000424859, gnorm=0.303, loss_scale=2, train_wall=79, gb_free=38.9, wall=46270
2023-06-12 04:38:52 | INFO | train_inner | epoch 005:  10417 / 11284 loss=3.661, nll_loss=1.966, ppl=3.91, wps=71677.6, ups=1.2, wpb=59530.8, bsz=2252.9, num_updates=55500, lr=0.000424476, gnorm=0.304, loss_scale=2, train_wall=79, gb_free=39.5, wall=46353
2023-06-12 04:40:15 | INFO | train_inner | epoch 005:  10517 / 11284 loss=3.646, nll_loss=1.95, ppl=3.86, wps=71467.8, ups=1.2, wpb=59363.6, bsz=2189.7, num_updates=55600, lr=0.000424094, gnorm=0.298, loss_scale=4, train_wall=79, gb_free=39.5, wall=46436
2023-06-12 04:41:39 | INFO | train_inner | epoch 005:  10617 / 11284 loss=3.649, nll_loss=1.954, ppl=3.87, wps=71460, ups=1.2, wpb=59635.4, bsz=2261.4, num_updates=55700, lr=0.000423714, gnorm=0.286, loss_scale=4, train_wall=79, gb_free=39.6, wall=46519
2023-06-12 04:41:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 04:43:03 | INFO | train_inner | epoch 005:  10718 / 11284 loss=3.627, nll_loss=1.929, ppl=3.81, wps=71135.5, ups=1.2, wpb=59481.1, bsz=2179.6, num_updates=55800, lr=0.000423334, gnorm=0.304, loss_scale=2, train_wall=80, gb_free=39.6, wall=46603
2023-06-12 04:44:25 | INFO | train_inner | epoch 005:  10818 / 11284 loss=3.65, nll_loss=1.955, ppl=3.88, wps=71539.1, ups=1.21, wpb=59338.1, bsz=2190.1, num_updates=55900, lr=0.000422955, gnorm=0.29, loss_scale=2, train_wall=79, gb_free=39.6, wall=46686
2023-06-12 04:45:49 | INFO | train_inner | epoch 005:  10918 / 11284 loss=3.63, nll_loss=1.932, ppl=3.82, wps=71286.1, ups=1.2, wpb=59344.4, bsz=2173.5, num_updates=56000, lr=0.000422577, gnorm=0.305, loss_scale=2, train_wall=79, gb_free=39.6, wall=46769
2023-06-12 04:47:12 | INFO | train_inner | epoch 005:  11018 / 11284 loss=3.652, nll_loss=1.957, ppl=3.88, wps=71594.3, ups=1.21, wpb=59383, bsz=2294.4, num_updates=56100, lr=0.0004222, gnorm=0.292, loss_scale=2, train_wall=79, gb_free=39.6, wall=46852
2023-06-12 04:48:35 | INFO | train_inner | epoch 005:  11118 / 11284 loss=3.66, nll_loss=1.966, ppl=3.91, wps=71424.2, ups=1.2, wpb=59329.4, bsz=2174.7, num_updates=56200, lr=0.000421825, gnorm=0.289, loss_scale=2, train_wall=79, gb_free=39.3, wall=46935
2023-06-12 04:49:58 | INFO | train_inner | epoch 005:  11218 / 11284 loss=3.649, nll_loss=1.953, ppl=3.87, wps=71912.1, ups=1.2, wpb=59768.7, bsz=2238.6, num_updates=56300, lr=0.00042145, gnorm=0.295, loss_scale=2, train_wall=79, gb_free=39.5, wall=47018
2023-06-12 04:50:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-12 04:51:10 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.419 | nll_loss 2.75 | ppl 6.73 | bleu 20.27 | wps 3746 | wpb 2397.5 | bsz 71.5 | num_updates 56366 | best_loss 4.419
2023-06-12 04:51:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 56366 updates
2023-06-12 04:51:10 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint5.pt
2023-06-12 04:51:11 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint5.pt
2023-06-12 04:51:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint5.pt (epoch 5 @ 56366 updates, score 4.419) (writing took 6.309165404178202 seconds)
2023-06-12 04:51:16 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-06-12 04:51:16 | INFO | train | epoch 005 | loss 3.659 | nll_loss 1.964 | ppl 3.9 | wps 71444.2 | ups 1.2 | wpb 59501.3 | bsz 2227.5 | num_updates 56366 | lr 0.000421203 | gnorm 0.298 | loss_scale 2 | train_wall 8911 | gb_free 39.6 | wall 47097
2023-06-12 04:51:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-12 04:51:16 | INFO | fairseq.trainer | begin training epoch 6
2023-06-12 04:51:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-12 04:51:46 | INFO | train_inner | epoch 006:     34 / 11284 loss=3.652, nll_loss=1.956, ppl=3.88, wps=54860, ups=0.93, wpb=59083.1, bsz=2173.7, num_updates=56400, lr=0.000421076, gnorm=0.312, loss_scale=2, train_wall=79, gb_free=39.5, wall=47126
2023-06-12 04:53:12 | INFO | train_inner | epoch 006:    134 / 11284 loss=3.645, nll_loss=1.949, ppl=3.86, wps=68986.1, ups=1.16, wpb=59416.6, bsz=2209.8, num_updates=56500, lr=0.000420703, gnorm=0.293, loss_scale=2, train_wall=82, gb_free=39.5, wall=47212
2023-06-12 04:54:38 | INFO | train_inner | epoch 006:    234 / 11284 loss=3.635, nll_loss=1.938, ppl=3.83, wps=68981.1, ups=1.16, wpb=59434.4, bsz=2202.5, num_updates=56600, lr=0.000420331, gnorm=0.302, loss_scale=2, train_wall=82, gb_free=39.4, wall=47298
2023-06-12 04:56:03 | INFO | train_inner | epoch 006:    334 / 11284 loss=3.632, nll_loss=1.934, ppl=3.82, wps=69781.1, ups=1.17, wpb=59463.5, bsz=2225.5, num_updates=56700, lr=0.000419961, gnorm=0.289, loss_scale=2, train_wall=81, gb_free=39.6, wall=47384
2023-06-12 04:57:28 | INFO | train_inner | epoch 006:    434 / 11284 loss=3.631, nll_loss=1.933, ppl=3.82, wps=70690.4, ups=1.18, wpb=59811.6, bsz=2158.7, num_updates=56800, lr=0.000419591, gnorm=0.293, loss_scale=4, train_wall=81, gb_free=39.5, wall=47468
2023-06-12 04:58:53 | INFO | train_inner | epoch 006:    534 / 11284 loss=3.637, nll_loss=1.94, ppl=3.84, wps=69502.7, ups=1.17, wpb=59470.3, bsz=2186.8, num_updates=56900, lr=0.000419222, gnorm=0.297, loss_scale=4, train_wall=82, gb_free=39.6, wall=47554
2023-06-12 04:59:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 05:00:20 | INFO | train_inner | epoch 006:    635 / 11284 loss=3.633, nll_loss=1.935, ppl=3.82, wps=68856.5, ups=1.16, wpb=59490.1, bsz=2255.2, num_updates=57000, lr=0.000418854, gnorm=0.294, loss_scale=2, train_wall=82, gb_free=39.6, wall=47640
2023-06-12 05:01:46 | INFO | train_inner | epoch 006:    735 / 11284 loss=3.624, nll_loss=1.925, ppl=3.8, wps=69155.8, ups=1.16, wpb=59492.7, bsz=2261.1, num_updates=57100, lr=0.000418487, gnorm=0.301, loss_scale=2, train_wall=82, gb_free=39.5, wall=47726
2023-06-12 05:03:11 | INFO | train_inner | epoch 006:    835 / 11284 loss=3.636, nll_loss=1.939, ppl=3.83, wps=69456.2, ups=1.17, wpb=59451.2, bsz=2249.2, num_updates=57200, lr=0.000418121, gnorm=0.289, loss_scale=2, train_wall=82, gb_free=39.6, wall=47812
2023-06-12 05:04:36 | INFO | train_inner | epoch 006:    935 / 11284 loss=3.632, nll_loss=1.934, ppl=3.82, wps=69820, ups=1.18, wpb=59403.1, bsz=2212.3, num_updates=57300, lr=0.000417756, gnorm=0.293, loss_scale=2, train_wall=81, gb_free=39.6, wall=47897
2023-06-12 05:06:01 | INFO | train_inner | epoch 006:   1035 / 11284 loss=3.636, nll_loss=1.939, ppl=3.83, wps=70115, ups=1.18, wpb=59586.7, bsz=2321.8, num_updates=57400, lr=0.000417392, gnorm=0.305, loss_scale=2, train_wall=81, gb_free=39.6, wall=47982
2023-06-12 05:07:28 | INFO | train_inner | epoch 006:   1135 / 11284 loss=3.624, nll_loss=1.925, ppl=3.8, wps=68963.5, ups=1.16, wpb=59590.1, bsz=2154.9, num_updates=57500, lr=0.000417029, gnorm=0.288, loss_scale=2, train_wall=83, gb_free=39.6, wall=48068
2023-06-12 05:08:53 | INFO | train_inner | epoch 006:   1235 / 11284 loss=3.623, nll_loss=1.924, ppl=3.8, wps=69241.1, ups=1.17, wpb=59381.9, bsz=2167.3, num_updates=57600, lr=0.000416667, gnorm=0.299, loss_scale=2, train_wall=82, gb_free=39.6, wall=48154
2023-06-12 05:10:16 | INFO | train_inner | epoch 006:   1335 / 11284 loss=3.642, nll_loss=1.946, ppl=3.85, wps=72465, ups=1.22, wpb=59604.8, bsz=2269.5, num_updates=57700, lr=0.000416305, gnorm=0.279, loss_scale=2, train_wall=78, gb_free=39.6, wall=48236
2023-06-12 05:11:38 | INFO | train_inner | epoch 006:   1435 / 11284 loss=3.62, nll_loss=1.921, ppl=3.79, wps=72115.7, ups=1.21, wpb=59467.5, bsz=2192.9, num_updates=57800, lr=0.000415945, gnorm=0.308, loss_scale=2, train_wall=78, gb_free=39.6, wall=48319
2023-06-12 05:13:02 | INFO | train_inner | epoch 006:   1535 / 11284 loss=3.623, nll_loss=1.924, ppl=3.79, wps=71775.7, ups=1.2, wpb=59809.8, bsz=2272.2, num_updates=57900, lr=0.000415586, gnorm=0.307, loss_scale=2, train_wall=79, gb_free=39.6, wall=48402
2023-06-12 05:13:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 05:14:26 | INFO | train_inner | epoch 006:   1636 / 11284 loss=3.648, nll_loss=1.951, ppl=3.87, wps=70851.5, ups=1.19, wpb=59569.5, bsz=2287.2, num_updates=58000, lr=0.000415227, gnorm=0.311, loss_scale=2, train_wall=80, gb_free=39.6, wall=48486
2023-06-12 05:15:48 | INFO | train_inner | epoch 006:   1736 / 11284 loss=3.636, nll_loss=1.938, ppl=3.83, wps=72071.5, ups=1.22, wpb=59232.5, bsz=2271.9, num_updates=58100, lr=0.00041487, gnorm=0.303, loss_scale=2, train_wall=78, gb_free=39.6, wall=48568
2023-06-12 05:17:10 | INFO | train_inner | epoch 006:   1836 / 11284 loss=3.634, nll_loss=1.937, ppl=3.83, wps=72399.1, ups=1.21, wpb=59691.8, bsz=2199, num_updates=58200, lr=0.000414513, gnorm=0.29, loss_scale=2, train_wall=78, gb_free=39.6, wall=48651
2023-06-12 05:18:33 | INFO | train_inner | epoch 006:   1936 / 11284 loss=3.619, nll_loss=1.92, ppl=3.78, wps=71792.5, ups=1.2, wpb=59737.5, bsz=2265.8, num_updates=58300, lr=0.000414158, gnorm=0.286, loss_scale=2, train_wall=79, gb_free=39.6, wall=48734
2023-06-12 05:19:55 | INFO | train_inner | epoch 006:   2036 / 11284 loss=3.636, nll_loss=1.938, ppl=3.83, wps=72600.4, ups=1.22, wpb=59439.1, bsz=2148.1, num_updates=58400, lr=0.000413803, gnorm=0.295, loss_scale=2, train_wall=78, gb_free=39.6, wall=48816
2023-06-12 05:21:18 | INFO | train_inner | epoch 006:   2136 / 11284 loss=3.628, nll_loss=1.93, ppl=3.81, wps=71602.5, ups=1.2, wpb=59482.4, bsz=2280.6, num_updates=58500, lr=0.000413449, gnorm=0.3, loss_scale=2, train_wall=79, gb_free=39.4, wall=48899
2023-06-12 05:22:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-06-12 05:22:42 | INFO | train_inner | epoch 006:   2237 / 11284 loss=3.632, nll_loss=1.934, ppl=3.82, wps=71100.6, ups=1.19, wpb=59715.9, bsz=2253.2, num_updates=58600, lr=0.000413096, gnorm=0.313, loss_scale=1, train_wall=80, gb_free=39.5, wall=48983
2023-06-12 05:24:06 | INFO | train_inner | epoch 006:   2337 / 11284 loss=3.634, nll_loss=1.936, ppl=3.83, wps=71562.7, ups=1.2, wpb=59622.8, bsz=2199.3, num_updates=58700, lr=0.000412744, gnorm=0.303, loss_scale=1, train_wall=79, gb_free=39.6, wall=49066
2023-06-12 05:25:28 | INFO | train_inner | epoch 006:   2437 / 11284 loss=3.649, nll_loss=1.953, ppl=3.87, wps=72482.2, ups=1.22, wpb=59402.9, bsz=2257.6, num_updates=58800, lr=0.000412393, gnorm=0.302, loss_scale=1, train_wall=78, gb_free=39.6, wall=49148
2023-06-12 05:26:50 | INFO | train_inner | epoch 006:   2537 / 11284 loss=3.639, nll_loss=1.942, ppl=3.84, wps=72126.5, ups=1.21, wpb=59510.4, bsz=2323.7, num_updates=58900, lr=0.000412043, gnorm=0.287, loss_scale=1, train_wall=78, gb_free=39.4, wall=49231
2023-06-12 05:28:13 | INFO | train_inner | epoch 006:   2637 / 11284 loss=3.647, nll_loss=1.952, ppl=3.87, wps=71744.8, ups=1.21, wpb=59537.9, bsz=2270.1, num_updates=59000, lr=0.000411693, gnorm=0.301, loss_scale=1, train_wall=79, gb_free=39.5, wall=49314
2023-06-12 05:29:36 | INFO | train_inner | epoch 006:   2737 / 11284 loss=3.65, nll_loss=1.954, ppl=3.87, wps=71218.7, ups=1.2, wpb=59297.6, bsz=2258.3, num_updates=59100, lr=0.000411345, gnorm=0.299, loss_scale=1, train_wall=79, gb_free=39.6, wall=49397
2023-06-12 05:31:00 | INFO | train_inner | epoch 006:   2837 / 11284 loss=3.639, nll_loss=1.942, ppl=3.84, wps=71660.8, ups=1.2, wpb=59656.8, bsz=2219.7, num_updates=59200, lr=0.000410997, gnorm=0.294, loss_scale=1, train_wall=79, gb_free=39.5, wall=49480
2023-06-12 05:32:23 | INFO | train_inner | epoch 006:   2937 / 11284 loss=3.639, nll_loss=1.943, ppl=3.84, wps=71375.7, ups=1.2, wpb=59394.1, bsz=2242.2, num_updates=59300, lr=0.000410651, gnorm=0.305, loss_scale=1, train_wall=79, gb_free=39.6, wall=49563
2023-06-12 05:33:45 | INFO | train_inner | epoch 006:   3037 / 11284 loss=3.638, nll_loss=1.941, ppl=3.84, wps=72715.8, ups=1.22, wpb=59421.7, bsz=2188.9, num_updates=59400, lr=0.000410305, gnorm=0.296, loss_scale=1, train_wall=78, gb_free=39.6, wall=49645
2023-06-12 05:35:07 | INFO | train_inner | epoch 006:   3137 / 11284 loss=3.652, nll_loss=1.957, ppl=3.88, wps=72186.7, ups=1.22, wpb=59255.1, bsz=2209.2, num_updates=59500, lr=0.00040996, gnorm=0.302, loss_scale=1, train_wall=78, gb_free=39.6, wall=49727
2023-06-12 05:36:30 | INFO | train_inner | epoch 006:   3237 / 11284 loss=3.627, nll_loss=1.928, ppl=3.81, wps=71670.9, ups=1.2, wpb=59516.2, bsz=2212.1, num_updates=59600, lr=0.000409616, gnorm=0.282, loss_scale=2, train_wall=79, gb_free=39.6, wall=49810
2023-06-12 05:37:53 | INFO | train_inner | epoch 006:   3337 / 11284 loss=3.623, nll_loss=1.924, ppl=3.8, wps=71514.9, ups=1.2, wpb=59504.5, bsz=2239.1, num_updates=59700, lr=0.000409273, gnorm=0.292, loss_scale=2, train_wall=79, gb_free=39.6, wall=49894
2023-06-12 05:39:16 | INFO | train_inner | epoch 006:   3437 / 11284 loss=3.63, nll_loss=1.932, ppl=3.82, wps=71355.7, ups=1.2, wpb=59504.8, bsz=2271.7, num_updates=59800, lr=0.00040893, gnorm=0.301, loss_scale=2, train_wall=79, gb_free=39.6, wall=49977
2023-06-12 05:40:39 | INFO | train_inner | epoch 006:   3537 / 11284 loss=3.628, nll_loss=1.93, ppl=3.81, wps=71728.3, ups=1.2, wpb=59540, bsz=2108.7, num_updates=59900, lr=0.000408589, gnorm=0.292, loss_scale=2, train_wall=79, gb_free=39.6, wall=50060
2023-06-12 05:42:02 | INFO | train_inner | epoch 006:   3637 / 11284 loss=3.624, nll_loss=1.926, ppl=3.8, wps=71619.6, ups=1.2, wpb=59488.5, bsz=2231.8, num_updates=60000, lr=0.000408248, gnorm=0.3, loss_scale=2, train_wall=79, gb_free=39.6, wall=50143
2023-06-12 05:43:26 | INFO | train_inner | epoch 006:   3737 / 11284 loss=3.622, nll_loss=1.923, ppl=3.79, wps=71429.7, ups=1.2, wpb=59512.8, bsz=2247.7, num_updates=60100, lr=0.000407909, gnorm=0.3, loss_scale=2, train_wall=79, gb_free=39.5, wall=50226
2023-06-12 05:44:48 | INFO | train_inner | epoch 006:   3837 / 11284 loss=3.616, nll_loss=1.916, ppl=3.77, wps=71687.7, ups=1.21, wpb=59320.7, bsz=2121, num_updates=60200, lr=0.00040757, gnorm=0.302, loss_scale=2, train_wall=79, gb_free=39.6, wall=50309
2023-06-12 05:46:11 | INFO | train_inner | epoch 006:   3937 / 11284 loss=3.635, nll_loss=1.938, ppl=3.83, wps=71914.6, ups=1.21, wpb=59461.8, bsz=2180.1, num_updates=60300, lr=0.000407231, gnorm=0.296, loss_scale=2, train_wall=79, gb_free=39.6, wall=50392
2023-06-12 05:47:33 | INFO | train_inner | epoch 006:   4037 / 11284 loss=3.637, nll_loss=1.94, ppl=3.84, wps=72924.5, ups=1.22, wpb=59635.7, bsz=2295.5, num_updates=60400, lr=0.000406894, gnorm=0.287, loss_scale=2, train_wall=78, gb_free=39.6, wall=50474
2023-06-12 05:48:55 | INFO | train_inner | epoch 006:   4137 / 11284 loss=3.637, nll_loss=1.941, ppl=3.84, wps=72588.9, ups=1.22, wpb=59544.3, bsz=2236.2, num_updates=60500, lr=0.000406558, gnorm=0.301, loss_scale=2, train_wall=78, gb_free=39.6, wall=50556
2023-06-12 05:50:17 | INFO | train_inner | epoch 006:   4237 / 11284 loss=3.647, nll_loss=1.952, ppl=3.87, wps=72999.5, ups=1.22, wpb=59655.2, bsz=2128.9, num_updates=60600, lr=0.000406222, gnorm=0.298, loss_scale=2, train_wall=78, gb_free=39.4, wall=50637
2023-06-12 05:51:39 | INFO | train_inner | epoch 006:   4337 / 11284 loss=3.634, nll_loss=1.937, ppl=3.83, wps=71823.7, ups=1.21, wpb=59462.6, bsz=2197.7, num_updates=60700, lr=0.000405887, gnorm=0.293, loss_scale=4, train_wall=79, gb_free=39.6, wall=50720
2023-06-12 05:51:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 05:53:04 | INFO | train_inner | epoch 006:   4438 / 11284 loss=3.63, nll_loss=1.932, ppl=3.82, wps=70610.2, ups=1.19, wpb=59413.5, bsz=2152.1, num_updates=60800, lr=0.000405554, gnorm=0.31, loss_scale=2, train_wall=80, gb_free=39.5, wall=50804
2023-06-12 05:54:27 | INFO | train_inner | epoch 006:   4538 / 11284 loss=3.626, nll_loss=1.928, ppl=3.8, wps=71450.9, ups=1.2, wpb=59478.7, bsz=2137, num_updates=60900, lr=0.00040522, gnorm=0.302, loss_scale=2, train_wall=79, gb_free=39.5, wall=50887
2023-06-12 05:55:50 | INFO | train_inner | epoch 006:   4638 / 11284 loss=3.622, nll_loss=1.923, ppl=3.79, wps=71871.6, ups=1.2, wpb=59675.1, bsz=2121.8, num_updates=61000, lr=0.000404888, gnorm=0.284, loss_scale=2, train_wall=79, gb_free=39.6, wall=50970
2023-06-12 05:57:13 | INFO | train_inner | epoch 006:   4738 / 11284 loss=3.625, nll_loss=1.926, ppl=3.8, wps=71244.5, ups=1.2, wpb=59344, bsz=2275.8, num_updates=61100, lr=0.000404557, gnorm=0.297, loss_scale=2, train_wall=79, gb_free=39.6, wall=51054
2023-06-12 05:58:36 | INFO | train_inner | epoch 006:   4838 / 11284 loss=3.654, nll_loss=1.959, ppl=3.89, wps=72014.1, ups=1.21, wpb=59317.4, bsz=2356.3, num_updates=61200, lr=0.000404226, gnorm=0.308, loss_scale=2, train_wall=78, gb_free=39.6, wall=51136
2023-06-12 05:59:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-06-12 05:59:59 | INFO | train_inner | epoch 006:   4939 / 11284 loss=3.618, nll_loss=1.919, ppl=3.78, wps=70859.6, ups=1.19, wpb=59452.3, bsz=2163.1, num_updates=61300, lr=0.000403896, gnorm=0.305, loss_scale=1, train_wall=80, gb_free=39.6, wall=51220
2023-06-12 06:01:21 | INFO | train_inner | epoch 006:   5039 / 11284 loss=3.628, nll_loss=1.93, ppl=3.81, wps=72503.7, ups=1.22, wpb=59369.2, bsz=2189.3, num_updates=61400, lr=0.000403567, gnorm=0.303, loss_scale=1, train_wall=78, gb_free=39.5, wall=51302
2023-06-12 06:02:43 | INFO | train_inner | epoch 006:   5139 / 11284 loss=3.633, nll_loss=1.935, ppl=3.82, wps=72576.7, ups=1.22, wpb=59485.5, bsz=2212.1, num_updates=61500, lr=0.000403239, gnorm=0.293, loss_scale=1, train_wall=78, gb_free=39.6, wall=51384
2023-06-12 06:04:07 | INFO | train_inner | epoch 006:   5239 / 11284 loss=3.624, nll_loss=1.926, ppl=3.8, wps=71534.7, ups=1.2, wpb=59508.4, bsz=2179.2, num_updates=61600, lr=0.000402911, gnorm=0.301, loss_scale=1, train_wall=79, gb_free=39.5, wall=51467
2023-06-12 06:05:30 | INFO | train_inner | epoch 006:   5339 / 11284 loss=3.649, nll_loss=1.953, ppl=3.87, wps=71594.9, ups=1.2, wpb=59569, bsz=2254, num_updates=61700, lr=0.000402585, gnorm=0.29, loss_scale=1, train_wall=79, gb_free=39.5, wall=51550
2023-06-12 06:06:53 | INFO | train_inner | epoch 006:   5439 / 11284 loss=3.634, nll_loss=1.936, ppl=3.83, wps=71987, ups=1.2, wpb=59823.6, bsz=2170.7, num_updates=61800, lr=0.000402259, gnorm=0.298, loss_scale=1, train_wall=79, gb_free=39.6, wall=51633
2023-06-12 06:08:18 | INFO | train_inner | epoch 006:   5539 / 11284 loss=3.628, nll_loss=1.93, ppl=3.81, wps=69969.3, ups=1.18, wpb=59499.7, bsz=2183.9, num_updates=61900, lr=0.000401934, gnorm=0.295, loss_scale=1, train_wall=81, gb_free=39.5, wall=51718
2023-06-12 06:09:43 | INFO | train_inner | epoch 006:   5639 / 11284 loss=3.634, nll_loss=1.937, ppl=3.83, wps=69577.6, ups=1.17, wpb=59328.7, bsz=2236.9, num_updates=62000, lr=0.00040161, gnorm=0.299, loss_scale=1, train_wall=81, gb_free=39.6, wall=51804
2023-06-12 06:11:07 | INFO | train_inner | epoch 006:   5739 / 11284 loss=3.646, nll_loss=1.95, ppl=3.86, wps=71414.3, ups=1.2, wpb=59600.7, bsz=2185.4, num_updates=62100, lr=0.000401286, gnorm=0.311, loss_scale=1, train_wall=80, gb_free=39.6, wall=51887
2023-06-12 06:12:30 | INFO | train_inner | epoch 006:   5839 / 11284 loss=3.641, nll_loss=1.945, ppl=3.85, wps=71737, ups=1.2, wpb=59705.7, bsz=2282.2, num_updates=62200, lr=0.000400963, gnorm=0.314, loss_scale=1, train_wall=79, gb_free=39.6, wall=51970
2023-06-12 06:13:53 | INFO | train_inner | epoch 006:   5939 / 11284 loss=3.629, nll_loss=1.931, ppl=3.81, wps=71183.2, ups=1.2, wpb=59444.2, bsz=2263.5, num_updates=62300, lr=0.000400642, gnorm=0.307, loss_scale=1, train_wall=79, gb_free=39.6, wall=52054
2023-06-12 06:15:16 | INFO | train_inner | epoch 006:   6039 / 11284 loss=3.634, nll_loss=1.937, ppl=3.83, wps=71340, ups=1.2, wpb=59301.1, bsz=2239.7, num_updates=62400, lr=0.00040032, gnorm=0.301, loss_scale=2, train_wall=79, gb_free=39.5, wall=52137
2023-06-12 06:16:39 | INFO | train_inner | epoch 006:   6139 / 11284 loss=3.643, nll_loss=1.947, ppl=3.85, wps=71625.3, ups=1.21, wpb=59297.7, bsz=2228.8, num_updates=62500, lr=0.0004, gnorm=0.297, loss_scale=2, train_wall=79, gb_free=39.6, wall=52220
2023-06-12 06:18:01 | INFO | train_inner | epoch 006:   6239 / 11284 loss=3.631, nll_loss=1.934, ppl=3.82, wps=72696.7, ups=1.22, wpb=59563.7, bsz=2208.1, num_updates=62600, lr=0.00039968, gnorm=0.297, loss_scale=2, train_wall=78, gb_free=39.5, wall=52302
2023-06-12 06:19:25 | INFO | train_inner | epoch 006:   6339 / 11284 loss=3.621, nll_loss=1.923, ppl=3.79, wps=71488.3, ups=1.2, wpb=59676.5, bsz=2322.7, num_updates=62700, lr=0.000399362, gnorm=0.302, loss_scale=2, train_wall=79, gb_free=39.6, wall=52385
2023-06-12 06:20:48 | INFO | train_inner | epoch 006:   6439 / 11284 loss=3.632, nll_loss=1.935, ppl=3.82, wps=71715.6, ups=1.2, wpb=59565.1, bsz=2257.9, num_updates=62800, lr=0.000399043, gnorm=0.289, loss_scale=2, train_wall=79, gb_free=38.5, wall=52468
2023-06-12 06:22:11 | INFO | train_inner | epoch 006:   6539 / 11284 loss=3.64, nll_loss=1.944, ppl=3.85, wps=71528, ups=1.2, wpb=59556.8, bsz=2186.7, num_updates=62900, lr=0.000398726, gnorm=0.294, loss_scale=2, train_wall=79, gb_free=39.5, wall=52552
2023-06-12 06:23:33 | INFO | train_inner | epoch 006:   6639 / 11284 loss=3.632, nll_loss=1.935, ppl=3.82, wps=72494.9, ups=1.22, wpb=59228, bsz=2281.4, num_updates=63000, lr=0.00039841, gnorm=0.288, loss_scale=2, train_wall=78, gb_free=39.6, wall=52633
2023-06-12 06:24:55 | INFO | train_inner | epoch 006:   6739 / 11284 loss=3.642, nll_loss=1.946, ppl=3.85, wps=72186.9, ups=1.21, wpb=59687.5, bsz=2194.9, num_updates=63100, lr=0.000398094, gnorm=0.297, loss_scale=2, train_wall=79, gb_free=39.4, wall=52716
2023-06-12 06:26:19 | INFO | train_inner | epoch 006:   6839 / 11284 loss=3.634, nll_loss=1.937, ppl=3.83, wps=71360.1, ups=1.2, wpb=59423.9, bsz=2269.6, num_updates=63200, lr=0.000397779, gnorm=0.304, loss_scale=2, train_wall=79, gb_free=39.2, wall=52799
2023-06-12 06:27:42 | INFO | train_inner | epoch 006:   6939 / 11284 loss=3.627, nll_loss=1.929, ppl=3.81, wps=71669.3, ups=1.2, wpb=59571.2, bsz=2259.4, num_updates=63300, lr=0.000397464, gnorm=0.296, loss_scale=2, train_wall=79, gb_free=39.6, wall=52882
2023-06-12 06:29:04 | INFO | train_inner | epoch 006:   7039 / 11284 loss=3.644, nll_loss=1.949, ppl=3.86, wps=71800.5, ups=1.21, wpb=59226.3, bsz=2150.2, num_updates=63400, lr=0.000397151, gnorm=0.297, loss_scale=4, train_wall=79, gb_free=39.6, wall=52965
2023-06-12 06:29:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 06:30:28 | INFO | train_inner | epoch 006:   7140 / 11284 loss=3.628, nll_loss=1.931, ppl=3.81, wps=70664.8, ups=1.19, wpb=59438.3, bsz=2224.3, num_updates=63500, lr=0.000396838, gnorm=0.297, loss_scale=2, train_wall=80, gb_free=39.5, wall=53049
2023-06-12 06:31:52 | INFO | train_inner | epoch 006:   7240 / 11284 loss=3.627, nll_loss=1.929, ppl=3.81, wps=71393.9, ups=1.2, wpb=59533.8, bsz=2272.1, num_updates=63600, lr=0.000396526, gnorm=0.297, loss_scale=2, train_wall=80, gb_free=39.6, wall=53132
2023-06-12 06:33:15 | INFO | train_inner | epoch 006:   7340 / 11284 loss=3.636, nll_loss=1.939, ppl=3.84, wps=71636.1, ups=1.21, wpb=59436.6, bsz=2145.9, num_updates=63700, lr=0.000396214, gnorm=0.299, loss_scale=2, train_wall=79, gb_free=39.6, wall=53215
2023-06-12 06:34:38 | INFO | train_inner | epoch 006:   7440 / 11284 loss=3.645, nll_loss=1.949, ppl=3.86, wps=71700.2, ups=1.2, wpb=59621.9, bsz=2372.4, num_updates=63800, lr=0.000395904, gnorm=0.304, loss_scale=2, train_wall=79, gb_free=39.6, wall=53298
2023-06-12 06:36:01 | INFO | train_inner | epoch 006:   7540 / 11284 loss=3.607, nll_loss=1.907, ppl=3.75, wps=71828.8, ups=1.2, wpb=59646.1, bsz=2223.4, num_updates=63900, lr=0.000395594, gnorm=0.29, loss_scale=2, train_wall=79, gb_free=39.5, wall=53382
2023-06-12 06:37:24 | INFO | train_inner | epoch 006:   7640 / 11284 loss=3.621, nll_loss=1.923, ppl=3.79, wps=71671.7, ups=1.2, wpb=59572.6, bsz=2260.6, num_updates=64000, lr=0.000395285, gnorm=0.296, loss_scale=2, train_wall=79, gb_free=39.6, wall=53465
2023-06-12 06:38:46 | INFO | train_inner | epoch 006:   7740 / 11284 loss=3.639, nll_loss=1.943, ppl=3.84, wps=72637.2, ups=1.22, wpb=59632.2, bsz=2295.6, num_updates=64100, lr=0.000394976, gnorm=0.3, loss_scale=2, train_wall=78, gb_free=39.6, wall=53547
2023-06-12 06:40:08 | INFO | train_inner | epoch 006:   7840 / 11284 loss=3.63, nll_loss=1.932, ppl=3.82, wps=72332.2, ups=1.22, wpb=59455.6, bsz=2262.7, num_updates=64200, lr=0.000394669, gnorm=0.297, loss_scale=2, train_wall=78, gb_free=39.6, wall=53629
2023-06-12 06:41:31 | INFO | train_inner | epoch 006:   7940 / 11284 loss=3.628, nll_loss=1.93, ppl=3.81, wps=71748.1, ups=1.21, wpb=59506.3, bsz=2218.7, num_updates=64300, lr=0.000394362, gnorm=0.301, loss_scale=2, train_wall=79, gb_free=39.6, wall=53712
2023-06-12 06:42:55 | INFO | train_inner | epoch 006:   8040 / 11284 loss=3.629, nll_loss=1.932, ppl=3.81, wps=71356.9, ups=1.2, wpb=59455.9, bsz=2271.2, num_updates=64400, lr=0.000394055, gnorm=0.303, loss_scale=2, train_wall=79, gb_free=39.5, wall=53795
2023-06-12 06:43:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 06:44:19 | INFO | train_inner | epoch 006:   8141 / 11284 loss=3.63, nll_loss=1.933, ppl=3.82, wps=70574.8, ups=1.19, wpb=59350.1, bsz=2265.2, num_updates=64500, lr=0.00039375, gnorm=0.294, loss_scale=2, train_wall=80, gb_free=39.6, wall=53879
2023-06-12 06:45:41 | INFO | train_inner | epoch 006:   8241 / 11284 loss=3.613, nll_loss=1.914, ppl=3.77, wps=71898.1, ups=1.21, wpb=59304.5, bsz=2175.4, num_updates=64600, lr=0.000393445, gnorm=0.311, loss_scale=2, train_wall=79, gb_free=39.6, wall=53962
2023-06-12 06:47:04 | INFO | train_inner | epoch 006:   8341 / 11284 loss=3.626, nll_loss=1.929, ppl=3.81, wps=72020.9, ups=1.21, wpb=59638.5, bsz=2252.4, num_updates=64700, lr=0.000393141, gnorm=0.289, loss_scale=2, train_wall=79, gb_free=39.6, wall=54045
2023-06-12 06:48:27 | INFO | train_inner | epoch 006:   8441 / 11284 loss=3.637, nll_loss=1.941, ppl=3.84, wps=72083.9, ups=1.21, wpb=59649.1, bsz=2200, num_updates=64800, lr=0.000392837, gnorm=0.297, loss_scale=2, train_wall=79, gb_free=39.6, wall=54127
2023-06-12 06:49:50 | INFO | train_inner | epoch 006:   8541 / 11284 loss=3.631, nll_loss=1.934, ppl=3.82, wps=71769.3, ups=1.2, wpb=59767.1, bsz=2285.4, num_updates=64900, lr=0.000392534, gnorm=0.295, loss_scale=2, train_wall=79, gb_free=39.6, wall=54211
2023-06-12 06:51:14 | INFO | train_inner | epoch 006:   8641 / 11284 loss=3.635, nll_loss=1.938, ppl=3.83, wps=70749.4, ups=1.19, wpb=59432.1, bsz=2179.1, num_updates=65000, lr=0.000392232, gnorm=0.3, loss_scale=2, train_wall=80, gb_free=39.6, wall=54295
2023-06-12 06:52:36 | INFO | train_inner | epoch 006:   8741 / 11284 loss=3.636, nll_loss=1.94, ppl=3.84, wps=72224.3, ups=1.22, wpb=59358.1, bsz=2242.2, num_updates=65100, lr=0.000391931, gnorm=0.3, loss_scale=2, train_wall=78, gb_free=39.6, wall=54377
2023-06-12 06:53:58 | INFO | train_inner | epoch 006:   8841 / 11284 loss=3.648, nll_loss=1.954, ppl=3.87, wps=72647.1, ups=1.22, wpb=59466.2, bsz=2245.2, num_updates=65200, lr=0.00039163, gnorm=0.295, loss_scale=2, train_wall=78, gb_free=39.5, wall=54459
2023-06-12 06:55:20 | INFO | train_inner | epoch 006:   8941 / 11284 loss=3.633, nll_loss=1.937, ppl=3.83, wps=72511.6, ups=1.22, wpb=59529, bsz=2307.4, num_updates=65300, lr=0.00039133, gnorm=0.288, loss_scale=2, train_wall=78, gb_free=39.6, wall=54541
2023-06-12 06:56:43 | INFO | train_inner | epoch 006:   9041 / 11284 loss=3.62, nll_loss=1.921, ppl=3.79, wps=71532.2, ups=1.2, wpb=59489.9, bsz=2117.2, num_updates=65400, lr=0.000391031, gnorm=0.307, loss_scale=2, train_wall=79, gb_free=39.5, wall=54624
2023-06-12 06:57:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 06:58:07 | INFO | train_inner | epoch 006:   9142 / 11284 loss=3.652, nll_loss=1.957, ppl=3.88, wps=70820.2, ups=1.19, wpb=59389.5, bsz=2197.3, num_updates=65500, lr=0.000390732, gnorm=0.287, loss_scale=2, train_wall=80, gb_free=39.6, wall=54708
2023-06-12 06:59:31 | INFO | train_inner | epoch 006:   9242 / 11284 loss=3.616, nll_loss=1.917, ppl=3.78, wps=71102.8, ups=1.2, wpb=59337.5, bsz=2233.5, num_updates=65600, lr=0.000390434, gnorm=0.286, loss_scale=2, train_wall=79, gb_free=39.6, wall=54791
2023-06-12 07:00:54 | INFO | train_inner | epoch 006:   9342 / 11284 loss=3.629, nll_loss=1.931, ppl=3.81, wps=71133.9, ups=1.2, wpb=59409.5, bsz=2199.3, num_updates=65700, lr=0.000390137, gnorm=0.292, loss_scale=2, train_wall=80, gb_free=39.5, wall=54875
2023-06-12 07:02:19 | INFO | train_inner | epoch 006:   9442 / 11284 loss=3.621, nll_loss=1.923, ppl=3.79, wps=70301.8, ups=1.18, wpb=59642, bsz=2259.7, num_updates=65800, lr=0.000389841, gnorm=0.293, loss_scale=2, train_wall=81, gb_free=39.5, wall=54960
2023-06-12 07:03:43 | INFO | train_inner | epoch 006:   9542 / 11284 loss=3.629, nll_loss=1.932, ppl=3.82, wps=71121.7, ups=1.19, wpb=59533.4, bsz=2224.8, num_updates=65900, lr=0.000389545, gnorm=0.299, loss_scale=2, train_wall=80, gb_free=39.5, wall=55043
2023-06-12 07:05:06 | INFO | train_inner | epoch 006:   9642 / 11284 loss=3.64, nll_loss=1.945, ppl=3.85, wps=71765, ups=1.21, wpb=59498.2, bsz=2155.2, num_updates=66000, lr=0.000389249, gnorm=0.303, loss_scale=2, train_wall=79, gb_free=39.6, wall=55126
2023-06-12 07:06:29 | INFO | train_inner | epoch 006:   9742 / 11284 loss=3.623, nll_loss=1.925, ppl=3.8, wps=71427, ups=1.2, wpb=59449.4, bsz=2243.5, num_updates=66100, lr=0.000388955, gnorm=0.303, loss_scale=2, train_wall=79, gb_free=39.6, wall=55209
2023-06-12 07:07:52 | INFO | train_inner | epoch 006:   9842 / 11284 loss=3.624, nll_loss=1.926, ppl=3.8, wps=71798, ups=1.21, wpb=59427.1, bsz=2109.9, num_updates=66200, lr=0.000388661, gnorm=0.3, loss_scale=2, train_wall=79, gb_free=39.6, wall=55292
2023-06-12 07:09:14 | INFO | train_inner | epoch 006:   9942 / 11284 loss=3.62, nll_loss=1.922, ppl=3.79, wps=72006.4, ups=1.21, wpb=59448, bsz=2190.8, num_updates=66300, lr=0.000388368, gnorm=0.3, loss_scale=2, train_wall=79, gb_free=39.6, wall=55375
2023-06-12 07:10:36 | INFO | train_inner | epoch 006:  10042 / 11284 loss=3.615, nll_loss=1.917, ppl=3.78, wps=72816.9, ups=1.22, wpb=59693.9, bsz=2193.4, num_updates=66400, lr=0.000388075, gnorm=0.302, loss_scale=2, train_wall=78, gb_free=39.6, wall=55457
2023-06-12 07:12:00 | INFO | train_inner | epoch 006:  10142 / 11284 loss=3.629, nll_loss=1.932, ppl=3.81, wps=71209.2, ups=1.2, wpb=59478.6, bsz=2284.4, num_updates=66500, lr=0.000387783, gnorm=0.296, loss_scale=4, train_wall=79, gb_free=39.5, wall=55540
2023-06-12 07:13:23 | INFO | train_inner | epoch 006:  10242 / 11284 loss=3.609, nll_loss=1.909, ppl=3.76, wps=71727.6, ups=1.2, wpb=59659.7, bsz=2313.4, num_updates=66600, lr=0.000387492, gnorm=0.289, loss_scale=4, train_wall=79, gb_free=39.6, wall=55623
2023-06-12 07:14:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 07:14:47 | INFO | train_inner | epoch 006:  10343 / 11284 loss=3.632, nll_loss=1.935, ppl=3.82, wps=70913.1, ups=1.19, wpb=59696.6, bsz=2213.2, num_updates=66700, lr=0.000387202, gnorm=0.296, loss_scale=2, train_wall=80, gb_free=39.5, wall=55708
2023-06-12 07:16:11 | INFO | train_inner | epoch 006:  10443 / 11284 loss=3.633, nll_loss=1.936, ppl=3.83, wps=71242.3, ups=1.2, wpb=59464.2, bsz=2344, num_updates=66800, lr=0.000386912, gnorm=0.296, loss_scale=2, train_wall=79, gb_free=39.6, wall=55791
2023-06-12 07:17:33 | INFO | train_inner | epoch 006:  10543 / 11284 loss=3.627, nll_loss=1.93, ppl=3.81, wps=72047.2, ups=1.21, wpb=59483.5, bsz=2161, num_updates=66900, lr=0.000386622, gnorm=0.295, loss_scale=2, train_wall=79, gb_free=39.6, wall=55874
2023-06-12 07:18:56 | INFO | train_inner | epoch 006:  10643 / 11284 loss=3.631, nll_loss=1.934, ppl=3.82, wps=71872.9, ups=1.21, wpb=59489.2, bsz=2269.9, num_updates=67000, lr=0.000386334, gnorm=0.303, loss_scale=2, train_wall=79, gb_free=39.5, wall=55956
2023-06-12 07:20:18 | INFO | train_inner | epoch 006:  10743 / 11284 loss=3.628, nll_loss=1.93, ppl=3.81, wps=72602.3, ups=1.22, wpb=59501.9, bsz=2185, num_updates=67100, lr=0.000386046, gnorm=0.3, loss_scale=2, train_wall=78, gb_free=39.6, wall=56038
2023-06-12 07:21:41 | INFO | train_inner | epoch 006:  10843 / 11284 loss=3.632, nll_loss=1.935, ppl=3.82, wps=71783.3, ups=1.21, wpb=59452, bsz=2240.9, num_updates=67200, lr=0.000385758, gnorm=0.301, loss_scale=2, train_wall=79, gb_free=39.6, wall=56121
2023-06-12 07:23:04 | INFO | train_inner | epoch 006:  10943 / 11284 loss=3.609, nll_loss=1.91, ppl=3.76, wps=71626.3, ups=1.2, wpb=59662.2, bsz=2224.3, num_updates=67300, lr=0.000385472, gnorm=0.294, loss_scale=2, train_wall=79, gb_free=38.9, wall=56205
2023-06-12 07:24:27 | INFO | train_inner | epoch 006:  11043 / 11284 loss=3.624, nll_loss=1.926, ppl=3.8, wps=71626.1, ups=1.2, wpb=59472.5, bsz=2296.2, num_updates=67400, lr=0.000385186, gnorm=0.297, loss_scale=2, train_wall=79, gb_free=39.5, wall=56288
2023-06-12 07:25:50 | INFO | train_inner | epoch 006:  11143 / 11284 loss=3.626, nll_loss=1.929, ppl=3.81, wps=71583.4, ups=1.21, wpb=59288.3, bsz=2302.4, num_updates=67500, lr=0.0003849, gnorm=0.301, loss_scale=2, train_wall=79, gb_free=39.6, wall=56370
2023-06-12 07:27:13 | INFO | train_inner | epoch 006:  11243 / 11284 loss=3.612, nll_loss=1.913, ppl=3.76, wps=71862.6, ups=1.21, wpb=59593.3, bsz=2185.4, num_updates=67600, lr=0.000384615, gnorm=0.288, loss_scale=2, train_wall=79, gb_free=39.6, wall=56453
2023-06-12 07:27:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-12 07:28:05 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 4.396 | nll_loss 2.723 | ppl 6.6 | bleu 20.86 | wps 3722.9 | wpb 2397.5 | bsz 71.5 | num_updates 67641 | best_loss 4.396
2023-06-12 07:28:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 67641 updates
2023-06-12 07:28:05 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint6.pt
2023-06-12 07:28:06 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint6.pt
2023-06-12 07:28:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint6.pt (epoch 6 @ 67641 updates, score 4.396) (writing took 6.042465622536838 seconds)
2023-06-12 07:28:11 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-06-12 07:28:11 | INFO | train | epoch 006 | loss 3.631 | nll_loss 1.934 | ppl 3.82 | wps 71259.9 | ups 1.2 | wpb 59500.8 | bsz 2227.5 | num_updates 67641 | lr 0.000384499 | gnorm 0.298 | loss_scale 2 | train_wall 8942 | gb_free 39.6 | wall 56511
2023-06-12 07:28:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-12 07:28:11 | INFO | fairseq.trainer | begin training epoch 7
2023-06-12 07:28:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-12 07:29:02 | INFO | train_inner | epoch 007:     59 / 11284 loss=3.622, nll_loss=1.924, ppl=3.79, wps=54250.2, ups=0.92, wpb=59142, bsz=2236.2, num_updates=67700, lr=0.000384331, gnorm=0.305, loss_scale=2, train_wall=80, gb_free=39.5, wall=56562
2023-06-12 07:29:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 07:30:28 | INFO | train_inner | epoch 007:    160 / 11284 loss=3.61, nll_loss=1.91, ppl=3.76, wps=68846, ups=1.16, wpb=59438.9, bsz=2223.4, num_updates=67800, lr=0.000384048, gnorm=0.292, loss_scale=2, train_wall=82, gb_free=39.6, wall=56649
2023-06-12 07:31:50 | INFO | train_inner | epoch 007:    260 / 11284 loss=3.605, nll_loss=1.904, ppl=3.74, wps=72434.3, ups=1.22, wpb=59572.4, bsz=2199.1, num_updates=67900, lr=0.000383765, gnorm=0.299, loss_scale=2, train_wall=78, gb_free=39.5, wall=56731
2023-06-12 07:33:13 | INFO | train_inner | epoch 007:    360 / 11284 loss=3.597, nll_loss=1.895, ppl=3.72, wps=71876.5, ups=1.21, wpb=59487.8, bsz=2191.9, num_updates=68000, lr=0.000383482, gnorm=0.292, loss_scale=2, train_wall=79, gb_free=39.5, wall=56814
2023-06-12 07:34:38 | INFO | train_inner | epoch 007:    460 / 11284 loss=3.609, nll_loss=1.909, ppl=3.76, wps=69980.3, ups=1.18, wpb=59545.6, bsz=2249.5, num_updates=68100, lr=0.000383201, gnorm=0.292, loss_scale=2, train_wall=81, gb_free=39.6, wall=56899
2023-06-12 07:36:02 | INFO | train_inner | epoch 007:    560 / 11284 loss=3.616, nll_loss=1.917, ppl=3.78, wps=71400, ups=1.2, wpb=59478, bsz=2302.1, num_updates=68200, lr=0.00038292, gnorm=0.295, loss_scale=2, train_wall=79, gb_free=39.6, wall=56982
2023-06-12 07:37:24 | INFO | train_inner | epoch 007:    660 / 11284 loss=3.613, nll_loss=1.914, ppl=3.77, wps=71785.7, ups=1.21, wpb=59548.2, bsz=2151, num_updates=68300, lr=0.000382639, gnorm=0.29, loss_scale=2, train_wall=79, gb_free=39.6, wall=57065
2023-06-12 07:38:48 | INFO | train_inner | epoch 007:    760 / 11284 loss=3.598, nll_loss=1.897, ppl=3.72, wps=71324.3, ups=1.2, wpb=59364.6, bsz=2262, num_updates=68400, lr=0.00038236, gnorm=0.296, loss_scale=2, train_wall=79, gb_free=39.5, wall=57148
2023-06-12 07:40:11 | INFO | train_inner | epoch 007:    860 / 11284 loss=3.611, nll_loss=1.912, ppl=3.76, wps=71820.8, ups=1.2, wpb=59645, bsz=2209.2, num_updates=68500, lr=0.00038208, gnorm=0.284, loss_scale=2, train_wall=79, gb_free=39.6, wall=57231
2023-06-12 07:41:34 | INFO | train_inner | epoch 007:    960 / 11284 loss=3.618, nll_loss=1.919, ppl=3.78, wps=71864.3, ups=1.21, wpb=59515.4, bsz=2204.9, num_updates=68600, lr=0.000381802, gnorm=0.29, loss_scale=2, train_wall=79, gb_free=39.6, wall=57314
2023-06-12 07:42:56 | INFO | train_inner | epoch 007:   1060 / 11284 loss=3.601, nll_loss=1.9, ppl=3.73, wps=71897.6, ups=1.21, wpb=59425.4, bsz=2264, num_updates=68700, lr=0.000381524, gnorm=0.311, loss_scale=2, train_wall=79, gb_free=39.5, wall=57397
2023-06-12 07:43:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 07:44:19 | INFO | train_inner | epoch 007:   1161 / 11284 loss=3.616, nll_loss=1.917, ppl=3.78, wps=72153.2, ups=1.21, wpb=59549.7, bsz=2250.4, num_updates=68800, lr=0.000381246, gnorm=0.297, loss_scale=2, train_wall=78, gb_free=39.6, wall=57479
2023-06-12 07:45:40 | INFO | train_inner | epoch 007:   1261 / 11284 loss=3.605, nll_loss=1.904, ppl=3.74, wps=72888.5, ups=1.23, wpb=59282.6, bsz=2221, num_updates=68900, lr=0.00038097, gnorm=0.289, loss_scale=2, train_wall=77, gb_free=39.6, wall=57561
2023-06-12 07:46:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-06-12 07:47:03 | INFO | train_inner | epoch 007:   1362 / 11284 loss=3.614, nll_loss=1.915, ppl=3.77, wps=72227.2, ups=1.21, wpb=59598.6, bsz=2295.7, num_updates=69000, lr=0.000380693, gnorm=0.294, loss_scale=1, train_wall=79, gb_free=39.5, wall=57643
2023-06-12 07:48:25 | INFO | train_inner | epoch 007:   1462 / 11284 loss=3.612, nll_loss=1.912, ppl=3.76, wps=72226.3, ups=1.21, wpb=59533, bsz=2216.7, num_updates=69100, lr=0.000380418, gnorm=0.302, loss_scale=1, train_wall=78, gb_free=39.5, wall=57726
2023-06-12 07:49:48 | INFO | train_inner | epoch 007:   1562 / 11284 loss=3.61, nll_loss=1.91, ppl=3.76, wps=71734.1, ups=1.21, wpb=59457.8, bsz=2207.9, num_updates=69200, lr=0.000380143, gnorm=0.305, loss_scale=1, train_wall=79, gb_free=38.8, wall=57808
2023-06-12 07:51:11 | INFO | train_inner | epoch 007:   1662 / 11284 loss=3.611, nll_loss=1.911, ppl=3.76, wps=71969.7, ups=1.21, wpb=59707.5, bsz=2187.2, num_updates=69300, lr=0.000379869, gnorm=0.298, loss_scale=1, train_wall=79, gb_free=39.6, wall=57891
2023-06-12 07:52:34 | INFO | train_inner | epoch 007:   1762 / 11284 loss=3.623, nll_loss=1.925, ppl=3.8, wps=71615.5, ups=1.2, wpb=59718.7, bsz=2250.4, num_updates=69400, lr=0.000379595, gnorm=0.298, loss_scale=1, train_wall=79, gb_free=39.6, wall=57975
2023-06-12 07:53:57 | INFO | train_inner | epoch 007:   1862 / 11284 loss=3.624, nll_loss=1.926, ppl=3.8, wps=71548.9, ups=1.21, wpb=59348.3, bsz=2137, num_updates=69500, lr=0.000379322, gnorm=0.302, loss_scale=1, train_wall=79, gb_free=39.6, wall=58058
2023-06-12 07:55:20 | INFO | train_inner | epoch 007:   1962 / 11284 loss=3.628, nll_loss=1.931, ppl=3.81, wps=71786.9, ups=1.2, wpb=59578.1, bsz=2221.1, num_updates=69600, lr=0.000379049, gnorm=0.292, loss_scale=1, train_wall=79, gb_free=39.5, wall=58141
2023-06-12 07:56:43 | INFO | train_inner | epoch 007:   2062 / 11284 loss=3.619, nll_loss=1.921, ppl=3.79, wps=71303.5, ups=1.2, wpb=59292.3, bsz=2170.5, num_updates=69700, lr=0.000378777, gnorm=0.304, loss_scale=1, train_wall=79, gb_free=39.6, wall=58224
2023-06-12 07:58:06 | INFO | train_inner | epoch 007:   2162 / 11284 loss=3.603, nll_loss=1.902, ppl=3.74, wps=71956.7, ups=1.21, wpb=59683, bsz=2212.3, num_updates=69800, lr=0.000378506, gnorm=0.293, loss_scale=1, train_wall=79, gb_free=39.6, wall=58307
2023-06-12 07:59:29 | INFO | train_inner | epoch 007:   2262 / 11284 loss=3.606, nll_loss=1.906, ppl=3.75, wps=71495.6, ups=1.2, wpb=59442.3, bsz=2271.5, num_updates=69900, lr=0.000378235, gnorm=0.294, loss_scale=1, train_wall=79, gb_free=39.6, wall=58390
2023-06-12 08:00:52 | INFO | train_inner | epoch 007:   2362 / 11284 loss=3.625, nll_loss=1.927, ppl=3.8, wps=72488.4, ups=1.22, wpb=59520.1, bsz=2145.8, num_updates=70000, lr=0.000377964, gnorm=0.295, loss_scale=2, train_wall=78, gb_free=39.5, wall=58472
2023-06-12 08:02:15 | INFO | train_inner | epoch 007:   2462 / 11284 loss=3.606, nll_loss=1.905, ppl=3.75, wps=71164.1, ups=1.19, wpb=59649.1, bsz=2366.8, num_updates=70100, lr=0.000377695, gnorm=0.306, loss_scale=2, train_wall=80, gb_free=39.5, wall=58556
2023-06-12 08:03:39 | INFO | train_inner | epoch 007:   2562 / 11284 loss=3.616, nll_loss=1.917, ppl=3.78, wps=71057, ups=1.2, wpb=59380.9, bsz=2275, num_updates=70200, lr=0.000377426, gnorm=0.299, loss_scale=2, train_wall=80, gb_free=39.6, wall=58640
2023-06-12 08:05:02 | INFO | train_inner | epoch 007:   2662 / 11284 loss=3.614, nll_loss=1.915, ppl=3.77, wps=71614.9, ups=1.2, wpb=59489.8, bsz=2250.6, num_updates=70300, lr=0.000377157, gnorm=0.305, loss_scale=2, train_wall=79, gb_free=39.6, wall=58723
2023-06-12 08:06:25 | INFO | train_inner | epoch 007:   2762 / 11284 loss=3.621, nll_loss=1.923, ppl=3.79, wps=72005.1, ups=1.21, wpb=59547, bsz=2212.3, num_updates=70400, lr=0.000376889, gnorm=0.292, loss_scale=2, train_wall=79, gb_free=39.6, wall=58805
2023-06-12 08:07:47 | INFO | train_inner | epoch 007:   2862 / 11284 loss=3.602, nll_loss=1.901, ppl=3.74, wps=71589.9, ups=1.21, wpb=59242, bsz=2179.2, num_updates=70500, lr=0.000376622, gnorm=0.289, loss_scale=2, train_wall=79, gb_free=39.6, wall=58888
2023-06-12 08:09:10 | INFO | train_inner | epoch 007:   2962 / 11284 loss=3.625, nll_loss=1.927, ppl=3.8, wps=71901.4, ups=1.21, wpb=59402.7, bsz=2312.5, num_updates=70600, lr=0.000376355, gnorm=0.301, loss_scale=2, train_wall=79, gb_free=39.6, wall=58971
2023-06-12 08:10:33 | INFO | train_inner | epoch 007:   3062 / 11284 loss=3.619, nll_loss=1.92, ppl=3.78, wps=71561.7, ups=1.2, wpb=59508.1, bsz=2214.1, num_updates=70700, lr=0.000376089, gnorm=0.294, loss_scale=2, train_wall=79, gb_free=39.6, wall=59054
2023-06-12 08:11:56 | INFO | train_inner | epoch 007:   3162 / 11284 loss=3.609, nll_loss=1.909, ppl=3.76, wps=71752.9, ups=1.2, wpb=59640.3, bsz=2267, num_updates=70800, lr=0.000375823, gnorm=0.303, loss_scale=2, train_wall=79, gb_free=39.5, wall=59137
2023-06-12 08:13:20 | INFO | train_inner | epoch 007:   3262 / 11284 loss=3.608, nll_loss=1.908, ppl=3.75, wps=71390.8, ups=1.2, wpb=59600.8, bsz=2213.3, num_updates=70900, lr=0.000375558, gnorm=0.299, loss_scale=2, train_wall=79, gb_free=39.6, wall=59220
2023-06-12 08:14:43 | INFO | train_inner | epoch 007:   3362 / 11284 loss=3.622, nll_loss=1.924, ppl=3.8, wps=71608.2, ups=1.21, wpb=59397.9, bsz=2213, num_updates=71000, lr=0.000375293, gnorm=0.303, loss_scale=4, train_wall=79, gb_free=39.6, wall=59303
2023-06-12 08:16:06 | INFO | train_inner | epoch 007:   3462 / 11284 loss=3.608, nll_loss=1.908, ppl=3.75, wps=71465.5, ups=1.2, wpb=59425.3, bsz=2228.8, num_updates=71100, lr=0.000375029, gnorm=0.283, loss_scale=4, train_wall=79, gb_free=39.6, wall=59387
2023-06-12 08:17:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 08:17:29 | INFO | train_inner | epoch 007:   3563 / 11284 loss=3.603, nll_loss=1.902, ppl=3.74, wps=71610.1, ups=1.2, wpb=59641.8, bsz=2320.1, num_updates=71200, lr=0.000374766, gnorm=0.304, loss_scale=2, train_wall=79, gb_free=39.5, wall=59470
2023-06-12 08:18:51 | INFO | train_inner | epoch 007:   3663 / 11284 loss=3.607, nll_loss=1.907, ppl=3.75, wps=72775.9, ups=1.22, wpb=59439.4, bsz=2262, num_updates=71300, lr=0.000374503, gnorm=0.304, loss_scale=2, train_wall=78, gb_free=39.6, wall=59552
2023-06-12 08:20:13 | INFO | train_inner | epoch 007:   3763 / 11284 loss=3.615, nll_loss=1.916, ppl=3.77, wps=72615.9, ups=1.22, wpb=59401.6, bsz=2224.2, num_updates=71400, lr=0.000374241, gnorm=0.302, loss_scale=2, train_wall=78, gb_free=39.6, wall=59633
2023-06-12 08:21:35 | INFO | train_inner | epoch 007:   3863 / 11284 loss=3.611, nll_loss=1.911, ppl=3.76, wps=72547.8, ups=1.22, wpb=59417.7, bsz=2212.4, num_updates=71500, lr=0.000373979, gnorm=0.309, loss_scale=2, train_wall=78, gb_free=39.6, wall=59715
2023-06-12 08:22:58 | INFO | train_inner | epoch 007:   3963 / 11284 loss=3.618, nll_loss=1.92, ppl=3.78, wps=71479.5, ups=1.2, wpb=59534.5, bsz=2306.7, num_updates=71600, lr=0.000373718, gnorm=0.3, loss_scale=2, train_wall=79, gb_free=39.5, wall=59799
2023-06-12 08:24:22 | INFO | train_inner | epoch 007:   4063 / 11284 loss=3.631, nll_loss=1.934, ppl=3.82, wps=71208.3, ups=1.2, wpb=59570.7, bsz=2280.2, num_updates=71700, lr=0.000373457, gnorm=0.313, loss_scale=2, train_wall=79, gb_free=39.6, wall=59882
2023-06-12 08:25:44 | INFO | train_inner | epoch 007:   4163 / 11284 loss=3.607, nll_loss=1.907, ppl=3.75, wps=71936.2, ups=1.21, wpb=59500.3, bsz=2284.6, num_updates=71800, lr=0.000373197, gnorm=0.296, loss_scale=2, train_wall=79, gb_free=39.6, wall=59965
2023-06-12 08:27:07 | INFO | train_inner | epoch 007:   4263 / 11284 loss=3.614, nll_loss=1.915, ppl=3.77, wps=71812.9, ups=1.2, wpb=59613.1, bsz=2214.8, num_updates=71900, lr=0.000372937, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.6, wall=60048
2023-06-12 08:28:30 | INFO | train_inner | epoch 007:   4363 / 11284 loss=3.607, nll_loss=1.908, ppl=3.75, wps=71572.6, ups=1.2, wpb=59482.1, bsz=2275, num_updates=72000, lr=0.000372678, gnorm=0.305, loss_scale=2, train_wall=79, gb_free=39.6, wall=60131
2023-06-12 08:29:54 | INFO | train_inner | epoch 007:   4463 / 11284 loss=3.622, nll_loss=1.924, ppl=3.79, wps=71245.9, ups=1.2, wpb=59441.1, bsz=2281.2, num_updates=72100, lr=0.000372419, gnorm=0.306, loss_scale=2, train_wall=79, gb_free=39.6, wall=60214
2023-06-12 08:31:17 | INFO | train_inner | epoch 007:   4563 / 11284 loss=3.615, nll_loss=1.916, ppl=3.77, wps=71409.4, ups=1.2, wpb=59444.9, bsz=2255.7, num_updates=72200, lr=0.000372161, gnorm=0.295, loss_scale=4, train_wall=79, gb_free=39.6, wall=60298
2023-06-12 08:31:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 08:32:41 | INFO | train_inner | epoch 007:   4664 / 11284 loss=3.612, nll_loss=1.913, ppl=3.77, wps=71406.5, ups=1.2, wpb=59580.4, bsz=2241.4, num_updates=72300, lr=0.000371904, gnorm=0.312, loss_scale=2, train_wall=80, gb_free=39.6, wall=60381
2023-06-12 08:34:02 | INFO | train_inner | epoch 007:   4764 / 11284 loss=3.608, nll_loss=1.909, ppl=3.75, wps=72632.2, ups=1.22, wpb=59346, bsz=2203.5, num_updates=72400, lr=0.000371647, gnorm=0.298, loss_scale=2, train_wall=78, gb_free=39.6, wall=60463
2023-06-12 08:35:25 | INFO | train_inner | epoch 007:   4864 / 11284 loss=3.612, nll_loss=1.913, ppl=3.77, wps=71890.7, ups=1.2, wpb=59705.5, bsz=2222.6, num_updates=72500, lr=0.000371391, gnorm=0.301, loss_scale=2, train_wall=79, gb_free=39.6, wall=60546
2023-06-12 08:36:48 | INFO | train_inner | epoch 007:   4964 / 11284 loss=3.628, nll_loss=1.931, ppl=3.81, wps=71838.7, ups=1.21, wpb=59590.2, bsz=2300.1, num_updates=72600, lr=0.000371135, gnorm=0.302, loss_scale=2, train_wall=79, gb_free=39.6, wall=60629
2023-06-12 08:38:11 | INFO | train_inner | epoch 007:   5064 / 11284 loss=3.62, nll_loss=1.921, ppl=3.79, wps=71539.8, ups=1.21, wpb=59349.7, bsz=2165.8, num_updates=72700, lr=0.000370879, gnorm=0.304, loss_scale=2, train_wall=79, gb_free=39.6, wall=60712
2023-06-12 08:39:34 | INFO | train_inner | epoch 007:   5164 / 11284 loss=3.616, nll_loss=1.917, ppl=3.78, wps=72302.4, ups=1.21, wpb=59585.2, bsz=2264, num_updates=72800, lr=0.000370625, gnorm=0.294, loss_scale=2, train_wall=78, gb_free=39.6, wall=60794
2023-06-12 08:40:57 | INFO | train_inner | epoch 007:   5264 / 11284 loss=3.603, nll_loss=1.903, ppl=3.74, wps=71504.4, ups=1.2, wpb=59441.6, bsz=2180.2, num_updates=72900, lr=0.00037037, gnorm=0.305, loss_scale=2, train_wall=79, gb_free=39.5, wall=60877
2023-06-12 08:42:20 | INFO | train_inner | epoch 007:   5364 / 11284 loss=3.608, nll_loss=1.908, ppl=3.75, wps=71230.1, ups=1.2, wpb=59305.2, bsz=2206, num_updates=73000, lr=0.000370117, gnorm=0.298, loss_scale=2, train_wall=79, gb_free=38.9, wall=60961
2023-06-12 08:43:43 | INFO | train_inner | epoch 007:   5464 / 11284 loss=3.605, nll_loss=1.905, ppl=3.75, wps=72188.2, ups=1.21, wpb=59731.6, bsz=2209.8, num_updates=73100, lr=0.000369863, gnorm=0.297, loss_scale=2, train_wall=79, gb_free=39.5, wall=61043
2023-06-12 08:45:06 | INFO | train_inner | epoch 007:   5564 / 11284 loss=3.609, nll_loss=1.91, ppl=3.76, wps=71547, ups=1.2, wpb=59533.3, bsz=2374.3, num_updates=73200, lr=0.000369611, gnorm=0.295, loss_scale=2, train_wall=79, gb_free=39.6, wall=61127
2023-06-12 08:46:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 08:46:29 | INFO | train_inner | epoch 007:   5665 / 11284 loss=3.6, nll_loss=1.899, ppl=3.73, wps=72058.6, ups=1.21, wpb=59702.4, bsz=2217.2, num_updates=73300, lr=0.000369358, gnorm=0.294, loss_scale=2, train_wall=79, gb_free=39.6, wall=61209
2023-06-12 08:47:50 | INFO | train_inner | epoch 007:   5765 / 11284 loss=3.618, nll_loss=1.92, ppl=3.79, wps=72772.9, ups=1.23, wpb=59358.8, bsz=2076.6, num_updates=73400, lr=0.000369107, gnorm=0.294, loss_scale=2, train_wall=78, gb_free=39.6, wall=61291
2023-06-12 08:49:13 | INFO | train_inner | epoch 007:   5865 / 11284 loss=3.605, nll_loss=1.906, ppl=3.75, wps=71553.9, ups=1.2, wpb=59409.6, bsz=2215.4, num_updates=73500, lr=0.000368856, gnorm=0.295, loss_scale=2, train_wall=79, gb_free=39.6, wall=61374
2023-06-12 08:50:36 | INFO | train_inner | epoch 007:   5965 / 11284 loss=3.618, nll_loss=1.919, ppl=3.78, wps=72516.9, ups=1.22, wpb=59568.9, bsz=2176.1, num_updates=73600, lr=0.000368605, gnorm=0.286, loss_scale=2, train_wall=78, gb_free=39.6, wall=61456
2023-06-12 08:51:58 | INFO | train_inner | epoch 007:   6065 / 11284 loss=3.605, nll_loss=1.905, ppl=3.75, wps=71690.9, ups=1.21, wpb=59400.6, bsz=2235.7, num_updates=73700, lr=0.000368355, gnorm=0.307, loss_scale=2, train_wall=79, gb_free=39.6, wall=61539
2023-06-12 08:53:21 | INFO | train_inner | epoch 007:   6165 / 11284 loss=3.625, nll_loss=1.927, ppl=3.8, wps=71604.4, ups=1.21, wpb=59370.7, bsz=2308.2, num_updates=73800, lr=0.000368105, gnorm=0.303, loss_scale=2, train_wall=79, gb_free=39.6, wall=61622
2023-06-12 08:54:44 | INFO | train_inner | epoch 007:   6265 / 11284 loss=3.598, nll_loss=1.898, ppl=3.73, wps=71756.4, ups=1.2, wpb=59630.2, bsz=2170.4, num_updates=73900, lr=0.000367856, gnorm=0.286, loss_scale=2, train_wall=79, gb_free=39.6, wall=61705
2023-06-12 08:56:06 | INFO | train_inner | epoch 007:   6365 / 11284 loss=3.605, nll_loss=1.905, ppl=3.75, wps=73011.7, ups=1.22, wpb=59645.2, bsz=2147.1, num_updates=74000, lr=0.000367607, gnorm=0.309, loss_scale=2, train_wall=78, gb_free=39.6, wall=61787
2023-06-12 08:57:29 | INFO | train_inner | epoch 007:   6465 / 11284 loss=3.633, nll_loss=1.937, ppl=3.83, wps=71683.9, ups=1.21, wpb=59320.3, bsz=2215.1, num_updates=74100, lr=0.000367359, gnorm=0.306, loss_scale=2, train_wall=79, gb_free=39.5, wall=61869
2023-06-12 08:58:52 | INFO | train_inner | epoch 007:   6565 / 11284 loss=3.627, nll_loss=1.93, ppl=3.81, wps=71346.4, ups=1.2, wpb=59265.7, bsz=2271.4, num_updates=74200, lr=0.000367112, gnorm=0.294, loss_scale=2, train_wall=79, gb_free=39.6, wall=61953
2023-06-12 09:00:15 | INFO | train_inner | epoch 007:   6665 / 11284 loss=3.595, nll_loss=1.894, ppl=3.72, wps=71956.2, ups=1.21, wpb=59668.1, bsz=2206.9, num_updates=74300, lr=0.000366864, gnorm=0.294, loss_scale=4, train_wall=79, gb_free=39.5, wall=62035
2023-06-12 09:01:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 09:01:39 | INFO | train_inner | epoch 007:   6766 / 11284 loss=3.616, nll_loss=1.917, ppl=3.78, wps=70837.1, ups=1.19, wpb=59508, bsz=2166.8, num_updates=74400, lr=0.000366618, gnorm=0.302, loss_scale=2, train_wall=80, gb_free=39.6, wall=62119
2023-06-12 09:03:01 | INFO | train_inner | epoch 007:   6866 / 11284 loss=3.618, nll_loss=1.92, ppl=3.78, wps=72255.9, ups=1.22, wpb=59430.1, bsz=2221.6, num_updates=74500, lr=0.000366372, gnorm=0.294, loss_scale=2, train_wall=78, gb_free=39.5, wall=62202
2023-06-12 09:04:24 | INFO | train_inner | epoch 007:   6966 / 11284 loss=3.61, nll_loss=1.911, ppl=3.76, wps=71720.8, ups=1.2, wpb=59588.6, bsz=2227.4, num_updates=74600, lr=0.000366126, gnorm=0.302, loss_scale=2, train_wall=79, gb_free=39.6, wall=62285
2023-06-12 09:05:48 | INFO | train_inner | epoch 007:   7066 / 11284 loss=3.61, nll_loss=1.911, ppl=3.76, wps=71388.5, ups=1.2, wpb=59453.3, bsz=2253.7, num_updates=74700, lr=0.000365881, gnorm=0.3, loss_scale=2, train_wall=79, gb_free=38.9, wall=62368
2023-06-12 09:07:11 | INFO | train_inner | epoch 007:   7166 / 11284 loss=3.6, nll_loss=1.9, ppl=3.73, wps=71683.9, ups=1.2, wpb=59665.5, bsz=2234.7, num_updates=74800, lr=0.000365636, gnorm=0.292, loss_scale=2, train_wall=79, gb_free=39.6, wall=62451
2023-06-12 09:08:34 | INFO | train_inner | epoch 007:   7266 / 11284 loss=3.598, nll_loss=1.897, ppl=3.72, wps=71694.9, ups=1.2, wpb=59523.2, bsz=2189.1, num_updates=74900, lr=0.000365392, gnorm=0.298, loss_scale=2, train_wall=79, gb_free=39.5, wall=62534
2023-06-12 09:09:57 | INFO | train_inner | epoch 007:   7366 / 11284 loss=3.598, nll_loss=1.897, ppl=3.72, wps=71821.4, ups=1.21, wpb=59585.9, bsz=2131.5, num_updates=75000, lr=0.000365148, gnorm=0.3, loss_scale=2, train_wall=79, gb_free=39.5, wall=62617
2023-06-12 09:11:20 | INFO | train_inner | epoch 007:   7466 / 11284 loss=3.621, nll_loss=1.924, ppl=3.79, wps=71710.8, ups=1.2, wpb=59520.2, bsz=2220.6, num_updates=75100, lr=0.000364905, gnorm=0.303, loss_scale=2, train_wall=79, gb_free=39.6, wall=62700
2023-06-12 09:12:44 | INFO | train_inner | epoch 007:   7566 / 11284 loss=3.613, nll_loss=1.914, ppl=3.77, wps=70875.7, ups=1.19, wpb=59501.1, bsz=2297.4, num_updates=75200, lr=0.000364662, gnorm=0.299, loss_scale=2, train_wall=80, gb_free=39.6, wall=62784
2023-06-12 09:14:07 | INFO | train_inner | epoch 007:   7666 / 11284 loss=3.604, nll_loss=1.904, ppl=3.74, wps=71452.5, ups=1.2, wpb=59583.8, bsz=2265.3, num_updates=75300, lr=0.00036442, gnorm=0.303, loss_scale=2, train_wall=79, gb_free=39.5, wall=62868
2023-06-12 09:15:30 | INFO | train_inner | epoch 007:   7766 / 11284 loss=3.619, nll_loss=1.921, ppl=3.79, wps=71769.7, ups=1.2, wpb=59655.7, bsz=2261.5, num_updates=75400, lr=0.000364179, gnorm=0.294, loss_scale=2, train_wall=79, gb_free=39.6, wall=62951
2023-06-12 09:15:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 09:16:55 | INFO | train_inner | epoch 007:   7867 / 11284 loss=3.618, nll_loss=1.92, ppl=3.78, wps=69827, ups=1.17, wpb=59482.6, bsz=2265.7, num_updates=75500, lr=0.000363937, gnorm=0.303, loss_scale=2, train_wall=81, gb_free=39.6, wall=63036
2023-06-12 09:18:19 | INFO | train_inner | epoch 007:   7967 / 11284 loss=3.606, nll_loss=1.907, ppl=3.75, wps=71413.9, ups=1.2, wpb=59432.3, bsz=2202.8, num_updates=75600, lr=0.000363696, gnorm=0.305, loss_scale=2, train_wall=79, gb_free=39.6, wall=63119
2023-06-12 09:19:42 | INFO | train_inner | epoch 007:   8067 / 11284 loss=3.606, nll_loss=1.907, ppl=3.75, wps=71767, ups=1.2, wpb=59800.3, bsz=2199.9, num_updates=75700, lr=0.000363456, gnorm=0.323, loss_scale=2, train_wall=79, gb_free=39.5, wall=63203
2023-06-12 09:21:04 | INFO | train_inner | epoch 007:   8167 / 11284 loss=3.613, nll_loss=1.914, ppl=3.77, wps=72619.4, ups=1.22, wpb=59409.4, bsz=2153.5, num_updates=75800, lr=0.000363216, gnorm=0.299, loss_scale=2, train_wall=78, gb_free=39.6, wall=63284
2023-06-12 09:22:27 | INFO | train_inner | epoch 007:   8267 / 11284 loss=3.616, nll_loss=1.918, ppl=3.78, wps=72033.7, ups=1.21, wpb=59700.2, bsz=2247.6, num_updates=75900, lr=0.000362977, gnorm=0.295, loss_scale=2, train_wall=79, gb_free=39.5, wall=63367
2023-06-12 09:23:50 | INFO | train_inner | epoch 007:   8367 / 11284 loss=3.616, nll_loss=1.918, ppl=3.78, wps=71721.2, ups=1.2, wpb=59707.1, bsz=2275.6, num_updates=76000, lr=0.000362738, gnorm=0.289, loss_scale=2, train_wall=79, gb_free=39.5, wall=63450
2023-06-12 09:25:13 | INFO | train_inner | epoch 007:   8467 / 11284 loss=3.616, nll_loss=1.917, ppl=3.78, wps=71709.3, ups=1.21, wpb=59454.1, bsz=2211.6, num_updates=76100, lr=0.0003625, gnorm=0.305, loss_scale=2, train_wall=79, gb_free=39.6, wall=63533
2023-06-12 09:26:36 | INFO | train_inner | epoch 007:   8567 / 11284 loss=3.622, nll_loss=1.924, ppl=3.79, wps=71484.6, ups=1.2, wpb=59357.8, bsz=2095.6, num_updates=76200, lr=0.000362262, gnorm=0.311, loss_scale=2, train_wall=79, gb_free=39.6, wall=63616
2023-06-12 09:27:59 | INFO | train_inner | epoch 007:   8667 / 11284 loss=3.606, nll_loss=1.907, ppl=3.75, wps=71746.2, ups=1.21, wpb=59435.2, bsz=2175.6, num_updates=76300, lr=0.000362024, gnorm=0.298, loss_scale=2, train_wall=79, gb_free=39.6, wall=63699
2023-06-12 09:29:21 | INFO | train_inner | epoch 007:   8767 / 11284 loss=3.609, nll_loss=1.91, ppl=3.76, wps=71861.5, ups=1.21, wpb=59481.4, bsz=2179.1, num_updates=76400, lr=0.000361787, gnorm=0.306, loss_scale=2, train_wall=79, gb_free=39.5, wall=63782
2023-06-12 09:30:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 09:30:45 | INFO | train_inner | epoch 007:   8868 / 11284 loss=3.598, nll_loss=1.898, ppl=3.73, wps=70878.2, ups=1.19, wpb=59453.6, bsz=2202.8, num_updates=76500, lr=0.000361551, gnorm=0.291, loss_scale=2, train_wall=80, gb_free=39.6, wall=63866
2023-06-12 09:32:08 | INFO | train_inner | epoch 007:   8968 / 11284 loss=3.595, nll_loss=1.894, ppl=3.72, wps=71802, ups=1.21, wpb=59500.6, bsz=2168.6, num_updates=76600, lr=0.000361315, gnorm=0.312, loss_scale=2, train_wall=79, gb_free=39.6, wall=63949
2023-06-12 09:33:31 | INFO | train_inner | epoch 007:   9068 / 11284 loss=3.604, nll_loss=1.904, ppl=3.74, wps=71671.4, ups=1.21, wpb=59448.7, bsz=2189.5, num_updates=76700, lr=0.000361079, gnorm=0.292, loss_scale=2, train_wall=79, gb_free=39.5, wall=64032
2023-06-12 09:34:54 | INFO | train_inner | epoch 007:   9168 / 11284 loss=3.602, nll_loss=1.902, ppl=3.74, wps=71235.5, ups=1.2, wpb=59336.9, bsz=2238.5, num_updates=76800, lr=0.000360844, gnorm=0.291, loss_scale=2, train_wall=79, gb_free=39.6, wall=64115
2023-06-12 09:36:18 | INFO | train_inner | epoch 007:   9268 / 11284 loss=3.609, nll_loss=1.91, ppl=3.76, wps=71860.3, ups=1.2, wpb=59692.9, bsz=2304.6, num_updates=76900, lr=0.000360609, gnorm=0.293, loss_scale=2, train_wall=79, gb_free=39.6, wall=64198
2023-06-12 09:37:40 | INFO | train_inner | epoch 007:   9368 / 11284 loss=3.61, nll_loss=1.911, ppl=3.76, wps=71841.5, ups=1.21, wpb=59449.3, bsz=2186.1, num_updates=77000, lr=0.000360375, gnorm=0.29, loss_scale=2, train_wall=79, gb_free=39.4, wall=64281
2023-06-12 09:39:02 | INFO | train_inner | epoch 007:   9468 / 11284 loss=3.611, nll_loss=1.912, ppl=3.76, wps=73042.5, ups=1.23, wpb=59538.2, bsz=2276.1, num_updates=77100, lr=0.000360141, gnorm=0.293, loss_scale=2, train_wall=78, gb_free=39.6, wall=64362
2023-06-12 09:40:24 | INFO | train_inner | epoch 007:   9568 / 11284 loss=3.606, nll_loss=1.907, ppl=3.75, wps=72208.4, ups=1.21, wpb=59697.9, bsz=2255.1, num_updates=77200, lr=0.000359908, gnorm=0.295, loss_scale=2, train_wall=79, gb_free=39.6, wall=64445
2023-06-12 09:41:47 | INFO | train_inner | epoch 007:   9668 / 11284 loss=3.604, nll_loss=1.905, ppl=3.74, wps=71781.1, ups=1.2, wpb=59596.4, bsz=2209.7, num_updates=77300, lr=0.000359675, gnorm=0.298, loss_scale=2, train_wall=79, gb_free=39.5, wall=64528
2023-06-12 09:43:11 | INFO | train_inner | epoch 007:   9768 / 11284 loss=3.601, nll_loss=1.901, ppl=3.74, wps=71533.5, ups=1.2, wpb=59580.7, bsz=2218.1, num_updates=77400, lr=0.000359443, gnorm=0.301, loss_scale=2, train_wall=79, gb_free=39.6, wall=64611
2023-06-12 09:44:34 | INFO | train_inner | epoch 007:   9868 / 11284 loss=3.599, nll_loss=1.899, ppl=3.73, wps=71529.3, ups=1.2, wpb=59609.2, bsz=2258.2, num_updates=77500, lr=0.000359211, gnorm=0.307, loss_scale=4, train_wall=79, gb_free=39.6, wall=64695
2023-06-12 09:45:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 09:45:58 | INFO | train_inner | epoch 007:   9969 / 11284 loss=3.609, nll_loss=1.91, ppl=3.76, wps=70571.4, ups=1.19, wpb=59211.6, bsz=2212, num_updates=77600, lr=0.000358979, gnorm=0.31, loss_scale=2, train_wall=80, gb_free=37.9, wall=64779
2023-06-12 09:47:21 | INFO | train_inner | epoch 007:  10069 / 11284 loss=3.624, nll_loss=1.926, ppl=3.8, wps=71619.3, ups=1.21, wpb=59366.7, bsz=2276.8, num_updates=77700, lr=0.000358748, gnorm=0.297, loss_scale=2, train_wall=79, gb_free=39.6, wall=64861
2023-06-12 09:48:44 | INFO | train_inner | epoch 007:  10169 / 11284 loss=3.619, nll_loss=1.921, ppl=3.79, wps=71343.9, ups=1.2, wpb=59538.6, bsz=2268.9, num_updates=77800, lr=0.000358517, gnorm=0.311, loss_scale=2, train_wall=79, gb_free=39.6, wall=64945
2023-06-12 09:50:09 | INFO | train_inner | epoch 007:  10269 / 11284 loss=3.611, nll_loss=1.913, ppl=3.77, wps=70021.4, ups=1.18, wpb=59363.1, bsz=2146.8, num_updates=77900, lr=0.000358287, gnorm=0.309, loss_scale=2, train_wall=81, gb_free=39.4, wall=65030
2023-06-12 09:51:33 | INFO | train_inner | epoch 007:  10369 / 11284 loss=3.606, nll_loss=1.907, ppl=3.75, wps=70641.3, ups=1.19, wpb=59386.6, bsz=2189.4, num_updates=78000, lr=0.000358057, gnorm=0.307, loss_scale=2, train_wall=80, gb_free=39.6, wall=65114
2023-06-12 09:52:56 | INFO | train_inner | epoch 007:  10469 / 11284 loss=3.622, nll_loss=1.924, ppl=3.8, wps=71441.6, ups=1.2, wpb=59311.9, bsz=2202.3, num_updates=78100, lr=0.000357828, gnorm=0.302, loss_scale=2, train_wall=79, gb_free=39.6, wall=65197
2023-06-12 09:54:19 | INFO | train_inner | epoch 007:  10569 / 11284 loss=3.629, nll_loss=1.932, ppl=3.82, wps=71786.3, ups=1.2, wpb=59580.2, bsz=2245.9, num_updates=78200, lr=0.000357599, gnorm=0.309, loss_scale=2, train_wall=79, gb_free=39.6, wall=65280
2023-06-12 09:55:42 | INFO | train_inner | epoch 007:  10669 / 11284 loss=3.608, nll_loss=1.909, ppl=3.76, wps=71686.8, ups=1.2, wpb=59527.1, bsz=2197.8, num_updates=78300, lr=0.000357371, gnorm=0.294, loss_scale=2, train_wall=79, gb_free=39.5, wall=65363
2023-06-12 09:57:05 | INFO | train_inner | epoch 007:  10769 / 11284 loss=3.613, nll_loss=1.914, ppl=3.77, wps=71306.9, ups=1.2, wpb=59198, bsz=2277.1, num_updates=78400, lr=0.000357143, gnorm=0.307, loss_scale=2, train_wall=79, gb_free=39.6, wall=65446
2023-06-12 09:58:29 | INFO | train_inner | epoch 007:  10869 / 11284 loss=3.596, nll_loss=1.895, ppl=3.72, wps=71426.6, ups=1.2, wpb=59642.8, bsz=2261.1, num_updates=78500, lr=0.000356915, gnorm=0.293, loss_scale=2, train_wall=79, gb_free=39.6, wall=65529
2023-06-12 09:59:52 | INFO | train_inner | epoch 007:  10969 / 11284 loss=3.604, nll_loss=1.905, ppl=3.74, wps=71552.6, ups=1.2, wpb=59393.5, bsz=2168.2, num_updates=78600, lr=0.000356688, gnorm=0.293, loss_scale=4, train_wall=79, gb_free=39.6, wall=65612
2023-06-12 10:00:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 10:01:16 | INFO | train_inner | epoch 007:  11070 / 11284 loss=3.595, nll_loss=1.895, ppl=3.72, wps=70903.6, ups=1.19, wpb=59652.1, bsz=2325.5, num_updates=78700, lr=0.000356462, gnorm=0.293, loss_scale=2, train_wall=80, gb_free=39.6, wall=65697
2023-06-12 10:02:38 | INFO | train_inner | epoch 007:  11170 / 11284 loss=3.606, nll_loss=1.907, ppl=3.75, wps=72059.5, ups=1.21, wpb=59446.3, bsz=2146.3, num_updates=78800, lr=0.000356235, gnorm=0.304, loss_scale=2, train_wall=78, gb_free=39.4, wall=65779
2023-06-12 10:04:02 | INFO | train_inner | epoch 007:  11270 / 11284 loss=3.595, nll_loss=1.894, ppl=3.72, wps=71323.6, ups=1.2, wpb=59582.6, bsz=2274.3, num_updates=78900, lr=0.000356009, gnorm=0.301, loss_scale=2, train_wall=79, gb_free=39.6, wall=65863
2023-06-12 10:04:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-12 10:04:31 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 4.385 | nll_loss 2.71 | ppl 6.54 | bleu 20.63 | wps 3712.5 | wpb 2397.5 | bsz 71.5 | num_updates 78914 | best_loss 4.385
2023-06-12 10:04:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 78914 updates
2023-06-12 10:04:31 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint7.pt
2023-06-12 10:04:33 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint7.pt
2023-06-12 10:04:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint7.pt (epoch 7 @ 78914 updates, score 4.385) (writing took 6.346196079626679 seconds)
2023-06-12 10:04:38 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-06-12 10:04:38 | INFO | train | epoch 007 | loss 3.611 | nll_loss 1.912 | ppl 3.76 | wps 71454.6 | ups 1.2 | wpb 59501.1 | bsz 2227.4 | num_updates 78914 | lr 0.000355978 | gnorm 0.299 | loss_scale 2 | train_wall 8917 | gb_free 39.6 | wall 65898
2023-06-12 10:04:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-12 10:04:38 | INFO | fairseq.trainer | begin training epoch 8
2023-06-12 10:04:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-12 10:05:50 | INFO | train_inner | epoch 008:     86 / 11284 loss=3.596, nll_loss=1.895, ppl=3.72, wps=54941.9, ups=0.92, wpb=59411.4, bsz=2168.1, num_updates=79000, lr=0.000355784, gnorm=0.295, loss_scale=2, train_wall=79, gb_free=39.7, wall=65971
2023-06-12 10:07:13 | INFO | train_inner | epoch 008:    186 / 11284 loss=3.606, nll_loss=1.906, ppl=3.75, wps=71224.5, ups=1.2, wpb=59323.7, bsz=2207.4, num_updates=79100, lr=0.000355559, gnorm=0.313, loss_scale=2, train_wall=79, gb_free=39.6, wall=66054
2023-06-12 10:08:36 | INFO | train_inner | epoch 008:    286 / 11284 loss=3.591, nll_loss=1.889, ppl=3.7, wps=71743.6, ups=1.21, wpb=59484.9, bsz=2182.8, num_updates=79200, lr=0.000355335, gnorm=0.298, loss_scale=2, train_wall=79, gb_free=39.6, wall=66137
2023-06-12 10:09:59 | INFO | train_inner | epoch 008:    386 / 11284 loss=3.57, nll_loss=1.866, ppl=3.65, wps=72308.7, ups=1.21, wpb=59596.1, bsz=2203.2, num_updates=79300, lr=0.00035511, gnorm=0.289, loss_scale=2, train_wall=79, gb_free=39.6, wall=66219
2023-06-12 10:11:21 | INFO | train_inner | epoch 008:    486 / 11284 loss=3.575, nll_loss=1.871, ppl=3.66, wps=72456.6, ups=1.22, wpb=59388.1, bsz=2194.2, num_updates=79400, lr=0.000354887, gnorm=0.286, loss_scale=2, train_wall=78, gb_free=39.6, wall=66301
2023-06-12 10:12:43 | INFO | train_inner | epoch 008:    586 / 11284 loss=3.59, nll_loss=1.889, ppl=3.7, wps=72744.7, ups=1.22, wpb=59502.4, bsz=2202.3, num_updates=79500, lr=0.000354663, gnorm=0.288, loss_scale=2, train_wall=78, gb_free=39.6, wall=66383
2023-06-12 10:14:05 | INFO | train_inner | epoch 008:    686 / 11284 loss=3.594, nll_loss=1.893, ppl=3.71, wps=71689.2, ups=1.2, wpb=59496, bsz=2133.4, num_updates=79600, lr=0.000354441, gnorm=0.299, loss_scale=2, train_wall=79, gb_free=39.6, wall=66466
2023-06-12 10:15:29 | INFO | train_inner | epoch 008:    786 / 11284 loss=3.606, nll_loss=1.906, ppl=3.75, wps=71446.2, ups=1.2, wpb=59559.6, bsz=2250.9, num_updates=79700, lr=0.000354218, gnorm=0.312, loss_scale=2, train_wall=79, gb_free=39.6, wall=66549
2023-06-12 10:15:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 10:16:52 | INFO | train_inner | epoch 008:    887 / 11284 loss=3.605, nll_loss=1.905, ppl=3.75, wps=71239.9, ups=1.2, wpb=59551.6, bsz=2215.1, num_updates=79800, lr=0.000353996, gnorm=0.306, loss_scale=2, train_wall=79, gb_free=39.6, wall=66633
2023-06-12 10:18:17 | INFO | train_inner | epoch 008:    987 / 11284 loss=3.602, nll_loss=1.902, ppl=3.74, wps=69952, ups=1.18, wpb=59385.8, bsz=2291.7, num_updates=79900, lr=0.000353775, gnorm=0.307, loss_scale=2, train_wall=81, gb_free=38.9, wall=66718
2023-06-12 10:19:39 | INFO | train_inner | epoch 008:   1087 / 11284 loss=3.606, nll_loss=1.906, ppl=3.75, wps=72782.3, ups=1.22, wpb=59581.9, bsz=2274.6, num_updates=80000, lr=0.000353553, gnorm=0.285, loss_scale=2, train_wall=78, gb_free=39.4, wall=66800
2023-06-12 10:21:01 | INFO | train_inner | epoch 008:   1187 / 11284 loss=3.597, nll_loss=1.897, ppl=3.72, wps=72996.6, ups=1.23, wpb=59387, bsz=2198, num_updates=80100, lr=0.000353333, gnorm=0.3, loss_scale=2, train_wall=77, gb_free=39.6, wall=66881
2023-06-12 10:22:23 | INFO | train_inner | epoch 008:   1287 / 11284 loss=3.589, nll_loss=1.888, ppl=3.7, wps=72455.9, ups=1.22, wpb=59387.5, bsz=2300, num_updates=80200, lr=0.000353112, gnorm=0.297, loss_scale=2, train_wall=78, gb_free=39, wall=66963
2023-06-12 10:23:44 | INFO | train_inner | epoch 008:   1387 / 11284 loss=3.589, nll_loss=1.887, ppl=3.7, wps=72776.5, ups=1.22, wpb=59538.5, bsz=2245, num_updates=80300, lr=0.000352892, gnorm=0.286, loss_scale=2, train_wall=78, gb_free=39.5, wall=67045
2023-06-12 10:25:06 | INFO | train_inner | epoch 008:   1487 / 11284 loss=3.599, nll_loss=1.898, ppl=3.73, wps=73003, ups=1.22, wpb=59665.1, bsz=2109.2, num_updates=80400, lr=0.000352673, gnorm=0.32, loss_scale=2, train_wall=78, gb_free=39.6, wall=67127
2023-06-12 10:26:29 | INFO | train_inner | epoch 008:   1587 / 11284 loss=3.61, nll_loss=1.91, ppl=3.76, wps=71651.8, ups=1.21, wpb=59202.3, bsz=2199.4, num_updates=80500, lr=0.000352454, gnorm=0.304, loss_scale=2, train_wall=79, gb_free=39.6, wall=67209
2023-06-12 10:27:52 | INFO | train_inner | epoch 008:   1687 / 11284 loss=3.592, nll_loss=1.891, ppl=3.71, wps=71782.3, ups=1.21, wpb=59537.6, bsz=2243.3, num_updates=80600, lr=0.000352235, gnorm=0.303, loss_scale=2, train_wall=79, gb_free=39.5, wall=67292
2023-06-12 10:29:15 | INFO | train_inner | epoch 008:   1787 / 11284 loss=3.597, nll_loss=1.896, ppl=3.72, wps=71831.7, ups=1.2, wpb=59628.5, bsz=2253.3, num_updates=80700, lr=0.000352017, gnorm=0.295, loss_scale=2, train_wall=79, gb_free=39.5, wall=67375
2023-06-12 10:29:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 10:30:38 | INFO | train_inner | epoch 008:   1888 / 11284 loss=3.573, nll_loss=1.869, ppl=3.65, wps=71445.7, ups=1.2, wpb=59623.7, bsz=2294.5, num_updates=80800, lr=0.000351799, gnorm=0.296, loss_scale=2, train_wall=79, gb_free=39.6, wall=67459
2023-06-12 10:32:01 | INFO | train_inner | epoch 008:   1988 / 11284 loss=3.604, nll_loss=1.904, ppl=3.74, wps=72163.1, ups=1.21, wpb=59571.3, bsz=2187.5, num_updates=80900, lr=0.000351581, gnorm=0.296, loss_scale=2, train_wall=79, gb_free=39.5, wall=67541
2023-06-12 10:33:24 | INFO | train_inner | epoch 008:   2088 / 11284 loss=3.605, nll_loss=1.905, ppl=3.75, wps=71580.1, ups=1.2, wpb=59449.1, bsz=2260.2, num_updates=81000, lr=0.000351364, gnorm=0.308, loss_scale=2, train_wall=79, gb_free=39.5, wall=67624
2023-06-12 10:34:47 | INFO | train_inner | epoch 008:   2188 / 11284 loss=3.589, nll_loss=1.887, ppl=3.7, wps=71363.7, ups=1.2, wpb=59414.2, bsz=2176.8, num_updates=81100, lr=0.000351147, gnorm=0.299, loss_scale=2, train_wall=79, gb_free=39.6, wall=67708
2023-06-12 10:36:10 | INFO | train_inner | epoch 008:   2288 / 11284 loss=3.588, nll_loss=1.886, ppl=3.7, wps=71501.2, ups=1.2, wpb=59412.2, bsz=2189.2, num_updates=81200, lr=0.000350931, gnorm=0.319, loss_scale=2, train_wall=79, gb_free=39.6, wall=67791
2023-06-12 10:37:32 | INFO | train_inner | epoch 008:   2388 / 11284 loss=3.593, nll_loss=1.891, ppl=3.71, wps=72198, ups=1.21, wpb=59449.9, bsz=2130.5, num_updates=81300, lr=0.000350715, gnorm=0.299, loss_scale=2, train_wall=78, gb_free=39.7, wall=67873
2023-06-12 10:38:56 | INFO | train_inner | epoch 008:   2488 / 11284 loss=3.606, nll_loss=1.907, ppl=3.75, wps=71721.5, ups=1.2, wpb=59619.5, bsz=2250.8, num_updates=81400, lr=0.0003505, gnorm=0.289, loss_scale=2, train_wall=79, gb_free=39.6, wall=67956
2023-06-12 10:40:19 | INFO | train_inner | epoch 008:   2588 / 11284 loss=3.594, nll_loss=1.892, ppl=3.71, wps=71427.1, ups=1.2, wpb=59433.9, bsz=2222.2, num_updates=81500, lr=0.000350285, gnorm=0.299, loss_scale=2, train_wall=79, gb_free=39.5, wall=68039
2023-06-12 10:41:41 | INFO | train_inner | epoch 008:   2688 / 11284 loss=3.583, nll_loss=1.881, ppl=3.68, wps=72140.5, ups=1.21, wpb=59444.9, bsz=2182.9, num_updates=81600, lr=0.00035007, gnorm=0.295, loss_scale=2, train_wall=78, gb_free=39.6, wall=68122
2023-06-12 10:43:03 | INFO | train_inner | epoch 008:   2788 / 11284 loss=3.6, nll_loss=1.9, ppl=3.73, wps=72766.4, ups=1.22, wpb=59519.2, bsz=2161.6, num_updates=81700, lr=0.000349856, gnorm=0.297, loss_scale=2, train_wall=78, gb_free=39.6, wall=68204
2023-06-12 10:44:24 | INFO | train_inner | epoch 008:   2888 / 11284 loss=3.605, nll_loss=1.906, ppl=3.75, wps=73153, ups=1.23, wpb=59571.8, bsz=2168.5, num_updates=81800, lr=0.000349642, gnorm=0.3, loss_scale=4, train_wall=78, gb_free=39.6, wall=68285
2023-06-12 10:45:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 10:45:47 | INFO | train_inner | epoch 008:   2989 / 11284 loss=3.593, nll_loss=1.892, ppl=3.71, wps=72367.1, ups=1.21, wpb=59726.6, bsz=2166, num_updates=81900, lr=0.000349428, gnorm=0.299, loss_scale=2, train_wall=78, gb_free=39.5, wall=68368
2023-06-12 10:47:09 | INFO | train_inner | epoch 008:   3089 / 11284 loss=3.587, nll_loss=1.885, ppl=3.69, wps=72548.2, ups=1.22, wpb=59521.5, bsz=2142.6, num_updates=82000, lr=0.000349215, gnorm=0.301, loss_scale=2, train_wall=78, gb_free=39.5, wall=68450
2023-06-12 10:48:32 | INFO | train_inner | epoch 008:   3189 / 11284 loss=3.606, nll_loss=1.907, ppl=3.75, wps=71357.9, ups=1.2, wpb=59429.1, bsz=2295.2, num_updates=82100, lr=0.000349002, gnorm=0.306, loss_scale=2, train_wall=79, gb_free=39.6, wall=68533
2023-06-12 10:49:55 | INFO | train_inner | epoch 008:   3289 / 11284 loss=3.602, nll_loss=1.902, ppl=3.74, wps=71742.7, ups=1.21, wpb=59432.5, bsz=2281.3, num_updates=82200, lr=0.00034879, gnorm=0.296, loss_scale=2, train_wall=79, gb_free=39.5, wall=68616
2023-06-12 10:51:19 | INFO | train_inner | epoch 008:   3389 / 11284 loss=3.607, nll_loss=1.908, ppl=3.75, wps=70822.9, ups=1.19, wpb=59484.4, bsz=2318.7, num_updates=82300, lr=0.000348578, gnorm=0.306, loss_scale=2, train_wall=80, gb_free=39.5, wall=68700
2023-06-12 10:52:42 | INFO | train_inner | epoch 008:   3489 / 11284 loss=3.594, nll_loss=1.893, ppl=3.71, wps=72023.5, ups=1.21, wpb=59564.1, bsz=2262, num_updates=82400, lr=0.000348367, gnorm=0.306, loss_scale=2, train_wall=78, gb_free=39.5, wall=68782
2023-06-12 10:54:05 | INFO | train_inner | epoch 008:   3589 / 11284 loss=3.596, nll_loss=1.896, ppl=3.72, wps=71697.4, ups=1.21, wpb=59301.2, bsz=2217.6, num_updates=82500, lr=0.000348155, gnorm=0.296, loss_scale=2, train_wall=79, gb_free=39.3, wall=68865
2023-06-12 10:55:28 | INFO | train_inner | epoch 008:   3689 / 11284 loss=3.597, nll_loss=1.896, ppl=3.72, wps=71368.2, ups=1.2, wpb=59377.6, bsz=2197.2, num_updates=82600, lr=0.000347945, gnorm=0.282, loss_scale=2, train_wall=79, gb_free=39.6, wall=68948
2023-06-12 10:56:50 | INFO | train_inner | epoch 008:   3789 / 11284 loss=3.59, nll_loss=1.888, ppl=3.7, wps=72036, ups=1.21, wpb=59514.5, bsz=2175.6, num_updates=82700, lr=0.000347734, gnorm=0.286, loss_scale=2, train_wall=79, gb_free=39.6, wall=69031
2023-06-12 10:58:13 | INFO | train_inner | epoch 008:   3889 / 11284 loss=3.593, nll_loss=1.892, ppl=3.71, wps=72126.1, ups=1.21, wpb=59442.3, bsz=2302.7, num_updates=82800, lr=0.000347524, gnorm=0.306, loss_scale=2, train_wall=78, gb_free=39.5, wall=69113
2023-06-12 10:59:35 | INFO | train_inner | epoch 008:   3989 / 11284 loss=3.598, nll_loss=1.898, ppl=3.73, wps=72194.9, ups=1.21, wpb=59566.2, bsz=2215, num_updates=82900, lr=0.000347314, gnorm=0.294, loss_scale=4, train_wall=78, gb_free=39.5, wall=69196
2023-06-12 10:59:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 11:00:58 | INFO | train_inner | epoch 008:   4090 / 11284 loss=3.603, nll_loss=1.903, ppl=3.74, wps=71834.7, ups=1.21, wpb=59483.2, bsz=2368.9, num_updates=83000, lr=0.000347105, gnorm=0.302, loss_scale=2, train_wall=79, gb_free=39.5, wall=69279
2023-06-12 11:02:19 | INFO | train_inner | epoch 008:   4190 / 11284 loss=3.582, nll_loss=1.88, ppl=3.68, wps=73077.5, ups=1.23, wpb=59384.8, bsz=2084.1, num_updates=83100, lr=0.000346896, gnorm=0.302, loss_scale=2, train_wall=77, gb_free=39.5, wall=69360
2023-06-12 11:03:42 | INFO | train_inner | epoch 008:   4290 / 11284 loss=3.603, nll_loss=1.904, ppl=3.74, wps=71915.6, ups=1.21, wpb=59319.4, bsz=2216.8, num_updates=83200, lr=0.000346688, gnorm=0.298, loss_scale=2, train_wall=79, gb_free=39.6, wall=69442
2023-06-12 11:05:05 | INFO | train_inner | epoch 008:   4390 / 11284 loss=3.601, nll_loss=1.901, ppl=3.73, wps=71330.3, ups=1.2, wpb=59278.4, bsz=2161.4, num_updates=83300, lr=0.000346479, gnorm=0.303, loss_scale=2, train_wall=79, gb_free=39.6, wall=69525
2023-06-12 11:06:28 | INFO | train_inner | epoch 008:   4490 / 11284 loss=3.6, nll_loss=1.9, ppl=3.73, wps=71766.1, ups=1.2, wpb=59628.9, bsz=2221.5, num_updates=83400, lr=0.000346272, gnorm=0.294, loss_scale=2, train_wall=79, gb_free=39.6, wall=69609
2023-06-12 11:07:51 | INFO | train_inner | epoch 008:   4590 / 11284 loss=3.603, nll_loss=1.903, ppl=3.74, wps=71595.3, ups=1.2, wpb=59567.2, bsz=2245.7, num_updates=83500, lr=0.000346064, gnorm=0.3, loss_scale=2, train_wall=79, gb_free=39.6, wall=69692
2023-06-12 11:09:15 | INFO | train_inner | epoch 008:   4690 / 11284 loss=3.593, nll_loss=1.892, ppl=3.71, wps=71471.9, ups=1.2, wpb=59579.7, bsz=2284.4, num_updates=83600, lr=0.000345857, gnorm=0.294, loss_scale=2, train_wall=79, gb_free=39.5, wall=69775
2023-06-12 11:10:38 | INFO | train_inner | epoch 008:   4790 / 11284 loss=3.589, nll_loss=1.888, ppl=3.7, wps=71714.8, ups=1.2, wpb=59600.5, bsz=2232.2, num_updates=83700, lr=0.000345651, gnorm=0.306, loss_scale=2, train_wall=79, gb_free=39.5, wall=69858
2023-06-12 11:12:01 | INFO | train_inner | epoch 008:   4890 / 11284 loss=3.585, nll_loss=1.884, ppl=3.69, wps=71707.9, ups=1.2, wpb=59610.7, bsz=2239.1, num_updates=83800, lr=0.000345444, gnorm=0.291, loss_scale=2, train_wall=79, gb_free=39.5, wall=69941
2023-06-12 11:13:24 | INFO | train_inner | epoch 008:   4990 / 11284 loss=3.6, nll_loss=1.9, ppl=3.73, wps=71458.8, ups=1.21, wpb=59299.5, bsz=2249.5, num_updates=83900, lr=0.000345238, gnorm=0.304, loss_scale=2, train_wall=79, gb_free=39.6, wall=70024
2023-06-12 11:14:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 11:14:47 | INFO | train_inner | epoch 008:   5091 / 11284 loss=3.592, nll_loss=1.891, ppl=3.71, wps=70967.7, ups=1.19, wpb=59392.7, bsz=2212.7, num_updates=84000, lr=0.000345033, gnorm=0.304, loss_scale=2, train_wall=80, gb_free=39.6, wall=70108
2023-06-12 11:16:10 | INFO | train_inner | epoch 008:   5191 / 11284 loss=3.607, nll_loss=1.909, ppl=3.75, wps=72046.3, ups=1.2, wpb=59799.8, bsz=2244.2, num_updates=84100, lr=0.000344828, gnorm=0.291, loss_scale=2, train_wall=79, gb_free=39.6, wall=70191
2023-06-12 11:17:33 | INFO | train_inner | epoch 008:   5291 / 11284 loss=3.604, nll_loss=1.905, ppl=3.74, wps=71569.1, ups=1.21, wpb=59344.4, bsz=2239.9, num_updates=84200, lr=0.000344623, gnorm=0.301, loss_scale=2, train_wall=79, gb_free=39.5, wall=70274
2023-06-12 11:18:56 | INFO | train_inner | epoch 008:   5391 / 11284 loss=3.6, nll_loss=1.9, ppl=3.73, wps=71783.9, ups=1.21, wpb=59570.9, bsz=2217.7, num_updates=84300, lr=0.000344418, gnorm=0.306, loss_scale=2, train_wall=79, gb_free=39.6, wall=70357
2023-06-12 11:20:19 | INFO | train_inner | epoch 008:   5491 / 11284 loss=3.606, nll_loss=1.907, ppl=3.75, wps=71854.5, ups=1.21, wpb=59520.7, bsz=2191.6, num_updates=84400, lr=0.000344214, gnorm=0.292, loss_scale=2, train_wall=79, gb_free=39.6, wall=70440
2023-06-12 11:21:42 | INFO | train_inner | epoch 008:   5591 / 11284 loss=3.602, nll_loss=1.902, ppl=3.74, wps=71840.2, ups=1.21, wpb=59331, bsz=2246, num_updates=84500, lr=0.00034401, gnorm=0.292, loss_scale=2, train_wall=79, gb_free=39.6, wall=70522
2023-06-12 11:23:05 | INFO | train_inner | epoch 008:   5691 / 11284 loss=3.601, nll_loss=1.901, ppl=3.73, wps=71836.1, ups=1.21, wpb=59599.9, bsz=2290.6, num_updates=84600, lr=0.000343807, gnorm=0.294, loss_scale=2, train_wall=79, gb_free=39.6, wall=70605
2023-06-12 11:24:28 | INFO | train_inner | epoch 008:   5791 / 11284 loss=3.59, nll_loss=1.889, ppl=3.7, wps=71408.2, ups=1.2, wpb=59517.6, bsz=2307.5, num_updates=84700, lr=0.000343604, gnorm=0.299, loss_scale=2, train_wall=79, gb_free=39.5, wall=70689
2023-06-12 11:25:51 | INFO | train_inner | epoch 008:   5891 / 11284 loss=3.598, nll_loss=1.898, ppl=3.73, wps=71742.5, ups=1.21, wpb=59527.7, bsz=2190.9, num_updates=84800, lr=0.000343401, gnorm=0.296, loss_scale=2, train_wall=79, gb_free=39.6, wall=70772
2023-06-12 11:27:14 | INFO | train_inner | epoch 008:   5991 / 11284 loss=3.594, nll_loss=1.894, ppl=3.72, wps=71551, ups=1.2, wpb=59547.7, bsz=2255.9, num_updates=84900, lr=0.000343199, gnorm=0.301, loss_scale=2, train_wall=79, gb_free=39.5, wall=70855
2023-06-12 11:28:37 | INFO | train_inner | epoch 008:   6091 / 11284 loss=3.603, nll_loss=1.904, ppl=3.74, wps=71556, ups=1.21, wpb=59369.9, bsz=2209.7, num_updates=85000, lr=0.000342997, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.6, wall=70938
2023-06-12 11:29:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 11:30:01 | INFO | train_inner | epoch 008:   6192 / 11284 loss=3.595, nll_loss=1.895, ppl=3.72, wps=70849.7, ups=1.19, wpb=59596.8, bsz=2207.9, num_updates=85100, lr=0.000342796, gnorm=0.295, loss_scale=2, train_wall=80, gb_free=39.6, wall=71022
2023-06-12 11:31:25 | INFO | train_inner | epoch 008:   6292 / 11284 loss=3.592, nll_loss=1.891, ppl=3.71, wps=71646.1, ups=1.2, wpb=59624.5, bsz=2259.3, num_updates=85200, lr=0.000342594, gnorm=0.296, loss_scale=2, train_wall=79, gb_free=39.6, wall=71105
2023-06-12 11:32:47 | INFO | train_inner | epoch 008:   6392 / 11284 loss=3.597, nll_loss=1.896, ppl=3.72, wps=71896.8, ups=1.21, wpb=59345.9, bsz=2251.9, num_updates=85300, lr=0.000342393, gnorm=0.303, loss_scale=2, train_wall=78, gb_free=39.5, wall=71188
2023-06-12 11:34:09 | INFO | train_inner | epoch 008:   6492 / 11284 loss=3.601, nll_loss=1.901, ppl=3.74, wps=72260.7, ups=1.22, wpb=59390.6, bsz=2205.6, num_updates=85400, lr=0.000342193, gnorm=0.308, loss_scale=2, train_wall=78, gb_free=39.2, wall=71270
2023-06-12 11:35:32 | INFO | train_inner | epoch 008:   6592 / 11284 loss=3.604, nll_loss=1.905, ppl=3.75, wps=71719, ups=1.21, wpb=59484.8, bsz=2176.1, num_updates=85500, lr=0.000341993, gnorm=0.291, loss_scale=2, train_wall=79, gb_free=39.4, wall=71353
2023-06-12 11:36:55 | INFO | train_inner | epoch 008:   6692 / 11284 loss=3.589, nll_loss=1.888, ppl=3.7, wps=71866.5, ups=1.21, wpb=59324.2, bsz=2216.3, num_updates=85600, lr=0.000341793, gnorm=0.313, loss_scale=2, train_wall=79, gb_free=39, wall=71435
2023-06-12 11:38:17 | INFO | train_inner | epoch 008:   6792 / 11284 loss=3.601, nll_loss=1.901, ppl=3.74, wps=72232.5, ups=1.22, wpb=59417.8, bsz=2209.8, num_updates=85700, lr=0.000341593, gnorm=0.294, loss_scale=2, train_wall=78, gb_free=39.5, wall=71518
2023-06-12 11:39:39 | INFO | train_inner | epoch 008:   6892 / 11284 loss=3.599, nll_loss=1.899, ppl=3.73, wps=72371.1, ups=1.22, wpb=59464.5, bsz=2237.6, num_updates=85800, lr=0.000341394, gnorm=0.292, loss_scale=2, train_wall=78, gb_free=39.6, wall=71600
2023-06-12 11:41:02 | INFO | train_inner | epoch 008:   6992 / 11284 loss=3.602, nll_loss=1.903, ppl=3.74, wps=71725.7, ups=1.21, wpb=59495.9, bsz=2307.4, num_updates=85900, lr=0.000341196, gnorm=0.3, loss_scale=2, train_wall=79, gb_free=39.6, wall=71683
2023-06-12 11:42:25 | INFO | train_inner | epoch 008:   7092 / 11284 loss=3.583, nll_loss=1.881, ppl=3.68, wps=71867.2, ups=1.21, wpb=59518.3, bsz=2200.9, num_updates=86000, lr=0.000340997, gnorm=0.291, loss_scale=2, train_wall=79, gb_free=39.6, wall=71766
2023-06-12 11:43:48 | INFO | train_inner | epoch 008:   7192 / 11284 loss=3.596, nll_loss=1.896, ppl=3.72, wps=71557.1, ups=1.2, wpb=59496.7, bsz=2267.6, num_updates=86100, lr=0.000340799, gnorm=0.3, loss_scale=2, train_wall=79, gb_free=39.6, wall=71849
2023-06-12 11:44:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 11:45:12 | INFO | train_inner | epoch 008:   7293 / 11284 loss=3.592, nll_loss=1.891, ppl=3.71, wps=70625.1, ups=1.19, wpb=59413.2, bsz=2265.6, num_updates=86200, lr=0.000340601, gnorm=0.303, loss_scale=2, train_wall=80, gb_free=39, wall=71933
2023-06-12 11:46:36 | INFO | train_inner | epoch 008:   7393 / 11284 loss=3.588, nll_loss=1.887, ppl=3.7, wps=71030.3, ups=1.2, wpb=59349.1, bsz=2201, num_updates=86300, lr=0.000340404, gnorm=0.303, loss_scale=2, train_wall=80, gb_free=39.6, wall=72016
2023-06-12 11:47:59 | INFO | train_inner | epoch 008:   7493 / 11284 loss=3.582, nll_loss=1.88, ppl=3.68, wps=71937.6, ups=1.21, wpb=59621.4, bsz=2206.3, num_updates=86400, lr=0.000340207, gnorm=0.298, loss_scale=2, train_wall=79, gb_free=39.5, wall=72099
2023-06-12 11:49:22 | INFO | train_inner | epoch 008:   7593 / 11284 loss=3.607, nll_loss=1.908, ppl=3.75, wps=71223.7, ups=1.2, wpb=59394.3, bsz=2304.9, num_updates=86500, lr=0.00034001, gnorm=0.318, loss_scale=2, train_wall=79, gb_free=39.3, wall=72183
2023-06-12 11:50:45 | INFO | train_inner | epoch 008:   7693 / 11284 loss=3.597, nll_loss=1.897, ppl=3.72, wps=71837.5, ups=1.2, wpb=59637.3, bsz=2292.5, num_updates=86600, lr=0.000339814, gnorm=0.297, loss_scale=2, train_wall=79, gb_free=39.6, wall=72266
2023-06-12 11:52:08 | INFO | train_inner | epoch 008:   7793 / 11284 loss=3.597, nll_loss=1.897, ppl=3.72, wps=71256.8, ups=1.2, wpb=59359, bsz=2321.3, num_updates=86700, lr=0.000339618, gnorm=0.297, loss_scale=2, train_wall=79, gb_free=39.6, wall=72349
2023-06-12 11:53:31 | INFO | train_inner | epoch 008:   7893 / 11284 loss=3.591, nll_loss=1.89, ppl=3.71, wps=71873.7, ups=1.21, wpb=59599.3, bsz=2254.1, num_updates=86800, lr=0.000339422, gnorm=0.306, loss_scale=2, train_wall=79, gb_free=39.6, wall=72432
2023-06-12 11:54:54 | INFO | train_inner | epoch 008:   7993 / 11284 loss=3.583, nll_loss=1.881, ppl=3.68, wps=71842.7, ups=1.21, wpb=59589.4, bsz=2267.6, num_updates=86900, lr=0.000339227, gnorm=0.297, loss_scale=2, train_wall=79, gb_free=39.6, wall=72515
2023-06-12 11:56:20 | INFO | train_inner | epoch 008:   8093 / 11284 loss=3.585, nll_loss=1.883, ppl=3.69, wps=69473, ups=1.17, wpb=59409.8, bsz=2322.2, num_updates=87000, lr=0.000339032, gnorm=0.307, loss_scale=2, train_wall=82, gb_free=39.5, wall=72600
2023-06-12 11:57:43 | INFO | train_inner | epoch 008:   8193 / 11284 loss=3.587, nll_loss=1.885, ppl=3.69, wps=71943.1, ups=1.21, wpb=59519.5, bsz=2166.1, num_updates=87100, lr=0.000338837, gnorm=0.297, loss_scale=2, train_wall=79, gb_free=39.5, wall=72683
2023-06-12 11:58:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 11:59:07 | INFO | train_inner | epoch 008:   8294 / 11284 loss=3.591, nll_loss=1.891, ppl=3.71, wps=70945.4, ups=1.19, wpb=59529.4, bsz=2186.5, num_updates=87200, lr=0.000338643, gnorm=0.309, loss_scale=2, train_wall=80, gb_free=39.6, wall=72767
2023-06-12 12:00:30 | INFO | train_inner | epoch 008:   8394 / 11284 loss=3.585, nll_loss=1.883, ppl=3.69, wps=71806.9, ups=1.2, wpb=59713.7, bsz=2294.6, num_updates=87300, lr=0.000338449, gnorm=0.301, loss_scale=2, train_wall=79, gb_free=39.6, wall=72850
2023-06-12 12:01:53 | INFO | train_inner | epoch 008:   8494 / 11284 loss=3.578, nll_loss=1.876, ppl=3.67, wps=71931.5, ups=1.21, wpb=59607.5, bsz=2131.5, num_updates=87400, lr=0.000338255, gnorm=0.295, loss_scale=2, train_wall=79, gb_free=39.5, wall=72933
2023-06-12 12:03:15 | INFO | train_inner | epoch 008:   8594 / 11284 loss=3.587, nll_loss=1.886, ppl=3.69, wps=71884.9, ups=1.21, wpb=59621.2, bsz=2208.9, num_updates=87500, lr=0.000338062, gnorm=0.326, loss_scale=2, train_wall=79, gb_free=39.6, wall=73016
2023-06-12 12:04:39 | INFO | train_inner | epoch 008:   8694 / 11284 loss=3.583, nll_loss=1.881, ppl=3.68, wps=71538.2, ups=1.2, wpb=59610, bsz=2250.2, num_updates=87600, lr=0.000337869, gnorm=0.306, loss_scale=2, train_wall=79, gb_free=39.6, wall=73099
2023-06-12 12:06:02 | INFO | train_inner | epoch 008:   8794 / 11284 loss=3.597, nll_loss=1.897, ppl=3.73, wps=72077.9, ups=1.21, wpb=59650.4, bsz=2130.8, num_updates=87700, lr=0.000337676, gnorm=0.3, loss_scale=2, train_wall=79, gb_free=39.6, wall=73182
2023-06-12 12:07:24 | INFO | train_inner | epoch 008:   8894 / 11284 loss=3.61, nll_loss=1.911, ppl=3.76, wps=71617.5, ups=1.21, wpb=59215.5, bsz=2220.2, num_updates=87800, lr=0.000337484, gnorm=0.305, loss_scale=2, train_wall=79, gb_free=39.5, wall=73265
2023-06-12 12:08:47 | INFO | train_inner | epoch 008:   8994 / 11284 loss=3.591, nll_loss=1.89, ppl=3.71, wps=72178.5, ups=1.21, wpb=59714.4, bsz=2224.6, num_updates=87900, lr=0.000337292, gnorm=0.296, loss_scale=2, train_wall=79, gb_free=39.5, wall=73348
2023-06-12 12:10:10 | INFO | train_inner | epoch 008:   9094 / 11284 loss=3.597, nll_loss=1.898, ppl=3.73, wps=71354.5, ups=1.2, wpb=59581.8, bsz=2274.2, num_updates=88000, lr=0.0003371, gnorm=0.303, loss_scale=2, train_wall=79, gb_free=39.5, wall=73431
2023-06-12 12:11:34 | INFO | train_inner | epoch 008:   9194 / 11284 loss=3.61, nll_loss=1.911, ppl=3.76, wps=71141.5, ups=1.2, wpb=59334.2, bsz=2276.3, num_updates=88100, lr=0.000336909, gnorm=0.31, loss_scale=2, train_wall=79, gb_free=39.6, wall=73514
2023-06-12 12:12:57 | INFO | train_inner | epoch 008:   9294 / 11284 loss=3.596, nll_loss=1.896, ppl=3.72, wps=71804.5, ups=1.21, wpb=59328.6, bsz=2182.8, num_updates=88200, lr=0.000336718, gnorm=0.302, loss_scale=2, train_wall=79, gb_free=39.5, wall=73597
2023-06-12 12:13:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 12:14:20 | INFO | train_inner | epoch 008:   9395 / 11284 loss=3.592, nll_loss=1.892, ppl=3.71, wps=70813.3, ups=1.19, wpb=59419.3, bsz=2248.1, num_updates=88300, lr=0.000336527, gnorm=0.301, loss_scale=2, train_wall=80, gb_free=39.5, wall=73681
2023-06-12 12:15:43 | INFO | train_inner | epoch 008:   9495 / 11284 loss=3.603, nll_loss=1.904, ppl=3.74, wps=71831.4, ups=1.21, wpb=59557.7, bsz=2192.3, num_updates=88400, lr=0.000336336, gnorm=0.306, loss_scale=2, train_wall=79, gb_free=39.5, wall=73764
2023-06-12 12:17:06 | INFO | train_inner | epoch 008:   9595 / 11284 loss=3.589, nll_loss=1.888, ppl=3.7, wps=72149.4, ups=1.21, wpb=59537.6, bsz=2250.9, num_updates=88500, lr=0.000336146, gnorm=0.297, loss_scale=2, train_wall=79, gb_free=39.6, wall=73846
2023-06-12 12:18:29 | INFO | train_inner | epoch 008:   9695 / 11284 loss=3.593, nll_loss=1.893, ppl=3.71, wps=71670.6, ups=1.21, wpb=59395.6, bsz=2287.3, num_updates=88600, lr=0.000335957, gnorm=0.297, loss_scale=2, train_wall=79, gb_free=39.5, wall=73929
2023-06-12 12:19:50 | INFO | train_inner | epoch 008:   9795 / 11284 loss=3.598, nll_loss=1.899, ppl=3.73, wps=73119.1, ups=1.23, wpb=59521.6, bsz=2230.1, num_updates=88700, lr=0.000335767, gnorm=0.294, loss_scale=2, train_wall=77, gb_free=39.6, wall=74011
2023-06-12 12:21:13 | INFO | train_inner | epoch 008:   9895 / 11284 loss=3.593, nll_loss=1.892, ppl=3.71, wps=72082.2, ups=1.21, wpb=59534.7, bsz=2228.2, num_updates=88800, lr=0.000335578, gnorm=0.304, loss_scale=2, train_wall=79, gb_free=39.6, wall=74093
2023-06-12 12:22:38 | INFO | train_inner | epoch 008:   9995 / 11284 loss=3.59, nll_loss=1.889, ppl=3.7, wps=69427.8, ups=1.17, wpb=59524.9, bsz=2182.2, num_updates=88900, lr=0.000335389, gnorm=0.298, loss_scale=2, train_wall=82, gb_free=39.5, wall=74179
2023-06-12 12:24:01 | INFO | train_inner | epoch 008:  10095 / 11284 loss=3.596, nll_loss=1.896, ppl=3.72, wps=72318.2, ups=1.21, wpb=59638.7, bsz=2255.6, num_updates=89000, lr=0.000335201, gnorm=0.296, loss_scale=2, train_wall=78, gb_free=39.5, wall=74262
2023-06-12 12:25:23 | INFO | train_inner | epoch 008:  10195 / 11284 loss=3.59, nll_loss=1.889, ppl=3.7, wps=71883.4, ups=1.21, wpb=59229.2, bsz=2206.9, num_updates=89100, lr=0.000335013, gnorm=0.303, loss_scale=2, train_wall=78, gb_free=39.6, wall=74344
2023-06-12 12:26:46 | INFO | train_inner | epoch 008:  10295 / 11284 loss=3.593, nll_loss=1.893, ppl=3.71, wps=72352.8, ups=1.22, wpb=59463.8, bsz=2250.4, num_updates=89200, lr=0.000334825, gnorm=0.315, loss_scale=2, train_wall=78, gb_free=39.5, wall=74426
2023-06-12 12:27:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 12:28:08 | INFO | train_inner | epoch 008:  10396 / 11284 loss=3.599, nll_loss=1.899, ppl=3.73, wps=72204, ups=1.21, wpb=59584.4, bsz=2161.6, num_updates=89300, lr=0.000334637, gnorm=0.286, loss_scale=2, train_wall=79, gb_free=39.6, wall=74509
2023-06-12 12:29:30 | INFO | train_inner | epoch 008:  10496 / 11284 loss=3.59, nll_loss=1.889, ppl=3.7, wps=73101.8, ups=1.23, wpb=59612.1, bsz=2095, num_updates=89400, lr=0.00033445, gnorm=0.303, loss_scale=2, train_wall=77, gb_free=39.5, wall=74590
2023-06-12 12:30:51 | INFO | train_inner | epoch 008:  10596 / 11284 loss=3.598, nll_loss=1.898, ppl=3.73, wps=73019.3, ups=1.22, wpb=59630.1, bsz=2200.8, num_updates=89500, lr=0.000334263, gnorm=0.292, loss_scale=2, train_wall=78, gb_free=39.5, wall=74672
2023-06-12 12:32:14 | INFO | train_inner | epoch 008:  10696 / 11284 loss=3.581, nll_loss=1.879, ppl=3.68, wps=71949, ups=1.21, wpb=59317.4, bsz=2348.2, num_updates=89600, lr=0.000334077, gnorm=0.313, loss_scale=2, train_wall=78, gb_free=39.3, wall=74754
2023-06-12 12:33:36 | INFO | train_inner | epoch 008:  10796 / 11284 loss=3.589, nll_loss=1.888, ppl=3.7, wps=72770.6, ups=1.22, wpb=59635.3, bsz=2207.2, num_updates=89700, lr=0.00033389, gnorm=0.295, loss_scale=2, train_wall=78, gb_free=39.5, wall=74836
2023-06-12 12:34:58 | INFO | train_inner | epoch 008:  10896 / 11284 loss=3.591, nll_loss=1.891, ppl=3.71, wps=72448, ups=1.22, wpb=59476.9, bsz=2273.7, num_updates=89800, lr=0.000333704, gnorm=0.305, loss_scale=2, train_wall=78, gb_free=39.6, wall=74918
2023-06-12 12:36:20 | INFO | train_inner | epoch 008:  10996 / 11284 loss=3.597, nll_loss=1.897, ppl=3.73, wps=72262.7, ups=1.21, wpb=59510.8, bsz=2147.9, num_updates=89900, lr=0.000333519, gnorm=0.304, loss_scale=2, train_wall=78, gb_free=39.6, wall=75001
2023-06-12 12:37:43 | INFO | train_inner | epoch 008:  11096 / 11284 loss=3.607, nll_loss=1.908, ppl=3.75, wps=71950.5, ups=1.21, wpb=59657.4, bsz=2277.6, num_updates=90000, lr=0.000333333, gnorm=0.31, loss_scale=2, train_wall=79, gb_free=39.6, wall=75084
2023-06-12 12:39:06 | INFO | train_inner | epoch 008:  11196 / 11284 loss=3.597, nll_loss=1.897, ppl=3.72, wps=71889.3, ups=1.21, wpb=59654.8, bsz=2275.4, num_updates=90100, lr=0.000333148, gnorm=0.308, loss_scale=2, train_wall=79, gb_free=39.6, wall=75167
2023-06-12 12:40:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-12 12:40:37 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 4.371 | nll_loss 2.697 | ppl 6.49 | bleu 20.52 | wps 3736.9 | wpb 2397.5 | bsz 71.5 | num_updates 90188 | best_loss 4.371
2023-06-12 12:40:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 90188 updates
2023-06-12 12:40:37 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint8.pt
2023-06-12 12:40:38 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint8.pt
2023-06-12 12:40:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint8.pt (epoch 8 @ 90188 updates, score 4.371) (writing took 6.535917448811233 seconds)
2023-06-12 12:40:43 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-06-12 12:40:43 | INFO | train | epoch 008 | loss 3.595 | nll_loss 1.895 | ppl 3.72 | wps 71623.9 | ups 1.2 | wpb 59499.8 | bsz 2227.4 | num_updates 90188 | lr 0.000332986 | gnorm 0.3 | loss_scale 2 | train_wall 8891 | gb_free 39.6 | wall 75264
2023-06-12 12:40:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-12 12:40:44 | INFO | fairseq.trainer | begin training epoch 9
2023-06-12 12:40:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-12 12:40:54 | INFO | train_inner | epoch 009:     12 / 11284 loss=3.6, nll_loss=1.901, ppl=3.73, wps=54960.5, ups=0.92, wpb=59591.4, bsz=2241.6, num_updates=90200, lr=0.000332964, gnorm=0.308, loss_scale=2, train_wall=80, gb_free=39.5, wall=75275
2023-06-12 12:42:19 | INFO | train_inner | epoch 009:    112 / 11284 loss=3.588, nll_loss=1.886, ppl=3.7, wps=70200.4, ups=1.18, wpb=59529.4, bsz=2218.1, num_updates=90300, lr=0.000332779, gnorm=0.293, loss_scale=4, train_wall=81, gb_free=39.6, wall=75360
2023-06-12 12:43:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 12:43:45 | INFO | train_inner | epoch 009:    213 / 11284 loss=3.579, nll_loss=1.877, ppl=3.67, wps=69794.3, ups=1.17, wpb=59541, bsz=2237.6, num_updates=90400, lr=0.000332595, gnorm=0.304, loss_scale=2, train_wall=81, gb_free=39.5, wall=75445
2023-06-12 12:45:07 | INFO | train_inner | epoch 009:    313 / 11284 loss=3.579, nll_loss=1.876, ppl=3.67, wps=72138.8, ups=1.21, wpb=59458.5, bsz=2195.3, num_updates=90500, lr=0.000332411, gnorm=0.308, loss_scale=2, train_wall=78, gb_free=39.5, wall=75528
2023-06-12 12:46:30 | INFO | train_inner | epoch 009:    413 / 11284 loss=3.588, nll_loss=1.886, ppl=3.7, wps=71946.5, ups=1.21, wpb=59438.4, bsz=2138, num_updates=90600, lr=0.000332228, gnorm=0.295, loss_scale=2, train_wall=79, gb_free=39.5, wall=75610
2023-06-12 12:47:52 | INFO | train_inner | epoch 009:    513 / 11284 loss=3.581, nll_loss=1.879, ppl=3.68, wps=72101.9, ups=1.21, wpb=59346.9, bsz=2238.8, num_updates=90700, lr=0.000332045, gnorm=0.301, loss_scale=2, train_wall=78, gb_free=39.6, wall=75692
2023-06-12 12:49:15 | INFO | train_inner | epoch 009:    613 / 11284 loss=3.582, nll_loss=1.88, ppl=3.68, wps=71690, ups=1.2, wpb=59596.9, bsz=2215.6, num_updates=90800, lr=0.000331862, gnorm=0.299, loss_scale=2, train_wall=79, gb_free=39.6, wall=75776
2023-06-12 12:50:38 | INFO | train_inner | epoch 009:    713 / 11284 loss=3.588, nll_loss=1.886, ppl=3.7, wps=71652.5, ups=1.2, wpb=59688.8, bsz=2230.1, num_updates=90900, lr=0.000331679, gnorm=0.298, loss_scale=2, train_wall=79, gb_free=39.5, wall=75859
2023-06-12 12:52:02 | INFO | train_inner | epoch 009:    813 / 11284 loss=3.575, nll_loss=1.872, ppl=3.66, wps=71507.1, ups=1.2, wpb=59524.3, bsz=2216.1, num_updates=91000, lr=0.000331497, gnorm=0.304, loss_scale=2, train_wall=79, gb_free=39.5, wall=75942
2023-06-12 12:53:25 | INFO | train_inner | epoch 009:    913 / 11284 loss=3.593, nll_loss=1.892, ppl=3.71, wps=71452.5, ups=1.2, wpb=59523.9, bsz=2236.4, num_updates=91100, lr=0.000331315, gnorm=0.308, loss_scale=2, train_wall=80, gb_free=39.6, wall=76025
2023-06-12 12:54:48 | INFO | train_inner | epoch 009:   1013 / 11284 loss=3.577, nll_loss=1.874, ppl=3.67, wps=71966.6, ups=1.21, wpb=59512.7, bsz=2214.3, num_updates=91200, lr=0.000331133, gnorm=0.299, loss_scale=2, train_wall=79, gb_free=39.6, wall=76108
2023-06-12 12:56:09 | INFO | train_inner | epoch 009:   1113 / 11284 loss=3.579, nll_loss=1.877, ppl=3.67, wps=72767.2, ups=1.22, wpb=59429.8, bsz=2243.2, num_updates=91300, lr=0.000330952, gnorm=0.291, loss_scale=2, train_wall=77, gb_free=39.6, wall=76190
2023-06-12 12:57:32 | INFO | train_inner | epoch 009:   1213 / 11284 loss=3.598, nll_loss=1.898, ppl=3.73, wps=72318, ups=1.21, wpb=59631.5, bsz=2265.8, num_updates=91400, lr=0.000330771, gnorm=0.295, loss_scale=4, train_wall=78, gb_free=39.6, wall=76272
2023-06-12 12:58:54 | INFO | train_inner | epoch 009:   1313 / 11284 loss=3.593, nll_loss=1.892, ppl=3.71, wps=72401.6, ups=1.22, wpb=59383.2, bsz=2178.9, num_updates=91500, lr=0.00033059, gnorm=0.298, loss_scale=4, train_wall=78, gb_free=39.5, wall=76354
2023-06-12 13:00:15 | INFO | train_inner | epoch 009:   1413 / 11284 loss=3.577, nll_loss=1.874, ppl=3.67, wps=72911.7, ups=1.23, wpb=59515.8, bsz=2157.2, num_updates=91600, lr=0.000330409, gnorm=0.288, loss_scale=4, train_wall=78, gb_free=39.6, wall=76436
2023-06-12 13:01:37 | INFO | train_inner | epoch 009:   1513 / 11284 loss=3.593, nll_loss=1.893, ppl=3.71, wps=72624.1, ups=1.22, wpb=59420.4, bsz=2210.8, num_updates=91700, lr=0.000330229, gnorm=0.288, loss_scale=4, train_wall=78, gb_free=39.6, wall=76518
2023-06-12 13:03:00 | INFO | train_inner | epoch 009:   1613 / 11284 loss=3.58, nll_loss=1.878, ppl=3.67, wps=71880.1, ups=1.21, wpb=59542.8, bsz=2199.8, num_updates=91800, lr=0.000330049, gnorm=0.303, loss_scale=4, train_wall=79, gb_free=39.6, wall=76601
2023-06-12 13:04:22 | INFO | train_inner | epoch 009:   1713 / 11284 loss=3.57, nll_loss=1.866, ppl=3.65, wps=72191.5, ups=1.21, wpb=59468.1, bsz=2185.4, num_updates=91900, lr=0.00032987, gnorm=0.31, loss_scale=4, train_wall=78, gb_free=39.6, wall=76683
2023-06-12 13:04:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 13:05:46 | INFO | train_inner | epoch 009:   1814 / 11284 loss=3.574, nll_loss=1.871, ppl=3.66, wps=70803.3, ups=1.19, wpb=59389.9, bsz=2268.7, num_updates=92000, lr=0.00032969, gnorm=0.299, loss_scale=2, train_wall=80, gb_free=39.5, wall=76767
2023-06-12 13:07:09 | INFO | train_inner | epoch 009:   1914 / 11284 loss=3.577, nll_loss=1.875, ppl=3.67, wps=71720.4, ups=1.2, wpb=59587, bsz=2151.6, num_updates=92100, lr=0.000329511, gnorm=0.308, loss_scale=2, train_wall=79, gb_free=39.6, wall=76850
2023-06-12 13:08:33 | INFO | train_inner | epoch 009:   2014 / 11284 loss=3.577, nll_loss=1.874, ppl=3.67, wps=71730.8, ups=1.2, wpb=59746.9, bsz=2290.7, num_updates=92200, lr=0.000329332, gnorm=0.286, loss_scale=2, train_wall=79, gb_free=39.6, wall=76933
2023-06-12 13:09:56 | INFO | train_inner | epoch 009:   2114 / 11284 loss=3.583, nll_loss=1.881, ppl=3.68, wps=71894.9, ups=1.21, wpb=59631.6, bsz=2218.8, num_updates=92300, lr=0.000329154, gnorm=0.298, loss_scale=2, train_wall=79, gb_free=39.6, wall=77016
2023-06-12 13:11:19 | INFO | train_inner | epoch 009:   2214 / 11284 loss=3.59, nll_loss=1.89, ppl=3.71, wps=71798.7, ups=1.2, wpb=59767.8, bsz=2193.1, num_updates=92400, lr=0.000328976, gnorm=0.304, loss_scale=2, train_wall=79, gb_free=39.6, wall=77099
2023-06-12 13:12:41 | INFO | train_inner | epoch 009:   2314 / 11284 loss=3.574, nll_loss=1.872, ppl=3.66, wps=72187.7, ups=1.21, wpb=59496.8, bsz=2158.3, num_updates=92500, lr=0.000328798, gnorm=0.31, loss_scale=2, train_wall=78, gb_free=39.5, wall=77182
2023-06-12 13:14:03 | INFO | train_inner | epoch 009:   2414 / 11284 loss=3.579, nll_loss=1.876, ppl=3.67, wps=72200.8, ups=1.22, wpb=59344.7, bsz=2224, num_updates=92600, lr=0.00032862, gnorm=0.302, loss_scale=2, train_wall=78, gb_free=39.6, wall=77264
2023-06-12 13:15:26 | INFO | train_inner | epoch 009:   2514 / 11284 loss=3.588, nll_loss=1.887, ppl=3.7, wps=71836.1, ups=1.21, wpb=59505.9, bsz=2193.9, num_updates=92700, lr=0.000328443, gnorm=0.306, loss_scale=2, train_wall=79, gb_free=39.5, wall=77347
2023-06-12 13:16:49 | INFO | train_inner | epoch 009:   2614 / 11284 loss=3.571, nll_loss=1.868, ppl=3.65, wps=71698.8, ups=1.21, wpb=59299.3, bsz=2176.2, num_updates=92800, lr=0.000328266, gnorm=0.318, loss_scale=2, train_wall=79, gb_free=39.6, wall=77430
2023-06-12 13:18:12 | INFO | train_inner | epoch 009:   2714 / 11284 loss=3.565, nll_loss=1.861, ppl=3.63, wps=72155.4, ups=1.21, wpb=59791.4, bsz=2265.6, num_updates=92900, lr=0.000328089, gnorm=0.303, loss_scale=2, train_wall=79, gb_free=39.6, wall=77512
2023-06-12 13:19:34 | INFO | train_inner | epoch 009:   2814 / 11284 loss=3.582, nll_loss=1.88, ppl=3.68, wps=72255.7, ups=1.22, wpb=59390.4, bsz=2185.5, num_updates=93000, lr=0.000327913, gnorm=0.3, loss_scale=4, train_wall=78, gb_free=39.6, wall=77595
2023-06-12 13:20:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 13:20:58 | INFO | train_inner | epoch 009:   2915 / 11284 loss=3.585, nll_loss=1.884, ppl=3.69, wps=70997.6, ups=1.19, wpb=59646.8, bsz=2240, num_updates=93100, lr=0.000327737, gnorm=0.292, loss_scale=2, train_wall=80, gb_free=39.6, wall=77679
2023-06-12 13:22:21 | INFO | train_inner | epoch 009:   3015 / 11284 loss=3.598, nll_loss=1.898, ppl=3.73, wps=71627.9, ups=1.21, wpb=59403.9, bsz=2220.9, num_updates=93200, lr=0.000327561, gnorm=0.308, loss_scale=2, train_wall=79, gb_free=39.5, wall=77762
2023-06-12 13:23:44 | INFO | train_inner | epoch 009:   3115 / 11284 loss=3.58, nll_loss=1.878, ppl=3.67, wps=71699, ups=1.2, wpb=59535.4, bsz=2225.4, num_updates=93300, lr=0.000327385, gnorm=0.317, loss_scale=2, train_wall=79, gb_free=39.6, wall=77845
2023-06-12 13:25:07 | INFO | train_inner | epoch 009:   3215 / 11284 loss=3.564, nll_loss=1.86, ppl=3.63, wps=72026.4, ups=1.21, wpb=59574.1, bsz=2220.3, num_updates=93400, lr=0.00032721, gnorm=0.288, loss_scale=2, train_wall=79, gb_free=39.5, wall=77927
2023-06-12 13:26:29 | INFO | train_inner | epoch 009:   3315 / 11284 loss=3.58, nll_loss=1.878, ppl=3.67, wps=71921.5, ups=1.21, wpb=59429.9, bsz=2161.3, num_updates=93500, lr=0.000327035, gnorm=0.308, loss_scale=2, train_wall=79, gb_free=39.5, wall=78010
2023-06-12 13:27:52 | INFO | train_inner | epoch 009:   3415 / 11284 loss=3.592, nll_loss=1.892, ppl=3.71, wps=71343.5, ups=1.2, wpb=59241.2, bsz=2224.9, num_updates=93600, lr=0.00032686, gnorm=0.323, loss_scale=2, train_wall=79, gb_free=39.6, wall=78093
2023-06-12 13:29:15 | INFO | train_inner | epoch 009:   3515 / 11284 loss=3.591, nll_loss=1.89, ppl=3.71, wps=71834.5, ups=1.21, wpb=59425.8, bsz=2195.1, num_updates=93700, lr=0.000326686, gnorm=0.293, loss_scale=2, train_wall=79, gb_free=39.6, wall=78176
2023-06-12 13:30:38 | INFO | train_inner | epoch 009:   3615 / 11284 loss=3.587, nll_loss=1.886, ppl=3.7, wps=71704.9, ups=1.2, wpb=59713.8, bsz=2256.4, num_updates=93800, lr=0.000326512, gnorm=0.305, loss_scale=2, train_wall=79, gb_free=39.5, wall=78259
2023-06-12 13:32:02 | INFO | train_inner | epoch 009:   3715 / 11284 loss=3.578, nll_loss=1.876, ppl=3.67, wps=71742.4, ups=1.2, wpb=59630.8, bsz=2249.9, num_updates=93900, lr=0.000326338, gnorm=0.292, loss_scale=2, train_wall=79, gb_free=39.6, wall=78342
2023-06-12 13:33:24 | INFO | train_inner | epoch 009:   3815 / 11284 loss=3.585, nll_loss=1.883, ppl=3.69, wps=72715.9, ups=1.22, wpb=59592.1, bsz=2264.4, num_updates=94000, lr=0.000326164, gnorm=0.295, loss_scale=2, train_wall=78, gb_free=39.6, wall=78424
2023-06-12 13:34:45 | INFO | train_inner | epoch 009:   3915 / 11284 loss=3.576, nll_loss=1.874, ppl=3.67, wps=73256.8, ups=1.23, wpb=59452.7, bsz=2191.9, num_updates=94100, lr=0.000325991, gnorm=0.308, loss_scale=4, train_wall=77, gb_free=39.6, wall=78505
2023-06-12 13:35:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 13:36:08 | INFO | train_inner | epoch 009:   4016 / 11284 loss=3.592, nll_loss=1.891, ppl=3.71, wps=71739.3, ups=1.21, wpb=59446.9, bsz=2276.5, num_updates=94200, lr=0.000325818, gnorm=0.312, loss_scale=2, train_wall=78, gb_free=39.6, wall=78588
2023-06-12 13:37:31 | INFO | train_inner | epoch 009:   4116 / 11284 loss=3.576, nll_loss=1.873, ppl=3.66, wps=71813.2, ups=1.2, wpb=59776.4, bsz=2180.8, num_updates=94300, lr=0.000325645, gnorm=0.296, loss_scale=2, train_wall=80, gb_free=39.6, wall=78671
2023-06-12 13:38:54 | INFO | train_inner | epoch 009:   4216 / 11284 loss=3.603, nll_loss=1.904, ppl=3.74, wps=71823, ups=1.21, wpb=59498, bsz=2208.9, num_updates=94400, lr=0.000325472, gnorm=0.308, loss_scale=2, train_wall=79, gb_free=39.6, wall=78754
2023-06-12 13:40:17 | INFO | train_inner | epoch 009:   4316 / 11284 loss=3.579, nll_loss=1.876, ppl=3.67, wps=71441.2, ups=1.2, wpb=59458.3, bsz=2180.4, num_updates=94500, lr=0.0003253, gnorm=0.305, loss_scale=2, train_wall=79, gb_free=39.6, wall=78837
2023-06-12 13:41:40 | INFO | train_inner | epoch 009:   4416 / 11284 loss=3.564, nll_loss=1.86, ppl=3.63, wps=71839.3, ups=1.2, wpb=59741.1, bsz=2255.2, num_updates=94600, lr=0.000325128, gnorm=0.297, loss_scale=2, train_wall=79, gb_free=39.6, wall=78921
2023-06-12 13:43:03 | INFO | train_inner | epoch 009:   4516 / 11284 loss=3.583, nll_loss=1.882, ppl=3.69, wps=71807.7, ups=1.2, wpb=59631.1, bsz=2231.8, num_updates=94700, lr=0.000324956, gnorm=0.313, loss_scale=2, train_wall=79, gb_free=39.6, wall=79004
2023-06-12 13:44:26 | INFO | train_inner | epoch 009:   4616 / 11284 loss=3.577, nll_loss=1.874, ppl=3.67, wps=71833.1, ups=1.2, wpb=59671.9, bsz=2277.7, num_updates=94800, lr=0.000324785, gnorm=0.314, loss_scale=2, train_wall=79, gb_free=39.1, wall=79087
2023-06-12 13:45:48 | INFO | train_inner | epoch 009:   4716 / 11284 loss=3.582, nll_loss=1.88, ppl=3.68, wps=72416.7, ups=1.22, wpb=59488.3, bsz=2176.7, num_updates=94900, lr=0.000324614, gnorm=0.3, loss_scale=2, train_wall=79, gb_free=39.6, wall=79169
2023-06-12 13:47:11 | INFO | train_inner | epoch 009:   4816 / 11284 loss=3.593, nll_loss=1.893, ppl=3.71, wps=72182.7, ups=1.22, wpb=59396.4, bsz=2178.1, num_updates=95000, lr=0.000324443, gnorm=0.31, loss_scale=2, train_wall=78, gb_free=39.5, wall=79251
2023-06-12 13:48:34 | INFO | train_inner | epoch 009:   4916 / 11284 loss=3.588, nll_loss=1.888, ppl=3.7, wps=71633.3, ups=1.2, wpb=59507.4, bsz=2341.1, num_updates=95100, lr=0.000324272, gnorm=0.318, loss_scale=2, train_wall=79, gb_free=39.6, wall=79334
2023-06-12 13:49:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 13:49:57 | INFO | train_inner | epoch 009:   5017 / 11284 loss=3.589, nll_loss=1.888, ppl=3.7, wps=70958.7, ups=1.19, wpb=59445, bsz=2188.4, num_updates=95200, lr=0.000324102, gnorm=0.313, loss_scale=2, train_wall=80, gb_free=39.5, wall=79418
2023-06-12 13:51:20 | INFO | train_inner | epoch 009:   5117 / 11284 loss=3.583, nll_loss=1.882, ppl=3.69, wps=71853.2, ups=1.2, wpb=59641.6, bsz=2278.6, num_updates=95300, lr=0.000323932, gnorm=0.29, loss_scale=2, train_wall=79, gb_free=39.4, wall=79501
2023-06-12 13:52:44 | INFO | train_inner | epoch 009:   5217 / 11284 loss=3.584, nll_loss=1.883, ppl=3.69, wps=71553.1, ups=1.2, wpb=59474, bsz=2233.4, num_updates=95400, lr=0.000323762, gnorm=0.294, loss_scale=2, train_wall=79, gb_free=39.5, wall=79584
2023-06-12 13:54:07 | INFO | train_inner | epoch 009:   5317 / 11284 loss=3.567, nll_loss=1.864, ppl=3.64, wps=71143.1, ups=1.19, wpb=59663, bsz=2286.6, num_updates=95500, lr=0.000323592, gnorm=0.314, loss_scale=2, train_wall=80, gb_free=39.5, wall=79668
2023-06-12 13:55:30 | INFO | train_inner | epoch 009:   5417 / 11284 loss=3.593, nll_loss=1.893, ppl=3.71, wps=71744.5, ups=1.21, wpb=59521.1, bsz=2249.4, num_updates=95600, lr=0.000323423, gnorm=0.287, loss_scale=2, train_wall=79, gb_free=39.6, wall=79751
2023-06-12 13:56:54 | INFO | train_inner | epoch 009:   5517 / 11284 loss=3.571, nll_loss=1.868, ppl=3.65, wps=71741.9, ups=1.2, wpb=59692.3, bsz=2247, num_updates=95700, lr=0.000323254, gnorm=0.302, loss_scale=2, train_wall=79, gb_free=39.6, wall=79834
2023-06-12 13:58:17 | INFO | train_inner | epoch 009:   5617 / 11284 loss=3.576, nll_loss=1.873, ppl=3.66, wps=71559.4, ups=1.2, wpb=59508.7, bsz=2220, num_updates=95800, lr=0.000323085, gnorm=0.295, loss_scale=2, train_wall=79, gb_free=39.6, wall=79917
2023-06-12 13:59:39 | INFO | train_inner | epoch 009:   5717 / 11284 loss=3.586, nll_loss=1.885, ppl=3.69, wps=71629.5, ups=1.21, wpb=59261.7, bsz=2179.6, num_updates=95900, lr=0.000322917, gnorm=0.306, loss_scale=2, train_wall=79, gb_free=39.6, wall=80000
2023-06-12 14:01:02 | INFO | train_inner | epoch 009:   5817 / 11284 loss=3.589, nll_loss=1.888, ppl=3.7, wps=71937.1, ups=1.21, wpb=59667.1, bsz=2225.8, num_updates=96000, lr=0.000322749, gnorm=0.3, loss_scale=2, train_wall=79, gb_free=39.5, wall=80083
2023-06-12 14:02:26 | INFO | train_inner | epoch 009:   5917 / 11284 loss=3.593, nll_loss=1.893, ppl=3.72, wps=71179.4, ups=1.2, wpb=59512.3, bsz=2298.3, num_updates=96100, lr=0.000322581, gnorm=0.308, loss_scale=2, train_wall=79, gb_free=39.5, wall=80167
2023-06-12 14:03:49 | INFO | train_inner | epoch 009:   6017 / 11284 loss=3.574, nll_loss=1.872, ppl=3.66, wps=71772.3, ups=1.2, wpb=59759.9, bsz=2237.9, num_updates=96200, lr=0.000322413, gnorm=0.302, loss_scale=2, train_wall=79, gb_free=39.6, wall=80250
2023-06-12 14:05:12 | INFO | train_inner | epoch 009:   6117 / 11284 loss=3.577, nll_loss=1.875, ppl=3.67, wps=71642.6, ups=1.2, wpb=59512.5, bsz=2187.3, num_updates=96300, lr=0.000322245, gnorm=0.293, loss_scale=4, train_wall=79, gb_free=39.6, wall=80333
2023-06-12 14:05:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 14:06:36 | INFO | train_inner | epoch 009:   6218 / 11284 loss=3.589, nll_loss=1.888, ppl=3.7, wps=70884.8, ups=1.19, wpb=59404.9, bsz=2176.4, num_updates=96400, lr=0.000322078, gnorm=0.305, loss_scale=2, train_wall=80, gb_free=39.6, wall=80417
2023-06-12 14:07:59 | INFO | train_inner | epoch 009:   6318 / 11284 loss=3.573, nll_loss=1.871, ppl=3.66, wps=71774.6, ups=1.21, wpb=59396.9, bsz=2214.7, num_updates=96500, lr=0.000321911, gnorm=0.308, loss_scale=2, train_wall=79, gb_free=39.6, wall=80500
2023-06-12 14:09:22 | INFO | train_inner | epoch 009:   6418 / 11284 loss=3.588, nll_loss=1.888, ppl=3.7, wps=71441.9, ups=1.2, wpb=59371.9, bsz=2269.2, num_updates=96600, lr=0.000321745, gnorm=0.298, loss_scale=2, train_wall=79, gb_free=39.6, wall=80583
2023-06-12 14:10:45 | INFO | train_inner | epoch 009:   6518 / 11284 loss=3.576, nll_loss=1.874, ppl=3.67, wps=71892.9, ups=1.21, wpb=59558.9, bsz=2180.7, num_updates=96700, lr=0.000321578, gnorm=0.297, loss_scale=2, train_wall=79, gb_free=39.6, wall=80665
2023-06-12 14:12:08 | INFO | train_inner | epoch 009:   6618 / 11284 loss=3.588, nll_loss=1.887, ppl=3.7, wps=71771.6, ups=1.21, wpb=59437.6, bsz=2250.4, num_updates=96800, lr=0.000321412, gnorm=0.306, loss_scale=2, train_wall=79, gb_free=39.6, wall=80748
2023-06-12 14:13:32 | INFO | train_inner | epoch 009:   6718 / 11284 loss=3.593, nll_loss=1.893, ppl=3.71, wps=70288.4, ups=1.18, wpb=59474.8, bsz=2229.7, num_updates=96900, lr=0.000321246, gnorm=0.308, loss_scale=2, train_wall=81, gb_free=39.6, wall=80833
2023-06-12 14:14:57 | INFO | train_inner | epoch 009:   6818 / 11284 loss=3.578, nll_loss=1.876, ppl=3.67, wps=70091.2, ups=1.18, wpb=59188.7, bsz=2094.2, num_updates=97000, lr=0.000321081, gnorm=0.305, loss_scale=2, train_wall=81, gb_free=39.6, wall=80917
2023-06-12 14:16:22 | INFO | train_inner | epoch 009:   6918 / 11284 loss=3.6, nll_loss=1.9, ppl=3.73, wps=69690.9, ups=1.17, wpb=59458.5, bsz=2320.1, num_updates=97100, lr=0.000320915, gnorm=0.299, loss_scale=2, train_wall=81, gb_free=39.6, wall=81003
2023-06-12 14:17:49 | INFO | train_inner | epoch 009:   7018 / 11284 loss=3.576, nll_loss=1.874, ppl=3.67, wps=68541.8, ups=1.15, wpb=59657.7, bsz=2189.9, num_updates=97200, lr=0.00032075, gnorm=0.309, loss_scale=2, train_wall=83, gb_free=39.6, wall=81090
2023-06-12 14:19:15 | INFO | train_inner | epoch 009:   7118 / 11284 loss=3.571, nll_loss=1.868, ppl=3.65, wps=69393.8, ups=1.17, wpb=59526.8, bsz=2332.7, num_updates=97300, lr=0.000320585, gnorm=0.294, loss_scale=2, train_wall=82, gb_free=39.6, wall=81175
2023-06-12 14:20:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 14:20:41 | INFO | train_inner | epoch 009:   7219 / 11284 loss=3.587, nll_loss=1.886, ppl=3.7, wps=69053.4, ups=1.16, wpb=59389.7, bsz=2263.2, num_updates=97400, lr=0.000320421, gnorm=0.298, loss_scale=2, train_wall=82, gb_free=39.6, wall=81261
2023-06-12 14:22:06 | INFO | train_inner | epoch 009:   7319 / 11284 loss=3.595, nll_loss=1.895, ppl=3.72, wps=69578.5, ups=1.17, wpb=59506.2, bsz=2318.1, num_updates=97500, lr=0.000320256, gnorm=0.319, loss_scale=2, train_wall=81, gb_free=39.5, wall=81347
2023-06-12 14:23:33 | INFO | train_inner | epoch 009:   7419 / 11284 loss=3.585, nll_loss=1.884, ppl=3.69, wps=68788.9, ups=1.15, wpb=59576.6, bsz=2278.1, num_updates=97600, lr=0.000320092, gnorm=0.297, loss_scale=2, train_wall=82, gb_free=39.3, wall=81434
2023-06-12 14:24:59 | INFO | train_inner | epoch 009:   7519 / 11284 loss=3.584, nll_loss=1.883, ppl=3.69, wps=69737.1, ups=1.17, wpb=59609.8, bsz=2435.9, num_updates=97700, lr=0.000319928, gnorm=0.288, loss_scale=2, train_wall=81, gb_free=39.5, wall=81519
2023-06-12 14:26:25 | INFO | train_inner | epoch 009:   7619 / 11284 loss=3.597, nll_loss=1.898, ppl=3.73, wps=68661.4, ups=1.15, wpb=59478.9, bsz=2346.3, num_updates=97800, lr=0.000319765, gnorm=0.301, loss_scale=2, train_wall=82, gb_free=39.6, wall=81606
2023-06-12 14:27:51 | INFO | train_inner | epoch 009:   7719 / 11284 loss=3.586, nll_loss=1.885, ppl=3.69, wps=68837.3, ups=1.16, wpb=59193, bsz=2231.8, num_updates=97900, lr=0.000319601, gnorm=0.308, loss_scale=2, train_wall=82, gb_free=39.6, wall=81692
2023-06-12 14:29:18 | INFO | train_inner | epoch 009:   7819 / 11284 loss=3.592, nll_loss=1.892, ppl=3.71, wps=68516.4, ups=1.15, wpb=59417.5, bsz=2308.4, num_updates=98000, lr=0.000319438, gnorm=0.311, loss_scale=2, train_wall=82, gb_free=39.5, wall=81778
2023-06-12 14:30:44 | INFO | train_inner | epoch 009:   7919 / 11284 loss=3.568, nll_loss=1.866, ppl=3.64, wps=69247, ups=1.17, wpb=59417.8, bsz=2304.1, num_updates=98100, lr=0.000319275, gnorm=0.311, loss_scale=2, train_wall=82, gb_free=39.6, wall=81864
2023-06-12 14:32:09 | INFO | train_inner | epoch 009:   8019 / 11284 loss=3.59, nll_loss=1.89, ppl=3.71, wps=69345.1, ups=1.17, wpb=59242.3, bsz=2231.6, num_updates=98200, lr=0.000319113, gnorm=0.297, loss_scale=2, train_wall=82, gb_free=39.6, wall=81950
2023-06-12 14:33:35 | INFO | train_inner | epoch 009:   8119 / 11284 loss=3.581, nll_loss=1.879, ppl=3.68, wps=69180.7, ups=1.16, wpb=59495, bsz=2341.1, num_updates=98300, lr=0.00031895, gnorm=0.293, loss_scale=2, train_wall=82, gb_free=39.6, wall=82036
2023-06-12 14:35:01 | INFO | train_inner | epoch 009:   8219 / 11284 loss=3.591, nll_loss=1.891, ppl=3.71, wps=69317.6, ups=1.17, wpb=59278.7, bsz=2141.9, num_updates=98400, lr=0.000318788, gnorm=0.306, loss_scale=4, train_wall=82, gb_free=39.5, wall=82121
2023-06-12 14:35:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 14:36:27 | INFO | train_inner | epoch 009:   8320 / 11284 loss=3.568, nll_loss=1.865, ppl=3.64, wps=68610.2, ups=1.15, wpb=59560.6, bsz=2190.1, num_updates=98500, lr=0.000318626, gnorm=0.299, loss_scale=2, train_wall=83, gb_free=39.6, wall=82208
2023-06-12 14:37:53 | INFO | train_inner | epoch 009:   8420 / 11284 loss=3.587, nll_loss=1.886, ppl=3.7, wps=69610.5, ups=1.17, wpb=59550.2, bsz=2215.9, num_updates=98600, lr=0.000318465, gnorm=0.309, loss_scale=2, train_wall=82, gb_free=39.6, wall=82294
2023-06-12 14:39:18 | INFO | train_inner | epoch 009:   8520 / 11284 loss=3.587, nll_loss=1.886, ppl=3.7, wps=69774.6, ups=1.18, wpb=59378.3, bsz=2265.8, num_updates=98700, lr=0.000318304, gnorm=0.307, loss_scale=2, train_wall=81, gb_free=39.6, wall=82379
2023-06-12 14:40:41 | INFO | train_inner | epoch 009:   8620 / 11284 loss=3.582, nll_loss=1.881, ppl=3.68, wps=71901.2, ups=1.21, wpb=59593.1, bsz=2239.9, num_updates=98800, lr=0.000318142, gnorm=0.305, loss_scale=2, train_wall=79, gb_free=39.3, wall=82462
2023-06-12 14:42:04 | INFO | train_inner | epoch 009:   8720 / 11284 loss=3.588, nll_loss=1.888, ppl=3.7, wps=71836.8, ups=1.21, wpb=59307.6, bsz=2284.4, num_updates=98900, lr=0.000317982, gnorm=0.304, loss_scale=2, train_wall=79, gb_free=39.5, wall=82544
2023-06-12 14:43:26 | INFO | train_inner | epoch 009:   8820 / 11284 loss=3.571, nll_loss=1.868, ppl=3.65, wps=71911.4, ups=1.21, wpb=59453, bsz=2271.5, num_updates=99000, lr=0.000317821, gnorm=0.302, loss_scale=2, train_wall=79, gb_free=39.6, wall=82627
2023-06-12 14:44:49 | INFO | train_inner | epoch 009:   8920 / 11284 loss=3.581, nll_loss=1.879, ppl=3.68, wps=71642.4, ups=1.2, wpb=59464, bsz=2208, num_updates=99100, lr=0.00031766, gnorm=0.307, loss_scale=2, train_wall=79, gb_free=39.6, wall=82710
2023-06-12 14:46:12 | INFO | train_inner | epoch 009:   9020 / 11284 loss=3.588, nll_loss=1.888, ppl=3.7, wps=71417.4, ups=1.2, wpb=59428.7, bsz=2294.8, num_updates=99200, lr=0.0003175, gnorm=0.31, loss_scale=2, train_wall=79, gb_free=39.5, wall=82793
2023-06-12 14:47:35 | INFO | train_inner | epoch 009:   9120 / 11284 loss=3.576, nll_loss=1.874, ppl=3.67, wps=71721, ups=1.21, wpb=59337.8, bsz=2163.5, num_updates=99300, lr=0.00031734, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.5, wall=82876
2023-06-12 14:48:58 | INFO | train_inner | epoch 009:   9220 / 11284 loss=3.576, nll_loss=1.874, ppl=3.67, wps=71726.7, ups=1.21, wpb=59465.6, bsz=2173.9, num_updates=99400, lr=0.000317181, gnorm=0.305, loss_scale=2, train_wall=79, gb_free=39.6, wall=82959
2023-06-12 14:50:21 | INFO | train_inner | epoch 009:   9320 / 11284 loss=3.583, nll_loss=1.882, ppl=3.69, wps=71863.1, ups=1.2, wpb=59639.5, bsz=2269.6, num_updates=99500, lr=0.000317021, gnorm=0.302, loss_scale=4, train_wall=79, gb_free=39.6, wall=83042
2023-06-12 14:51:44 | INFO | train_inner | epoch 009:   9420 / 11284 loss=3.581, nll_loss=1.879, ppl=3.68, wps=71577, ups=1.2, wpb=59464.9, bsz=2164.7, num_updates=99600, lr=0.000316862, gnorm=0.3, loss_scale=4, train_wall=79, gb_free=39.5, wall=83125
2023-06-12 14:51:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 14:53:08 | INFO | train_inner | epoch 009:   9521 / 11284 loss=3.582, nll_loss=1.881, ppl=3.68, wps=70894.3, ups=1.2, wpb=59265.5, bsz=2179.6, num_updates=99700, lr=0.000316703, gnorm=0.304, loss_scale=2, train_wall=80, gb_free=39.5, wall=83208
2023-06-12 14:54:31 | INFO | train_inner | epoch 009:   9621 / 11284 loss=3.573, nll_loss=1.871, ppl=3.66, wps=71965, ups=1.21, wpb=59562.8, bsz=2244.8, num_updates=99800, lr=0.000316544, gnorm=0.292, loss_scale=2, train_wall=79, gb_free=39.6, wall=83291
2023-06-12 14:55:52 | INFO | train_inner | epoch 009:   9721 / 11284 loss=3.581, nll_loss=1.879, ppl=3.68, wps=72773.6, ups=1.22, wpb=59652.6, bsz=2277.7, num_updates=99900, lr=0.000316386, gnorm=0.298, loss_scale=2, train_wall=78, gb_free=39.6, wall=83373
2023-06-12 14:57:15 | INFO | train_inner | epoch 009:   9821 / 11284 loss=3.561, nll_loss=1.857, ppl=3.62, wps=72579.9, ups=1.22, wpb=59583.5, bsz=2200.8, num_updates=100000, lr=0.000316228, gnorm=0.297, loss_scale=2, train_wall=78, gb_free=39.6, wall=83455
2023-06-12 14:58:38 | INFO | train_inner | epoch 009:   9921 / 11284 loss=3.58, nll_loss=1.878, ppl=3.68, wps=71609, ups=1.2, wpb=59492.8, bsz=2225.5, num_updates=100100, lr=0.00031607, gnorm=0.32, loss_scale=2, train_wall=79, gb_free=39.6, wall=83538
2023-06-12 15:00:01 | INFO | train_inner | epoch 009:  10021 / 11284 loss=3.573, nll_loss=1.87, ppl=3.66, wps=71764, ups=1.21, wpb=59472.4, bsz=2219.8, num_updates=100200, lr=0.000315912, gnorm=0.309, loss_scale=2, train_wall=79, gb_free=39.6, wall=83621
2023-06-12 15:01:23 | INFO | train_inner | epoch 009:  10121 / 11284 loss=3.569, nll_loss=1.867, ppl=3.65, wps=71737.1, ups=1.21, wpb=59383.2, bsz=2215.5, num_updates=100300, lr=0.000315754, gnorm=0.289, loss_scale=2, train_wall=79, gb_free=39.6, wall=83704
2023-06-12 15:02:46 | INFO | train_inner | epoch 009:  10221 / 11284 loss=3.587, nll_loss=1.886, ppl=3.7, wps=72282.8, ups=1.21, wpb=59649.8, bsz=2206.1, num_updates=100400, lr=0.000315597, gnorm=0.301, loss_scale=2, train_wall=79, gb_free=39.6, wall=83786
2023-06-12 15:04:09 | INFO | train_inner | epoch 009:  10321 / 11284 loss=3.574, nll_loss=1.871, ppl=3.66, wps=72031.7, ups=1.21, wpb=59630.4, bsz=2212.4, num_updates=100500, lr=0.00031544, gnorm=0.3, loss_scale=2, train_wall=79, gb_free=39.5, wall=83869
2023-06-12 15:05:32 | INFO | train_inner | epoch 009:  10421 / 11284 loss=3.578, nll_loss=1.877, ppl=3.67, wps=71767.7, ups=1.21, wpb=59541.2, bsz=2172.7, num_updates=100600, lr=0.000315283, gnorm=0.305, loss_scale=2, train_wall=79, gb_free=39.5, wall=83952
2023-06-12 15:06:55 | INFO | train_inner | epoch 009:  10521 / 11284 loss=3.586, nll_loss=1.885, ppl=3.69, wps=71522.7, ups=1.2, wpb=59463, bsz=2196.7, num_updates=100700, lr=0.000315127, gnorm=0.316, loss_scale=4, train_wall=79, gb_free=39.6, wall=84035
2023-06-12 15:07:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 15:08:18 | INFO | train_inner | epoch 009:  10622 / 11284 loss=3.583, nll_loss=1.881, ppl=3.68, wps=71182.2, ups=1.19, wpb=59594.3, bsz=2301.8, num_updates=100800, lr=0.00031497, gnorm=0.311, loss_scale=2, train_wall=80, gb_free=39.6, wall=84119
2023-06-12 15:09:40 | INFO | train_inner | epoch 009:  10722 / 11284 loss=3.581, nll_loss=1.879, ppl=3.68, wps=72547, ups=1.22, wpb=59333.2, bsz=2245.4, num_updates=100900, lr=0.000314814, gnorm=0.301, loss_scale=2, train_wall=78, gb_free=39.6, wall=84201
2023-06-12 15:11:02 | INFO | train_inner | epoch 009:  10822 / 11284 loss=3.573, nll_loss=1.871, ppl=3.66, wps=72774.1, ups=1.22, wpb=59706, bsz=2242, num_updates=101000, lr=0.000314658, gnorm=0.302, loss_scale=2, train_wall=78, gb_free=39.6, wall=84283
2023-06-12 15:12:24 | INFO | train_inner | epoch 009:  10922 / 11284 loss=3.582, nll_loss=1.881, ppl=3.68, wps=72747.5, ups=1.23, wpb=59333.3, bsz=2131.1, num_updates=101100, lr=0.000314503, gnorm=0.307, loss_scale=2, train_wall=78, gb_free=39.5, wall=84364
2023-06-12 15:13:45 | INFO | train_inner | epoch 009:  11022 / 11284 loss=3.592, nll_loss=1.892, ppl=3.71, wps=72943.2, ups=1.23, wpb=59474.7, bsz=2178.3, num_updates=101200, lr=0.000314347, gnorm=0.315, loss_scale=2, train_wall=77, gb_free=39.6, wall=84446
2023-06-12 15:15:08 | INFO | train_inner | epoch 009:  11122 / 11284 loss=3.579, nll_loss=1.877, ppl=3.67, wps=72379, ups=1.22, wpb=59535.4, bsz=2225.4, num_updates=101300, lr=0.000314192, gnorm=0.317, loss_scale=2, train_wall=78, gb_free=39.6, wall=84528
2023-06-12 15:16:30 | INFO | train_inner | epoch 009:  11222 / 11284 loss=3.593, nll_loss=1.894, ppl=3.72, wps=72680.8, ups=1.22, wpb=59531.9, bsz=2139.4, num_updates=101400, lr=0.000314037, gnorm=0.302, loss_scale=2, train_wall=78, gb_free=39.5, wall=84610
2023-06-12 15:17:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-12 15:17:39 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 4.352 | nll_loss 2.676 | ppl 6.39 | bleu 21.08 | wps 3767.6 | wpb 2397.5 | bsz 71.5 | num_updates 101462 | best_loss 4.352
2023-06-12 15:17:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 101462 updates
2023-06-12 15:17:39 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint9.pt
2023-06-12 15:17:43 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint9.pt
2023-06-12 15:20:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint9.pt (epoch 9 @ 101462 updates, score 4.352) (writing took 144.10610832553357 seconds)
2023-06-12 15:20:03 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-06-12 15:20:03 | INFO | train | epoch 009 | loss 3.582 | nll_loss 1.881 | ppl 3.68 | wps 70169.5 | ups 1.18 | wpb 59500.2 | bsz 2227.5 | num_updates 101462 | lr 0.000313941 | gnorm 0.303 | loss_scale 2 | train_wall 8950 | gb_free 39.6 | wall 84824
2023-06-12 15:20:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-12 15:20:04 | INFO | fairseq.trainer | begin training epoch 10
2023-06-12 15:20:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-12 15:20:35 | INFO | train_inner | epoch 010:     38 / 11284 loss=3.564, nll_loss=1.86, ppl=3.63, wps=24049, ups=0.41, wpb=59091.1, bsz=2178.7, num_updates=101500, lr=0.000313882, gnorm=0.296, loss_scale=2, train_wall=79, gb_free=38.9, wall=84856
2023-06-12 15:21:58 | INFO | train_inner | epoch 010:    138 / 11284 loss=3.561, nll_loss=1.856, ppl=3.62, wps=71782.7, ups=1.2, wpb=59595, bsz=2271.5, num_updates=101600, lr=0.000313728, gnorm=0.307, loss_scale=2, train_wall=79, gb_free=39.5, wall=84939
2023-06-12 15:23:21 | INFO | train_inner | epoch 010:    238 / 11284 loss=3.551, nll_loss=1.846, ppl=3.6, wps=71535.7, ups=1.2, wpb=59415.2, bsz=2262.1, num_updates=101700, lr=0.000313574, gnorm=0.305, loss_scale=2, train_wall=79, gb_free=39.5, wall=85022
2023-06-12 15:24:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 15:24:45 | INFO | train_inner | epoch 010:    339 / 11284 loss=3.557, nll_loss=1.852, ppl=3.61, wps=70783.7, ups=1.19, wpb=59370.8, bsz=2256.4, num_updates=101800, lr=0.00031342, gnorm=0.304, loss_scale=2, train_wall=80, gb_free=39.6, wall=85106
2023-06-12 15:26:08 | INFO | train_inner | epoch 010:    439 / 11284 loss=3.559, nll_loss=1.854, ppl=3.62, wps=72021.7, ups=1.21, wpb=59718.2, bsz=2265.6, num_updates=101900, lr=0.000313266, gnorm=0.309, loss_scale=2, train_wall=79, gb_free=39.5, wall=85189
2023-06-12 15:27:30 | INFO | train_inner | epoch 010:    539 / 11284 loss=3.574, nll_loss=1.872, ppl=3.66, wps=72971, ups=1.23, wpb=59536.9, bsz=2170.6, num_updates=102000, lr=0.000313112, gnorm=0.31, loss_scale=2, train_wall=78, gb_free=39.5, wall=85270
2023-06-12 15:28:52 | INFO | train_inner | epoch 010:    639 / 11284 loss=3.573, nll_loss=1.87, ppl=3.66, wps=72474.2, ups=1.21, wpb=59672.9, bsz=2194.9, num_updates=102100, lr=0.000312959, gnorm=0.298, loss_scale=2, train_wall=78, gb_free=39.5, wall=85353
2023-06-12 15:30:15 | INFO | train_inner | epoch 010:    739 / 11284 loss=3.561, nll_loss=1.857, ppl=3.62, wps=71247.4, ups=1.2, wpb=59312.9, bsz=2309.9, num_updates=102200, lr=0.000312806, gnorm=0.289, loss_scale=2, train_wall=79, gb_free=39.6, wall=85436
2023-06-12 15:31:38 | INFO | train_inner | epoch 010:    839 / 11284 loss=3.577, nll_loss=1.875, ppl=3.67, wps=71689.5, ups=1.2, wpb=59532.5, bsz=2263, num_updates=102300, lr=0.000312653, gnorm=0.321, loss_scale=2, train_wall=79, gb_free=39.6, wall=85519
2023-06-12 15:33:01 | INFO | train_inner | epoch 010:    939 / 11284 loss=3.562, nll_loss=1.858, ppl=3.62, wps=71589.4, ups=1.21, wpb=59362.4, bsz=2219.3, num_updates=102400, lr=0.0003125, gnorm=0.293, loss_scale=2, train_wall=79, gb_free=39.6, wall=85602
2023-06-12 15:34:25 | INFO | train_inner | epoch 010:   1039 / 11284 loss=3.569, nll_loss=1.866, ppl=3.64, wps=71568.3, ups=1.2, wpb=59598, bsz=2262.5, num_updates=102500, lr=0.000312348, gnorm=0.296, loss_scale=2, train_wall=79, gb_free=39.6, wall=85685
2023-06-12 15:35:48 | INFO | train_inner | epoch 010:   1139 / 11284 loss=3.574, nll_loss=1.871, ppl=3.66, wps=71399.4, ups=1.2, wpb=59538.5, bsz=2275.6, num_updates=102600, lr=0.000312195, gnorm=0.307, loss_scale=2, train_wall=79, gb_free=39.6, wall=85769
2023-06-12 15:37:10 | INFO | train_inner | epoch 010:   1239 / 11284 loss=3.578, nll_loss=1.876, ppl=3.67, wps=72547.4, ups=1.21, wpb=59782.3, bsz=2231.1, num_updates=102700, lr=0.000312043, gnorm=0.299, loss_scale=2, train_wall=78, gb_free=39.6, wall=85851
2023-06-12 15:38:33 | INFO | train_inner | epoch 010:   1339 / 11284 loss=3.578, nll_loss=1.876, ppl=3.67, wps=71780.8, ups=1.21, wpb=59391.7, bsz=2269.6, num_updates=102800, lr=0.000311891, gnorm=0.304, loss_scale=2, train_wall=79, gb_free=39.3, wall=85934
2023-06-12 15:39:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 15:39:55 | INFO | train_inner | epoch 010:   1440 / 11284 loss=3.569, nll_loss=1.865, ppl=3.64, wps=72126, ups=1.21, wpb=59399.6, bsz=2241, num_updates=102900, lr=0.00031174, gnorm=0.314, loss_scale=2, train_wall=78, gb_free=39.6, wall=86016
2023-06-12 15:41:17 | INFO | train_inner | epoch 010:   1540 / 11284 loss=3.577, nll_loss=1.875, ppl=3.67, wps=72789.6, ups=1.22, wpb=59509.4, bsz=2234.4, num_updates=103000, lr=0.000311588, gnorm=0.302, loss_scale=2, train_wall=78, gb_free=39.6, wall=86098
2023-06-12 15:42:40 | INFO | train_inner | epoch 010:   1640 / 11284 loss=3.565, nll_loss=1.862, ppl=3.63, wps=71591.7, ups=1.2, wpb=59415.3, bsz=2157.2, num_updates=103100, lr=0.000311437, gnorm=0.314, loss_scale=2, train_wall=79, gb_free=39.3, wall=86181
2023-06-12 15:44:03 | INFO | train_inner | epoch 010:   1740 / 11284 loss=3.555, nll_loss=1.85, ppl=3.6, wps=71861.9, ups=1.21, wpb=59585.7, bsz=2179.8, num_updates=103200, lr=0.000311286, gnorm=0.302, loss_scale=2, train_wall=79, gb_free=39.6, wall=86264
2023-06-12 15:45:25 | INFO | train_inner | epoch 010:   1840 / 11284 loss=3.586, nll_loss=1.885, ppl=3.69, wps=72935.9, ups=1.23, wpb=59446.8, bsz=2204.3, num_updates=103300, lr=0.000311136, gnorm=0.306, loss_scale=2, train_wall=77, gb_free=39.6, wall=86345
2023-06-12 15:46:47 | INFO | train_inner | epoch 010:   1940 / 11284 loss=3.582, nll_loss=1.88, ppl=3.68, wps=72011.1, ups=1.21, wpb=59561.7, bsz=2272.8, num_updates=103400, lr=0.000310985, gnorm=0.293, loss_scale=2, train_wall=79, gb_free=39.6, wall=86428
2023-06-12 15:48:10 | INFO | train_inner | epoch 010:   2040 / 11284 loss=3.556, nll_loss=1.851, ppl=3.61, wps=71833.6, ups=1.21, wpb=59598.3, bsz=2234.6, num_updates=103500, lr=0.000310835, gnorm=0.304, loss_scale=2, train_wall=79, gb_free=39.6, wall=86511
2023-06-12 15:49:33 | INFO | train_inner | epoch 010:   2140 / 11284 loss=3.565, nll_loss=1.861, ppl=3.63, wps=72516.3, ups=1.22, wpb=59658.9, bsz=2214.4, num_updates=103600, lr=0.000310685, gnorm=0.298, loss_scale=2, train_wall=78, gb_free=39.6, wall=86593
2023-06-12 15:50:56 | INFO | train_inner | epoch 010:   2240 / 11284 loss=3.59, nll_loss=1.889, ppl=3.7, wps=71716.1, ups=1.2, wpb=59538.1, bsz=2209.2, num_updates=103700, lr=0.000310535, gnorm=0.312, loss_scale=2, train_wall=79, gb_free=39.5, wall=86676
2023-06-12 15:52:18 | INFO | train_inner | epoch 010:   2340 / 11284 loss=3.584, nll_loss=1.883, ppl=3.69, wps=71704.6, ups=1.21, wpb=59415.8, bsz=2218.5, num_updates=103800, lr=0.000310385, gnorm=0.308, loss_scale=2, train_wall=79, gb_free=39.6, wall=86759
2023-06-12 15:53:41 | INFO | train_inner | epoch 010:   2440 / 11284 loss=3.577, nll_loss=1.875, ppl=3.67, wps=71545.2, ups=1.21, wpb=59255.5, bsz=2235.3, num_updates=103900, lr=0.000310236, gnorm=0.298, loss_scale=4, train_wall=79, gb_free=39.6, wall=86842
2023-06-12 15:54:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 15:55:05 | INFO | train_inner | epoch 010:   2541 / 11284 loss=3.562, nll_loss=1.859, ppl=3.63, wps=71162.7, ups=1.19, wpb=59573.6, bsz=2147.1, num_updates=104000, lr=0.000310087, gnorm=0.297, loss_scale=2, train_wall=80, gb_free=39.6, wall=86926
2023-06-12 15:56:28 | INFO | train_inner | epoch 010:   2641 / 11284 loss=3.571, nll_loss=1.868, ppl=3.65, wps=71619.4, ups=1.21, wpb=59304.5, bsz=2223.9, num_updates=104100, lr=0.000309938, gnorm=0.325, loss_scale=2, train_wall=79, gb_free=39.6, wall=87008
2023-06-12 15:57:50 | INFO | train_inner | epoch 010:   2741 / 11284 loss=3.568, nll_loss=1.865, ppl=3.64, wps=72351.9, ups=1.22, wpb=59419, bsz=2200.4, num_updates=104200, lr=0.000309789, gnorm=0.299, loss_scale=2, train_wall=78, gb_free=39.5, wall=87091
2023-06-12 15:59:12 | INFO | train_inner | epoch 010:   2841 / 11284 loss=3.588, nll_loss=1.887, ppl=3.7, wps=72893.8, ups=1.22, wpb=59510.8, bsz=2261.9, num_updates=104300, lr=0.000309641, gnorm=0.305, loss_scale=2, train_wall=77, gb_free=38.4, wall=87172
2023-06-12 16:00:34 | INFO | train_inner | epoch 010:   2941 / 11284 loss=3.574, nll_loss=1.872, ppl=3.66, wps=71961.2, ups=1.21, wpb=59274.5, bsz=2217.3, num_updates=104400, lr=0.000309492, gnorm=0.318, loss_scale=2, train_wall=78, gb_free=39.6, wall=87255
2023-06-12 16:01:58 | INFO | train_inner | epoch 010:   3041 / 11284 loss=3.572, nll_loss=1.869, ppl=3.65, wps=70801.5, ups=1.19, wpb=59437.1, bsz=2190.4, num_updates=104500, lr=0.000309344, gnorm=0.302, loss_scale=2, train_wall=80, gb_free=39.5, wall=87338
2023-06-12 16:03:23 | INFO | train_inner | epoch 010:   3141 / 11284 loss=3.577, nll_loss=1.875, ppl=3.67, wps=69700.9, ups=1.17, wpb=59590, bsz=2094.4, num_updates=104600, lr=0.000309196, gnorm=0.3, loss_scale=2, train_wall=82, gb_free=39.6, wall=87424
2023-06-12 16:04:49 | INFO | train_inner | epoch 010:   3241 / 11284 loss=3.565, nll_loss=1.861, ppl=3.63, wps=69219.3, ups=1.16, wpb=59445.9, bsz=2242.8, num_updates=104700, lr=0.000309049, gnorm=0.287, loss_scale=2, train_wall=82, gb_free=39.6, wall=87510
2023-06-12 16:06:15 | INFO | train_inner | epoch 010:   3341 / 11284 loss=3.567, nll_loss=1.864, ppl=3.64, wps=69640.8, ups=1.17, wpb=59635.8, bsz=2155.4, num_updates=104800, lr=0.000308901, gnorm=0.288, loss_scale=2, train_wall=82, gb_free=39.5, wall=87595
2023-06-12 16:07:40 | INFO | train_inner | epoch 010:   3441 / 11284 loss=3.574, nll_loss=1.872, ppl=3.66, wps=69465.2, ups=1.17, wpb=59398.9, bsz=2264.7, num_updates=104900, lr=0.000308754, gnorm=0.305, loss_scale=2, train_wall=82, gb_free=39.6, wall=87681
2023-06-12 16:09:06 | INFO | train_inner | epoch 010:   3541 / 11284 loss=3.575, nll_loss=1.873, ppl=3.66, wps=69109.3, ups=1.16, wpb=59402, bsz=2215.6, num_updates=105000, lr=0.000308607, gnorm=0.314, loss_scale=2, train_wall=82, gb_free=39.6, wall=87767
2023-06-12 16:09:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 16:10:33 | INFO | train_inner | epoch 010:   3642 / 11284 loss=3.574, nll_loss=1.871, ppl=3.66, wps=68953.1, ups=1.16, wpb=59523, bsz=2308, num_updates=105100, lr=0.00030846, gnorm=0.298, loss_scale=2, train_wall=82, gb_free=39.6, wall=87853
2023-06-12 16:11:58 | INFO | train_inner | epoch 010:   3742 / 11284 loss=3.578, nll_loss=1.876, ppl=3.67, wps=69678, ups=1.17, wpb=59496.9, bsz=2193, num_updates=105200, lr=0.000308313, gnorm=0.3, loss_scale=2, train_wall=82, gb_free=39.6, wall=87939
2023-06-12 16:13:24 | INFO | train_inner | epoch 010:   3842 / 11284 loss=3.581, nll_loss=1.88, ppl=3.68, wps=68916.5, ups=1.16, wpb=59435.7, bsz=2237.2, num_updates=105300, lr=0.000308167, gnorm=0.319, loss_scale=2, train_wall=82, gb_free=39.5, wall=88025
2023-06-12 16:14:50 | INFO | train_inner | epoch 010:   3942 / 11284 loss=3.583, nll_loss=1.882, ppl=3.69, wps=69031.7, ups=1.16, wpb=59404.3, bsz=2210.2, num_updates=105400, lr=0.000308021, gnorm=0.308, loss_scale=2, train_wall=82, gb_free=39.5, wall=88111
2023-06-12 16:16:16 | INFO | train_inner | epoch 010:   4042 / 11284 loss=3.578, nll_loss=1.876, ppl=3.67, wps=69852.4, ups=1.17, wpb=59893.3, bsz=2251.5, num_updates=105500, lr=0.000307875, gnorm=0.312, loss_scale=2, train_wall=82, gb_free=39.6, wall=88197
2023-06-12 16:17:42 | INFO | train_inner | epoch 010:   4142 / 11284 loss=3.571, nll_loss=1.869, ppl=3.65, wps=69895.7, ups=1.17, wpb=59669.4, bsz=2132.7, num_updates=105600, lr=0.000307729, gnorm=0.299, loss_scale=2, train_wall=81, gb_free=39.6, wall=88282
2023-06-12 16:19:07 | INFO | train_inner | epoch 010:   4242 / 11284 loss=3.571, nll_loss=1.868, ppl=3.65, wps=69678.4, ups=1.17, wpb=59438, bsz=2220.7, num_updates=105700, lr=0.000307583, gnorm=0.302, loss_scale=2, train_wall=82, gb_free=39.6, wall=88367
2023-06-12 16:20:32 | INFO | train_inner | epoch 010:   4342 / 11284 loss=3.567, nll_loss=1.864, ppl=3.64, wps=69536.9, ups=1.17, wpb=59362.6, bsz=2187.6, num_updates=105800, lr=0.000307438, gnorm=0.318, loss_scale=2, train_wall=81, gb_free=39.6, wall=88453
2023-06-12 16:21:56 | INFO | train_inner | epoch 010:   4442 / 11284 loss=3.552, nll_loss=1.847, ppl=3.6, wps=70819.6, ups=1.19, wpb=59662.6, bsz=2222.1, num_updates=105900, lr=0.000307293, gnorm=0.295, loss_scale=2, train_wall=80, gb_free=39.6, wall=88537
2023-06-12 16:23:20 | INFO | train_inner | epoch 010:   4542 / 11284 loss=3.573, nll_loss=1.871, ppl=3.66, wps=71659.1, ups=1.2, wpb=59548.2, bsz=2308.1, num_updates=106000, lr=0.000307148, gnorm=0.309, loss_scale=2, train_wall=79, gb_free=39.6, wall=88620
2023-06-12 16:24:42 | INFO | train_inner | epoch 010:   4642 / 11284 loss=3.572, nll_loss=1.87, ppl=3.66, wps=71547.1, ups=1.21, wpb=59322.8, bsz=2235.5, num_updates=106100, lr=0.000307003, gnorm=0.308, loss_scale=4, train_wall=79, gb_free=39.6, wall=88703
2023-06-12 16:25:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 16:26:06 | INFO | train_inner | epoch 010:   4743 / 11284 loss=3.578, nll_loss=1.877, ppl=3.67, wps=71493.6, ups=1.2, wpb=59746.3, bsz=2170.4, num_updates=106200, lr=0.000306858, gnorm=0.292, loss_scale=2, train_wall=80, gb_free=39.6, wall=88787
2023-06-12 16:27:28 | INFO | train_inner | epoch 010:   4843 / 11284 loss=3.566, nll_loss=1.863, ppl=3.64, wps=72906, ups=1.22, wpb=59642.5, bsz=2160.1, num_updates=106300, lr=0.000306714, gnorm=0.314, loss_scale=2, train_wall=78, gb_free=39.6, wall=88868
2023-06-12 16:28:49 | INFO | train_inner | epoch 010:   4943 / 11284 loss=3.587, nll_loss=1.886, ppl=3.7, wps=72976.4, ups=1.23, wpb=59515.6, bsz=2258.6, num_updates=106400, lr=0.00030657, gnorm=0.308, loss_scale=2, train_wall=78, gb_free=38, wall=88950
2023-06-12 16:30:12 | INFO | train_inner | epoch 010:   5043 / 11284 loss=3.585, nll_loss=1.884, ppl=3.69, wps=72151, ups=1.21, wpb=59510.4, bsz=2211.3, num_updates=106500, lr=0.000306426, gnorm=0.322, loss_scale=2, train_wall=79, gb_free=39.5, wall=89032
2023-06-12 16:31:35 | INFO | train_inner | epoch 010:   5143 / 11284 loss=3.563, nll_loss=1.859, ppl=3.63, wps=71673.9, ups=1.2, wpb=59488, bsz=2218.2, num_updates=106600, lr=0.000306282, gnorm=0.296, loss_scale=2, train_wall=79, gb_free=39.6, wall=89115
2023-06-12 16:32:58 | INFO | train_inner | epoch 010:   5243 / 11284 loss=3.579, nll_loss=1.877, ppl=3.67, wps=71805.8, ups=1.2, wpb=59604.8, bsz=2200.4, num_updates=106700, lr=0.000306138, gnorm=0.31, loss_scale=2, train_wall=79, gb_free=39.6, wall=89198
2023-06-12 16:34:21 | INFO | train_inner | epoch 010:   5343 / 11284 loss=3.568, nll_loss=1.864, ppl=3.64, wps=71358.8, ups=1.2, wpb=59566.2, bsz=2246.3, num_updates=106800, lr=0.000305995, gnorm=0.296, loss_scale=2, train_wall=79, gb_free=39.5, wall=89282
2023-06-12 16:35:45 | INFO | train_inner | epoch 010:   5443 / 11284 loss=3.568, nll_loss=1.865, ppl=3.64, wps=71642.4, ups=1.2, wpb=59601.1, bsz=2179.9, num_updates=106900, lr=0.000305852, gnorm=0.299, loss_scale=2, train_wall=79, gb_free=39.5, wall=89365
2023-06-12 16:37:08 | INFO | train_inner | epoch 010:   5543 / 11284 loss=3.57, nll_loss=1.867, ppl=3.65, wps=71713.7, ups=1.2, wpb=59713.4, bsz=2212.6, num_updates=107000, lr=0.000305709, gnorm=0.299, loss_scale=2, train_wall=79, gb_free=39.6, wall=89448
2023-06-12 16:38:31 | INFO | train_inner | epoch 010:   5643 / 11284 loss=3.574, nll_loss=1.871, ppl=3.66, wps=71350.3, ups=1.21, wpb=59178, bsz=2254.7, num_updates=107100, lr=0.000305566, gnorm=0.314, loss_scale=2, train_wall=79, gb_free=39.5, wall=89531
2023-06-12 16:39:53 | INFO | train_inner | epoch 010:   5743 / 11284 loss=3.568, nll_loss=1.866, ppl=3.64, wps=71709.2, ups=1.21, wpb=59289.8, bsz=2235.1, num_updates=107200, lr=0.000305424, gnorm=0.311, loss_scale=2, train_wall=79, gb_free=39.6, wall=89614
2023-06-12 16:40:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 16:41:17 | INFO | train_inner | epoch 010:   5844 / 11284 loss=3.587, nll_loss=1.886, ppl=3.7, wps=71260.9, ups=1.2, wpb=59500.8, bsz=2235.5, num_updates=107300, lr=0.000305281, gnorm=0.305, loss_scale=2, train_wall=80, gb_free=39.6, wall=89698
2023-06-12 16:42:40 | INFO | train_inner | epoch 010:   5944 / 11284 loss=3.559, nll_loss=1.855, ppl=3.62, wps=71410.5, ups=1.2, wpb=59369.9, bsz=2255.1, num_updates=107400, lr=0.000305139, gnorm=0.309, loss_scale=2, train_wall=79, gb_free=39.6, wall=89781
2023-06-12 16:44:02 | INFO | train_inner | epoch 010:   6044 / 11284 loss=3.57, nll_loss=1.868, ppl=3.65, wps=72364.4, ups=1.22, wpb=59366.3, bsz=2297.7, num_updates=107500, lr=0.000304997, gnorm=0.3, loss_scale=2, train_wall=78, gb_free=39.6, wall=89863
2023-06-12 16:45:24 | INFO | train_inner | epoch 010:   6144 / 11284 loss=3.574, nll_loss=1.872, ppl=3.66, wps=72567.6, ups=1.22, wpb=59633.3, bsz=2264.9, num_updates=107600, lr=0.000304855, gnorm=0.306, loss_scale=2, train_wall=78, gb_free=39.5, wall=89945
2023-06-12 16:46:47 | INFO | train_inner | epoch 010:   6244 / 11284 loss=3.57, nll_loss=1.867, ppl=3.65, wps=71557.1, ups=1.2, wpb=59476.2, bsz=2193.9, num_updates=107700, lr=0.000304714, gnorm=0.298, loss_scale=2, train_wall=79, gb_free=39.6, wall=90028
2023-06-12 16:48:10 | INFO | train_inner | epoch 010:   6344 / 11284 loss=3.564, nll_loss=1.861, ppl=3.63, wps=71823.2, ups=1.21, wpb=59433.9, bsz=2226.4, num_updates=107800, lr=0.000304572, gnorm=0.317, loss_scale=2, train_wall=79, gb_free=39.6, wall=90111
2023-06-12 16:49:33 | INFO | train_inner | epoch 010:   6444 / 11284 loss=3.56, nll_loss=1.856, ppl=3.62, wps=71546, ups=1.2, wpb=59546.9, bsz=2240.2, num_updates=107900, lr=0.000304431, gnorm=0.287, loss_scale=2, train_wall=79, gb_free=39.5, wall=90194
2023-06-12 16:50:56 | INFO | train_inner | epoch 010:   6544 / 11284 loss=3.568, nll_loss=1.866, ppl=3.64, wps=72452.5, ups=1.22, wpb=59630.4, bsz=2272.5, num_updates=108000, lr=0.00030429, gnorm=0.298, loss_scale=2, train_wall=78, gb_free=39.6, wall=90276
2023-06-12 16:51:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-06-12 16:52:20 | INFO | train_inner | epoch 010:   6645 / 11284 loss=3.573, nll_loss=1.871, ppl=3.66, wps=70691.7, ups=1.19, wpb=59294.2, bsz=2268.4, num_updates=108100, lr=0.00030415, gnorm=0.327, loss_scale=1, train_wall=80, gb_free=39.6, wall=90360
2023-06-12 16:53:42 | INFO | train_inner | epoch 010:   6745 / 11284 loss=3.572, nll_loss=1.87, ppl=3.66, wps=71750.3, ups=1.21, wpb=59487, bsz=2253.4, num_updates=108200, lr=0.000304009, gnorm=0.315, loss_scale=1, train_wall=79, gb_free=39.5, wall=90443
2023-06-12 16:55:06 | INFO | train_inner | epoch 010:   6845 / 11284 loss=3.57, nll_loss=1.868, ppl=3.65, wps=71829.7, ups=1.2, wpb=59653.9, bsz=2232.9, num_updates=108300, lr=0.000303869, gnorm=0.297, loss_scale=1, train_wall=79, gb_free=39.6, wall=90526
2023-06-12 16:56:29 | INFO | train_inner | epoch 010:   6945 / 11284 loss=3.57, nll_loss=1.868, ppl=3.65, wps=71679.9, ups=1.2, wpb=59550.1, bsz=2259.1, num_updates=108400, lr=0.000303728, gnorm=0.303, loss_scale=1, train_wall=79, gb_free=39.6, wall=90609
2023-06-12 16:57:52 | INFO | train_inner | epoch 010:   7045 / 11284 loss=3.571, nll_loss=1.869, ppl=3.65, wps=71189.8, ups=1.2, wpb=59411, bsz=2309.1, num_updates=108500, lr=0.000303588, gnorm=0.308, loss_scale=1, train_wall=79, gb_free=39.6, wall=90693
2023-06-12 16:59:15 | INFO | train_inner | epoch 010:   7145 / 11284 loss=3.575, nll_loss=1.873, ppl=3.66, wps=71560, ups=1.2, wpb=59566.1, bsz=2226.8, num_updates=108600, lr=0.000303449, gnorm=0.304, loss_scale=1, train_wall=79, gb_free=39.5, wall=90776
2023-06-12 17:00:38 | INFO | train_inner | epoch 010:   7245 / 11284 loss=3.588, nll_loss=1.888, ppl=3.7, wps=72117.1, ups=1.22, wpb=59333.1, bsz=2139.2, num_updates=108700, lr=0.000303309, gnorm=0.318, loss_scale=1, train_wall=78, gb_free=39.6, wall=90858
2023-06-12 17:02:01 | INFO | train_inner | epoch 010:   7345 / 11284 loss=3.587, nll_loss=1.886, ppl=3.7, wps=71402.7, ups=1.2, wpb=59507.8, bsz=2238.4, num_updates=108800, lr=0.00030317, gnorm=0.301, loss_scale=1, train_wall=79, gb_free=39.5, wall=90942
2023-06-12 17:03:24 | INFO | train_inner | epoch 010:   7445 / 11284 loss=3.582, nll_loss=1.881, ppl=3.68, wps=71846.4, ups=1.21, wpb=59459.6, bsz=2227.9, num_updates=108900, lr=0.00030303, gnorm=0.303, loss_scale=1, train_wall=79, gb_free=39.6, wall=91024
2023-06-12 17:04:48 | INFO | train_inner | epoch 010:   7545 / 11284 loss=3.565, nll_loss=1.862, ppl=3.63, wps=71024.1, ups=1.19, wpb=59593.5, bsz=2229.1, num_updates=109000, lr=0.000302891, gnorm=0.3, loss_scale=1, train_wall=80, gb_free=39.4, wall=91108
2023-06-12 17:06:10 | INFO | train_inner | epoch 010:   7645 / 11284 loss=3.593, nll_loss=1.893, ppl=3.71, wps=71926, ups=1.21, wpb=59474.7, bsz=2182.6, num_updates=109100, lr=0.000302752, gnorm=0.302, loss_scale=2, train_wall=79, gb_free=39.6, wall=91191
2023-06-12 17:07:33 | INFO | train_inner | epoch 010:   7745 / 11284 loss=3.566, nll_loss=1.863, ppl=3.64, wps=71523.3, ups=1.2, wpb=59503, bsz=2221.3, num_updates=109200, lr=0.000302614, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.6, wall=91274
2023-06-12 17:08:57 | INFO | train_inner | epoch 010:   7845 / 11284 loss=3.569, nll_loss=1.866, ppl=3.65, wps=71192.4, ups=1.19, wpb=59618.5, bsz=2288.6, num_updates=109300, lr=0.000302475, gnorm=0.298, loss_scale=2, train_wall=80, gb_free=39.5, wall=91358
2023-06-12 17:10:20 | INFO | train_inner | epoch 010:   7945 / 11284 loss=3.566, nll_loss=1.863, ppl=3.64, wps=71841, ups=1.2, wpb=59696.7, bsz=2225.1, num_updates=109400, lr=0.000302337, gnorm=0.314, loss_scale=2, train_wall=79, gb_free=39.6, wall=91441
2023-06-12 17:11:43 | INFO | train_inner | epoch 010:   8045 / 11284 loss=3.568, nll_loss=1.866, ppl=3.65, wps=71846.1, ups=1.2, wpb=59675.3, bsz=2125.4, num_updates=109500, lr=0.000302199, gnorm=0.304, loss_scale=2, train_wall=79, gb_free=39.6, wall=91524
2023-06-12 17:13:07 | INFO | train_inner | epoch 010:   8145 / 11284 loss=3.558, nll_loss=1.854, ppl=3.62, wps=71316.8, ups=1.2, wpb=59411.6, bsz=2203.8, num_updates=109600, lr=0.000302061, gnorm=0.301, loss_scale=2, train_wall=79, gb_free=39.5, wall=91607
2023-06-12 17:14:29 | INFO | train_inner | epoch 010:   8245 / 11284 loss=3.579, nll_loss=1.877, ppl=3.67, wps=72091.6, ups=1.21, wpb=59411.1, bsz=2172.2, num_updates=109700, lr=0.000301923, gnorm=0.312, loss_scale=2, train_wall=78, gb_free=39.6, wall=91690
2023-06-12 17:15:52 | INFO | train_inner | epoch 010:   8345 / 11284 loss=3.575, nll_loss=1.874, ppl=3.66, wps=71610, ups=1.2, wpb=59556.2, bsz=2122.8, num_updates=109800, lr=0.000301786, gnorm=0.311, loss_scale=2, train_wall=79, gb_free=39.6, wall=91773
2023-06-12 17:17:16 | INFO | train_inner | epoch 010:   8445 / 11284 loss=3.576, nll_loss=1.874, ppl=3.67, wps=71252.2, ups=1.2, wpb=59368, bsz=2182.2, num_updates=109900, lr=0.000301648, gnorm=0.308, loss_scale=2, train_wall=80, gb_free=39.6, wall=91856
2023-06-12 17:18:39 | INFO | train_inner | epoch 010:   8545 / 11284 loss=3.583, nll_loss=1.882, ppl=3.69, wps=71095.9, ups=1.19, wpb=59513, bsz=2288.8, num_updates=110000, lr=0.000301511, gnorm=0.319, loss_scale=2, train_wall=79, gb_free=39.5, wall=91940
2023-06-12 17:20:02 | INFO | train_inner | epoch 010:   8645 / 11284 loss=3.566, nll_loss=1.863, ppl=3.64, wps=72191.5, ups=1.21, wpb=59509.7, bsz=2187.2, num_updates=110100, lr=0.000301374, gnorm=0.301, loss_scale=2, train_wall=78, gb_free=39.6, wall=92022
2023-06-12 17:20:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 17:21:26 | INFO | train_inner | epoch 010:   8746 / 11284 loss=3.57, nll_loss=1.867, ppl=3.65, wps=70793.1, ups=1.19, wpb=59680, bsz=2229.3, num_updates=110200, lr=0.000301238, gnorm=0.303, loss_scale=2, train_wall=80, gb_free=39.6, wall=92107
2023-06-12 17:22:49 | INFO | train_inner | epoch 010:   8846 / 11284 loss=3.569, nll_loss=1.867, ppl=3.65, wps=71676.3, ups=1.2, wpb=59549.6, bsz=2129, num_updates=110300, lr=0.000301101, gnorm=0.311, loss_scale=2, train_wall=79, gb_free=39.6, wall=92190
2023-06-12 17:24:12 | INFO | train_inner | epoch 010:   8946 / 11284 loss=3.575, nll_loss=1.874, ppl=3.66, wps=71659, ups=1.2, wpb=59485.6, bsz=2133.3, num_updates=110400, lr=0.000300965, gnorm=0.309, loss_scale=2, train_wall=79, gb_free=39.5, wall=92273
2023-06-12 17:25:36 | INFO | train_inner | epoch 010:   9046 / 11284 loss=3.573, nll_loss=1.871, ppl=3.66, wps=71006, ups=1.19, wpb=59574.7, bsz=2294.2, num_updates=110500, lr=0.000300828, gnorm=0.307, loss_scale=2, train_wall=80, gb_free=39.6, wall=92357
2023-06-12 17:26:57 | INFO | train_inner | epoch 010:   9146 / 11284 loss=3.567, nll_loss=1.864, ppl=3.64, wps=72940.3, ups=1.23, wpb=59320.4, bsz=2287.1, num_updates=110600, lr=0.000300692, gnorm=0.307, loss_scale=2, train_wall=77, gb_free=39.5, wall=92438
2023-06-12 17:28:20 | INFO | train_inner | epoch 010:   9246 / 11284 loss=3.569, nll_loss=1.866, ppl=3.65, wps=72055.4, ups=1.21, wpb=59337.3, bsz=2239.9, num_updates=110700, lr=0.000300557, gnorm=0.313, loss_scale=2, train_wall=78, gb_free=39.6, wall=92520
2023-06-12 17:29:43 | INFO | train_inner | epoch 010:   9346 / 11284 loss=3.577, nll_loss=1.876, ppl=3.67, wps=71787, ups=1.2, wpb=59706.5, bsz=2260.5, num_updates=110800, lr=0.000300421, gnorm=0.299, loss_scale=2, train_wall=79, gb_free=39.6, wall=92603
2023-06-12 17:31:05 | INFO | train_inner | epoch 010:   9446 / 11284 loss=3.57, nll_loss=1.868, ppl=3.65, wps=72341.4, ups=1.21, wpb=59652.7, bsz=2313.9, num_updates=110900, lr=0.000300285, gnorm=0.32, loss_scale=2, train_wall=78, gb_free=39.6, wall=92686
2023-06-12 17:32:28 | INFO | train_inner | epoch 010:   9546 / 11284 loss=3.565, nll_loss=1.862, ppl=3.64, wps=71733.4, ups=1.2, wpb=59548.4, bsz=2227, num_updates=111000, lr=0.00030015, gnorm=0.308, loss_scale=2, train_wall=79, gb_free=39.5, wall=92769
2023-06-12 17:33:52 | INFO | train_inner | epoch 010:   9646 / 11284 loss=3.578, nll_loss=1.877, ppl=3.67, wps=71501.8, ups=1.2, wpb=59667.6, bsz=2237.6, num_updates=111100, lr=0.000300015, gnorm=0.307, loss_scale=2, train_wall=79, gb_free=39.6, wall=92852
2023-06-12 17:35:15 | INFO | train_inner | epoch 010:   9746 / 11284 loss=3.569, nll_loss=1.866, ppl=3.65, wps=71165.3, ups=1.2, wpb=59384.3, bsz=2318.4, num_updates=111200, lr=0.00029988, gnorm=0.311, loss_scale=4, train_wall=79, gb_free=39.6, wall=92936
2023-06-12 17:35:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 17:36:39 | INFO | train_inner | epoch 010:   9847 / 11284 loss=3.561, nll_loss=1.858, ppl=3.63, wps=71049.6, ups=1.19, wpb=59552.1, bsz=2258.5, num_updates=111300, lr=0.000299745, gnorm=0.319, loss_scale=2, train_wall=80, gb_free=39.5, wall=93020
2023-06-12 17:38:02 | INFO | train_inner | epoch 010:   9947 / 11284 loss=3.583, nll_loss=1.883, ppl=3.69, wps=71707.8, ups=1.21, wpb=59429.2, bsz=2241.9, num_updates=111400, lr=0.000299611, gnorm=0.302, loss_scale=2, train_wall=79, gb_free=39.5, wall=93103
2023-06-12 17:39:25 | INFO | train_inner | epoch 010:  10047 / 11284 loss=3.573, nll_loss=1.871, ppl=3.66, wps=71635.9, ups=1.2, wpb=59504.1, bsz=2213.4, num_updates=111500, lr=0.000299476, gnorm=0.312, loss_scale=2, train_wall=79, gb_free=39.6, wall=93186
2023-06-12 17:40:48 | INFO | train_inner | epoch 010:  10147 / 11284 loss=3.562, nll_loss=1.859, ppl=3.63, wps=71597.2, ups=1.2, wpb=59473.7, bsz=2266.6, num_updates=111600, lr=0.000299342, gnorm=0.306, loss_scale=2, train_wall=79, gb_free=39.6, wall=93269
2023-06-12 17:42:11 | INFO | train_inner | epoch 010:  10247 / 11284 loss=3.563, nll_loss=1.86, ppl=3.63, wps=71852.5, ups=1.21, wpb=59451.4, bsz=2181, num_updates=111700, lr=0.000299208, gnorm=0.311, loss_scale=2, train_wall=79, gb_free=39.6, wall=93351
2023-06-12 17:43:33 | INFO | train_inner | epoch 010:  10347 / 11284 loss=3.57, nll_loss=1.868, ppl=3.65, wps=72125.1, ups=1.21, wpb=59500.9, bsz=2263.4, num_updates=111800, lr=0.000299074, gnorm=0.301, loss_scale=2, train_wall=78, gb_free=39.6, wall=93434
2023-06-12 17:44:56 | INFO | train_inner | epoch 010:  10447 / 11284 loss=3.576, nll_loss=1.874, ppl=3.67, wps=71760.5, ups=1.21, wpb=59184.7, bsz=2258.7, num_updates=111900, lr=0.000298941, gnorm=0.318, loss_scale=2, train_wall=79, gb_free=39.6, wall=93516
2023-06-12 17:46:19 | INFO | train_inner | epoch 010:  10547 / 11284 loss=3.577, nll_loss=1.875, ppl=3.67, wps=71660.3, ups=1.2, wpb=59606.2, bsz=2285.2, num_updates=112000, lr=0.000298807, gnorm=0.305, loss_scale=2, train_wall=79, gb_free=39.6, wall=93600
2023-06-12 17:47:42 | INFO | train_inner | epoch 010:  10647 / 11284 loss=3.565, nll_loss=1.862, ppl=3.64, wps=71749.6, ups=1.21, wpb=59430.7, bsz=2194.2, num_updates=112100, lr=0.000298674, gnorm=0.292, loss_scale=2, train_wall=79, gb_free=39.6, wall=93682
2023-06-12 17:49:05 | INFO | train_inner | epoch 010:  10747 / 11284 loss=3.576, nll_loss=1.874, ppl=3.67, wps=71386.7, ups=1.2, wpb=59488.9, bsz=2241.4, num_updates=112200, lr=0.000298541, gnorm=0.327, loss_scale=2, train_wall=80, gb_free=39.6, wall=93766
2023-06-12 17:50:28 | INFO | train_inner | epoch 010:  10847 / 11284 loss=3.555, nll_loss=1.851, ppl=3.61, wps=71563.2, ups=1.2, wpb=59551.2, bsz=2208.6, num_updates=112300, lr=0.000298408, gnorm=0.311, loss_scale=4, train_wall=79, gb_free=39.6, wall=93849
2023-06-12 17:51:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 17:51:52 | INFO | train_inner | epoch 010:  10948 / 11284 loss=3.574, nll_loss=1.872, ppl=3.66, wps=70919.2, ups=1.2, wpb=59214.8, bsz=2161.6, num_updates=112400, lr=0.000298275, gnorm=0.303, loss_scale=2, train_wall=80, gb_free=39.6, wall=93932
2023-06-12 17:53:15 | INFO | train_inner | epoch 010:  11048 / 11284 loss=3.58, nll_loss=1.879, ppl=3.68, wps=71651.1, ups=1.2, wpb=59566.8, bsz=2260.3, num_updates=112500, lr=0.000298142, gnorm=0.305, loss_scale=2, train_wall=79, gb_free=39.5, wall=94016
2023-06-12 17:54:38 | INFO | train_inner | epoch 010:  11148 / 11284 loss=3.573, nll_loss=1.871, ppl=3.66, wps=71641.9, ups=1.2, wpb=59476.4, bsz=2242.8, num_updates=112600, lr=0.00029801, gnorm=0.311, loss_scale=2, train_wall=79, gb_free=39.6, wall=94099
2023-06-12 17:56:01 | INFO | train_inner | epoch 010:  11248 / 11284 loss=3.57, nll_loss=1.868, ppl=3.65, wps=71823.8, ups=1.2, wpb=59769.6, bsz=2240.2, num_updates=112700, lr=0.000297878, gnorm=0.299, loss_scale=2, train_wall=79, gb_free=39.6, wall=94182
2023-06-12 17:56:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-12 17:56:49 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 4.343 | nll_loss 2.663 | ppl 6.34 | bleu 20.87 | wps 3696.5 | wpb 2397.5 | bsz 71.5 | num_updates 112736 | best_loss 4.343
2023-06-12 17:56:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 112736 updates
2023-06-12 17:56:49 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint10.pt
2023-06-12 17:56:50 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint10.pt
2023-06-12 17:56:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint10.pt (epoch 10 @ 112736 updates, score 4.343) (writing took 6.2386261420324445 seconds)
2023-06-12 17:56:55 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-06-12 17:56:55 | INFO | train | epoch 010 | loss 3.571 | nll_loss 1.869 | ppl 3.65 | wps 71271.6 | ups 1.2 | wpb 59501.1 | bsz 2227.4 | num_updates 112736 | lr 0.00029783 | gnorm 0.306 | loss_scale 2 | train_wall 8941 | gb_free 39.6 | wall 94236
2023-06-12 17:56:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-12 17:56:56 | INFO | fairseq.trainer | begin training epoch 11
2023-06-12 17:56:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-12 17:57:49 | INFO | train_inner | epoch 011:     64 / 11284 loss=3.545, nll_loss=1.84, ppl=3.58, wps=54771.1, ups=0.92, wpb=59222.5, bsz=2223.6, num_updates=112800, lr=0.000297746, gnorm=0.302, loss_scale=2, train_wall=79, gb_free=39.6, wall=94290
2023-06-12 17:59:13 | INFO | train_inner | epoch 011:    164 / 11284 loss=3.561, nll_loss=1.857, ppl=3.62, wps=71333.5, ups=1.2, wpb=59474.8, bsz=2350.2, num_updates=112900, lr=0.000297614, gnorm=0.297, loss_scale=2, train_wall=79, gb_free=39.6, wall=94373
2023-06-12 18:00:36 | INFO | train_inner | epoch 011:    264 / 11284 loss=3.559, nll_loss=1.855, ppl=3.62, wps=71548.6, ups=1.2, wpb=59540.3, bsz=2165.8, num_updates=113000, lr=0.000297482, gnorm=0.296, loss_scale=2, train_wall=79, gb_free=39.6, wall=94457
2023-06-12 18:01:58 | INFO | train_inner | epoch 011:    364 / 11284 loss=3.564, nll_loss=1.861, ppl=3.63, wps=72588.3, ups=1.22, wpb=59331.6, bsz=2241.5, num_updates=113100, lr=0.000297351, gnorm=0.308, loss_scale=2, train_wall=78, gb_free=39.5, wall=94538
2023-06-12 18:03:20 | INFO | train_inner | epoch 011:    464 / 11284 loss=3.548, nll_loss=1.842, ppl=3.59, wps=71928.7, ups=1.21, wpb=59540.8, bsz=2221.2, num_updates=113200, lr=0.000297219, gnorm=0.306, loss_scale=2, train_wall=79, gb_free=39.6, wall=94621
2023-06-12 18:04:44 | INFO | train_inner | epoch 011:    564 / 11284 loss=3.546, nll_loss=1.84, ppl=3.58, wps=71924.6, ups=1.2, wpb=59848.5, bsz=2248, num_updates=113300, lr=0.000297088, gnorm=0.292, loss_scale=2, train_wall=79, gb_free=39.5, wall=94704
2023-06-12 18:06:07 | INFO | train_inner | epoch 011:    664 / 11284 loss=3.57, nll_loss=1.867, ppl=3.65, wps=71715.9, ups=1.2, wpb=59517.2, bsz=2204.1, num_updates=113400, lr=0.000296957, gnorm=0.302, loss_scale=2, train_wall=79, gb_free=39.6, wall=94787
2023-06-12 18:06:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 18:07:30 | INFO | train_inner | epoch 011:    765 / 11284 loss=3.561, nll_loss=1.857, ppl=3.62, wps=71018.5, ups=1.19, wpb=59511.3, bsz=2308.1, num_updates=113500, lr=0.000296826, gnorm=0.307, loss_scale=2, train_wall=80, gb_free=39.5, wall=94871
2023-06-12 18:08:53 | INFO | train_inner | epoch 011:    865 / 11284 loss=3.56, nll_loss=1.856, ppl=3.62, wps=72318.8, ups=1.22, wpb=59515.1, bsz=2241.9, num_updates=113600, lr=0.000296695, gnorm=0.293, loss_scale=2, train_wall=78, gb_free=39.6, wall=94953
2023-06-12 18:10:15 | INFO | train_inner | epoch 011:    965 / 11284 loss=3.555, nll_loss=1.85, ppl=3.6, wps=72749, ups=1.22, wpb=59447.6, bsz=2204.1, num_updates=113700, lr=0.000296565, gnorm=0.305, loss_scale=2, train_wall=78, gb_free=39.6, wall=95035
2023-06-12 18:11:37 | INFO | train_inner | epoch 011:   1065 / 11284 loss=3.566, nll_loss=1.862, ppl=3.64, wps=71804.8, ups=1.21, wpb=59552.5, bsz=2187.7, num_updates=113800, lr=0.000296435, gnorm=0.303, loss_scale=2, train_wall=79, gb_free=39.6, wall=95118
2023-06-12 18:13:01 | INFO | train_inner | epoch 011:   1165 / 11284 loss=3.55, nll_loss=1.845, ppl=3.59, wps=71322.5, ups=1.2, wpb=59296, bsz=2212.9, num_updates=113900, lr=0.000296304, gnorm=0.314, loss_scale=2, train_wall=79, gb_free=39.6, wall=95201
2023-06-12 18:14:24 | INFO | train_inner | epoch 011:   1265 / 11284 loss=3.558, nll_loss=1.854, ppl=3.62, wps=71414, ups=1.2, wpb=59301.5, bsz=2156.8, num_updates=114000, lr=0.000296174, gnorm=0.313, loss_scale=2, train_wall=79, gb_free=39.6, wall=95284
2023-06-12 18:15:47 | INFO | train_inner | epoch 011:   1365 / 11284 loss=3.548, nll_loss=1.843, ppl=3.59, wps=71585.6, ups=1.2, wpb=59538, bsz=2239, num_updates=114100, lr=0.000296045, gnorm=0.304, loss_scale=2, train_wall=79, gb_free=39.6, wall=95367
2023-06-12 18:17:10 | INFO | train_inner | epoch 011:   1465 / 11284 loss=3.57, nll_loss=1.867, ppl=3.65, wps=71344.7, ups=1.2, wpb=59501.7, bsz=2299.5, num_updates=114200, lr=0.000295915, gnorm=0.307, loss_scale=2, train_wall=79, gb_free=39.5, wall=95451
2023-06-12 18:18:34 | INFO | train_inner | epoch 011:   1565 / 11284 loss=3.546, nll_loss=1.84, ppl=3.58, wps=70961.6, ups=1.19, wpb=59630.4, bsz=2293.2, num_updates=114300, lr=0.000295786, gnorm=0.311, loss_scale=2, train_wall=80, gb_free=39.6, wall=95535
2023-06-12 18:19:57 | INFO | train_inner | epoch 011:   1665 / 11284 loss=3.57, nll_loss=1.867, ppl=3.65, wps=71915.1, ups=1.2, wpb=59853.7, bsz=2213.2, num_updates=114400, lr=0.000295656, gnorm=0.31, loss_scale=2, train_wall=79, gb_free=39.6, wall=95618
2023-06-12 18:20:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 18:21:21 | INFO | train_inner | epoch 011:   1766 / 11284 loss=3.567, nll_loss=1.865, ppl=3.64, wps=71013.7, ups=1.19, wpb=59615.5, bsz=2257.9, num_updates=114500, lr=0.000295527, gnorm=0.314, loss_scale=2, train_wall=80, gb_free=39.6, wall=95702
2023-06-12 18:22:45 | INFO | train_inner | epoch 011:   1866 / 11284 loss=3.558, nll_loss=1.854, ppl=3.61, wps=71795.9, ups=1.2, wpb=59717.1, bsz=2221.2, num_updates=114600, lr=0.000295398, gnorm=0.298, loss_scale=2, train_wall=79, gb_free=39.6, wall=95785
2023-06-12 18:24:08 | INFO | train_inner | epoch 011:   1966 / 11284 loss=3.548, nll_loss=1.842, ppl=3.59, wps=71357.3, ups=1.2, wpb=59252.5, bsz=2184.3, num_updates=114700, lr=0.000295269, gnorm=0.307, loss_scale=2, train_wall=79, gb_free=39.6, wall=95868
2023-06-12 18:25:31 | INFO | train_inner | epoch 011:   2066 / 11284 loss=3.556, nll_loss=1.851, ppl=3.61, wps=71759.5, ups=1.21, wpb=59531.4, bsz=2195.2, num_updates=114800, lr=0.000295141, gnorm=0.303, loss_scale=2, train_wall=79, gb_free=39.6, wall=95951
2023-06-12 18:26:53 | INFO | train_inner | epoch 011:   2166 / 11284 loss=3.568, nll_loss=1.865, ppl=3.64, wps=71643.4, ups=1.21, wpb=59325.6, bsz=2131.2, num_updates=114900, lr=0.000295012, gnorm=0.318, loss_scale=2, train_wall=79, gb_free=39.4, wall=96034
2023-06-12 18:28:17 | INFO | train_inner | epoch 011:   2266 / 11284 loss=3.567, nll_loss=1.864, ppl=3.64, wps=71371.3, ups=1.2, wpb=59562.4, bsz=2266.2, num_updates=115000, lr=0.000294884, gnorm=0.308, loss_scale=2, train_wall=79, gb_free=39.5, wall=96117
2023-06-12 18:29:40 | INFO | train_inner | epoch 011:   2366 / 11284 loss=3.561, nll_loss=1.858, ppl=3.62, wps=71325.6, ups=1.2, wpb=59658.2, bsz=2390, num_updates=115100, lr=0.000294756, gnorm=0.314, loss_scale=2, train_wall=79, gb_free=39.6, wall=96201
2023-06-12 18:31:03 | INFO | train_inner | epoch 011:   2466 / 11284 loss=3.556, nll_loss=1.852, ppl=3.61, wps=71923.6, ups=1.21, wpb=59343.2, bsz=2214.9, num_updates=115200, lr=0.000294628, gnorm=0.298, loss_scale=2, train_wall=78, gb_free=39.6, wall=96284
2023-06-12 18:32:26 | INFO | train_inner | epoch 011:   2566 / 11284 loss=3.559, nll_loss=1.855, ppl=3.62, wps=71382.8, ups=1.2, wpb=59411.4, bsz=2243, num_updates=115300, lr=0.0002945, gnorm=0.308, loss_scale=2, train_wall=79, gb_free=39.6, wall=96367
2023-06-12 18:33:49 | INFO | train_inner | epoch 011:   2666 / 11284 loss=3.538, nll_loss=1.831, ppl=3.56, wps=71950.8, ups=1.21, wpb=59635.1, bsz=2232.3, num_updates=115400, lr=0.000294372, gnorm=0.298, loss_scale=2, train_wall=79, gb_free=39.6, wall=96450
2023-06-12 18:35:11 | INFO | train_inner | epoch 011:   2766 / 11284 loss=3.573, nll_loss=1.871, ppl=3.66, wps=72558.1, ups=1.22, wpb=59693.7, bsz=2207.7, num_updates=115500, lr=0.000294245, gnorm=0.308, loss_scale=4, train_wall=78, gb_free=39.6, wall=96532
2023-06-12 18:35:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 18:36:36 | INFO | train_inner | epoch 011:   2867 / 11284 loss=3.558, nll_loss=1.854, ppl=3.61, wps=70765.2, ups=1.19, wpb=59652.2, bsz=2213.3, num_updates=115600, lr=0.000294118, gnorm=0.309, loss_scale=2, train_wall=80, gb_free=39.6, wall=96616
2023-06-12 18:37:58 | INFO | train_inner | epoch 011:   2967 / 11284 loss=3.579, nll_loss=1.878, ppl=3.67, wps=71912.3, ups=1.21, wpb=59454.4, bsz=2220.9, num_updates=115700, lr=0.000293991, gnorm=0.304, loss_scale=2, train_wall=79, gb_free=39.6, wall=96699
2023-06-12 18:39:21 | INFO | train_inner | epoch 011:   3067 / 11284 loss=3.548, nll_loss=1.843, ppl=3.59, wps=71874, ups=1.21, wpb=59639.6, bsz=2250.8, num_updates=115800, lr=0.000293864, gnorm=0.318, loss_scale=2, train_wall=79, gb_free=39.6, wall=96782
2023-06-12 18:40:44 | INFO | train_inner | epoch 011:   3167 / 11284 loss=3.574, nll_loss=1.872, ppl=3.66, wps=71618.7, ups=1.21, wpb=59298.4, bsz=2238.4, num_updates=115900, lr=0.000293737, gnorm=0.308, loss_scale=2, train_wall=79, gb_free=39.6, wall=96865
2023-06-12 18:42:07 | INFO | train_inner | epoch 011:   3267 / 11284 loss=3.571, nll_loss=1.869, ppl=3.65, wps=71284.1, ups=1.2, wpb=59289.1, bsz=2217.4, num_updates=116000, lr=0.00029361, gnorm=0.311, loss_scale=2, train_wall=79, gb_free=39.6, wall=96948
2023-06-12 18:43:29 | INFO | train_inner | epoch 011:   3367 / 11284 loss=3.566, nll_loss=1.863, ppl=3.64, wps=72643.1, ups=1.22, wpb=59627.8, bsz=2232.6, num_updates=116100, lr=0.000293484, gnorm=0.305, loss_scale=2, train_wall=78, gb_free=39.5, wall=97030
2023-06-12 18:44:51 | INFO | train_inner | epoch 011:   3467 / 11284 loss=3.564, nll_loss=1.861, ppl=3.63, wps=72592.3, ups=1.22, wpb=59361.9, bsz=2164.3, num_updates=116200, lr=0.000293357, gnorm=0.303, loss_scale=2, train_wall=78, gb_free=39.5, wall=97112
2023-06-12 18:46:15 | INFO | train_inner | epoch 011:   3567 / 11284 loss=3.569, nll_loss=1.867, ppl=3.65, wps=71438.7, ups=1.2, wpb=59541.9, bsz=2215.9, num_updates=116300, lr=0.000293231, gnorm=0.307, loss_scale=2, train_wall=79, gb_free=39.5, wall=97195
2023-06-12 18:47:38 | INFO | train_inner | epoch 011:   3667 / 11284 loss=3.559, nll_loss=1.855, ppl=3.62, wps=71822.7, ups=1.2, wpb=59649.2, bsz=2282.3, num_updates=116400, lr=0.000293105, gnorm=0.318, loss_scale=2, train_wall=79, gb_free=39.6, wall=97278
2023-06-12 18:49:02 | INFO | train_inner | epoch 011:   3767 / 11284 loss=3.566, nll_loss=1.863, ppl=3.64, wps=70590.8, ups=1.18, wpb=59577.8, bsz=2229.8, num_updates=116500, lr=0.000292979, gnorm=0.301, loss_scale=2, train_wall=80, gb_free=39.6, wall=97363
2023-06-12 18:49:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 18:50:25 | INFO | train_inner | epoch 011:   3868 / 11284 loss=3.573, nll_loss=1.871, ppl=3.66, wps=71199.9, ups=1.2, wpb=59290.2, bsz=2143.4, num_updates=116600, lr=0.000292854, gnorm=0.312, loss_scale=2, train_wall=80, gb_free=39.6, wall=97446
2023-06-12 18:51:47 | INFO | train_inner | epoch 011:   3968 / 11284 loss=3.571, nll_loss=1.868, ppl=3.65, wps=72942.9, ups=1.23, wpb=59464.8, bsz=2243.7, num_updates=116700, lr=0.000292728, gnorm=0.308, loss_scale=2, train_wall=77, gb_free=39.5, wall=97527
2023-06-12 18:53:09 | INFO | train_inner | epoch 011:   4068 / 11284 loss=3.574, nll_loss=1.872, ppl=3.66, wps=72378.9, ups=1.22, wpb=59516.5, bsz=2268.2, num_updates=116800, lr=0.000292603, gnorm=0.308, loss_scale=2, train_wall=78, gb_free=39.6, wall=97610
2023-06-12 18:54:32 | INFO | train_inner | epoch 011:   4168 / 11284 loss=3.578, nll_loss=1.877, ppl=3.67, wps=72114.5, ups=1.21, wpb=59671.2, bsz=2200.9, num_updates=116900, lr=0.000292478, gnorm=0.292, loss_scale=2, train_wall=79, gb_free=39.4, wall=97692
2023-06-12 18:55:55 | INFO | train_inner | epoch 011:   4268 / 11284 loss=3.56, nll_loss=1.856, ppl=3.62, wps=71575.5, ups=1.2, wpb=59535.4, bsz=2151.8, num_updates=117000, lr=0.000292353, gnorm=0.321, loss_scale=2, train_wall=79, gb_free=39.5, wall=97776
2023-06-12 18:57:18 | INFO | train_inner | epoch 011:   4368 / 11284 loss=3.573, nll_loss=1.871, ppl=3.66, wps=71424.7, ups=1.2, wpb=59497.8, bsz=2264, num_updates=117100, lr=0.000292228, gnorm=0.31, loss_scale=2, train_wall=79, gb_free=39.6, wall=97859
2023-06-12 18:58:41 | INFO | train_inner | epoch 011:   4468 / 11284 loss=3.551, nll_loss=1.846, ppl=3.6, wps=71758.5, ups=1.21, wpb=59503.9, bsz=2083.2, num_updates=117200, lr=0.000292103, gnorm=0.316, loss_scale=2, train_wall=79, gb_free=39.4, wall=97942
2023-06-12 19:00:05 | INFO | train_inner | epoch 011:   4568 / 11284 loss=3.569, nll_loss=1.867, ppl=3.65, wps=71021.4, ups=1.19, wpb=59603.3, bsz=2231.9, num_updates=117300, lr=0.000291979, gnorm=0.3, loss_scale=2, train_wall=80, gb_free=39.6, wall=98026
2023-06-12 19:01:28 | INFO | train_inner | epoch 011:   4668 / 11284 loss=3.551, nll_loss=1.846, ppl=3.6, wps=72063.3, ups=1.21, wpb=59616.9, bsz=2195, num_updates=117400, lr=0.000291854, gnorm=0.302, loss_scale=2, train_wall=79, gb_free=39.5, wall=98108
2023-06-12 19:02:49 | INFO | train_inner | epoch 011:   4768 / 11284 loss=3.568, nll_loss=1.865, ppl=3.64, wps=73118, ups=1.23, wpb=59546.7, bsz=2152.3, num_updates=117500, lr=0.00029173, gnorm=0.3, loss_scale=2, train_wall=78, gb_free=39.6, wall=98190
2023-06-12 19:04:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 19:04:12 | INFO | train_inner | epoch 011:   4869 / 11284 loss=3.564, nll_loss=1.86, ppl=3.63, wps=71594, ups=1.21, wpb=59290.2, bsz=2176.8, num_updates=117600, lr=0.000291606, gnorm=0.313, loss_scale=2, train_wall=79, gb_free=39.6, wall=98273
2023-06-12 19:05:35 | INFO | train_inner | epoch 011:   4969 / 11284 loss=3.569, nll_loss=1.867, ppl=3.65, wps=71285.2, ups=1.2, wpb=59429.5, bsz=2341.1, num_updates=117700, lr=0.000291482, gnorm=0.31, loss_scale=2, train_wall=79, gb_free=39.4, wall=98356
2023-06-12 19:06:58 | INFO | train_inner | epoch 011:   5069 / 11284 loss=3.567, nll_loss=1.864, ppl=3.64, wps=71692.1, ups=1.2, wpb=59525.7, bsz=2244.5, num_updates=117800, lr=0.000291358, gnorm=0.317, loss_scale=2, train_wall=79, gb_free=39.6, wall=98439
2023-06-12 19:08:20 | INFO | train_inner | epoch 011:   5169 / 11284 loss=3.571, nll_loss=1.869, ppl=3.65, wps=72604.9, ups=1.22, wpb=59388.5, bsz=2184.3, num_updates=117900, lr=0.000291235, gnorm=0.305, loss_scale=2, train_wall=78, gb_free=39.6, wall=98521
2023-06-12 19:09:42 | INFO | train_inner | epoch 011:   5269 / 11284 loss=3.547, nll_loss=1.842, ppl=3.58, wps=73184.1, ups=1.22, wpb=59797.6, bsz=2196.4, num_updates=118000, lr=0.000291111, gnorm=0.301, loss_scale=2, train_wall=78, gb_free=39.6, wall=98603
2023-06-12 19:11:04 | INFO | train_inner | epoch 011:   5369 / 11284 loss=3.561, nll_loss=1.858, ppl=3.62, wps=72699.5, ups=1.22, wpb=59518.4, bsz=2272.5, num_updates=118100, lr=0.000290988, gnorm=0.299, loss_scale=2, train_wall=78, gb_free=39.6, wall=98684
2023-06-12 19:12:27 | INFO | train_inner | epoch 011:   5469 / 11284 loss=3.572, nll_loss=1.87, ppl=3.66, wps=71876.4, ups=1.2, wpb=59798.2, bsz=2227.8, num_updates=118200, lr=0.000290865, gnorm=0.31, loss_scale=2, train_wall=79, gb_free=39.6, wall=98768
2023-06-12 19:13:50 | INFO | train_inner | epoch 011:   5569 / 11284 loss=3.561, nll_loss=1.857, ppl=3.62, wps=71486, ups=1.2, wpb=59436.5, bsz=2228.7, num_updates=118300, lr=0.000290742, gnorm=0.309, loss_scale=2, train_wall=79, gb_free=39.6, wall=98851
2023-06-12 19:15:13 | INFO | train_inner | epoch 011:   5669 / 11284 loss=3.556, nll_loss=1.852, ppl=3.61, wps=71510.1, ups=1.21, wpb=59309.6, bsz=2226, num_updates=118400, lr=0.000290619, gnorm=0.302, loss_scale=2, train_wall=79, gb_free=39.6, wall=98934
2023-06-12 19:16:36 | INFO | train_inner | epoch 011:   5769 / 11284 loss=3.564, nll_loss=1.861, ppl=3.63, wps=71986.7, ups=1.21, wpb=59529.9, bsz=2212.5, num_updates=118500, lr=0.000290496, gnorm=0.322, loss_scale=2, train_wall=79, gb_free=39.6, wall=99016
2023-06-12 19:17:58 | INFO | train_inner | epoch 011:   5869 / 11284 loss=3.554, nll_loss=1.85, ppl=3.61, wps=72350.8, ups=1.21, wpb=59590.8, bsz=2150.8, num_updates=118600, lr=0.000290374, gnorm=0.306, loss_scale=2, train_wall=79, gb_free=39.6, wall=99099
2023-06-12 19:18:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 19:19:21 | INFO | train_inner | epoch 011:   5970 / 11284 loss=3.57, nll_loss=1.867, ppl=3.65, wps=71759.7, ups=1.2, wpb=59673.8, bsz=2293, num_updates=118700, lr=0.000290252, gnorm=0.305, loss_scale=2, train_wall=79, gb_free=39.6, wall=99182
2023-06-12 19:20:43 | INFO | train_inner | epoch 011:   6070 / 11284 loss=3.561, nll_loss=1.858, ppl=3.62, wps=72624.7, ups=1.22, wpb=59528.7, bsz=2222.4, num_updates=118800, lr=0.000290129, gnorm=0.321, loss_scale=2, train_wall=78, gb_free=39.6, wall=99264
2023-06-12 19:22:06 | INFO | train_inner | epoch 011:   6170 / 11284 loss=3.557, nll_loss=1.853, ppl=3.61, wps=71681.5, ups=1.21, wpb=59464.8, bsz=2251.9, num_updates=118900, lr=0.000290007, gnorm=0.302, loss_scale=2, train_wall=79, gb_free=39.6, wall=99347
2023-06-12 19:23:31 | INFO | train_inner | epoch 011:   6270 / 11284 loss=3.578, nll_loss=1.877, ppl=3.67, wps=70324.8, ups=1.18, wpb=59386.3, bsz=2165.4, num_updates=119000, lr=0.000289886, gnorm=0.317, loss_scale=2, train_wall=81, gb_free=39.6, wall=99431
2023-06-12 19:24:54 | INFO | train_inner | epoch 011:   6370 / 11284 loss=3.557, nll_loss=1.853, ppl=3.61, wps=71136.1, ups=1.19, wpb=59578.3, bsz=2280.8, num_updates=119100, lr=0.000289764, gnorm=0.3, loss_scale=2, train_wall=80, gb_free=39.5, wall=99515
2023-06-12 19:26:17 | INFO | train_inner | epoch 011:   6470 / 11284 loss=3.557, nll_loss=1.854, ppl=3.61, wps=72332.5, ups=1.21, wpb=59825.4, bsz=2143.7, num_updates=119200, lr=0.000289642, gnorm=0.294, loss_scale=2, train_wall=79, gb_free=39.6, wall=99598
2023-06-12 19:27:40 | INFO | train_inner | epoch 011:   6570 / 11284 loss=3.553, nll_loss=1.849, ppl=3.6, wps=71445.4, ups=1.2, wpb=59494.6, bsz=2228.3, num_updates=119300, lr=0.000289521, gnorm=0.308, loss_scale=2, train_wall=79, gb_free=39.6, wall=99681
2023-06-12 19:29:03 | INFO | train_inner | epoch 011:   6670 / 11284 loss=3.565, nll_loss=1.862, ppl=3.64, wps=71963.3, ups=1.21, wpb=59631.6, bsz=2196.6, num_updates=119400, lr=0.0002894, gnorm=0.3, loss_scale=2, train_wall=79, gb_free=39.5, wall=99764
2023-06-12 19:30:26 | INFO | train_inner | epoch 011:   6770 / 11284 loss=3.568, nll_loss=1.865, ppl=3.64, wps=71436.7, ups=1.2, wpb=59399.5, bsz=2218.2, num_updates=119500, lr=0.000289278, gnorm=0.298, loss_scale=2, train_wall=79, gb_free=39.6, wall=99847
2023-06-12 19:31:50 | INFO | train_inner | epoch 011:   6870 / 11284 loss=3.557, nll_loss=1.853, ppl=3.61, wps=71591.2, ups=1.2, wpb=59495.9, bsz=2228.3, num_updates=119600, lr=0.000289157, gnorm=0.313, loss_scale=2, train_wall=79, gb_free=39.6, wall=99930
2023-06-12 19:33:13 | INFO | train_inner | epoch 011:   6970 / 11284 loss=3.554, nll_loss=1.85, ppl=3.61, wps=71719, ups=1.21, wpb=59489.1, bsz=2240.9, num_updates=119700, lr=0.000289037, gnorm=0.316, loss_scale=4, train_wall=79, gb_free=39.6, wall=100013
2023-06-12 19:34:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 19:34:36 | INFO | train_inner | epoch 011:   7071 / 11284 loss=3.542, nll_loss=1.836, ppl=3.57, wps=70986.6, ups=1.19, wpb=59507.6, bsz=2187.1, num_updates=119800, lr=0.000288916, gnorm=0.311, loss_scale=2, train_wall=80, gb_free=39.6, wall=100097
2023-06-12 19:36:00 | INFO | train_inner | epoch 011:   7171 / 11284 loss=3.57, nll_loss=1.868, ppl=3.65, wps=71533.3, ups=1.2, wpb=59551.2, bsz=2243.6, num_updates=119900, lr=0.000288795, gnorm=0.31, loss_scale=2, train_wall=79, gb_free=39.6, wall=100180
2023-06-12 19:37:23 | INFO | train_inner | epoch 011:   7271 / 11284 loss=3.561, nll_loss=1.858, ppl=3.62, wps=71327.1, ups=1.2, wpb=59501.8, bsz=2379.2, num_updates=120000, lr=0.000288675, gnorm=0.307, loss_scale=2, train_wall=79, gb_free=39.6, wall=100264
2023-06-12 19:38:46 | INFO | train_inner | epoch 011:   7371 / 11284 loss=3.561, nll_loss=1.858, ppl=3.62, wps=72156.1, ups=1.21, wpb=59620.3, bsz=2255.6, num_updates=120100, lr=0.000288555, gnorm=0.298, loss_scale=2, train_wall=79, gb_free=39.5, wall=100346
2023-06-12 19:40:08 | INFO | train_inner | epoch 011:   7471 / 11284 loss=3.563, nll_loss=1.86, ppl=3.63, wps=71811.8, ups=1.21, wpb=59284.1, bsz=2098.1, num_updates=120200, lr=0.000288435, gnorm=0.299, loss_scale=2, train_wall=79, gb_free=39.6, wall=100429
2023-06-12 19:41:31 | INFO | train_inner | epoch 011:   7571 / 11284 loss=3.549, nll_loss=1.844, ppl=3.59, wps=72079.4, ups=1.21, wpb=59490.8, bsz=2221.4, num_updates=120300, lr=0.000288315, gnorm=0.303, loss_scale=2, train_wall=78, gb_free=39.6, wall=100511
2023-06-12 19:42:54 | INFO | train_inner | epoch 011:   7671 / 11284 loss=3.56, nll_loss=1.857, ppl=3.62, wps=71905.2, ups=1.21, wpb=59612.6, bsz=2227.2, num_updates=120400, lr=0.000288195, gnorm=0.295, loss_scale=2, train_wall=79, gb_free=39.5, wall=100594
2023-06-12 19:44:16 | INFO | train_inner | epoch 011:   7771 / 11284 loss=3.578, nll_loss=1.877, ppl=3.67, wps=72152.6, ups=1.22, wpb=59247.7, bsz=2263.6, num_updates=120500, lr=0.000288076, gnorm=0.305, loss_scale=2, train_wall=78, gb_free=39.6, wall=100676
2023-06-12 19:45:39 | INFO | train_inner | epoch 011:   7871 / 11284 loss=3.558, nll_loss=1.855, ppl=3.62, wps=71621.4, ups=1.2, wpb=59581.7, bsz=2245.7, num_updates=120600, lr=0.000287956, gnorm=0.304, loss_scale=2, train_wall=79, gb_free=39.6, wall=100760
2023-06-12 19:47:02 | INFO | train_inner | epoch 011:   7971 / 11284 loss=3.563, nll_loss=1.86, ppl=3.63, wps=71456.1, ups=1.2, wpb=59426.2, bsz=2225, num_updates=120700, lr=0.000287837, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.6, wall=100843
2023-06-12 19:48:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 19:48:27 | INFO | train_inner | epoch 011:   8072 / 11284 loss=3.569, nll_loss=1.867, ppl=3.65, wps=70744.3, ups=1.18, wpb=59714.9, bsz=2296, num_updates=120800, lr=0.000287718, gnorm=0.299, loss_scale=2, train_wall=80, gb_free=39.5, wall=100927
2023-06-12 19:49:50 | INFO | train_inner | epoch 011:   8172 / 11284 loss=3.55, nll_loss=1.845, ppl=3.59, wps=71415.7, ups=1.2, wpb=59397.6, bsz=2155.8, num_updates=120900, lr=0.000287599, gnorm=0.308, loss_scale=2, train_wall=79, gb_free=39.6, wall=101010
2023-06-12 19:51:12 | INFO | train_inner | epoch 011:   8272 / 11284 loss=3.565, nll_loss=1.862, ppl=3.64, wps=72487.2, ups=1.22, wpb=59452.2, bsz=2129.7, num_updates=121000, lr=0.00028748, gnorm=0.302, loss_scale=2, train_wall=78, gb_free=39.6, wall=101092
2023-06-12 19:52:35 | INFO | train_inner | epoch 011:   8372 / 11284 loss=3.56, nll_loss=1.856, ppl=3.62, wps=71666.3, ups=1.21, wpb=59335.8, bsz=2226.8, num_updates=121100, lr=0.000287361, gnorm=0.327, loss_scale=2, train_wall=79, gb_free=39.5, wall=101175
2023-06-12 19:53:57 | INFO | train_inner | epoch 011:   8472 / 11284 loss=3.557, nll_loss=1.854, ppl=3.61, wps=72084.1, ups=1.21, wpb=59545.6, bsz=2320.4, num_updates=121200, lr=0.000287242, gnorm=0.306, loss_scale=2, train_wall=78, gb_free=39.6, wall=101258
2023-06-12 19:55:20 | INFO | train_inner | epoch 011:   8572 / 11284 loss=3.566, nll_loss=1.863, ppl=3.64, wps=71484.7, ups=1.2, wpb=59558.1, bsz=2144, num_updates=121300, lr=0.000287124, gnorm=0.314, loss_scale=2, train_wall=79, gb_free=39.6, wall=101341
2023-06-12 19:56:43 | INFO | train_inner | epoch 011:   8672 / 11284 loss=3.565, nll_loss=1.862, ppl=3.64, wps=72297.6, ups=1.22, wpb=59378.4, bsz=2210.5, num_updates=121400, lr=0.000287006, gnorm=0.309, loss_scale=2, train_wall=78, gb_free=39.6, wall=101423
2023-06-12 19:58:04 | INFO | train_inner | epoch 011:   8772 / 11284 loss=3.565, nll_loss=1.863, ppl=3.64, wps=72771.8, ups=1.22, wpb=59504.4, bsz=2233.2, num_updates=121500, lr=0.000286888, gnorm=0.309, loss_scale=2, train_wall=78, gb_free=39.6, wall=101505
2023-06-12 19:59:27 | INFO | train_inner | epoch 011:   8872 / 11284 loss=3.562, nll_loss=1.859, ppl=3.63, wps=72347, ups=1.22, wpb=59528.3, bsz=2232.4, num_updates=121600, lr=0.00028677, gnorm=0.3, loss_scale=2, train_wall=78, gb_free=39.6, wall=101587
2023-06-12 20:00:50 | INFO | train_inner | epoch 011:   8972 / 11284 loss=3.583, nll_loss=1.883, ppl=3.69, wps=71355.8, ups=1.2, wpb=59585.2, bsz=2244.3, num_updates=121700, lr=0.000286652, gnorm=0.313, loss_scale=2, train_wall=80, gb_free=39.6, wall=101671
2023-06-12 20:02:13 | INFO | train_inner | epoch 011:   9072 / 11284 loss=3.567, nll_loss=1.865, ppl=3.64, wps=71516.6, ups=1.2, wpb=59594.4, bsz=2216.6, num_updates=121800, lr=0.000286534, gnorm=0.307, loss_scale=2, train_wall=79, gb_free=39.5, wall=101754
2023-06-12 20:03:35 | INFO | train_inner | epoch 011:   9172 / 11284 loss=3.56, nll_loss=1.857, ppl=3.62, wps=72763.9, ups=1.22, wpb=59504.8, bsz=2195.9, num_updates=121900, lr=0.000286417, gnorm=0.302, loss_scale=4, train_wall=78, gb_free=39.6, wall=101836
2023-06-12 20:04:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 20:04:58 | INFO | train_inner | epoch 011:   9273 / 11284 loss=3.575, nll_loss=1.873, ppl=3.66, wps=71768.5, ups=1.21, wpb=59400.5, bsz=2159, num_updates=122000, lr=0.000286299, gnorm=0.309, loss_scale=2, train_wall=78, gb_free=39.6, wall=101919
2023-06-12 20:06:21 | INFO | train_inner | epoch 011:   9373 / 11284 loss=3.579, nll_loss=1.878, ppl=3.68, wps=71289.5, ups=1.2, wpb=59501.1, bsz=2278.7, num_updates=122100, lr=0.000286182, gnorm=0.313, loss_scale=2, train_wall=79, gb_free=39.6, wall=102002
2023-06-12 20:07:45 | INFO | train_inner | epoch 011:   9473 / 11284 loss=3.554, nll_loss=1.85, ppl=3.61, wps=71622.7, ups=1.2, wpb=59482.7, bsz=2203.6, num_updates=122200, lr=0.000286065, gnorm=0.306, loss_scale=2, train_wall=79, gb_free=39.6, wall=102085
2023-06-12 20:09:08 | INFO | train_inner | epoch 011:   9573 / 11284 loss=3.561, nll_loss=1.858, ppl=3.62, wps=71318.6, ups=1.2, wpb=59343.8, bsz=2235.5, num_updates=122300, lr=0.000285948, gnorm=0.31, loss_scale=2, train_wall=79, gb_free=39.5, wall=102168
2023-06-12 20:10:31 | INFO | train_inner | epoch 011:   9673 / 11284 loss=3.57, nll_loss=1.868, ppl=3.65, wps=71505.5, ups=1.2, wpb=59573.2, bsz=2280, num_updates=122400, lr=0.000285831, gnorm=0.299, loss_scale=2, train_wall=79, gb_free=39.6, wall=102252
2023-06-12 20:11:54 | INFO | train_inner | epoch 011:   9773 / 11284 loss=3.558, nll_loss=1.854, ppl=3.61, wps=71686.4, ups=1.2, wpb=59690.1, bsz=2154.8, num_updates=122500, lr=0.000285714, gnorm=0.309, loss_scale=2, train_wall=79, gb_free=39.6, wall=102335
2023-06-12 20:13:18 | INFO | train_inner | epoch 011:   9873 / 11284 loss=3.56, nll_loss=1.857, ppl=3.62, wps=71423.1, ups=1.2, wpb=59521.9, bsz=2300.6, num_updates=122600, lr=0.000285598, gnorm=0.318, loss_scale=2, train_wall=79, gb_free=39.5, wall=102418
2023-06-12 20:14:39 | INFO | train_inner | epoch 011:   9973 / 11284 loss=3.574, nll_loss=1.872, ppl=3.66, wps=72715.1, ups=1.22, wpb=59469.5, bsz=2150.7, num_updates=122700, lr=0.000285481, gnorm=0.298, loss_scale=2, train_wall=78, gb_free=39.6, wall=102500
2023-06-12 20:16:01 | INFO | train_inner | epoch 011:  10073 / 11284 loss=3.574, nll_loss=1.873, ppl=3.66, wps=72764.5, ups=1.23, wpb=59343.7, bsz=2233.9, num_updates=122800, lr=0.000285365, gnorm=0.31, loss_scale=2, train_wall=77, gb_free=39.5, wall=102582
2023-06-12 20:17:23 | INFO | train_inner | epoch 011:  10173 / 11284 loss=3.568, nll_loss=1.865, ppl=3.64, wps=72530.1, ups=1.22, wpb=59289, bsz=2217.1, num_updates=122900, lr=0.000285249, gnorm=0.306, loss_scale=2, train_wall=78, gb_free=39.5, wall=102663
2023-06-12 20:18:46 | INFO | train_inner | epoch 011:  10273 / 11284 loss=3.559, nll_loss=1.856, ppl=3.62, wps=71192.1, ups=1.2, wpb=59366.3, bsz=2367.3, num_updates=123000, lr=0.000285133, gnorm=0.308, loss_scale=4, train_wall=79, gb_free=39.6, wall=102747
2023-06-12 20:18:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 20:20:10 | INFO | train_inner | epoch 011:  10374 / 11284 loss=3.574, nll_loss=1.873, ppl=3.66, wps=70906, ups=1.19, wpb=59553.4, bsz=2189.4, num_updates=123100, lr=0.000285017, gnorm=0.311, loss_scale=2, train_wall=80, gb_free=39.6, wall=102831
2023-06-12 20:21:33 | INFO | train_inner | epoch 011:  10474 / 11284 loss=3.56, nll_loss=1.857, ppl=3.62, wps=72011.5, ups=1.21, wpb=59411.3, bsz=2170.3, num_updates=123200, lr=0.000284901, gnorm=0.311, loss_scale=2, train_wall=79, gb_free=39.5, wall=102913
2023-06-12 20:22:56 | INFO | train_inner | epoch 011:  10574 / 11284 loss=3.559, nll_loss=1.856, ppl=3.62, wps=71917.2, ups=1.21, wpb=59650.5, bsz=2302.6, num_updates=123300, lr=0.000284786, gnorm=0.293, loss_scale=2, train_wall=79, gb_free=39.6, wall=102996
2023-06-12 20:24:19 | INFO | train_inner | epoch 011:  10674 / 11284 loss=3.546, nll_loss=1.841, ppl=3.58, wps=71845.3, ups=1.2, wpb=59643, bsz=2292.9, num_updates=123400, lr=0.00028467, gnorm=0.305, loss_scale=2, train_wall=79, gb_free=39.5, wall=103079
2023-06-12 20:25:42 | INFO | train_inner | epoch 011:  10774 / 11284 loss=3.556, nll_loss=1.852, ppl=3.61, wps=71138.7, ups=1.2, wpb=59337.6, bsz=2209.3, num_updates=123500, lr=0.000284555, gnorm=0.31, loss_scale=2, train_wall=80, gb_free=39.6, wall=103163
2023-06-12 20:27:05 | INFO | train_inner | epoch 011:  10874 / 11284 loss=3.562, nll_loss=1.859, ppl=3.63, wps=71442.1, ups=1.2, wpb=59562.9, bsz=2219, num_updates=123600, lr=0.00028444, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.5, wall=103246
2023-06-12 20:28:28 | INFO | train_inner | epoch 011:  10974 / 11284 loss=3.553, nll_loss=1.85, ppl=3.6, wps=71785.1, ups=1.21, wpb=59376.8, bsz=2295.1, num_updates=123700, lr=0.000284325, gnorm=0.31, loss_scale=2, train_wall=78, gb_free=39.5, wall=103329
2023-06-12 20:29:52 | INFO | train_inner | epoch 011:  11074 / 11284 loss=3.558, nll_loss=1.855, ppl=3.62, wps=71124.4, ups=1.2, wpb=59354.9, bsz=2175.4, num_updates=123800, lr=0.00028421, gnorm=0.307, loss_scale=2, train_wall=80, gb_free=39.6, wall=103412
2023-06-12 20:31:15 | INFO | train_inner | epoch 011:  11174 / 11284 loss=3.586, nll_loss=1.886, ppl=3.7, wps=71332.4, ups=1.2, wpb=59200.7, bsz=2242.8, num_updates=123900, lr=0.000284095, gnorm=0.305, loss_scale=2, train_wall=79, gb_free=39.6, wall=103495
2023-06-12 20:32:38 | INFO | train_inner | epoch 011:  11274 / 11284 loss=3.575, nll_loss=1.874, ppl=3.67, wps=71081, ups=1.2, wpb=59220.1, bsz=2357.1, num_updates=124000, lr=0.000283981, gnorm=0.324, loss_scale=2, train_wall=79, gb_free=39.6, wall=103578
2023-06-12 20:32:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-12 20:33:04 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 4.334 | nll_loss 2.654 | ppl 6.29 | bleu 21.09 | wps 3678.5 | wpb 2397.5 | bsz 71.5 | num_updates 124010 | best_loss 4.334
2023-06-12 20:33:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 124010 updates
2023-06-12 20:33:04 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint11.pt
2023-06-12 20:33:06 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint11.pt
2023-06-12 20:33:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint11.pt (epoch 11 @ 124010 updates, score 4.334) (writing took 6.7453000554814935 seconds)
2023-06-12 20:33:11 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-06-12 20:33:11 | INFO | train | epoch 011 | loss 3.562 | nll_loss 1.859 | ppl 3.63 | wps 71548.7 | ups 1.2 | wpb 59500.9 | bsz 2227.2 | num_updates 124010 | lr 0.000283969 | gnorm 0.307 | loss_scale 2 | train_wall 8900 | gb_free 39.6 | wall 103611
2023-06-12 20:33:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-12 20:33:11 | INFO | fairseq.trainer | begin training epoch 12
2023-06-12 20:33:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-12 20:33:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 20:34:26 | INFO | train_inner | epoch 012:     91 / 11284 loss=3.553, nll_loss=1.849, ppl=3.6, wps=54631, ups=0.92, wpb=59252.5, bsz=2245.8, num_updates=124100, lr=0.000283866, gnorm=0.31, loss_scale=2, train_wall=79, gb_free=39.5, wall=103687
2023-06-12 20:35:50 | INFO | train_inner | epoch 012:    191 / 11284 loss=3.542, nll_loss=1.836, ppl=3.57, wps=71603.8, ups=1.2, wpb=59581, bsz=2235.8, num_updates=124200, lr=0.000283752, gnorm=0.31, loss_scale=2, train_wall=79, gb_free=39.6, wall=103770
2023-06-12 20:37:12 | INFO | train_inner | epoch 012:    291 / 11284 loss=3.565, nll_loss=1.862, ppl=3.63, wps=71473.7, ups=1.21, wpb=59232.1, bsz=2184.8, num_updates=124300, lr=0.000283638, gnorm=0.313, loss_scale=2, train_wall=79, gb_free=39.6, wall=103853
2023-06-12 20:38:35 | INFO | train_inner | epoch 012:    391 / 11284 loss=3.566, nll_loss=1.863, ppl=3.64, wps=72363.1, ups=1.21, wpb=59611.8, bsz=2196.2, num_updates=124400, lr=0.000283524, gnorm=0.309, loss_scale=2, train_wall=78, gb_free=39.5, wall=103935
2023-06-12 20:39:58 | INFO | train_inner | epoch 012:    491 / 11284 loss=3.558, nll_loss=1.854, ppl=3.61, wps=71433.6, ups=1.21, wpb=59239, bsz=2275.4, num_updates=124500, lr=0.00028341, gnorm=0.307, loss_scale=2, train_wall=79, gb_free=39.5, wall=104018
2023-06-12 20:41:20 | INFO | train_inner | epoch 012:    591 / 11284 loss=3.549, nll_loss=1.844, ppl=3.59, wps=72029.2, ups=1.21, wpb=59413.2, bsz=2170.4, num_updates=124600, lr=0.000283296, gnorm=0.293, loss_scale=2, train_wall=78, gb_free=39.6, wall=104101
2023-06-12 20:42:44 | INFO | train_inner | epoch 012:    691 / 11284 loss=3.552, nll_loss=1.847, ppl=3.6, wps=71317, ups=1.2, wpb=59457.9, bsz=2284.8, num_updates=124700, lr=0.000283183, gnorm=0.31, loss_scale=2, train_wall=79, gb_free=39.6, wall=104184
2023-06-12 20:44:06 | INFO | train_inner | epoch 012:    791 / 11284 loss=3.558, nll_loss=1.854, ppl=3.62, wps=71929.4, ups=1.21, wpb=59542.8, bsz=2184.6, num_updates=124800, lr=0.000283069, gnorm=0.305, loss_scale=2, train_wall=79, gb_free=39.6, wall=104267
2023-06-12 20:45:29 | INFO | train_inner | epoch 012:    891 / 11284 loss=3.552, nll_loss=1.847, ppl=3.6, wps=72091.9, ups=1.21, wpb=59528.3, bsz=2242.8, num_updates=124900, lr=0.000282956, gnorm=0.295, loss_scale=2, train_wall=78, gb_free=39.4, wall=104350
2023-06-12 20:46:50 | INFO | train_inner | epoch 012:    991 / 11284 loss=3.554, nll_loss=1.85, ppl=3.61, wps=73202.6, ups=1.23, wpb=59567.2, bsz=2198.3, num_updates=125000, lr=0.000282843, gnorm=0.314, loss_scale=2, train_wall=77, gb_free=39.6, wall=104431
2023-06-12 20:47:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 20:48:14 | INFO | train_inner | epoch 012:   1092 / 11284 loss=3.544, nll_loss=1.838, ppl=3.58, wps=71595.1, ups=1.2, wpb=59601.4, bsz=2281.8, num_updates=125100, lr=0.00028273, gnorm=0.296, loss_scale=2, train_wall=79, gb_free=39.6, wall=104514
2023-06-12 20:49:37 | INFO | train_inner | epoch 012:   1192 / 11284 loss=3.554, nll_loss=1.85, ppl=3.6, wps=71323.2, ups=1.2, wpb=59274.3, bsz=2225.8, num_updates=125200, lr=0.000282617, gnorm=0.326, loss_scale=2, train_wall=79, gb_free=39.6, wall=104597
2023-06-12 20:51:00 | INFO | train_inner | epoch 012:   1292 / 11284 loss=3.552, nll_loss=1.847, ppl=3.6, wps=71599.6, ups=1.2, wpb=59435.2, bsz=2162, num_updates=125300, lr=0.000282504, gnorm=0.322, loss_scale=2, train_wall=79, gb_free=39.6, wall=104680
2023-06-12 20:52:23 | INFO | train_inner | epoch 012:   1392 / 11284 loss=3.555, nll_loss=1.85, ppl=3.61, wps=70935.3, ups=1.2, wpb=59243.5, bsz=2287.6, num_updates=125400, lr=0.000282391, gnorm=0.302, loss_scale=2, train_wall=79, gb_free=39.5, wall=104764
2023-06-12 20:53:46 | INFO | train_inner | epoch 012:   1492 / 11284 loss=3.553, nll_loss=1.849, ppl=3.6, wps=71614.1, ups=1.2, wpb=59480.8, bsz=2172.9, num_updates=125500, lr=0.000282279, gnorm=0.311, loss_scale=2, train_wall=79, gb_free=39.6, wall=104847
2023-06-12 20:55:09 | INFO | train_inner | epoch 012:   1592 / 11284 loss=3.546, nll_loss=1.841, ppl=3.58, wps=72015.2, ups=1.21, wpb=59645.7, bsz=2307.1, num_updates=125600, lr=0.000282166, gnorm=0.299, loss_scale=2, train_wall=79, gb_free=39.5, wall=104930
2023-06-12 20:56:32 | INFO | train_inner | epoch 012:   1692 / 11284 loss=3.555, nll_loss=1.85, ppl=3.61, wps=71794.6, ups=1.21, wpb=59441.9, bsz=2203.9, num_updates=125700, lr=0.000282054, gnorm=0.307, loss_scale=2, train_wall=79, gb_free=39.6, wall=105012
2023-06-12 20:57:55 | INFO | train_inner | epoch 012:   1792 / 11284 loss=3.561, nll_loss=1.857, ppl=3.62, wps=71661.3, ups=1.21, wpb=59456.6, bsz=2260.3, num_updates=125800, lr=0.000281942, gnorm=0.317, loss_scale=2, train_wall=79, gb_free=39.6, wall=105095
2023-06-12 20:59:18 | INFO | train_inner | epoch 012:   1892 / 11284 loss=3.551, nll_loss=1.847, ppl=3.6, wps=71694.6, ups=1.2, wpb=59592.5, bsz=2230.4, num_updates=125900, lr=0.00028183, gnorm=0.299, loss_scale=2, train_wall=79, gb_free=39.6, wall=105179
2023-06-12 21:00:41 | INFO | train_inner | epoch 012:   1992 / 11284 loss=3.549, nll_loss=1.844, ppl=3.59, wps=71457.9, ups=1.2, wpb=59404.7, bsz=2259.9, num_updates=126000, lr=0.000281718, gnorm=0.309, loss_scale=2, train_wall=79, gb_free=39.5, wall=105262
2023-06-12 21:02:05 | INFO | train_inner | epoch 012:   2092 / 11284 loss=3.546, nll_loss=1.841, ppl=3.58, wps=70462.1, ups=1.19, wpb=59442.4, bsz=2194.4, num_updates=126100, lr=0.000281606, gnorm=0.305, loss_scale=4, train_wall=80, gb_free=39.6, wall=105346
2023-06-12 21:02:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 21:03:29 | INFO | train_inner | epoch 012:   2193 / 11284 loss=3.565, nll_loss=1.862, ppl=3.63, wps=70683, ups=1.19, wpb=59275.7, bsz=2226.2, num_updates=126200, lr=0.000281495, gnorm=0.313, loss_scale=2, train_wall=80, gb_free=39.6, wall=105430
2023-06-12 21:04:51 | INFO | train_inner | epoch 012:   2293 / 11284 loss=3.543, nll_loss=1.837, ppl=3.57, wps=72507.9, ups=1.22, wpb=59470.7, bsz=2089, num_updates=126300, lr=0.000281383, gnorm=0.304, loss_scale=2, train_wall=78, gb_free=39.6, wall=105512
2023-06-12 21:06:14 | INFO | train_inner | epoch 012:   2393 / 11284 loss=3.547, nll_loss=1.842, ppl=3.58, wps=72174.6, ups=1.22, wpb=59322.6, bsz=2167.6, num_updates=126400, lr=0.000281272, gnorm=0.306, loss_scale=2, train_wall=78, gb_free=39.6, wall=105594
2023-06-12 21:07:37 | INFO | train_inner | epoch 012:   2493 / 11284 loss=3.558, nll_loss=1.855, ppl=3.62, wps=71605.5, ups=1.21, wpb=59412.2, bsz=2220.3, num_updates=126500, lr=0.000281161, gnorm=0.307, loss_scale=2, train_wall=79, gb_free=39.6, wall=105677
2023-06-12 21:08:59 | INFO | train_inner | epoch 012:   2593 / 11284 loss=3.556, nll_loss=1.852, ppl=3.61, wps=71687.3, ups=1.21, wpb=59389.8, bsz=2310.3, num_updates=126600, lr=0.00028105, gnorm=0.303, loss_scale=2, train_wall=79, gb_free=39.6, wall=105760
2023-06-12 21:10:22 | INFO | train_inner | epoch 012:   2693 / 11284 loss=3.554, nll_loss=1.85, ppl=3.6, wps=72058.5, ups=1.21, wpb=59566.5, bsz=2141.7, num_updates=126700, lr=0.000280939, gnorm=0.318, loss_scale=2, train_wall=79, gb_free=39.6, wall=105843
2023-06-12 21:11:46 | INFO | train_inner | epoch 012:   2793 / 11284 loss=3.554, nll_loss=1.85, ppl=3.6, wps=71421.5, ups=1.2, wpb=59617.7, bsz=2319.4, num_updates=126800, lr=0.000280828, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.1, wall=105926
2023-06-12 21:13:09 | INFO | train_inner | epoch 012:   2893 / 11284 loss=3.558, nll_loss=1.855, ppl=3.62, wps=71538.7, ups=1.2, wpb=59580.2, bsz=2273, num_updates=126900, lr=0.000280717, gnorm=0.311, loss_scale=2, train_wall=79, gb_free=39.6, wall=106009
2023-06-12 21:14:32 | INFO | train_inner | epoch 012:   2993 / 11284 loss=3.563, nll_loss=1.86, ppl=3.63, wps=71457.3, ups=1.2, wpb=59516.9, bsz=2273.2, num_updates=127000, lr=0.000280607, gnorm=0.303, loss_scale=2, train_wall=79, gb_free=39.4, wall=106093
2023-06-12 21:15:56 | INFO | train_inner | epoch 012:   3093 / 11284 loss=3.561, nll_loss=1.858, ppl=3.62, wps=71454.6, ups=1.2, wpb=59641.7, bsz=2278.7, num_updates=127100, lr=0.000280496, gnorm=0.311, loss_scale=2, train_wall=79, gb_free=39.6, wall=106176
2023-06-12 21:16:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 21:17:20 | INFO | train_inner | epoch 012:   3194 / 11284 loss=3.552, nll_loss=1.848, ppl=3.6, wps=70587.8, ups=1.19, wpb=59353.3, bsz=2262.9, num_updates=127200, lr=0.000280386, gnorm=0.313, loss_scale=2, train_wall=80, gb_free=39.6, wall=106260
2023-06-12 21:18:43 | INFO | train_inner | epoch 012:   3294 / 11284 loss=3.548, nll_loss=1.844, ppl=3.59, wps=72166.6, ups=1.21, wpb=59870.2, bsz=2196.9, num_updates=127300, lr=0.000280276, gnorm=0.308, loss_scale=2, train_wall=79, gb_free=39.6, wall=106343
2023-06-12 21:20:05 | INFO | train_inner | epoch 012:   3394 / 11284 loss=3.552, nll_loss=1.848, ppl=3.6, wps=71704.6, ups=1.21, wpb=59362.6, bsz=2171.2, num_updates=127400, lr=0.000280166, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.5, wall=106426
2023-06-12 21:21:29 | INFO | train_inner | epoch 012:   3494 / 11284 loss=3.548, nll_loss=1.843, ppl=3.59, wps=71631.4, ups=1.2, wpb=59563.1, bsz=2192.5, num_updates=127500, lr=0.000280056, gnorm=0.319, loss_scale=2, train_wall=79, gb_free=39.6, wall=106509
2023-06-12 21:22:52 | INFO | train_inner | epoch 012:   3594 / 11284 loss=3.545, nll_loss=1.84, ppl=3.58, wps=71676.8, ups=1.2, wpb=59577.7, bsz=2200.1, num_updates=127600, lr=0.000279946, gnorm=0.298, loss_scale=2, train_wall=79, gb_free=39.5, wall=106592
2023-06-12 21:24:15 | INFO | train_inner | epoch 012:   3694 / 11284 loss=3.547, nll_loss=1.842, ppl=3.58, wps=71331.9, ups=1.2, wpb=59399.8, bsz=2210.1, num_updates=127700, lr=0.000279837, gnorm=0.308, loss_scale=2, train_wall=79, gb_free=39.6, wall=106676
2023-06-12 21:25:38 | INFO | train_inner | epoch 012:   3794 / 11284 loss=3.556, nll_loss=1.852, ppl=3.61, wps=71563.6, ups=1.2, wpb=59670.7, bsz=2367.5, num_updates=127800, lr=0.000279727, gnorm=0.303, loss_scale=2, train_wall=79, gb_free=39.5, wall=106759
2023-06-12 21:27:02 | INFO | train_inner | epoch 012:   3894 / 11284 loss=3.554, nll_loss=1.85, ppl=3.61, wps=71198.3, ups=1.2, wpb=59506.5, bsz=2230.5, num_updates=127900, lr=0.000279618, gnorm=0.312, loss_scale=2, train_wall=80, gb_free=39.6, wall=106842
2023-06-12 21:28:25 | INFO | train_inner | epoch 012:   3994 / 11284 loss=3.572, nll_loss=1.87, ppl=3.66, wps=71774.8, ups=1.2, wpb=59680.8, bsz=2256.8, num_updates=128000, lr=0.000279508, gnorm=0.309, loss_scale=2, train_wall=79, gb_free=39.6, wall=106926
2023-06-12 21:29:48 | INFO | train_inner | epoch 012:   4094 / 11284 loss=3.541, nll_loss=1.835, ppl=3.57, wps=71232.6, ups=1.2, wpb=59288.4, bsz=2151.3, num_updates=128100, lr=0.000279399, gnorm=0.308, loss_scale=2, train_wall=79, gb_free=39.6, wall=107009
2023-06-12 21:30:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 21:31:12 | INFO | train_inner | epoch 012:   4195 / 11284 loss=3.549, nll_loss=1.845, ppl=3.59, wps=70864.7, ups=1.19, wpb=59664.1, bsz=2269.5, num_updates=128200, lr=0.00027929, gnorm=0.311, loss_scale=2, train_wall=80, gb_free=39.6, wall=107093
2023-06-12 21:32:36 | INFO | train_inner | epoch 012:   4295 / 11284 loss=3.561, nll_loss=1.858, ppl=3.62, wps=71354, ups=1.2, wpb=59340.6, bsz=2248.4, num_updates=128300, lr=0.000279182, gnorm=0.314, loss_scale=2, train_wall=79, gb_free=39.6, wall=107176
2023-06-12 21:33:59 | INFO | train_inner | epoch 012:   4395 / 11284 loss=3.562, nll_loss=1.859, ppl=3.63, wps=71699.7, ups=1.21, wpb=59439.1, bsz=2244.3, num_updates=128400, lr=0.000279073, gnorm=0.309, loss_scale=2, train_wall=79, gb_free=39.5, wall=107259
2023-06-12 21:35:22 | INFO | train_inner | epoch 012:   4495 / 11284 loss=3.577, nll_loss=1.876, ppl=3.67, wps=71527.6, ups=1.2, wpb=59490.1, bsz=2206.9, num_updates=128500, lr=0.000278964, gnorm=0.321, loss_scale=2, train_wall=79, gb_free=39.6, wall=107342
2023-06-12 21:36:45 | INFO | train_inner | epoch 012:   4595 / 11284 loss=3.542, nll_loss=1.836, ppl=3.57, wps=71774, ups=1.21, wpb=59528.1, bsz=2352.8, num_updates=128600, lr=0.000278856, gnorm=0.312, loss_scale=2, train_wall=79, gb_free=39.6, wall=107425
2023-06-12 21:38:08 | INFO | train_inner | epoch 012:   4695 / 11284 loss=3.565, nll_loss=1.862, ppl=3.64, wps=71580.8, ups=1.2, wpb=59520.7, bsz=2199.6, num_updates=128700, lr=0.000278747, gnorm=0.314, loss_scale=2, train_wall=79, gb_free=39.5, wall=107508
2023-06-12 21:39:31 | INFO | train_inner | epoch 012:   4795 / 11284 loss=3.555, nll_loss=1.851, ppl=3.61, wps=71201.1, ups=1.2, wpb=59258, bsz=2201.7, num_updates=128800, lr=0.000278639, gnorm=0.313, loss_scale=2, train_wall=79, gb_free=39.5, wall=107592
2023-06-12 21:40:54 | INFO | train_inner | epoch 012:   4895 / 11284 loss=3.551, nll_loss=1.847, ppl=3.6, wps=71323.8, ups=1.2, wpb=59493.2, bsz=2220.2, num_updates=128900, lr=0.000278531, gnorm=0.301, loss_scale=2, train_wall=79, gb_free=39.6, wall=107675
2023-06-12 21:42:18 | INFO | train_inner | epoch 012:   4995 / 11284 loss=3.549, nll_loss=1.844, ppl=3.59, wps=71265.2, ups=1.2, wpb=59422.8, bsz=2220.6, num_updates=129000, lr=0.000278423, gnorm=0.304, loss_scale=2, train_wall=79, gb_free=39.5, wall=107758
2023-06-12 21:43:42 | INFO | train_inner | epoch 012:   5095 / 11284 loss=3.555, nll_loss=1.852, ppl=3.61, wps=70963.1, ups=1.19, wpb=59538.6, bsz=2291.2, num_updates=129100, lr=0.000278315, gnorm=0.311, loss_scale=2, train_wall=80, gb_free=39.6, wall=107842
2023-06-12 21:45:04 | INFO | train_inner | epoch 012:   5195 / 11284 loss=3.561, nll_loss=1.858, ppl=3.62, wps=72349.1, ups=1.22, wpb=59499.9, bsz=2226.6, num_updates=129200, lr=0.000278207, gnorm=0.311, loss_scale=2, train_wall=78, gb_free=39.4, wall=107925
2023-06-12 21:46:26 | INFO | train_inner | epoch 012:   5295 / 11284 loss=3.551, nll_loss=1.847, ppl=3.6, wps=73113.1, ups=1.23, wpb=59679.8, bsz=2168.7, num_updates=129300, lr=0.0002781, gnorm=0.303, loss_scale=4, train_wall=78, gb_free=39.6, wall=108006
2023-06-12 21:47:49 | INFO | train_inner | epoch 012:   5395 / 11284 loss=3.552, nll_loss=1.848, ppl=3.6, wps=71822.9, ups=1.2, wpb=59653.9, bsz=2161.2, num_updates=129400, lr=0.000277992, gnorm=0.305, loss_scale=4, train_wall=79, gb_free=39.6, wall=108089
2023-06-12 21:48:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 21:49:13 | INFO | train_inner | epoch 012:   5496 / 11284 loss=3.551, nll_loss=1.847, ppl=3.6, wps=70846.7, ups=1.19, wpb=59609.9, bsz=2219.3, num_updates=129500, lr=0.000277885, gnorm=0.322, loss_scale=2, train_wall=80, gb_free=39.6, wall=108173
2023-06-12 21:50:36 | INFO | train_inner | epoch 012:   5596 / 11284 loss=3.549, nll_loss=1.844, ppl=3.59, wps=71870.4, ups=1.21, wpb=59578.1, bsz=2182.9, num_updates=129600, lr=0.000277778, gnorm=0.31, loss_scale=2, train_wall=79, gb_free=39.6, wall=108256
2023-06-12 21:51:59 | INFO | train_inner | epoch 012:   5696 / 11284 loss=3.554, nll_loss=1.85, ppl=3.6, wps=71429.1, ups=1.2, wpb=59471.3, bsz=2151.8, num_updates=129700, lr=0.000277671, gnorm=0.308, loss_scale=2, train_wall=79, gb_free=39.6, wall=108340
2023-06-12 21:53:22 | INFO | train_inner | epoch 012:   5796 / 11284 loss=3.562, nll_loss=1.859, ppl=3.63, wps=71638.2, ups=1.2, wpb=59637.4, bsz=2238.9, num_updates=129800, lr=0.000277564, gnorm=0.325, loss_scale=2, train_wall=79, gb_free=39, wall=108423
2023-06-12 21:54:45 | INFO | train_inner | epoch 012:   5896 / 11284 loss=3.553, nll_loss=1.849, ppl=3.6, wps=71389.6, ups=1.2, wpb=59438, bsz=2169.5, num_updates=129900, lr=0.000277457, gnorm=0.32, loss_scale=2, train_wall=79, gb_free=39.6, wall=108506
2023-06-12 21:56:08 | INFO | train_inner | epoch 012:   5996 / 11284 loss=3.551, nll_loss=1.847, ppl=3.6, wps=71846.6, ups=1.21, wpb=59512.8, bsz=2167.2, num_updates=130000, lr=0.00027735, gnorm=0.309, loss_scale=2, train_wall=79, gb_free=39.6, wall=108589
2023-06-12 21:57:30 | INFO | train_inner | epoch 012:   6096 / 11284 loss=3.551, nll_loss=1.847, ppl=3.6, wps=72884.7, ups=1.22, wpb=59519.9, bsz=2243.3, num_updates=130100, lr=0.000277243, gnorm=0.311, loss_scale=2, train_wall=78, gb_free=39.6, wall=108671
2023-06-12 21:58:51 | INFO | train_inner | epoch 012:   6196 / 11284 loss=3.563, nll_loss=1.86, ppl=3.63, wps=72933, ups=1.23, wpb=59346.9, bsz=2183.1, num_updates=130200, lr=0.000277137, gnorm=0.309, loss_scale=2, train_wall=77, gb_free=39.6, wall=108752
2023-06-12 22:00:13 | INFO | train_inner | epoch 012:   6296 / 11284 loss=3.554, nll_loss=1.85, ppl=3.61, wps=72672.9, ups=1.22, wpb=59435.9, bsz=2197.7, num_updates=130300, lr=0.000277031, gnorm=0.311, loss_scale=2, train_wall=78, gb_free=39.6, wall=108834
2023-06-12 22:01:36 | INFO | train_inner | epoch 012:   6396 / 11284 loss=3.556, nll_loss=1.853, ppl=3.61, wps=71775.8, ups=1.21, wpb=59549.2, bsz=2215, num_updates=130400, lr=0.000276924, gnorm=0.298, loss_scale=2, train_wall=79, gb_free=39.6, wall=108917
2023-06-12 22:03:00 | INFO | train_inner | epoch 012:   6496 / 11284 loss=3.548, nll_loss=1.844, ppl=3.59, wps=71373.6, ups=1.2, wpb=59669.5, bsz=2285.1, num_updates=130500, lr=0.000276818, gnorm=0.297, loss_scale=4, train_wall=80, gb_free=39.6, wall=109000
2023-06-12 22:03:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 22:04:23 | INFO | train_inner | epoch 012:   6597 / 11284 loss=3.544, nll_loss=1.839, ppl=3.58, wps=71134.4, ups=1.2, wpb=59475.2, bsz=2301.3, num_updates=130600, lr=0.000276712, gnorm=0.308, loss_scale=2, train_wall=80, gb_free=39.6, wall=109084
2023-06-12 22:05:47 | INFO | train_inner | epoch 012:   6697 / 11284 loss=3.564, nll_loss=1.862, ppl=3.63, wps=71445.7, ups=1.2, wpb=59584.1, bsz=2246.3, num_updates=130700, lr=0.000276606, gnorm=0.31, loss_scale=2, train_wall=80, gb_free=39.6, wall=109167
2023-06-12 22:07:10 | INFO | train_inner | epoch 012:   6797 / 11284 loss=3.573, nll_loss=1.872, ppl=3.66, wps=71809.7, ups=1.21, wpb=59586.4, bsz=2174.3, num_updates=130800, lr=0.000276501, gnorm=0.301, loss_scale=2, train_wall=79, gb_free=39.6, wall=109250
2023-06-12 22:08:33 | INFO | train_inner | epoch 012:   6897 / 11284 loss=3.55, nll_loss=1.846, ppl=3.59, wps=71745.8, ups=1.2, wpb=59564.9, bsz=2268.9, num_updates=130900, lr=0.000276395, gnorm=0.305, loss_scale=2, train_wall=79, gb_free=39.5, wall=109333
2023-06-12 22:09:56 | INFO | train_inner | epoch 012:   6997 / 11284 loss=3.547, nll_loss=1.843, ppl=3.59, wps=71714.7, ups=1.2, wpb=59746.7, bsz=2258.6, num_updates=131000, lr=0.000276289, gnorm=0.302, loss_scale=2, train_wall=80, gb_free=39.6, wall=109417
2023-06-12 22:11:19 | INFO | train_inner | epoch 012:   7097 / 11284 loss=3.543, nll_loss=1.838, ppl=3.57, wps=71640.8, ups=1.2, wpb=59515.9, bsz=2214.3, num_updates=131100, lr=0.000276184, gnorm=0.306, loss_scale=2, train_wall=79, gb_free=39.5, wall=109500
2023-06-12 22:12:42 | INFO | train_inner | epoch 012:   7197 / 11284 loss=3.538, nll_loss=1.832, ppl=3.56, wps=72036.1, ups=1.21, wpb=59678.9, bsz=2172.8, num_updates=131200, lr=0.000276079, gnorm=0.306, loss_scale=2, train_wall=79, gb_free=39.6, wall=109583
2023-06-12 22:14:05 | INFO | train_inner | epoch 012:   7297 / 11284 loss=3.558, nll_loss=1.855, ppl=3.62, wps=71779.8, ups=1.21, wpb=59567, bsz=2172.1, num_updates=131300, lr=0.000275974, gnorm=0.303, loss_scale=2, train_wall=79, gb_free=39.4, wall=109666
2023-06-12 22:15:28 | INFO | train_inner | epoch 012:   7397 / 11284 loss=3.557, nll_loss=1.853, ppl=3.61, wps=71842.6, ups=1.21, wpb=59597.5, bsz=2225.6, num_updates=131400, lr=0.000275869, gnorm=0.323, loss_scale=2, train_wall=79, gb_free=39.6, wall=109748
2023-06-12 22:16:50 | INFO | train_inner | epoch 012:   7497 / 11284 loss=3.545, nll_loss=1.84, ppl=3.58, wps=72103.8, ups=1.21, wpb=59400.3, bsz=2213.8, num_updates=131500, lr=0.000275764, gnorm=0.317, loss_scale=2, train_wall=78, gb_free=39.6, wall=109831
2023-06-12 22:18:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 22:18:14 | INFO | train_inner | epoch 012:   7598 / 11284 loss=3.554, nll_loss=1.85, ppl=3.61, wps=71459.7, ups=1.2, wpb=59690, bsz=2295.4, num_updates=131600, lr=0.000275659, gnorm=0.301, loss_scale=2, train_wall=79, gb_free=39.5, wall=109914
2023-06-12 22:19:36 | INFO | train_inner | epoch 012:   7698 / 11284 loss=3.548, nll_loss=1.844, ppl=3.59, wps=71919.6, ups=1.21, wpb=59364.6, bsz=2215.2, num_updates=131700, lr=0.000275554, gnorm=0.316, loss_scale=2, train_wall=78, gb_free=39.6, wall=109997
2023-06-12 22:20:59 | INFO | train_inner | epoch 012:   7798 / 11284 loss=3.559, nll_loss=1.856, ppl=3.62, wps=71679.6, ups=1.21, wpb=59435.7, bsz=2270.9, num_updates=131800, lr=0.00027545, gnorm=0.302, loss_scale=2, train_wall=79, gb_free=39.6, wall=110080
2023-06-12 22:22:23 | INFO | train_inner | epoch 012:   7898 / 11284 loss=3.55, nll_loss=1.846, ppl=3.6, wps=71538.9, ups=1.2, wpb=59552.2, bsz=2275.3, num_updates=131900, lr=0.000275345, gnorm=0.309, loss_scale=2, train_wall=79, gb_free=39.6, wall=110163
2023-06-12 22:23:45 | INFO | train_inner | epoch 012:   7998 / 11284 loss=3.552, nll_loss=1.848, ppl=3.6, wps=71988, ups=1.21, wpb=59345.2, bsz=2152, num_updates=132000, lr=0.000275241, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.5, wall=110246
2023-06-12 22:25:07 | INFO | train_inner | epoch 012:   8098 / 11284 loss=3.57, nll_loss=1.868, ppl=3.65, wps=72288.2, ups=1.22, wpb=59217.6, bsz=2214.4, num_updates=132100, lr=0.000275137, gnorm=0.313, loss_scale=2, train_wall=77, gb_free=39.6, wall=110327
2023-06-12 22:26:29 | INFO | train_inner | epoch 012:   8198 / 11284 loss=3.56, nll_loss=1.857, ppl=3.62, wps=72728, ups=1.22, wpb=59453.8, bsz=2259.1, num_updates=132200, lr=0.000275033, gnorm=0.314, loss_scale=2, train_wall=78, gb_free=39.6, wall=110409
2023-06-12 22:27:51 | INFO | train_inner | epoch 012:   8298 / 11284 loss=3.549, nll_loss=1.845, ppl=3.59, wps=72573, ups=1.22, wpb=59581.2, bsz=2221.2, num_updates=132300, lr=0.000274929, gnorm=0.315, loss_scale=2, train_wall=78, gb_free=39.6, wall=110491
2023-06-12 22:29:13 | INFO | train_inner | epoch 012:   8398 / 11284 loss=3.56, nll_loss=1.857, ppl=3.62, wps=72538.4, ups=1.22, wpb=59426.2, bsz=2273.8, num_updates=132400, lr=0.000274825, gnorm=0.301, loss_scale=2, train_wall=77, gb_free=39.6, wall=110573
2023-06-12 22:30:35 | INFO | train_inner | epoch 012:   8498 / 11284 loss=3.573, nll_loss=1.871, ppl=3.66, wps=72499.4, ups=1.22, wpb=59435.9, bsz=2244.8, num_updates=132500, lr=0.000274721, gnorm=0.318, loss_scale=2, train_wall=78, gb_free=39.6, wall=110655
2023-06-12 22:31:58 | INFO | train_inner | epoch 012:   8598 / 11284 loss=3.562, nll_loss=1.859, ppl=3.63, wps=71919.5, ups=1.21, wpb=59639, bsz=2156.4, num_updates=132600, lr=0.000274618, gnorm=0.301, loss_scale=2, train_wall=79, gb_free=39.6, wall=110738
2023-06-12 22:32:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 22:33:21 | INFO | train_inner | epoch 012:   8699 / 11284 loss=3.555, nll_loss=1.851, ppl=3.61, wps=71227.3, ups=1.2, wpb=59561.4, bsz=2215.5, num_updates=132700, lr=0.000274514, gnorm=0.312, loss_scale=2, train_wall=80, gb_free=39.6, wall=110822
2023-06-12 22:34:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-06-12 22:34:45 | INFO | train_inner | epoch 012:   8800 / 11284 loss=3.558, nll_loss=1.855, ppl=3.62, wps=71441.8, ups=1.2, wpb=59568.3, bsz=2214, num_updates=132800, lr=0.000274411, gnorm=0.327, loss_scale=1, train_wall=80, gb_free=39.5, wall=110905
2023-06-12 22:36:06 | INFO | train_inner | epoch 012:   8900 / 11284 loss=3.558, nll_loss=1.855, ppl=3.62, wps=72706, ups=1.23, wpb=59317.9, bsz=2169.1, num_updates=132900, lr=0.000274307, gnorm=0.308, loss_scale=1, train_wall=78, gb_free=39.6, wall=110987
2023-06-12 22:37:28 | INFO | train_inner | epoch 012:   9000 / 11284 loss=3.558, nll_loss=1.855, ppl=3.62, wps=72701.4, ups=1.22, wpb=59462.2, bsz=2301.1, num_updates=133000, lr=0.000274204, gnorm=0.307, loss_scale=1, train_wall=78, gb_free=39.6, wall=111069
2023-06-12 22:38:50 | INFO | train_inner | epoch 012:   9100 / 11284 loss=3.541, nll_loss=1.835, ppl=3.57, wps=72572.1, ups=1.21, wpb=59766.1, bsz=2211.8, num_updates=133100, lr=0.000274101, gnorm=0.308, loss_scale=1, train_wall=78, gb_free=39.5, wall=111151
2023-06-12 22:40:14 | INFO | train_inner | epoch 012:   9200 / 11284 loss=3.578, nll_loss=1.877, ppl=3.67, wps=71656.1, ups=1.2, wpb=59671.4, bsz=2284.2, num_updates=133200, lr=0.000273998, gnorm=0.313, loss_scale=1, train_wall=79, gb_free=39.6, wall=111234
2023-06-12 22:41:37 | INFO | train_inner | epoch 012:   9300 / 11284 loss=3.552, nll_loss=1.848, ppl=3.6, wps=71208.3, ups=1.2, wpb=59430.7, bsz=2254.9, num_updates=133300, lr=0.000273896, gnorm=0.321, loss_scale=1, train_wall=80, gb_free=39.6, wall=111318
2023-06-12 22:43:01 | INFO | train_inner | epoch 012:   9400 / 11284 loss=3.56, nll_loss=1.857, ppl=3.62, wps=71360.8, ups=1.2, wpb=59666.4, bsz=2367.8, num_updates=133400, lr=0.000273793, gnorm=0.303, loss_scale=1, train_wall=80, gb_free=39.6, wall=111401
2023-06-12 22:44:24 | INFO | train_inner | epoch 012:   9500 / 11284 loss=3.564, nll_loss=1.861, ppl=3.63, wps=71292.8, ups=1.2, wpb=59281.4, bsz=2241.2, num_updates=133500, lr=0.00027369, gnorm=0.329, loss_scale=1, train_wall=79, gb_free=39.6, wall=111484
2023-06-12 22:45:47 | INFO | train_inner | epoch 012:   9600 / 11284 loss=3.542, nll_loss=1.837, ppl=3.57, wps=71962.6, ups=1.21, wpb=59507.7, bsz=2134.5, num_updates=133600, lr=0.000273588, gnorm=0.306, loss_scale=1, train_wall=79, gb_free=39.6, wall=111567
2023-06-12 22:47:09 | INFO | train_inner | epoch 012:   9700 / 11284 loss=3.537, nll_loss=1.831, ppl=3.56, wps=72374.3, ups=1.22, wpb=59523.1, bsz=2268.7, num_updates=133700, lr=0.000273485, gnorm=0.304, loss_scale=1, train_wall=78, gb_free=39.6, wall=111649
2023-06-12 22:48:30 | INFO | train_inner | epoch 012:   9800 / 11284 loss=3.548, nll_loss=1.844, ppl=3.59, wps=72978.8, ups=1.23, wpb=59556.1, bsz=2320.1, num_updates=133800, lr=0.000273383, gnorm=0.311, loss_scale=2, train_wall=78, gb_free=39.5, wall=111731
2023-06-12 22:49:52 | INFO | train_inner | epoch 012:   9900 / 11284 loss=3.559, nll_loss=1.856, ppl=3.62, wps=72678.1, ups=1.22, wpb=59412.3, bsz=2183.5, num_updates=133900, lr=0.000273281, gnorm=0.304, loss_scale=2, train_wall=78, gb_free=39.6, wall=111813
2023-06-12 22:51:15 | INFO | train_inner | epoch 012:  10000 / 11284 loss=3.555, nll_loss=1.852, ppl=3.61, wps=71381, ups=1.2, wpb=59468.9, bsz=2191.5, num_updates=134000, lr=0.000273179, gnorm=0.312, loss_scale=2, train_wall=79, gb_free=39.5, wall=111896
2023-06-12 22:52:39 | INFO | train_inner | epoch 012:  10100 / 11284 loss=3.537, nll_loss=1.831, ppl=3.56, wps=71396.1, ups=1.2, wpb=59444.4, bsz=2150.6, num_updates=134100, lr=0.000273077, gnorm=0.317, loss_scale=2, train_wall=79, gb_free=39.5, wall=111979
2023-06-12 22:54:01 | INFO | train_inner | epoch 012:  10200 / 11284 loss=3.56, nll_loss=1.858, ppl=3.62, wps=72235.6, ups=1.21, wpb=59478.4, bsz=2184.9, num_updates=134200, lr=0.000272976, gnorm=0.306, loss_scale=2, train_wall=78, gb_free=39.5, wall=112062
2023-06-12 22:55:24 | INFO | train_inner | epoch 012:  10300 / 11284 loss=3.571, nll_loss=1.87, ppl=3.66, wps=71806.1, ups=1.21, wpb=59413, bsz=2128.4, num_updates=134300, lr=0.000272874, gnorm=0.312, loss_scale=2, train_wall=79, gb_free=39.6, wall=112144
2023-06-12 22:56:47 | INFO | train_inner | epoch 012:  10400 / 11284 loss=3.564, nll_loss=1.862, ppl=3.64, wps=71585.9, ups=1.2, wpb=59456.9, bsz=2249, num_updates=134400, lr=0.000272772, gnorm=0.304, loss_scale=2, train_wall=79, gb_free=39.6, wall=112227
2023-06-12 22:58:10 | INFO | train_inner | epoch 012:  10500 / 11284 loss=3.55, nll_loss=1.846, ppl=3.6, wps=71732.3, ups=1.2, wpb=59740.3, bsz=2240.5, num_updates=134500, lr=0.000272671, gnorm=0.321, loss_scale=2, train_wall=79, gb_free=39.4, wall=112311
2023-06-12 22:59:32 | INFO | train_inner | epoch 012:  10600 / 11284 loss=3.556, nll_loss=1.853, ppl=3.61, wps=73284.5, ups=1.23, wpb=59744.1, bsz=2301.3, num_updates=134600, lr=0.00027257, gnorm=0.319, loss_scale=2, train_wall=77, gb_free=39.1, wall=112392
2023-06-12 23:00:55 | INFO | train_inner | epoch 012:  10700 / 11284 loss=3.556, nll_loss=1.853, ppl=3.61, wps=71776.2, ups=1.21, wpb=59558.5, bsz=2231.1, num_updates=134700, lr=0.000272468, gnorm=0.309, loss_scale=2, train_wall=79, gb_free=39.6, wall=112475
2023-06-12 23:02:18 | INFO | train_inner | epoch 012:  10800 / 11284 loss=3.563, nll_loss=1.86, ppl=3.63, wps=71222.1, ups=1.2, wpb=59450.3, bsz=2246.5, num_updates=134800, lr=0.000272367, gnorm=0.303, loss_scale=2, train_wall=79, gb_free=39.6, wall=112559
2023-06-12 23:03:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 23:03:42 | INFO | train_inner | epoch 012:  10901 / 11284 loss=3.546, nll_loss=1.842, ppl=3.58, wps=70938, ups=1.19, wpb=59584.7, bsz=2260, num_updates=134900, lr=0.000272266, gnorm=0.31, loss_scale=2, train_wall=80, gb_free=39.5, wall=112643
2023-06-12 23:05:05 | INFO | train_inner | epoch 012:  11001 / 11284 loss=3.563, nll_loss=1.861, ppl=3.63, wps=71445.3, ups=1.2, wpb=59414.9, bsz=2215.2, num_updates=135000, lr=0.000272166, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.5, wall=112726
2023-06-12 23:06:28 | INFO | train_inner | epoch 012:  11101 / 11284 loss=3.553, nll_loss=1.85, ppl=3.6, wps=72231.3, ups=1.21, wpb=59552.1, bsz=2187.7, num_updates=135100, lr=0.000272065, gnorm=0.311, loss_scale=2, train_wall=78, gb_free=39.6, wall=112808
2023-06-12 23:07:50 | INFO | train_inner | epoch 012:  11201 / 11284 loss=3.549, nll_loss=1.845, ppl=3.59, wps=71804.8, ups=1.21, wpb=59437.3, bsz=2273.8, num_updates=135200, lr=0.000271964, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.6, wall=112891
2023-06-12 23:08:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-12 23:09:17 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.347 | nll_loss 2.67 | ppl 6.36 | bleu 20.63 | wps 3767.6 | wpb 2397.5 | bsz 71.5 | num_updates 135283 | best_loss 4.334
2023-06-12 23:09:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 135283 updates
2023-06-12 23:09:17 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint12.pt
2023-06-12 23:09:18 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint12.pt
2023-06-12 23:09:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint12.pt (epoch 12 @ 135283 updates, score 4.347) (writing took 3.4854509169235826 seconds)
2023-06-12 23:09:20 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-06-12 23:09:20 | INFO | train | epoch 012 | loss 3.555 | nll_loss 1.851 | ppl 3.61 | wps 71589 | ups 1.2 | wpb 59500.9 | bsz 2227.3 | num_updates 135283 | lr 0.000271881 | gnorm 0.31 | loss_scale 2 | train_wall 8899 | gb_free 39.6 | wall 112981
2023-06-12 23:09:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-12 23:09:21 | INFO | fairseq.trainer | begin training epoch 13
2023-06-12 23:09:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-12 23:09:35 | INFO | train_inner | epoch 013:     17 / 11284 loss=3.557, nll_loss=1.854, ppl=3.61, wps=56453.7, ups=0.95, wpb=59264.6, bsz=2245.6, num_updates=135300, lr=0.000271864, gnorm=0.306, loss_scale=2, train_wall=79, gb_free=39.6, wall=112996
2023-06-12 23:11:01 | INFO | train_inner | epoch 013:    117 / 11284 loss=3.529, nll_loss=1.822, ppl=3.54, wps=69640.2, ups=1.17, wpb=59607.9, bsz=2256.5, num_updates=135400, lr=0.000271763, gnorm=0.31, loss_scale=2, train_wall=81, gb_free=39.4, wall=113082
2023-06-12 23:12:27 | INFO | train_inner | epoch 013:    217 / 11284 loss=3.535, nll_loss=1.828, ppl=3.55, wps=69142.9, ups=1.16, wpb=59650.2, bsz=2293, num_updates=135500, lr=0.000271663, gnorm=0.318, loss_scale=2, train_wall=82, gb_free=39.6, wall=113168
2023-06-12 23:13:53 | INFO | train_inner | epoch 013:    317 / 11284 loss=3.532, nll_loss=1.825, ppl=3.54, wps=69755.8, ups=1.17, wpb=59601.3, bsz=2220.2, num_updates=135600, lr=0.000271563, gnorm=0.314, loss_scale=2, train_wall=81, gb_free=39.6, wall=113253
2023-06-12 23:15:18 | INFO | train_inner | epoch 013:    417 / 11284 loss=3.539, nll_loss=1.833, ppl=3.56, wps=69212.8, ups=1.17, wpb=59305.2, bsz=2239.9, num_updates=135700, lr=0.000271463, gnorm=0.306, loss_scale=2, train_wall=82, gb_free=39.6, wall=113339
2023-06-12 23:16:44 | INFO | train_inner | epoch 013:    517 / 11284 loss=3.552, nll_loss=1.848, ppl=3.6, wps=69903.1, ups=1.18, wpb=59453.2, bsz=2332.5, num_updates=135800, lr=0.000271363, gnorm=0.306, loss_scale=2, train_wall=81, gb_free=39.5, wall=113424
2023-06-12 23:18:07 | INFO | train_inner | epoch 013:    617 / 11284 loss=3.549, nll_loss=1.844, ppl=3.59, wps=71243.6, ups=1.2, wpb=59132.4, bsz=2174.9, num_updates=135900, lr=0.000271263, gnorm=0.319, loss_scale=2, train_wall=79, gb_free=39.6, wall=113507
2023-06-12 23:18:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 23:19:30 | INFO | train_inner | epoch 013:    718 / 11284 loss=3.554, nll_loss=1.849, ppl=3.6, wps=70969.6, ups=1.19, wpb=59508.8, bsz=2312.2, num_updates=136000, lr=0.000271163, gnorm=0.319, loss_scale=2, train_wall=80, gb_free=39.6, wall=113591
2023-06-12 23:20:53 | INFO | train_inner | epoch 013:    818 / 11284 loss=3.558, nll_loss=1.855, ppl=3.62, wps=71684.5, ups=1.21, wpb=59449.6, bsz=2239.5, num_updates=136100, lr=0.000271063, gnorm=0.316, loss_scale=2, train_wall=79, gb_free=39.6, wall=113674
2023-06-12 23:22:15 | INFO | train_inner | epoch 013:    918 / 11284 loss=3.551, nll_loss=1.847, ppl=3.6, wps=72819.2, ups=1.22, wpb=59491, bsz=2135.7, num_updates=136200, lr=0.000270964, gnorm=0.306, loss_scale=2, train_wall=78, gb_free=39.6, wall=113756
2023-06-12 23:23:37 | INFO | train_inner | epoch 013:   1018 / 11284 loss=3.532, nll_loss=1.826, ppl=3.54, wps=72755.2, ups=1.22, wpb=59601.2, bsz=2221.4, num_updates=136300, lr=0.000270864, gnorm=0.312, loss_scale=2, train_wall=78, gb_free=39.6, wall=113837
2023-06-12 23:24:59 | INFO | train_inner | epoch 013:   1118 / 11284 loss=3.536, nll_loss=1.83, ppl=3.55, wps=72489.4, ups=1.22, wpb=59581.8, bsz=2197.9, num_updates=136400, lr=0.000270765, gnorm=0.297, loss_scale=2, train_wall=78, gb_free=39.6, wall=113920
2023-06-12 23:26:21 | INFO | train_inner | epoch 013:   1218 / 11284 loss=3.541, nll_loss=1.836, ppl=3.57, wps=72788.5, ups=1.22, wpb=59717.8, bsz=2255.9, num_updates=136500, lr=0.000270666, gnorm=0.319, loss_scale=2, train_wall=78, gb_free=39.5, wall=114002
2023-06-12 23:27:43 | INFO | train_inner | epoch 013:   1318 / 11284 loss=3.552, nll_loss=1.848, ppl=3.6, wps=72657.5, ups=1.22, wpb=59474.8, bsz=2144.2, num_updates=136600, lr=0.000270567, gnorm=0.313, loss_scale=2, train_wall=78, gb_free=39.6, wall=114084
2023-06-12 23:29:05 | INFO | train_inner | epoch 013:   1418 / 11284 loss=3.536, nll_loss=1.83, ppl=3.55, wps=72875.3, ups=1.22, wpb=59563.5, bsz=2188.6, num_updates=136700, lr=0.000270468, gnorm=0.325, loss_scale=2, train_wall=78, gb_free=39.6, wall=114165
2023-06-12 23:30:28 | INFO | train_inner | epoch 013:   1518 / 11284 loss=3.547, nll_loss=1.843, ppl=3.59, wps=71578.7, ups=1.2, wpb=59574, bsz=2229.8, num_updates=136800, lr=0.000270369, gnorm=0.304, loss_scale=2, train_wall=79, gb_free=39.6, wall=114249
2023-06-12 23:31:51 | INFO | train_inner | epoch 013:   1618 / 11284 loss=3.534, nll_loss=1.828, ppl=3.55, wps=71092.8, ups=1.2, wpb=59249.1, bsz=2281.5, num_updates=136900, lr=0.00027027, gnorm=0.318, loss_scale=2, train_wall=79, gb_free=39.6, wall=114332
2023-06-12 23:32:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 23:33:15 | INFO | train_inner | epoch 013:   1719 / 11284 loss=3.564, nll_loss=1.861, ppl=3.63, wps=71110.5, ups=1.19, wpb=59710.1, bsz=2249.7, num_updates=137000, lr=0.000270172, gnorm=0.304, loss_scale=2, train_wall=80, gb_free=39.6, wall=114416
2023-06-12 23:34:38 | INFO | train_inner | epoch 013:   1819 / 11284 loss=3.542, nll_loss=1.837, ppl=3.57, wps=71628.1, ups=1.2, wpb=59460.1, bsz=2236.7, num_updates=137100, lr=0.000270073, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.6, wall=114499
2023-06-12 23:36:02 | INFO | train_inner | epoch 013:   1919 / 11284 loss=3.56, nll_loss=1.857, ppl=3.62, wps=71316.6, ups=1.2, wpb=59534.5, bsz=2277.5, num_updates=137200, lr=0.000269975, gnorm=0.302, loss_scale=2, train_wall=79, gb_free=39.6, wall=114582
2023-06-12 23:37:25 | INFO | train_inner | epoch 013:   2019 / 11284 loss=3.567, nll_loss=1.865, ppl=3.64, wps=70985.7, ups=1.2, wpb=59379.5, bsz=2290.4, num_updates=137300, lr=0.000269876, gnorm=0.319, loss_scale=2, train_wall=80, gb_free=39.4, wall=114666
2023-06-12 23:38:48 | INFO | train_inner | epoch 013:   2119 / 11284 loss=3.557, nll_loss=1.853, ppl=3.61, wps=71818.4, ups=1.21, wpb=59358, bsz=2192, num_updates=137400, lr=0.000269778, gnorm=0.322, loss_scale=2, train_wall=79, gb_free=39.6, wall=114749
2023-06-12 23:40:11 | INFO | train_inner | epoch 013:   2219 / 11284 loss=3.555, nll_loss=1.851, ppl=3.61, wps=71947.8, ups=1.21, wpb=59628.7, bsz=2276.9, num_updates=137500, lr=0.00026968, gnorm=0.3, loss_scale=2, train_wall=79, gb_free=39.6, wall=114832
2023-06-12 23:41:34 | INFO | train_inner | epoch 013:   2319 / 11284 loss=3.544, nll_loss=1.839, ppl=3.58, wps=71909.1, ups=1.21, wpb=59465.3, bsz=2316.8, num_updates=137600, lr=0.000269582, gnorm=0.307, loss_scale=2, train_wall=79, gb_free=39.6, wall=114914
2023-06-12 23:42:56 | INFO | train_inner | epoch 013:   2419 / 11284 loss=3.537, nll_loss=1.831, ppl=3.56, wps=72063.1, ups=1.21, wpb=59649.5, bsz=2208.2, num_updates=137700, lr=0.000269484, gnorm=0.32, loss_scale=2, train_wall=79, gb_free=39.6, wall=114997
2023-06-12 23:44:20 | INFO | train_inner | epoch 013:   2519 / 11284 loss=3.537, nll_loss=1.831, ppl=3.56, wps=71676.3, ups=1.2, wpb=59653.5, bsz=2202, num_updates=137800, lr=0.000269386, gnorm=0.31, loss_scale=2, train_wall=79, gb_free=39.6, wall=115080
2023-06-12 23:45:43 | INFO | train_inner | epoch 013:   2619 / 11284 loss=3.536, nll_loss=1.83, ppl=3.56, wps=71338.5, ups=1.2, wpb=59253.6, bsz=2159.2, num_updates=137900, lr=0.000269289, gnorm=0.313, loss_scale=2, train_wall=79, gb_free=39.6, wall=115163
2023-06-12 23:47:06 | INFO | train_inner | epoch 013:   2719 / 11284 loss=3.532, nll_loss=1.826, ppl=3.54, wps=71678.1, ups=1.21, wpb=59402.5, bsz=2242.9, num_updates=138000, lr=0.000269191, gnorm=0.311, loss_scale=4, train_wall=79, gb_free=39.6, wall=115246
2023-06-12 23:47:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-12 23:48:29 | INFO | train_inner | epoch 013:   2820 / 11284 loss=3.546, nll_loss=1.841, ppl=3.58, wps=71768.2, ups=1.21, wpb=59531.2, bsz=2225.2, num_updates=138100, lr=0.000269093, gnorm=0.3, loss_scale=2, train_wall=79, gb_free=39.6, wall=115329
2023-06-12 23:49:51 | INFO | train_inner | epoch 013:   2920 / 11284 loss=3.538, nll_loss=1.832, ppl=3.56, wps=72393.8, ups=1.22, wpb=59469.2, bsz=2209.6, num_updates=138200, lr=0.000268996, gnorm=0.309, loss_scale=2, train_wall=78, gb_free=39.6, wall=115411
2023-06-12 23:51:13 | INFO | train_inner | epoch 013:   3020 / 11284 loss=3.543, nll_loss=1.838, ppl=3.58, wps=72267.2, ups=1.21, wpb=59824, bsz=2252.3, num_updates=138300, lr=0.000268899, gnorm=0.323, loss_scale=2, train_wall=79, gb_free=39.6, wall=115494
2023-06-12 23:51:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-06-12 23:52:37 | INFO | train_inner | epoch 013:   3121 / 11284 loss=3.545, nll_loss=1.841, ppl=3.58, wps=71903.3, ups=1.2, wpb=59826.7, bsz=2298.9, num_updates=138400, lr=0.000268802, gnorm=0.305, loss_scale=1, train_wall=79, gb_free=39.6, wall=115577
2023-06-12 23:53:59 | INFO | train_inner | epoch 013:   3221 / 11284 loss=3.538, nll_loss=1.832, ppl=3.56, wps=71719.9, ups=1.21, wpb=59303.5, bsz=2223.7, num_updates=138500, lr=0.000268705, gnorm=0.315, loss_scale=1, train_wall=79, gb_free=39.6, wall=115660
2023-06-12 23:55:22 | INFO | train_inner | epoch 013:   3321 / 11284 loss=3.544, nll_loss=1.839, ppl=3.58, wps=71404.4, ups=1.21, wpb=59248.2, bsz=2254.4, num_updates=138600, lr=0.000268608, gnorm=0.314, loss_scale=1, train_wall=79, gb_free=39.5, wall=115743
2023-06-12 23:56:46 | INFO | train_inner | epoch 013:   3421 / 11284 loss=3.554, nll_loss=1.85, ppl=3.6, wps=71715.8, ups=1.2, wpb=59675.7, bsz=2195.8, num_updates=138700, lr=0.000268511, gnorm=0.317, loss_scale=1, train_wall=79, gb_free=39.5, wall=115826
2023-06-12 23:58:09 | INFO | train_inner | epoch 013:   3521 / 11284 loss=3.559, nll_loss=1.856, ppl=3.62, wps=71670.2, ups=1.2, wpb=59612.4, bsz=2320, num_updates=138800, lr=0.000268414, gnorm=0.321, loss_scale=1, train_wall=79, gb_free=39.6, wall=115909
2023-06-12 23:59:32 | INFO | train_inner | epoch 013:   3621 / 11284 loss=3.546, nll_loss=1.841, ppl=3.58, wps=71762.5, ups=1.21, wpb=59438.4, bsz=2228.4, num_updates=138900, lr=0.000268317, gnorm=0.308, loss_scale=1, train_wall=79, gb_free=39.6, wall=115992
2023-06-13 00:00:55 | INFO | train_inner | epoch 013:   3721 / 11284 loss=3.538, nll_loss=1.833, ppl=3.56, wps=71778.6, ups=1.21, wpb=59534.6, bsz=2161.9, num_updates=139000, lr=0.000268221, gnorm=0.319, loss_scale=1, train_wall=79, gb_free=39.5, wall=116075
2023-06-13 00:02:17 | INFO | train_inner | epoch 013:   3821 / 11284 loss=3.549, nll_loss=1.845, ppl=3.59, wps=71864, ups=1.21, wpb=59547.1, bsz=2267.4, num_updates=139100, lr=0.000268124, gnorm=0.311, loss_scale=1, train_wall=79, gb_free=39.6, wall=116158
2023-06-13 00:03:40 | INFO | train_inner | epoch 013:   3921 / 11284 loss=3.536, nll_loss=1.83, ppl=3.56, wps=71551.1, ups=1.2, wpb=59418.9, bsz=2115.2, num_updates=139200, lr=0.000268028, gnorm=0.304, loss_scale=1, train_wall=79, gb_free=39.6, wall=116241
2023-06-13 00:05:04 | INFO | train_inner | epoch 013:   4021 / 11284 loss=3.541, nll_loss=1.835, ppl=3.57, wps=71952, ups=1.2, wpb=59810.3, bsz=2260.9, num_updates=139300, lr=0.000267932, gnorm=0.321, loss_scale=1, train_wall=79, gb_free=39.6, wall=116324
2023-06-13 00:06:27 | INFO | train_inner | epoch 013:   4121 / 11284 loss=3.552, nll_loss=1.848, ppl=3.6, wps=71983.4, ups=1.2, wpb=59782.2, bsz=2265.5, num_updates=139400, lr=0.000267836, gnorm=0.304, loss_scale=2, train_wall=79, gb_free=39.6, wall=116407
2023-06-13 00:07:49 | INFO | train_inner | epoch 013:   4221 / 11284 loss=3.557, nll_loss=1.853, ppl=3.61, wps=71802.7, ups=1.21, wpb=59477.2, bsz=2156.9, num_updates=139500, lr=0.00026774, gnorm=0.3, loss_scale=2, train_wall=79, gb_free=39.6, wall=116490
2023-06-13 00:09:13 | INFO | train_inner | epoch 013:   4321 / 11284 loss=3.544, nll_loss=1.839, ppl=3.58, wps=71925, ups=1.2, wpb=59791.4, bsz=2203.8, num_updates=139600, lr=0.000267644, gnorm=0.307, loss_scale=2, train_wall=79, gb_free=39.6, wall=116573
2023-06-13 00:10:36 | INFO | train_inner | epoch 013:   4421 / 11284 loss=3.541, nll_loss=1.836, ppl=3.57, wps=71583.6, ups=1.2, wpb=59462.3, bsz=2238.6, num_updates=139700, lr=0.000267548, gnorm=0.314, loss_scale=2, train_wall=79, gb_free=39.5, wall=116656
2023-06-13 00:11:59 | INFO | train_inner | epoch 013:   4521 / 11284 loss=3.542, nll_loss=1.836, ppl=3.57, wps=71597.6, ups=1.2, wpb=59670.6, bsz=2282.5, num_updates=139800, lr=0.000267452, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.6, wall=116740
2023-06-13 00:13:22 | INFO | train_inner | epoch 013:   4621 / 11284 loss=3.552, nll_loss=1.848, ppl=3.6, wps=72203.4, ups=1.21, wpb=59709.6, bsz=2214.5, num_updates=139900, lr=0.000267357, gnorm=0.301, loss_scale=2, train_wall=79, gb_free=39.6, wall=116822
2023-06-13 00:14:44 | INFO | train_inner | epoch 013:   4721 / 11284 loss=3.553, nll_loss=1.849, ppl=3.6, wps=72868.5, ups=1.22, wpb=59630.2, bsz=2191.5, num_updates=140000, lr=0.000267261, gnorm=0.319, loss_scale=2, train_wall=78, gb_free=39.6, wall=116904
2023-06-13 00:16:05 | INFO | train_inner | epoch 013:   4821 / 11284 loss=3.547, nll_loss=1.842, ppl=3.59, wps=72536.4, ups=1.22, wpb=59431.7, bsz=2215, num_updates=140100, lr=0.000267166, gnorm=0.317, loss_scale=2, train_wall=78, gb_free=39.6, wall=116986
2023-06-13 00:17:28 | INFO | train_inner | epoch 013:   4921 / 11284 loss=3.551, nll_loss=1.847, ppl=3.6, wps=71563.3, ups=1.21, wpb=59262.5, bsz=2178.7, num_updates=140200, lr=0.000267071, gnorm=0.307, loss_scale=2, train_wall=79, gb_free=39.4, wall=117069
2023-06-13 00:18:51 | INFO | train_inner | epoch 013:   5021 / 11284 loss=3.542, nll_loss=1.837, ppl=3.57, wps=71451.3, ups=1.21, wpb=59199.8, bsz=2231.1, num_updates=140300, lr=0.000266975, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.6, wall=117152
2023-06-13 00:20:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 00:20:15 | INFO | train_inner | epoch 013:   5122 / 11284 loss=3.552, nll_loss=1.848, ppl=3.6, wps=71043.2, ups=1.2, wpb=59418.9, bsz=2170.3, num_updates=140400, lr=0.00026688, gnorm=0.326, loss_scale=2, train_wall=80, gb_free=39.6, wall=117235
2023-06-13 00:21:38 | INFO | train_inner | epoch 013:   5222 / 11284 loss=3.543, nll_loss=1.837, ppl=3.57, wps=72109.5, ups=1.21, wpb=59799, bsz=2180.5, num_updates=140500, lr=0.000266785, gnorm=0.305, loss_scale=2, train_wall=79, gb_free=39.6, wall=117318
2023-06-13 00:23:01 | INFO | train_inner | epoch 013:   5322 / 11284 loss=3.547, nll_loss=1.843, ppl=3.59, wps=71666.2, ups=1.2, wpb=59645.2, bsz=2248.6, num_updates=140600, lr=0.00026669, gnorm=0.309, loss_scale=2, train_wall=79, gb_free=39.6, wall=117401
2023-06-13 00:24:24 | INFO | train_inner | epoch 013:   5422 / 11284 loss=3.551, nll_loss=1.847, ppl=3.6, wps=71386.9, ups=1.2, wpb=59274.9, bsz=2215.3, num_updates=140700, lr=0.000266596, gnorm=0.309, loss_scale=2, train_wall=79, gb_free=39.1, wall=117485
2023-06-13 00:25:47 | INFO | train_inner | epoch 013:   5522 / 11284 loss=3.559, nll_loss=1.856, ppl=3.62, wps=71454.9, ups=1.21, wpb=59242.1, bsz=2226.9, num_updates=140800, lr=0.000266501, gnorm=0.322, loss_scale=2, train_wall=79, gb_free=39.6, wall=117567
2023-06-13 00:27:10 | INFO | train_inner | epoch 013:   5622 / 11284 loss=3.535, nll_loss=1.829, ppl=3.55, wps=71564.4, ups=1.21, wpb=59365.2, bsz=2211.5, num_updates=140900, lr=0.000266406, gnorm=0.313, loss_scale=2, train_wall=79, gb_free=39.5, wall=117650
2023-06-13 00:28:33 | INFO | train_inner | epoch 013:   5722 / 11284 loss=3.533, nll_loss=1.827, ppl=3.55, wps=71983.8, ups=1.21, wpb=59535.2, bsz=2232.3, num_updates=141000, lr=0.000266312, gnorm=0.323, loss_scale=2, train_wall=79, gb_free=39.6, wall=117733
2023-06-13 00:29:55 | INFO | train_inner | epoch 013:   5822 / 11284 loss=3.541, nll_loss=1.836, ppl=3.57, wps=72490, ups=1.22, wpb=59570.8, bsz=2211.8, num_updates=141100, lr=0.000266217, gnorm=0.313, loss_scale=2, train_wall=78, gb_free=39.5, wall=117815
2023-06-13 00:31:16 | INFO | train_inner | epoch 013:   5922 / 11284 loss=3.55, nll_loss=1.846, ppl=3.59, wps=73063.8, ups=1.23, wpb=59597.5, bsz=2248.3, num_updates=141200, lr=0.000266123, gnorm=0.326, loss_scale=2, train_wall=78, gb_free=39.5, wall=117897
2023-06-13 00:32:38 | INFO | train_inner | epoch 013:   6022 / 11284 loss=3.547, nll_loss=1.843, ppl=3.59, wps=72267.7, ups=1.22, wpb=59247.2, bsz=2216.1, num_updates=141300, lr=0.000266029, gnorm=0.321, loss_scale=2, train_wall=78, gb_free=39.6, wall=117979
2023-06-13 00:34:01 | INFO | train_inner | epoch 013:   6122 / 11284 loss=3.539, nll_loss=1.833, ppl=3.56, wps=71675.3, ups=1.2, wpb=59561.2, bsz=2187.7, num_updates=141400, lr=0.000265935, gnorm=0.31, loss_scale=2, train_wall=79, gb_free=39.6, wall=118062
2023-06-13 00:34:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 00:35:25 | INFO | train_inner | epoch 013:   6223 / 11284 loss=3.565, nll_loss=1.863, ppl=3.64, wps=70889.9, ups=1.19, wpb=59559.6, bsz=2188.7, num_updates=141500, lr=0.000265841, gnorm=0.333, loss_scale=2, train_wall=80, gb_free=38.9, wall=118146
2023-06-13 00:36:49 | INFO | train_inner | epoch 013:   6323 / 11284 loss=3.54, nll_loss=1.835, ppl=3.57, wps=71517, ups=1.2, wpb=59525.9, bsz=2188, num_updates=141600, lr=0.000265747, gnorm=0.308, loss_scale=2, train_wall=79, gb_free=39.5, wall=118229
2023-06-13 00:38:10 | INFO | train_inner | epoch 013:   6423 / 11284 loss=3.555, nll_loss=1.851, ppl=3.61, wps=72553.7, ups=1.22, wpb=59344, bsz=2112, num_updates=141700, lr=0.000265653, gnorm=0.301, loss_scale=2, train_wall=78, gb_free=39.6, wall=118311
2023-06-13 00:39:33 | INFO | train_inner | epoch 013:   6523 / 11284 loss=3.553, nll_loss=1.849, ppl=3.6, wps=72295.8, ups=1.21, wpb=59597.1, bsz=2204.7, num_updates=141800, lr=0.00026556, gnorm=0.311, loss_scale=2, train_wall=78, gb_free=39.6, wall=118393
2023-06-13 00:40:56 | INFO | train_inner | epoch 013:   6623 / 11284 loss=3.544, nll_loss=1.839, ppl=3.58, wps=71455.8, ups=1.2, wpb=59511.1, bsz=2298.2, num_updates=141900, lr=0.000265466, gnorm=0.305, loss_scale=2, train_wall=79, gb_free=39.6, wall=118477
2023-06-13 00:41:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-06-13 00:42:20 | INFO | train_inner | epoch 013:   6724 / 11284 loss=3.566, nll_loss=1.864, ppl=3.64, wps=70888.4, ups=1.19, wpb=59378.9, bsz=2158.8, num_updates=142000, lr=0.000265372, gnorm=0.328, loss_scale=1, train_wall=80, gb_free=39.6, wall=118560
2023-06-13 00:43:43 | INFO | train_inner | epoch 013:   6824 / 11284 loss=3.551, nll_loss=1.847, ppl=3.6, wps=71337.3, ups=1.2, wpb=59303.9, bsz=2241.5, num_updates=142100, lr=0.000265279, gnorm=0.321, loss_scale=1, train_wall=79, gb_free=39.6, wall=118644
2023-06-13 00:45:06 | INFO | train_inner | epoch 013:   6924 / 11284 loss=3.532, nll_loss=1.826, ppl=3.55, wps=71804.6, ups=1.2, wpb=59648.1, bsz=2241.1, num_updates=142200, lr=0.000265186, gnorm=0.31, loss_scale=1, train_wall=79, gb_free=39.6, wall=118727
2023-06-13 00:46:29 | INFO | train_inner | epoch 013:   7024 / 11284 loss=3.544, nll_loss=1.839, ppl=3.58, wps=71495.6, ups=1.21, wpb=59323.5, bsz=2088, num_updates=142300, lr=0.000265093, gnorm=0.315, loss_scale=1, train_wall=79, gb_free=39.6, wall=118810
2023-06-13 00:47:52 | INFO | train_inner | epoch 013:   7124 / 11284 loss=3.556, nll_loss=1.852, ppl=3.61, wps=71607.3, ups=1.2, wpb=59453, bsz=2180.3, num_updates=142400, lr=0.000264999, gnorm=0.309, loss_scale=1, train_wall=79, gb_free=39.6, wall=118893
2023-06-13 00:49:15 | INFO | train_inner | epoch 013:   7224 / 11284 loss=3.552, nll_loss=1.849, ppl=3.6, wps=71539, ups=1.21, wpb=59293.3, bsz=2163.4, num_updates=142500, lr=0.000264906, gnorm=0.305, loss_scale=1, train_wall=79, gb_free=39.6, wall=118976
2023-06-13 00:50:38 | INFO | train_inner | epoch 013:   7324 / 11284 loss=3.562, nll_loss=1.859, ppl=3.63, wps=71373.8, ups=1.2, wpb=59299.6, bsz=2238.8, num_updates=142600, lr=0.000264814, gnorm=0.31, loss_scale=1, train_wall=79, gb_free=39.6, wall=119059
2023-06-13 00:52:01 | INFO | train_inner | epoch 013:   7424 / 11284 loss=3.557, nll_loss=1.854, ppl=3.62, wps=71732.6, ups=1.2, wpb=59778.3, bsz=2303.5, num_updates=142700, lr=0.000264721, gnorm=0.301, loss_scale=1, train_wall=79, gb_free=39.6, wall=119142
2023-06-13 00:53:25 | INFO | train_inner | epoch 013:   7524 / 11284 loss=3.553, nll_loss=1.849, ppl=3.6, wps=71063.9, ups=1.2, wpb=59443.8, bsz=2357.4, num_updates=142800, lr=0.000264628, gnorm=0.312, loss_scale=1, train_wall=80, gb_free=39.5, wall=119226
2023-06-13 00:54:48 | INFO | train_inner | epoch 013:   7624 / 11284 loss=3.554, nll_loss=1.85, ppl=3.61, wps=71892.6, ups=1.21, wpb=59597, bsz=2195.8, num_updates=142900, lr=0.000264535, gnorm=0.312, loss_scale=1, train_wall=79, gb_free=39.5, wall=119309
2023-06-13 00:56:11 | INFO | train_inner | epoch 013:   7724 / 11284 loss=3.551, nll_loss=1.847, ppl=3.6, wps=71898.3, ups=1.21, wpb=59522.5, bsz=2316.8, num_updates=143000, lr=0.000264443, gnorm=0.32, loss_scale=2, train_wall=79, gb_free=39.6, wall=119391
2023-06-13 00:57:34 | INFO | train_inner | epoch 013:   7824 / 11284 loss=3.553, nll_loss=1.849, ppl=3.6, wps=71385.9, ups=1.2, wpb=59544.8, bsz=2273.1, num_updates=143100, lr=0.000264351, gnorm=0.318, loss_scale=2, train_wall=79, gb_free=39.6, wall=119475
2023-06-13 00:58:57 | INFO | train_inner | epoch 013:   7924 / 11284 loss=3.548, nll_loss=1.844, ppl=3.59, wps=71903.8, ups=1.21, wpb=59326.9, bsz=2199.4, num_updates=143200, lr=0.000264258, gnorm=0.318, loss_scale=2, train_wall=78, gb_free=39.6, wall=119557
2023-06-13 01:00:18 | INFO | train_inner | epoch 013:   8024 / 11284 loss=3.546, nll_loss=1.842, ppl=3.58, wps=72788.1, ups=1.23, wpb=59288.4, bsz=2184.2, num_updates=143300, lr=0.000264166, gnorm=0.325, loss_scale=2, train_wall=77, gb_free=39.6, wall=119639
2023-06-13 01:01:40 | INFO | train_inner | epoch 013:   8124 / 11284 loss=3.524, nll_loss=1.817, ppl=3.52, wps=72683.2, ups=1.22, wpb=59661, bsz=2275.4, num_updates=143400, lr=0.000264074, gnorm=0.306, loss_scale=2, train_wall=78, gb_free=39.5, wall=119721
2023-06-13 01:03:02 | INFO | train_inner | epoch 013:   8224 / 11284 loss=3.545, nll_loss=1.84, ppl=3.58, wps=72755.1, ups=1.22, wpb=59679.9, bsz=2231.9, num_updates=143500, lr=0.000263982, gnorm=0.319, loss_scale=2, train_wall=78, gb_free=39.6, wall=119803
2023-06-13 01:04:25 | INFO | train_inner | epoch 013:   8324 / 11284 loss=3.542, nll_loss=1.837, ppl=3.57, wps=71998.5, ups=1.21, wpb=59380.3, bsz=2201, num_updates=143600, lr=0.00026389, gnorm=0.317, loss_scale=2, train_wall=79, gb_free=39.6, wall=119885
2023-06-13 01:05:48 | INFO | train_inner | epoch 013:   8424 / 11284 loss=3.545, nll_loss=1.84, ppl=3.58, wps=71924.1, ups=1.21, wpb=59567, bsz=2257.6, num_updates=143700, lr=0.000263798, gnorm=0.32, loss_scale=2, train_wall=79, gb_free=39.6, wall=119968
2023-06-13 01:07:11 | INFO | train_inner | epoch 013:   8524 / 11284 loss=3.556, nll_loss=1.853, ppl=3.61, wps=71460, ups=1.2, wpb=59400.5, bsz=2244.8, num_updates=143800, lr=0.000263706, gnorm=0.318, loss_scale=2, train_wall=79, gb_free=39.5, wall=120051
2023-06-13 01:08:33 | INFO | train_inner | epoch 013:   8624 / 11284 loss=3.549, nll_loss=1.845, ppl=3.59, wps=71908.2, ups=1.21, wpb=59545.4, bsz=2105.3, num_updates=143900, lr=0.000263615, gnorm=0.305, loss_scale=2, train_wall=79, gb_free=39.5, wall=120134
2023-06-13 01:09:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 01:09:56 | INFO | train_inner | epoch 013:   8725 / 11284 loss=3.554, nll_loss=1.85, ppl=3.61, wps=71749.8, ups=1.21, wpb=59389.9, bsz=2190.3, num_updates=144000, lr=0.000263523, gnorm=0.312, loss_scale=2, train_wall=79, gb_free=39.5, wall=120217
2023-06-13 01:11:18 | INFO | train_inner | epoch 013:   8825 / 11284 loss=3.567, nll_loss=1.865, ppl=3.64, wps=72684.5, ups=1.23, wpb=59290.8, bsz=2253.9, num_updates=144100, lr=0.000263432, gnorm=0.332, loss_scale=2, train_wall=78, gb_free=39.6, wall=120298
2023-06-13 01:12:40 | INFO | train_inner | epoch 013:   8925 / 11284 loss=3.559, nll_loss=1.856, ppl=3.62, wps=72231.8, ups=1.22, wpb=59113.2, bsz=2282.3, num_updates=144200, lr=0.00026334, gnorm=0.317, loss_scale=2, train_wall=78, gb_free=39.6, wall=120380
2023-06-13 01:14:03 | INFO | train_inner | epoch 013:   9025 / 11284 loss=3.553, nll_loss=1.849, ppl=3.6, wps=71861, ups=1.21, wpb=59618.7, bsz=2321.1, num_updates=144300, lr=0.000263249, gnorm=0.308, loss_scale=2, train_wall=79, gb_free=39.6, wall=120463
2023-06-13 01:15:26 | INFO | train_inner | epoch 013:   9125 / 11284 loss=3.542, nll_loss=1.837, ppl=3.57, wps=71543.6, ups=1.2, wpb=59593, bsz=2237.3, num_updates=144400, lr=0.000263158, gnorm=0.304, loss_scale=2, train_wall=79, gb_free=39.6, wall=120546
2023-06-13 01:16:49 | INFO | train_inner | epoch 013:   9225 / 11284 loss=3.566, nll_loss=1.864, ppl=3.64, wps=71107.3, ups=1.2, wpb=59196, bsz=2252.1, num_updates=144500, lr=0.000263067, gnorm=0.314, loss_scale=2, train_wall=79, gb_free=39.6, wall=120630
2023-06-13 01:18:12 | INFO | train_inner | epoch 013:   9325 / 11284 loss=3.547, nll_loss=1.843, ppl=3.59, wps=71530, ups=1.2, wpb=59451.4, bsz=2224.1, num_updates=144600, lr=0.000262976, gnorm=0.311, loss_scale=2, train_wall=79, gb_free=39.6, wall=120713
2023-06-13 01:19:35 | INFO | train_inner | epoch 013:   9425 / 11284 loss=3.57, nll_loss=1.869, ppl=3.65, wps=71976.1, ups=1.21, wpb=59502.7, bsz=2227.4, num_updates=144700, lr=0.000262885, gnorm=0.316, loss_scale=2, train_wall=79, gb_free=39.5, wall=120796
2023-06-13 01:20:58 | INFO | train_inner | epoch 013:   9525 / 11284 loss=3.542, nll_loss=1.837, ppl=3.57, wps=71570.5, ups=1.2, wpb=59505.7, bsz=2247.2, num_updates=144800, lr=0.000262794, gnorm=0.306, loss_scale=2, train_wall=79, gb_free=39.6, wall=120879
2023-06-13 01:22:21 | INFO | train_inner | epoch 013:   9625 / 11284 loss=3.549, nll_loss=1.845, ppl=3.59, wps=71655, ups=1.21, wpb=59434.5, bsz=2115.3, num_updates=144900, lr=0.000262703, gnorm=0.299, loss_scale=2, train_wall=79, gb_free=39.6, wall=120962
2023-06-13 01:23:44 | INFO | train_inner | epoch 013:   9725 / 11284 loss=3.536, nll_loss=1.83, ppl=3.56, wps=71440.4, ups=1.2, wpb=59510, bsz=2209, num_updates=145000, lr=0.000262613, gnorm=0.316, loss_scale=4, train_wall=79, gb_free=39.6, wall=121045
2023-06-13 01:23:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 01:25:08 | INFO | train_inner | epoch 013:   9826 / 11284 loss=3.559, nll_loss=1.857, ppl=3.62, wps=70847.2, ups=1.19, wpb=59451.1, bsz=2219.1, num_updates=145100, lr=0.000262522, gnorm=0.323, loss_scale=2, train_wall=80, gb_free=39.6, wall=121129
2023-06-13 01:26:30 | INFO | train_inner | epoch 013:   9926 / 11284 loss=3.556, nll_loss=1.853, ppl=3.61, wps=72395.3, ups=1.22, wpb=59434.1, bsz=2214.5, num_updates=145200, lr=0.000262432, gnorm=0.313, loss_scale=2, train_wall=78, gb_free=39.6, wall=121211
2023-06-13 01:27:52 | INFO | train_inner | epoch 013:  10026 / 11284 loss=3.558, nll_loss=1.854, ppl=3.62, wps=72567.6, ups=1.22, wpb=59252.9, bsz=2314.4, num_updates=145300, lr=0.000262342, gnorm=0.321, loss_scale=2, train_wall=77, gb_free=39.5, wall=121293
2023-06-13 01:29:14 | INFO | train_inner | epoch 013:  10126 / 11284 loss=3.552, nll_loss=1.849, ppl=3.6, wps=72392.7, ups=1.21, wpb=59616, bsz=2302.1, num_updates=145400, lr=0.000262251, gnorm=0.3, loss_scale=2, train_wall=78, gb_free=39.5, wall=121375
2023-06-13 01:30:38 | INFO | train_inner | epoch 013:  10226 / 11284 loss=3.548, nll_loss=1.844, ppl=3.59, wps=71544.2, ups=1.2, wpb=59503.4, bsz=2229.8, num_updates=145500, lr=0.000262161, gnorm=0.313, loss_scale=2, train_wall=79, gb_free=39.6, wall=121458
2023-06-13 01:32:00 | INFO | train_inner | epoch 013:  10326 / 11284 loss=3.554, nll_loss=1.851, ppl=3.61, wps=72697.3, ups=1.22, wpb=59732.3, bsz=2166.6, num_updates=145600, lr=0.000262071, gnorm=0.32, loss_scale=2, train_wall=78, gb_free=39.6, wall=121540
2023-06-13 01:33:22 | INFO | train_inner | epoch 013:  10426 / 11284 loss=3.552, nll_loss=1.848, ppl=3.6, wps=72183.2, ups=1.21, wpb=59489.4, bsz=2224.2, num_updates=145700, lr=0.000261981, gnorm=0.322, loss_scale=2, train_wall=78, gb_free=39.6, wall=121623
2023-06-13 01:34:45 | INFO | train_inner | epoch 013:  10526 / 11284 loss=3.546, nll_loss=1.842, ppl=3.59, wps=71710.1, ups=1.2, wpb=59625.4, bsz=2194.2, num_updates=145800, lr=0.000261891, gnorm=0.318, loss_scale=2, train_wall=79, gb_free=39.5, wall=121706
2023-06-13 01:36:08 | INFO | train_inner | epoch 013:  10626 / 11284 loss=3.561, nll_loss=1.858, ppl=3.63, wps=72257.5, ups=1.21, wpb=59645.1, bsz=2179.6, num_updates=145900, lr=0.000261802, gnorm=0.31, loss_scale=2, train_wall=79, gb_free=39.6, wall=121788
2023-06-13 01:37:31 | INFO | train_inner | epoch 013:  10726 / 11284 loss=3.541, nll_loss=1.836, ppl=3.57, wps=71932, ups=1.21, wpb=59625.8, bsz=2210.2, num_updates=146000, lr=0.000261712, gnorm=0.329, loss_scale=2, train_wall=79, gb_free=39.7, wall=121871
2023-06-13 01:38:54 | INFO | train_inner | epoch 013:  10826 / 11284 loss=3.558, nll_loss=1.855, ppl=3.62, wps=71304.7, ups=1.2, wpb=59413.9, bsz=2327.6, num_updates=146100, lr=0.000261622, gnorm=0.311, loss_scale=4, train_wall=79, gb_free=39.5, wall=121955
2023-06-13 01:38:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 01:40:18 | INFO | train_inner | epoch 013:  10927 / 11284 loss=3.546, nll_loss=1.842, ppl=3.58, wps=70706.5, ups=1.19, wpb=59463.7, bsz=2318.6, num_updates=146200, lr=0.000261533, gnorm=0.3, loss_scale=2, train_wall=80, gb_free=39.6, wall=122039
2023-06-13 01:41:41 | INFO | train_inner | epoch 013:  11027 / 11284 loss=3.544, nll_loss=1.839, ppl=3.58, wps=71561.3, ups=1.2, wpb=59615.3, bsz=2249.1, num_updates=146300, lr=0.000261443, gnorm=0.31, loss_scale=2, train_wall=80, gb_free=39.6, wall=122122
2023-06-13 01:43:04 | INFO | train_inner | epoch 013:  11127 / 11284 loss=3.551, nll_loss=1.847, ppl=3.6, wps=71964.8, ups=1.21, wpb=59600.5, bsz=2168.2, num_updates=146400, lr=0.000261354, gnorm=0.314, loss_scale=2, train_wall=79, gb_free=39.6, wall=122205
2023-06-13 01:44:27 | INFO | train_inner | epoch 013:  11227 / 11284 loss=3.545, nll_loss=1.841, ppl=3.58, wps=71812.3, ups=1.2, wpb=59653.9, bsz=2200.5, num_updates=146500, lr=0.000261265, gnorm=0.323, loss_scale=2, train_wall=79, gb_free=39.5, wall=122288
2023-06-13 01:45:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-13 01:45:32 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.319 | nll_loss 2.639 | ppl 6.23 | bleu 20.98 | wps 3764 | wpb 2397.5 | bsz 71.5 | num_updates 146557 | best_loss 4.319
2023-06-13 01:45:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 146557 updates
2023-06-13 01:45:32 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint13.pt
2023-06-13 01:45:33 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint13.pt
2023-06-13 01:45:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint13.pt (epoch 13 @ 146557 updates, score 4.319) (writing took 6.217152213677764 seconds)
2023-06-13 01:45:38 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-06-13 01:45:38 | INFO | train | epoch 013 | loss 3.548 | nll_loss 1.843 | ppl 3.59 | wps 71530 | ups 1.2 | wpb 59500.2 | bsz 2227.4 | num_updates 146557 | lr 0.000261214 | gnorm 0.313 | loss_scale 2 | train_wall 8907 | gb_free 39.6 | wall 122359
2023-06-13 01:45:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-13 01:45:39 | INFO | fairseq.trainer | begin training epoch 14
2023-06-13 01:45:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-13 01:46:16 | INFO | train_inner | epoch 014:     43 / 11284 loss=3.544, nll_loss=1.84, ppl=3.58, wps=54734.4, ups=0.92, wpb=59479.2, bsz=2226.8, num_updates=146600, lr=0.000261176, gnorm=0.304, loss_scale=2, train_wall=80, gb_free=39.6, wall=122397
2023-06-13 01:47:39 | INFO | train_inner | epoch 014:    143 / 11284 loss=3.536, nll_loss=1.83, ppl=3.56, wps=71628.2, ups=1.2, wpb=59496.2, bsz=2237.2, num_updates=146700, lr=0.000261087, gnorm=0.3, loss_scale=2, train_wall=79, gb_free=39.5, wall=122480
2023-06-13 01:49:02 | INFO | train_inner | epoch 014:    243 / 11284 loss=3.523, nll_loss=1.815, ppl=3.52, wps=72051.9, ups=1.21, wpb=59506.4, bsz=2252.2, num_updates=146800, lr=0.000260998, gnorm=0.317, loss_scale=2, train_wall=79, gb_free=39.5, wall=122562
2023-06-13 01:50:24 | INFO | train_inner | epoch 014:    343 / 11284 loss=3.529, nll_loss=1.822, ppl=3.54, wps=71850.5, ups=1.21, wpb=59505.2, bsz=2242.1, num_updates=146900, lr=0.000260909, gnorm=0.306, loss_scale=2, train_wall=79, gb_free=39.6, wall=122645
2023-06-13 01:51:48 | INFO | train_inner | epoch 014:    443 / 11284 loss=3.552, nll_loss=1.848, ppl=3.6, wps=71785, ups=1.2, wpb=59634, bsz=2283.6, num_updates=147000, lr=0.00026082, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.5, wall=122728
2023-06-13 01:53:12 | INFO | train_inner | epoch 014:    543 / 11284 loss=3.531, nll_loss=1.825, ppl=3.54, wps=70519, ups=1.18, wpb=59733.9, bsz=2192.7, num_updates=147100, lr=0.000260732, gnorm=0.308, loss_scale=2, train_wall=81, gb_free=39.6, wall=122813
2023-06-13 01:53:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 01:54:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-06-13 01:54:37 | INFO | train_inner | epoch 014:    645 / 11284 loss=3.534, nll_loss=1.827, ppl=3.55, wps=70385.2, ups=1.19, wpb=59345.9, bsz=2170.6, num_updates=147200, lr=0.000260643, gnorm=0.314, loss_scale=1, train_wall=80, gb_free=39.4, wall=122897
2023-06-13 01:56:00 | INFO | train_inner | epoch 014:    745 / 11284 loss=3.55, nll_loss=1.846, ppl=3.59, wps=71349.8, ups=1.2, wpb=59491.8, bsz=2287.2, num_updates=147300, lr=0.000260555, gnorm=0.315, loss_scale=1, train_wall=79, gb_free=39.6, wall=122981
2023-06-13 01:57:23 | INFO | train_inner | epoch 014:    845 / 11284 loss=3.54, nll_loss=1.834, ppl=3.57, wps=71754.6, ups=1.2, wpb=59748.4, bsz=2217.8, num_updates=147400, lr=0.000260466, gnorm=0.311, loss_scale=1, train_wall=80, gb_free=39.6, wall=123064
2023-06-13 01:58:46 | INFO | train_inner | epoch 014:    945 / 11284 loss=3.543, nll_loss=1.837, ppl=3.57, wps=71364.7, ups=1.2, wpb=59320.5, bsz=2328.9, num_updates=147500, lr=0.000260378, gnorm=0.315, loss_scale=1, train_wall=79, gb_free=39.5, wall=123147
2023-06-13 02:00:09 | INFO | train_inner | epoch 014:   1045 / 11284 loss=3.547, nll_loss=1.842, ppl=3.59, wps=72229.6, ups=1.21, wpb=59621.9, bsz=2249.4, num_updates=147600, lr=0.00026029, gnorm=0.31, loss_scale=1, train_wall=79, gb_free=39.6, wall=123229
2023-06-13 02:01:32 | INFO | train_inner | epoch 014:   1145 / 11284 loss=3.546, nll_loss=1.841, ppl=3.58, wps=71313.1, ups=1.2, wpb=59229.1, bsz=2240.5, num_updates=147700, lr=0.000260201, gnorm=0.326, loss_scale=1, train_wall=79, gb_free=39.6, wall=123313
2023-06-13 02:02:55 | INFO | train_inner | epoch 014:   1245 / 11284 loss=3.543, nll_loss=1.838, ppl=3.57, wps=71785.5, ups=1.21, wpb=59359.2, bsz=2219.1, num_updates=147800, lr=0.000260113, gnorm=0.324, loss_scale=1, train_wall=79, gb_free=39.6, wall=123395
2023-06-13 02:04:18 | INFO | train_inner | epoch 014:   1345 / 11284 loss=3.535, nll_loss=1.829, ppl=3.55, wps=71616.2, ups=1.2, wpb=59729.1, bsz=2312.3, num_updates=147900, lr=0.000260025, gnorm=0.309, loss_scale=1, train_wall=79, gb_free=39.6, wall=123479
2023-06-13 02:05:41 | INFO | train_inner | epoch 014:   1445 / 11284 loss=3.535, nll_loss=1.829, ppl=3.55, wps=71260.2, ups=1.2, wpb=59369.4, bsz=2293.2, num_updates=148000, lr=0.000259938, gnorm=0.31, loss_scale=1, train_wall=79, gb_free=39.6, wall=123562
2023-06-13 02:07:05 | INFO | train_inner | epoch 014:   1545 / 11284 loss=3.534, nll_loss=1.827, ppl=3.55, wps=71438.7, ups=1.2, wpb=59440.6, bsz=2178.3, num_updates=148100, lr=0.00025985, gnorm=0.305, loss_scale=1, train_wall=79, gb_free=39.6, wall=123645
2023-06-13 02:08:28 | INFO | train_inner | epoch 014:   1645 / 11284 loss=3.534, nll_loss=1.828, ppl=3.55, wps=71408, ups=1.2, wpb=59467.1, bsz=2300.3, num_updates=148200, lr=0.000259762, gnorm=0.318, loss_scale=1, train_wall=79, gb_free=39.6, wall=123728
2023-06-13 02:09:50 | INFO | train_inner | epoch 014:   1745 / 11284 loss=3.549, nll_loss=1.845, ppl=3.59, wps=72641.9, ups=1.22, wpb=59406.2, bsz=2236.1, num_updates=148300, lr=0.000259675, gnorm=0.325, loss_scale=2, train_wall=78, gb_free=39.5, wall=123810
2023-06-13 02:11:13 | INFO | train_inner | epoch 014:   1845 / 11284 loss=3.531, nll_loss=1.824, ppl=3.54, wps=71880.4, ups=1.21, wpb=59642.9, bsz=2183.2, num_updates=148400, lr=0.000259587, gnorm=0.313, loss_scale=2, train_wall=79, gb_free=39.6, wall=123893
2023-06-13 02:12:36 | INFO | train_inner | epoch 014:   1945 / 11284 loss=3.534, nll_loss=1.828, ppl=3.55, wps=71626.3, ups=1.2, wpb=59472.5, bsz=2192.3, num_updates=148500, lr=0.0002595, gnorm=0.307, loss_scale=2, train_wall=79, gb_free=39.4, wall=123976
2023-06-13 02:14:00 | INFO | train_inner | epoch 014:   2045 / 11284 loss=3.542, nll_loss=1.837, ppl=3.57, wps=70023.1, ups=1.18, wpb=59383, bsz=2297.7, num_updates=148600, lr=0.000259412, gnorm=0.306, loss_scale=2, train_wall=81, gb_free=39.6, wall=124061
2023-06-13 02:15:23 | INFO | train_inner | epoch 014:   2145 / 11284 loss=3.539, nll_loss=1.833, ppl=3.56, wps=71670.2, ups=1.2, wpb=59502.7, bsz=2185.8, num_updates=148700, lr=0.000259325, gnorm=0.305, loss_scale=2, train_wall=79, gb_free=39.6, wall=124144
2023-06-13 02:16:47 | INFO | train_inner | epoch 014:   2245 / 11284 loss=3.526, nll_loss=1.819, ppl=3.53, wps=71704.6, ups=1.2, wpb=59670, bsz=2136.6, num_updates=148800, lr=0.000259238, gnorm=0.304, loss_scale=2, train_wall=79, gb_free=39.6, wall=124227
2023-06-13 02:18:10 | INFO | train_inner | epoch 014:   2345 / 11284 loss=3.545, nll_loss=1.84, ppl=3.58, wps=71578.5, ups=1.2, wpb=59420.1, bsz=2220.4, num_updates=148900, lr=0.000259151, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.6, wall=124310
2023-06-13 02:19:32 | INFO | train_inner | epoch 014:   2445 / 11284 loss=3.538, nll_loss=1.832, ppl=3.56, wps=71986.9, ups=1.21, wpb=59526.9, bsz=2196.1, num_updates=149000, lr=0.000259064, gnorm=0.317, loss_scale=2, train_wall=79, gb_free=39.6, wall=124393
2023-06-13 02:20:55 | INFO | train_inner | epoch 014:   2545 / 11284 loss=3.533, nll_loss=1.827, ppl=3.55, wps=71653.6, ups=1.21, wpb=59436.8, bsz=2239.4, num_updates=149100, lr=0.000258977, gnorm=0.312, loss_scale=2, train_wall=79, gb_free=39.6, wall=124476
2023-06-13 02:22:18 | INFO | train_inner | epoch 014:   2645 / 11284 loss=3.547, nll_loss=1.842, ppl=3.59, wps=71689.3, ups=1.2, wpb=59586.2, bsz=2219.7, num_updates=149200, lr=0.00025889, gnorm=0.308, loss_scale=2, train_wall=79, gb_free=39.6, wall=124559
2023-06-13 02:23:42 | INFO | train_inner | epoch 014:   2745 / 11284 loss=3.532, nll_loss=1.826, ppl=3.54, wps=71440.4, ups=1.2, wpb=59454.1, bsz=2233.2, num_updates=149300, lr=0.000258803, gnorm=0.31, loss_scale=4, train_wall=79, gb_free=39.6, wall=124642
2023-06-13 02:24:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 02:25:05 | INFO | train_inner | epoch 014:   2846 / 11284 loss=3.538, nll_loss=1.832, ppl=3.56, wps=71428.8, ups=1.2, wpb=59552.7, bsz=2202.1, num_updates=149400, lr=0.000258717, gnorm=0.317, loss_scale=2, train_wall=79, gb_free=39.5, wall=124726
2023-06-13 02:26:28 | INFO | train_inner | epoch 014:   2946 / 11284 loss=3.544, nll_loss=1.839, ppl=3.58, wps=71313.7, ups=1.2, wpb=59433.4, bsz=2242.8, num_updates=149500, lr=0.00025863, gnorm=0.308, loss_scale=2, train_wall=79, gb_free=39.5, wall=124809
2023-06-13 02:27:51 | INFO | train_inner | epoch 014:   3046 / 11284 loss=3.535, nll_loss=1.829, ppl=3.55, wps=71697.9, ups=1.21, wpb=59389.8, bsz=2204.4, num_updates=149600, lr=0.000258544, gnorm=0.322, loss_scale=2, train_wall=79, gb_free=39.6, wall=124892
2023-06-13 02:29:14 | INFO | train_inner | epoch 014:   3146 / 11284 loss=3.54, nll_loss=1.834, ppl=3.57, wps=71339.9, ups=1.2, wpb=59373.2, bsz=2186.5, num_updates=149700, lr=0.000258457, gnorm=0.313, loss_scale=2, train_wall=79, gb_free=39.6, wall=124975
2023-06-13 02:30:38 | INFO | train_inner | epoch 014:   3246 / 11284 loss=3.532, nll_loss=1.826, ppl=3.54, wps=71541.6, ups=1.2, wpb=59537.4, bsz=2214.5, num_updates=149800, lr=0.000258371, gnorm=0.319, loss_scale=2, train_wall=79, gb_free=39.6, wall=125058
2023-06-13 02:32:01 | INFO | train_inner | epoch 014:   3346 / 11284 loss=3.552, nll_loss=1.848, ppl=3.6, wps=71570, ups=1.2, wpb=59686.8, bsz=2234.3, num_updates=149900, lr=0.000258285, gnorm=0.324, loss_scale=2, train_wall=79, gb_free=39.6, wall=125142
2023-06-13 02:33:24 | INFO | train_inner | epoch 014:   3446 / 11284 loss=3.542, nll_loss=1.837, ppl=3.57, wps=71433.5, ups=1.21, wpb=59140.4, bsz=2253, num_updates=150000, lr=0.000258199, gnorm=0.325, loss_scale=2, train_wall=79, gb_free=39, wall=125224
2023-06-13 02:34:46 | INFO | train_inner | epoch 014:   3546 / 11284 loss=3.539, nll_loss=1.833, ppl=3.56, wps=72791.7, ups=1.22, wpb=59423.5, bsz=2209.6, num_updates=150100, lr=0.000258113, gnorm=0.307, loss_scale=2, train_wall=78, gb_free=39.5, wall=125306
2023-06-13 02:36:09 | INFO | train_inner | epoch 014:   3646 / 11284 loss=3.541, nll_loss=1.836, ppl=3.57, wps=71951.6, ups=1.2, wpb=59717.5, bsz=2251.6, num_updates=150200, lr=0.000258027, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.6, wall=125389
2023-06-13 02:37:33 | INFO | train_inner | epoch 014:   3746 / 11284 loss=3.54, nll_loss=1.835, ppl=3.57, wps=70801.1, ups=1.19, wpb=59652.5, bsz=2185.6, num_updates=150300, lr=0.000257941, gnorm=0.32, loss_scale=2, train_wall=80, gb_free=39.6, wall=125473
2023-06-13 02:38:56 | INFO | train_inner | epoch 014:   3846 / 11284 loss=3.548, nll_loss=1.844, ppl=3.59, wps=71740.3, ups=1.21, wpb=59509.1, bsz=2266.5, num_updates=150400, lr=0.000257855, gnorm=0.311, loss_scale=4, train_wall=79, gb_free=39.6, wall=125556
2023-06-13 02:39:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 02:40:18 | INFO | train_inner | epoch 014:   3947 / 11284 loss=3.547, nll_loss=1.842, ppl=3.59, wps=71998.1, ups=1.21, wpb=59455.5, bsz=2213.2, num_updates=150500, lr=0.00025777, gnorm=0.31, loss_scale=2, train_wall=78, gb_free=39.6, wall=125639
2023-06-13 02:41:40 | INFO | train_inner | epoch 014:   4047 / 11284 loss=3.544, nll_loss=1.839, ppl=3.58, wps=72817.6, ups=1.22, wpb=59588, bsz=2167.2, num_updates=150600, lr=0.000257684, gnorm=0.311, loss_scale=2, train_wall=78, gb_free=39.5, wall=125721
2023-06-13 02:43:04 | INFO | train_inner | epoch 014:   4147 / 11284 loss=3.541, nll_loss=1.836, ppl=3.57, wps=70479, ups=1.19, wpb=59324.7, bsz=2196.4, num_updates=150700, lr=0.000257599, gnorm=0.316, loss_scale=2, train_wall=80, gb_free=39.6, wall=125805
2023-06-13 02:44:27 | INFO | train_inner | epoch 014:   4247 / 11284 loss=3.537, nll_loss=1.832, ppl=3.56, wps=71812.1, ups=1.2, wpb=59599.3, bsz=2160.2, num_updates=150800, lr=0.000257513, gnorm=0.319, loss_scale=2, train_wall=79, gb_free=39.6, wall=125888
2023-06-13 02:45:49 | INFO | train_inner | epoch 014:   4347 / 11284 loss=3.539, nll_loss=1.834, ppl=3.57, wps=72560.2, ups=1.22, wpb=59500.8, bsz=2188.5, num_updates=150900, lr=0.000257428, gnorm=0.309, loss_scale=2, train_wall=78, gb_free=39.6, wall=125970
2023-06-13 02:47:11 | INFO | train_inner | epoch 014:   4447 / 11284 loss=3.541, nll_loss=1.836, ppl=3.57, wps=72990.5, ups=1.22, wpb=59721, bsz=2228.5, num_updates=151000, lr=0.000257343, gnorm=0.313, loss_scale=2, train_wall=78, gb_free=38.8, wall=126052
2023-06-13 02:48:33 | INFO | train_inner | epoch 014:   4547 / 11284 loss=3.54, nll_loss=1.835, ppl=3.57, wps=72661.6, ups=1.22, wpb=59463.2, bsz=2155.5, num_updates=151100, lr=0.000257257, gnorm=0.326, loss_scale=2, train_wall=78, gb_free=39.6, wall=126134
2023-06-13 02:49:56 | INFO | train_inner | epoch 014:   4647 / 11284 loss=3.54, nll_loss=1.835, ppl=3.57, wps=71279.6, ups=1.2, wpb=59348.1, bsz=2240.1, num_updates=151200, lr=0.000257172, gnorm=0.321, loss_scale=2, train_wall=79, gb_free=39.6, wall=126217
2023-06-13 02:51:22 | INFO | train_inner | epoch 014:   4747 / 11284 loss=3.545, nll_loss=1.84, ppl=3.58, wps=69019.9, ups=1.17, wpb=59129.2, bsz=2262.9, num_updates=151300, lr=0.000257087, gnorm=0.322, loss_scale=2, train_wall=82, gb_free=39.6, wall=126302
2023-06-13 02:52:47 | INFO | train_inner | epoch 014:   4847 / 11284 loss=3.547, nll_loss=1.843, ppl=3.59, wps=69582.8, ups=1.17, wpb=59313.5, bsz=2131.6, num_updates=151400, lr=0.000257002, gnorm=0.35, loss_scale=2, train_wall=81, gb_free=39.6, wall=126388
2023-06-13 02:53:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 02:54:13 | INFO | train_inner | epoch 014:   4948 / 11284 loss=3.546, nll_loss=1.842, ppl=3.58, wps=69610.1, ups=1.17, wpb=59632.5, bsz=2226.4, num_updates=151500, lr=0.000256917, gnorm=0.317, loss_scale=2, train_wall=82, gb_free=39.6, wall=126473
2023-06-13 02:55:37 | INFO | train_inner | epoch 014:   5048 / 11284 loss=3.543, nll_loss=1.838, ppl=3.58, wps=70617.8, ups=1.18, wpb=59640.6, bsz=2176.7, num_updates=151600, lr=0.000256833, gnorm=0.318, loss_scale=2, train_wall=81, gb_free=39.6, wall=126558
2023-06-13 02:57:03 | INFO | train_inner | epoch 014:   5148 / 11284 loss=3.54, nll_loss=1.835, ppl=3.57, wps=69638.5, ups=1.17, wpb=59570.9, bsz=2302.5, num_updates=151700, lr=0.000256748, gnorm=0.31, loss_scale=2, train_wall=82, gb_free=39.6, wall=126643
2023-06-13 02:58:28 | INFO | train_inner | epoch 014:   5248 / 11284 loss=3.559, nll_loss=1.857, ppl=3.62, wps=69562.6, ups=1.17, wpb=59454.3, bsz=2171.9, num_updates=151800, lr=0.000256664, gnorm=0.317, loss_scale=2, train_wall=82, gb_free=39.5, wall=126729
2023-06-13 02:59:53 | INFO | train_inner | epoch 014:   5348 / 11284 loss=3.549, nll_loss=1.845, ppl=3.59, wps=69849.5, ups=1.18, wpb=59443.5, bsz=2198.5, num_updates=151900, lr=0.000256579, gnorm=0.308, loss_scale=2, train_wall=81, gb_free=39.5, wall=126814
2023-06-13 03:01:19 | INFO | train_inner | epoch 014:   5448 / 11284 loss=3.547, nll_loss=1.843, ppl=3.59, wps=69611.8, ups=1.17, wpb=59547, bsz=2273.8, num_updates=152000, lr=0.000256495, gnorm=0.314, loss_scale=2, train_wall=81, gb_free=39.6, wall=126900
2023-06-13 03:02:44 | INFO | train_inner | epoch 014:   5548 / 11284 loss=3.539, nll_loss=1.834, ppl=3.57, wps=70171.7, ups=1.18, wpb=59533.2, bsz=2209.3, num_updates=152100, lr=0.00025641, gnorm=0.314, loss_scale=2, train_wall=81, gb_free=39.6, wall=126984
2023-06-13 03:04:09 | INFO | train_inner | epoch 014:   5648 / 11284 loss=3.54, nll_loss=1.835, ppl=3.57, wps=69199.3, ups=1.17, wpb=59246.8, bsz=2318.7, num_updates=152200, lr=0.000256326, gnorm=0.32, loss_scale=2, train_wall=81, gb_free=39.6, wall=127070
2023-06-13 03:05:34 | INFO | train_inner | epoch 014:   5748 / 11284 loss=3.539, nll_loss=1.833, ppl=3.56, wps=69908.4, ups=1.18, wpb=59491.3, bsz=2190.9, num_updates=152300, lr=0.000256242, gnorm=0.309, loss_scale=2, train_wall=81, gb_free=39.6, wall=127155
2023-06-13 03:07:00 | INFO | train_inner | epoch 014:   5848 / 11284 loss=3.543, nll_loss=1.838, ppl=3.57, wps=69683.6, ups=1.17, wpb=59449.8, bsz=2269.2, num_updates=152400, lr=0.000256158, gnorm=0.313, loss_scale=2, train_wall=81, gb_free=39.5, wall=127240
2023-06-13 03:08:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 03:08:26 | INFO | train_inner | epoch 014:   5949 / 11284 loss=3.544, nll_loss=1.84, ppl=3.58, wps=69082.8, ups=1.16, wpb=59496.5, bsz=2247.6, num_updates=152500, lr=0.000256074, gnorm=0.313, loss_scale=2, train_wall=82, gb_free=39.5, wall=127327
2023-06-13 03:09:52 | INFO | train_inner | epoch 014:   6049 / 11284 loss=3.524, nll_loss=1.817, ppl=3.52, wps=69491.6, ups=1.17, wpb=59635.6, bsz=2208.5, num_updates=152600, lr=0.00025599, gnorm=0.314, loss_scale=2, train_wall=82, gb_free=39.4, wall=127412
2023-06-13 03:11:15 | INFO | train_inner | epoch 014:   6149 / 11284 loss=3.541, nll_loss=1.836, ppl=3.57, wps=71511.5, ups=1.2, wpb=59779.1, bsz=2210.5, num_updates=152700, lr=0.000255906, gnorm=0.311, loss_scale=2, train_wall=80, gb_free=39.6, wall=127496
2023-06-13 03:12:39 | INFO | train_inner | epoch 014:   6249 / 11284 loss=3.538, nll_loss=1.832, ppl=3.56, wps=71225.9, ups=1.2, wpb=59513.6, bsz=2205.5, num_updates=152800, lr=0.000255822, gnorm=0.326, loss_scale=2, train_wall=79, gb_free=39.6, wall=127579
2023-06-13 03:14:03 | INFO | train_inner | epoch 014:   6349 / 11284 loss=3.554, nll_loss=1.851, ppl=3.61, wps=70292.3, ups=1.18, wpb=59326.8, bsz=2129.6, num_updates=152900, lr=0.000255739, gnorm=0.311, loss_scale=2, train_wall=80, gb_free=39.5, wall=127664
2023-06-13 03:15:26 | INFO | train_inner | epoch 014:   6449 / 11284 loss=3.547, nll_loss=1.843, ppl=3.59, wps=71604.4, ups=1.2, wpb=59513.7, bsz=2250, num_updates=153000, lr=0.000255655, gnorm=0.321, loss_scale=2, train_wall=79, gb_free=39.5, wall=127747
2023-06-13 03:16:50 | INFO | train_inner | epoch 014:   6549 / 11284 loss=3.548, nll_loss=1.844, ppl=3.59, wps=71213.9, ups=1.2, wpb=59375, bsz=2310.2, num_updates=153100, lr=0.000255571, gnorm=0.319, loss_scale=2, train_wall=80, gb_free=39.5, wall=127830
2023-06-13 03:18:13 | INFO | train_inner | epoch 014:   6649 / 11284 loss=3.54, nll_loss=1.834, ppl=3.57, wps=71417.1, ups=1.2, wpb=59404.7, bsz=2216.2, num_updates=153200, lr=0.000255488, gnorm=0.318, loss_scale=2, train_wall=79, gb_free=39.6, wall=127914
2023-06-13 03:19:36 | INFO | train_inner | epoch 014:   6749 / 11284 loss=3.53, nll_loss=1.824, ppl=3.54, wps=71798.1, ups=1.21, wpb=59527.5, bsz=2178.3, num_updates=153300, lr=0.000255405, gnorm=0.295, loss_scale=2, train_wall=79, gb_free=39.6, wall=127996
2023-06-13 03:20:59 | INFO | train_inner | epoch 014:   6849 / 11284 loss=3.554, nll_loss=1.851, ppl=3.61, wps=71955.8, ups=1.21, wpb=59632, bsz=2234.9, num_updates=153400, lr=0.000255321, gnorm=0.33, loss_scale=2, train_wall=79, gb_free=39.5, wall=128079
2023-06-13 03:22:20 | INFO | train_inner | epoch 014:   6949 / 11284 loss=3.536, nll_loss=1.831, ppl=3.56, wps=73233.3, ups=1.23, wpb=59437.3, bsz=2085.8, num_updates=153500, lr=0.000255238, gnorm=0.31, loss_scale=2, train_wall=77, gb_free=39.4, wall=128161
2023-06-13 03:23:43 | INFO | train_inner | epoch 014:   7049 / 11284 loss=3.533, nll_loss=1.828, ppl=3.55, wps=71907.9, ups=1.21, wpb=59433.4, bsz=2293.7, num_updates=153600, lr=0.000255155, gnorm=0.313, loss_scale=4, train_wall=78, gb_free=39.6, wall=128243
2023-06-13 03:23:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 03:25:07 | INFO | train_inner | epoch 014:   7150 / 11284 loss=3.525, nll_loss=1.818, ppl=3.53, wps=70822.7, ups=1.19, wpb=59597.6, bsz=2221.2, num_updates=153700, lr=0.000255072, gnorm=0.312, loss_scale=2, train_wall=80, gb_free=39.6, wall=128327
2023-06-13 03:26:30 | INFO | train_inner | epoch 014:   7250 / 11284 loss=3.537, nll_loss=1.832, ppl=3.56, wps=71274.5, ups=1.2, wpb=59545.6, bsz=2234.7, num_updates=153800, lr=0.000254989, gnorm=0.319, loss_scale=2, train_wall=80, gb_free=39.6, wall=128411
2023-06-13 03:27:53 | INFO | train_inner | epoch 014:   7350 / 11284 loss=3.539, nll_loss=1.833, ppl=3.56, wps=71753.3, ups=1.21, wpb=59528.7, bsz=2214.5, num_updates=153900, lr=0.000254906, gnorm=0.309, loss_scale=2, train_wall=79, gb_free=39.6, wall=128494
2023-06-13 03:29:17 | INFO | train_inner | epoch 014:   7450 / 11284 loss=3.547, nll_loss=1.843, ppl=3.59, wps=71002, ups=1.19, wpb=59446.1, bsz=2197.3, num_updates=154000, lr=0.000254824, gnorm=0.319, loss_scale=2, train_wall=80, gb_free=39.5, wall=128578
2023-06-13 03:30:41 | INFO | train_inner | epoch 014:   7550 / 11284 loss=3.536, nll_loss=1.831, ppl=3.56, wps=71051.5, ups=1.2, wpb=59436.5, bsz=2194.4, num_updates=154100, lr=0.000254741, gnorm=0.314, loss_scale=2, train_wall=80, gb_free=39.6, wall=128661
2023-06-13 03:32:04 | INFO | train_inner | epoch 014:   7650 / 11284 loss=3.552, nll_loss=1.848, ppl=3.6, wps=71075.5, ups=1.2, wpb=59469.1, bsz=2231, num_updates=154200, lr=0.000254658, gnorm=0.312, loss_scale=2, train_wall=80, gb_free=39.5, wall=128745
2023-06-13 03:33:28 | INFO | train_inner | epoch 014:   7750 / 11284 loss=3.537, nll_loss=1.832, ppl=3.56, wps=71308.8, ups=1.2, wpb=59621.3, bsz=2272.1, num_updates=154300, lr=0.000254576, gnorm=0.317, loss_scale=2, train_wall=80, gb_free=39.6, wall=128828
2023-06-13 03:34:51 | INFO | train_inner | epoch 014:   7850 / 11284 loss=3.533, nll_loss=1.827, ppl=3.55, wps=71336.1, ups=1.2, wpb=59456.3, bsz=2253.5, num_updates=154400, lr=0.000254493, gnorm=0.328, loss_scale=2, train_wall=79, gb_free=39.5, wall=128912
2023-06-13 03:36:15 | INFO | train_inner | epoch 014:   7950 / 11284 loss=3.537, nll_loss=1.831, ppl=3.56, wps=71164.5, ups=1.2, wpb=59385.4, bsz=2214.4, num_updates=154500, lr=0.000254411, gnorm=0.317, loss_scale=2, train_wall=79, gb_free=39.6, wall=128995
2023-06-13 03:37:38 | INFO | train_inner | epoch 014:   8050 / 11284 loss=3.561, nll_loss=1.858, ppl=3.63, wps=71793.4, ups=1.2, wpb=59719, bsz=2273.4, num_updates=154600, lr=0.000254329, gnorm=0.303, loss_scale=2, train_wall=79, gb_free=39.6, wall=129078
2023-06-13 03:39:01 | INFO | train_inner | epoch 014:   8150 / 11284 loss=3.549, nll_loss=1.845, ppl=3.59, wps=71199.9, ups=1.2, wpb=59323.6, bsz=2231.3, num_updates=154700, lr=0.000254246, gnorm=0.31, loss_scale=4, train_wall=79, gb_free=39.6, wall=129162
2023-06-13 03:39:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 03:40:25 | INFO | train_inner | epoch 014:   8251 / 11284 loss=3.549, nll_loss=1.846, ppl=3.59, wps=71076.4, ups=1.19, wpb=59603, bsz=2174.2, num_updates=154800, lr=0.000254164, gnorm=0.313, loss_scale=2, train_wall=80, gb_free=39.5, wall=129246
2023-06-13 03:41:48 | INFO | train_inner | epoch 014:   8351 / 11284 loss=3.534, nll_loss=1.828, ppl=3.55, wps=72284.9, ups=1.21, wpb=59702.8, bsz=2270.3, num_updates=154900, lr=0.000254082, gnorm=0.31, loss_scale=2, train_wall=79, gb_free=39.6, wall=129328
2023-06-13 03:43:10 | INFO | train_inner | epoch 014:   8451 / 11284 loss=3.535, nll_loss=1.829, ppl=3.55, wps=72524.1, ups=1.22, wpb=59535.4, bsz=2204.3, num_updates=155000, lr=0.000254, gnorm=0.31, loss_scale=2, train_wall=78, gb_free=39.5, wall=129410
2023-06-13 03:44:33 | INFO | train_inner | epoch 014:   8551 / 11284 loss=3.534, nll_loss=1.828, ppl=3.55, wps=71616.1, ups=1.2, wpb=59521.3, bsz=2328, num_updates=155100, lr=0.000253918, gnorm=0.316, loss_scale=2, train_wall=79, gb_free=39.6, wall=129493
2023-06-13 03:45:56 | INFO | train_inner | epoch 014:   8651 / 11284 loss=3.553, nll_loss=1.85, ppl=3.6, wps=71095.2, ups=1.2, wpb=59217.2, bsz=2169, num_updates=155200, lr=0.000253837, gnorm=0.314, loss_scale=2, train_wall=79, gb_free=39.5, wall=129577
2023-06-13 03:47:20 | INFO | train_inner | epoch 014:   8751 / 11284 loss=3.524, nll_loss=1.818, ppl=3.52, wps=71442.2, ups=1.2, wpb=59662.7, bsz=2127.5, num_updates=155300, lr=0.000253755, gnorm=0.312, loss_scale=2, train_wall=80, gb_free=39.6, wall=129660
2023-06-13 03:48:42 | INFO | train_inner | epoch 014:   8851 / 11284 loss=3.537, nll_loss=1.831, ppl=3.56, wps=72358.5, ups=1.22, wpb=59401.6, bsz=2214.5, num_updates=155400, lr=0.000253673, gnorm=0.316, loss_scale=2, train_wall=78, gb_free=39.6, wall=129742
2023-06-13 03:50:03 | INFO | train_inner | epoch 014:   8951 / 11284 loss=3.558, nll_loss=1.855, ppl=3.62, wps=72702.4, ups=1.23, wpb=59246.6, bsz=2238.8, num_updates=155500, lr=0.000253592, gnorm=0.326, loss_scale=2, train_wall=77, gb_free=39.5, wall=129824
2023-06-13 03:51:25 | INFO | train_inner | epoch 014:   9051 / 11284 loss=3.543, nll_loss=1.838, ppl=3.58, wps=72566.6, ups=1.22, wpb=59637.2, bsz=2225.9, num_updates=155600, lr=0.00025351, gnorm=0.307, loss_scale=2, train_wall=78, gb_free=39.6, wall=129906
2023-06-13 03:52:49 | INFO | train_inner | epoch 014:   9151 / 11284 loss=3.547, nll_loss=1.843, ppl=3.59, wps=71295.6, ups=1.2, wpb=59611.9, bsz=2202.5, num_updates=155700, lr=0.000253429, gnorm=0.314, loss_scale=2, train_wall=80, gb_free=39.6, wall=129990
2023-06-13 03:53:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 03:54:13 | INFO | train_inner | epoch 014:   9252 / 11284 loss=3.54, nll_loss=1.835, ppl=3.57, wps=70712.4, ups=1.19, wpb=59407.1, bsz=2188.7, num_updates=155800, lr=0.000253347, gnorm=0.328, loss_scale=2, train_wall=80, gb_free=39.6, wall=130074
2023-06-13 03:55:37 | INFO | train_inner | epoch 014:   9352 / 11284 loss=3.544, nll_loss=1.84, ppl=3.58, wps=71115.5, ups=1.2, wpb=59331.7, bsz=2263.7, num_updates=155900, lr=0.000253266, gnorm=0.319, loss_scale=2, train_wall=79, gb_free=39.5, wall=130157
2023-06-13 03:57:00 | INFO | train_inner | epoch 014:   9452 / 11284 loss=3.546, nll_loss=1.842, ppl=3.59, wps=71352.7, ups=1.2, wpb=59611.3, bsz=2260.1, num_updates=156000, lr=0.000253185, gnorm=0.322, loss_scale=2, train_wall=80, gb_free=39.6, wall=130241
2023-06-13 03:58:23 | INFO | train_inner | epoch 014:   9552 / 11284 loss=3.535, nll_loss=1.829, ppl=3.55, wps=71835.9, ups=1.2, wpb=59678, bsz=2261.9, num_updates=156100, lr=0.000253104, gnorm=0.309, loss_scale=2, train_wall=79, gb_free=39.6, wall=130324
2023-06-13 03:59:46 | INFO | train_inner | epoch 014:   9652 / 11284 loss=3.548, nll_loss=1.845, ppl=3.59, wps=71561, ups=1.2, wpb=59465.8, bsz=2232.9, num_updates=156200, lr=0.000253023, gnorm=0.308, loss_scale=2, train_wall=79, gb_free=39.6, wall=130407
2023-06-13 04:01:10 | INFO | train_inner | epoch 014:   9752 / 11284 loss=3.54, nll_loss=1.835, ppl=3.57, wps=71242.9, ups=1.19, wpb=59677.8, bsz=2345.9, num_updates=156300, lr=0.000252942, gnorm=0.316, loss_scale=2, train_wall=80, gb_free=39.5, wall=130491
2023-06-13 04:02:33 | INFO | train_inner | epoch 014:   9852 / 11284 loss=3.531, nll_loss=1.825, ppl=3.54, wps=71363.2, ups=1.2, wpb=59490, bsz=2247.7, num_updates=156400, lr=0.000252861, gnorm=0.323, loss_scale=2, train_wall=79, gb_free=39.5, wall=130574
2023-06-13 04:03:56 | INFO | train_inner | epoch 014:   9952 / 11284 loss=3.539, nll_loss=1.834, ppl=3.56, wps=71784.6, ups=1.2, wpb=59604.6, bsz=2243.5, num_updates=156500, lr=0.00025278, gnorm=0.333, loss_scale=2, train_wall=79, gb_free=39.5, wall=130657
2023-06-13 04:05:19 | INFO | train_inner | epoch 014:  10052 / 11284 loss=3.552, nll_loss=1.849, ppl=3.6, wps=72158, ups=1.21, wpb=59508.2, bsz=2223.3, num_updates=156600, lr=0.000252699, gnorm=0.313, loss_scale=2, train_wall=78, gb_free=39.6, wall=130739
2023-06-13 04:06:41 | INFO | train_inner | epoch 014:  10152 / 11284 loss=3.549, nll_loss=1.845, ppl=3.59, wps=72784.2, ups=1.22, wpb=59543.9, bsz=2214.9, num_updates=156700, lr=0.000252619, gnorm=0.315, loss_scale=2, train_wall=78, gb_free=39.6, wall=130821
2023-06-13 04:08:04 | INFO | train_inner | epoch 014:  10252 / 11284 loss=3.54, nll_loss=1.835, ppl=3.57, wps=71460.3, ups=1.2, wpb=59514.5, bsz=2253.9, num_updates=156800, lr=0.000252538, gnorm=0.321, loss_scale=2, train_wall=79, gb_free=39.5, wall=130905
2023-06-13 04:08:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 04:09:29 | INFO | train_inner | epoch 014:  10353 / 11284 loss=3.547, nll_loss=1.843, ppl=3.59, wps=70214.9, ups=1.18, wpb=59436.5, bsz=2293.9, num_updates=156900, lr=0.000252458, gnorm=0.318, loss_scale=2, train_wall=81, gb_free=39.6, wall=130989
2023-06-13 04:10:51 | INFO | train_inner | epoch 014:  10453 / 11284 loss=3.566, nll_loss=1.864, ppl=3.64, wps=72281.6, ups=1.21, wpb=59666.3, bsz=2340.6, num_updates=157000, lr=0.000252377, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.6, wall=131072
2023-06-13 04:12:14 | INFO | train_inner | epoch 014:  10553 / 11284 loss=3.544, nll_loss=1.84, ppl=3.58, wps=71711.7, ups=1.2, wpb=59639.4, bsz=2272.3, num_updates=157100, lr=0.000252297, gnorm=0.319, loss_scale=2, train_wall=79, gb_free=39.6, wall=131155
2023-06-13 04:13:37 | INFO | train_inner | epoch 014:  10653 / 11284 loss=3.564, nll_loss=1.862, ppl=3.64, wps=72084.9, ups=1.21, wpb=59770.2, bsz=2260.4, num_updates=157200, lr=0.000252217, gnorm=0.318, loss_scale=2, train_wall=79, gb_free=39.6, wall=131238
2023-06-13 04:15:00 | INFO | train_inner | epoch 014:  10753 / 11284 loss=3.543, nll_loss=1.838, ppl=3.58, wps=71373.3, ups=1.2, wpb=59411.1, bsz=2271.4, num_updates=157300, lr=0.000252136, gnorm=0.309, loss_scale=2, train_wall=79, gb_free=39.6, wall=131321
2023-06-13 04:16:24 | INFO | train_inner | epoch 014:  10853 / 11284 loss=3.552, nll_loss=1.849, ppl=3.6, wps=71289.4, ups=1.2, wpb=59530.3, bsz=2236.1, num_updates=157400, lr=0.000252056, gnorm=0.326, loss_scale=2, train_wall=80, gb_free=39.6, wall=131405
2023-06-13 04:17:46 | INFO | train_inner | epoch 014:  10953 / 11284 loss=3.547, nll_loss=1.844, ppl=3.59, wps=72305.9, ups=1.21, wpb=59515.7, bsz=2104.8, num_updates=157500, lr=0.000251976, gnorm=0.321, loss_scale=2, train_wall=79, gb_free=39.5, wall=131487
2023-06-13 04:19:09 | INFO | train_inner | epoch 014:  11053 / 11284 loss=3.553, nll_loss=1.849, ppl=3.6, wps=71660.3, ups=1.21, wpb=59408.5, bsz=2252.5, num_updates=157600, lr=0.000251896, gnorm=0.305, loss_scale=2, train_wall=79, gb_free=39.6, wall=131570
2023-06-13 04:20:32 | INFO | train_inner | epoch 014:  11153 / 11284 loss=3.557, nll_loss=1.854, ppl=3.61, wps=71406.1, ups=1.2, wpb=59305, bsz=2200.1, num_updates=157700, lr=0.000251816, gnorm=0.323, loss_scale=2, train_wall=79, gb_free=39.5, wall=131653
2023-06-13 04:21:56 | INFO | train_inner | epoch 014:  11253 / 11284 loss=3.538, nll_loss=1.833, ppl=3.56, wps=71437, ups=1.2, wpb=59520.4, bsz=2171.9, num_updates=157800, lr=0.000251737, gnorm=0.312, loss_scale=2, train_wall=80, gb_free=39.6, wall=131736
2023-06-13 04:22:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-13 04:22:39 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.34 | nll_loss 2.662 | ppl 6.33 | bleu 20.55 | wps 3825.3 | wpb 2397.5 | bsz 71.5 | num_updates 157831 | best_loss 4.319
2023-06-13 04:22:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 157831 updates
2023-06-13 04:22:39 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint14.pt
2023-06-13 04:22:41 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint14.pt
2023-06-13 04:22:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint14.pt (epoch 14 @ 157831 updates, score 4.34) (writing took 4.5780552150681615 seconds)
2023-06-13 04:22:43 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-06-13 04:22:43 | INFO | train | epoch 014 | loss 3.542 | nll_loss 1.837 | ppl 3.57 | wps 71171.2 | ups 1.2 | wpb 59500 | bsz 2227.3 | num_updates 157831 | lr 0.000251712 | gnorm 0.315 | loss_scale 2 | train_wall 8955 | gb_free 39.6 | wall 131784
2023-06-13 04:22:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-13 04:22:44 | INFO | fairseq.trainer | begin training epoch 15
2023-06-13 04:22:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-13 04:23:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 04:23:42 | INFO | train_inner | epoch 015:     70 / 11284 loss=3.525, nll_loss=1.818, ppl=3.53, wps=55800.4, ups=0.94, wpb=59320.9, bsz=2207.6, num_updates=157900, lr=0.000251657, gnorm=0.312, loss_scale=2, train_wall=79, gb_free=39.5, wall=131842
2023-06-13 04:25:04 | INFO | train_inner | epoch 015:    170 / 11284 loss=3.515, nll_loss=1.806, ppl=3.5, wps=72498.5, ups=1.22, wpb=59297.1, bsz=2225, num_updates=158000, lr=0.000251577, gnorm=0.31, loss_scale=2, train_wall=78, gb_free=39.6, wall=131924
2023-06-13 04:26:26 | INFO | train_inner | epoch 015:    270 / 11284 loss=3.524, nll_loss=1.816, ppl=3.52, wps=72316.5, ups=1.21, wpb=59647.1, bsz=2207.6, num_updates=158100, lr=0.000251498, gnorm=0.308, loss_scale=2, train_wall=79, gb_free=39.5, wall=132007
2023-06-13 04:27:49 | INFO | train_inner | epoch 015:    370 / 11284 loss=3.521, nll_loss=1.814, ppl=3.52, wps=71990.8, ups=1.21, wpb=59477.7, bsz=2212.2, num_updates=158200, lr=0.000251418, gnorm=0.321, loss_scale=2, train_wall=79, gb_free=39.6, wall=132089
2023-06-13 04:29:11 | INFO | train_inner | epoch 015:    470 / 11284 loss=3.531, nll_loss=1.825, ppl=3.54, wps=72087.6, ups=1.21, wpb=59452.4, bsz=2221.3, num_updates=158300, lr=0.000251339, gnorm=0.327, loss_scale=2, train_wall=79, gb_free=39.6, wall=132172
2023-06-13 04:30:34 | INFO | train_inner | epoch 015:    570 / 11284 loss=3.548, nll_loss=1.844, ppl=3.59, wps=71458.9, ups=1.2, wpb=59386, bsz=2295.2, num_updates=158400, lr=0.000251259, gnorm=0.32, loss_scale=2, train_wall=79, gb_free=39.6, wall=132255
2023-06-13 04:31:57 | INFO | train_inner | epoch 015:    670 / 11284 loss=3.538, nll_loss=1.832, ppl=3.56, wps=72210.4, ups=1.22, wpb=59417.6, bsz=2132.4, num_updates=158500, lr=0.00025118, gnorm=0.321, loss_scale=2, train_wall=78, gb_free=39.6, wall=132337
2023-06-13 04:33:19 | INFO | train_inner | epoch 015:    770 / 11284 loss=3.536, nll_loss=1.83, ppl=3.56, wps=72376.2, ups=1.21, wpb=59800.2, bsz=2285.6, num_updates=158600, lr=0.000251101, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.6, wall=132420
2023-06-13 04:34:42 | INFO | train_inner | epoch 015:    870 / 11284 loss=3.515, nll_loss=1.807, ppl=3.5, wps=71658.5, ups=1.2, wpb=59494.8, bsz=2216.7, num_updates=158700, lr=0.000251022, gnorm=0.332, loss_scale=2, train_wall=79, gb_free=39.6, wall=132503
2023-06-13 04:36:05 | INFO | train_inner | epoch 015:    970 / 11284 loss=3.535, nll_loss=1.829, ppl=3.55, wps=71705.9, ups=1.21, wpb=59417.2, bsz=2183, num_updates=158800, lr=0.000250943, gnorm=0.335, loss_scale=2, train_wall=79, gb_free=39.5, wall=132586
2023-06-13 04:37:27 | INFO | train_inner | epoch 015:   1070 / 11284 loss=3.531, nll_loss=1.825, ppl=3.54, wps=72787.6, ups=1.22, wpb=59628.6, bsz=2342.1, num_updates=158900, lr=0.000250864, gnorm=0.313, loss_scale=4, train_wall=78, gb_free=39.5, wall=132668
2023-06-13 04:37:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 04:38:50 | INFO | train_inner | epoch 015:   1171 / 11284 loss=3.532, nll_loss=1.825, ppl=3.54, wps=71957.4, ups=1.21, wpb=59354.5, bsz=2134.6, num_updates=159000, lr=0.000250785, gnorm=0.317, loss_scale=2, train_wall=78, gb_free=39.6, wall=132750
2023-06-13 04:40:11 | INFO | train_inner | epoch 015:   1271 / 11284 loss=3.539, nll_loss=1.834, ppl=3.56, wps=72790.4, ups=1.23, wpb=59416.1, bsz=2253.2, num_updates=159100, lr=0.000250706, gnorm=0.323, loss_scale=2, train_wall=78, gb_free=39.6, wall=132832
2023-06-13 04:41:33 | INFO | train_inner | epoch 015:   1371 / 11284 loss=3.536, nll_loss=1.83, ppl=3.56, wps=72557, ups=1.22, wpb=59548.7, bsz=2226, num_updates=159200, lr=0.000250627, gnorm=0.311, loss_scale=2, train_wall=78, gb_free=39.6, wall=132914
2023-06-13 04:42:55 | INFO | train_inner | epoch 015:   1471 / 11284 loss=3.537, nll_loss=1.831, ppl=3.56, wps=73035.1, ups=1.23, wpb=59568.7, bsz=2192.1, num_updates=159300, lr=0.000250549, gnorm=0.304, loss_scale=2, train_wall=77, gb_free=39.6, wall=132995
2023-06-13 04:44:18 | INFO | train_inner | epoch 015:   1571 / 11284 loss=3.541, nll_loss=1.835, ppl=3.57, wps=71749.3, ups=1.21, wpb=59423.6, bsz=2152.1, num_updates=159400, lr=0.00025047, gnorm=0.316, loss_scale=2, train_wall=79, gb_free=39.6, wall=133078
2023-06-13 04:45:41 | INFO | train_inner | epoch 015:   1671 / 11284 loss=3.533, nll_loss=1.827, ppl=3.55, wps=71439.7, ups=1.2, wpb=59429.8, bsz=2227.8, num_updates=159500, lr=0.000250392, gnorm=0.309, loss_scale=2, train_wall=79, gb_free=39.6, wall=133161
2023-06-13 04:47:04 | INFO | train_inner | epoch 015:   1771 / 11284 loss=3.553, nll_loss=1.849, ppl=3.6, wps=71197.8, ups=1.2, wpb=59424.2, bsz=2248.6, num_updates=159600, lr=0.000250313, gnorm=0.318, loss_scale=2, train_wall=80, gb_free=39.6, wall=133245
2023-06-13 04:48:28 | INFO | train_inner | epoch 015:   1871 / 11284 loss=3.537, nll_loss=1.831, ppl=3.56, wps=71179.8, ups=1.19, wpb=59610.9, bsz=2291.7, num_updates=159700, lr=0.000250235, gnorm=0.311, loss_scale=2, train_wall=80, gb_free=39.6, wall=133329
2023-06-13 04:49:51 | INFO | train_inner | epoch 015:   1971 / 11284 loss=3.539, nll_loss=1.834, ppl=3.56, wps=71521.2, ups=1.2, wpb=59445.9, bsz=2169.2, num_updates=159800, lr=0.000250156, gnorm=0.328, loss_scale=2, train_wall=79, gb_free=39.6, wall=133412
2023-06-13 04:51:14 | INFO | train_inner | epoch 015:   2071 / 11284 loss=3.537, nll_loss=1.831, ppl=3.56, wps=71356.6, ups=1.2, wpb=59443, bsz=2216, num_updates=159900, lr=0.000250078, gnorm=0.319, loss_scale=2, train_wall=79, gb_free=39.6, wall=133495
2023-06-13 04:51:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 04:52:38 | INFO | train_inner | epoch 015:   2172 / 11284 loss=3.532, nll_loss=1.826, ppl=3.55, wps=71404.4, ups=1.2, wpb=59483.6, bsz=2276, num_updates=160000, lr=0.00025, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.5, wall=133578
2023-06-13 04:54:01 | INFO | train_inner | epoch 015:   2272 / 11284 loss=3.54, nll_loss=1.835, ppl=3.57, wps=71526, ups=1.2, wpb=59559.8, bsz=2175.5, num_updates=160100, lr=0.000249922, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.6, wall=133662
2023-06-13 04:55:24 | INFO | train_inner | epoch 015:   2372 / 11284 loss=3.535, nll_loss=1.83, ppl=3.55, wps=71284.6, ups=1.2, wpb=59424.7, bsz=2200.1, num_updates=160200, lr=0.000249844, gnorm=0.321, loss_scale=2, train_wall=79, gb_free=39.7, wall=133745
2023-06-13 04:56:47 | INFO | train_inner | epoch 015:   2472 / 11284 loss=3.543, nll_loss=1.838, ppl=3.58, wps=71749.5, ups=1.21, wpb=59344.4, bsz=2206.9, num_updates=160300, lr=0.000249766, gnorm=0.322, loss_scale=2, train_wall=79, gb_free=39.5, wall=133828
2023-06-13 04:58:10 | INFO | train_inner | epoch 015:   2572 / 11284 loss=3.538, nll_loss=1.832, ppl=3.56, wps=72114.7, ups=1.21, wpb=59454.4, bsz=2249.3, num_updates=160400, lr=0.000249688, gnorm=0.313, loss_scale=2, train_wall=78, gb_free=39.5, wall=133910
2023-06-13 04:59:31 | INFO | train_inner | epoch 015:   2672 / 11284 loss=3.542, nll_loss=1.837, ppl=3.57, wps=72873, ups=1.22, wpb=59615.7, bsz=2199.6, num_updates=160500, lr=0.00024961, gnorm=0.305, loss_scale=2, train_wall=78, gb_free=39.6, wall=133992
2023-06-13 05:00:55 | INFO | train_inner | epoch 015:   2772 / 11284 loss=3.54, nll_loss=1.835, ppl=3.57, wps=71307.8, ups=1.2, wpb=59261.7, bsz=2205.7, num_updates=160600, lr=0.000249533, gnorm=0.319, loss_scale=2, train_wall=79, gb_free=39.5, wall=134075
2023-06-13 05:02:18 | INFO | train_inner | epoch 015:   2872 / 11284 loss=3.539, nll_loss=1.834, ppl=3.56, wps=71333.9, ups=1.2, wpb=59612.2, bsz=2236.5, num_updates=160700, lr=0.000249455, gnorm=0.332, loss_scale=2, train_wall=79, gb_free=39.6, wall=134159
2023-06-13 05:03:42 | INFO | train_inner | epoch 015:   2972 / 11284 loss=3.537, nll_loss=1.831, ppl=3.56, wps=71270, ups=1.2, wpb=59629.4, bsz=2175.5, num_updates=160800, lr=0.000249377, gnorm=0.322, loss_scale=2, train_wall=80, gb_free=39.6, wall=134242
2023-06-13 05:05:05 | INFO | train_inner | epoch 015:   3072 / 11284 loss=3.527, nll_loss=1.821, ppl=3.53, wps=71073.4, ups=1.19, wpb=59517.6, bsz=2357.2, num_updates=160900, lr=0.0002493, gnorm=0.315, loss_scale=2, train_wall=80, gb_free=39.6, wall=134326
2023-06-13 05:06:28 | INFO | train_inner | epoch 015:   3172 / 11284 loss=3.54, nll_loss=1.835, ppl=3.57, wps=71886.1, ups=1.21, wpb=59335.1, bsz=2168.6, num_updates=161000, lr=0.000249222, gnorm=0.317, loss_scale=4, train_wall=78, gb_free=39.5, wall=134409
2023-06-13 05:06:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 05:07:52 | INFO | train_inner | epoch 015:   3273 / 11284 loss=3.541, nll_loss=1.835, ppl=3.57, wps=70138.5, ups=1.18, wpb=59243.3, bsz=2186.4, num_updates=161100, lr=0.000249145, gnorm=0.322, loss_scale=2, train_wall=80, gb_free=39.6, wall=134493
2023-06-13 05:09:18 | INFO | train_inner | epoch 015:   3373 / 11284 loss=3.521, nll_loss=1.813, ppl=3.51, wps=70239.5, ups=1.18, wpb=59706.6, bsz=2233.8, num_updates=161200, lr=0.000249068, gnorm=0.311, loss_scale=2, train_wall=81, gb_free=39.5, wall=134578
2023-06-13 05:10:44 | INFO | train_inner | epoch 015:   3473 / 11284 loss=3.529, nll_loss=1.823, ppl=3.54, wps=69203.1, ups=1.16, wpb=59624.1, bsz=2237.7, num_updates=161300, lr=0.000248991, gnorm=0.316, loss_scale=2, train_wall=82, gb_free=39.6, wall=134664
2023-06-13 05:12:10 | INFO | train_inner | epoch 015:   3573 / 11284 loss=3.545, nll_loss=1.84, ppl=3.58, wps=68841.8, ups=1.16, wpb=59386.3, bsz=2198.8, num_updates=161400, lr=0.000248913, gnorm=0.319, loss_scale=2, train_wall=82, gb_free=39.6, wall=134751
2023-06-13 05:13:35 | INFO | train_inner | epoch 015:   3673 / 11284 loss=3.534, nll_loss=1.828, ppl=3.55, wps=70100.1, ups=1.18, wpb=59317.9, bsz=2116.6, num_updates=161500, lr=0.000248836, gnorm=0.314, loss_scale=2, train_wall=81, gb_free=39.5, wall=134835
2023-06-13 05:15:00 | INFO | train_inner | epoch 015:   3773 / 11284 loss=3.54, nll_loss=1.835, ppl=3.57, wps=69596, ups=1.17, wpb=59457.1, bsz=2303.4, num_updates=161600, lr=0.000248759, gnorm=0.336, loss_scale=2, train_wall=82, gb_free=39.6, wall=134921
2023-06-13 05:16:25 | INFO | train_inner | epoch 015:   3873 / 11284 loss=3.545, nll_loss=1.84, ppl=3.58, wps=69703.3, ups=1.18, wpb=59253.5, bsz=2233.6, num_updates=161700, lr=0.000248682, gnorm=0.314, loss_scale=2, train_wall=81, gb_free=39, wall=135006
2023-06-13 05:17:50 | INFO | train_inner | epoch 015:   3973 / 11284 loss=3.536, nll_loss=1.83, ppl=3.56, wps=70311.3, ups=1.18, wpb=59665.6, bsz=2181, num_updates=161800, lr=0.000248606, gnorm=0.309, loss_scale=2, train_wall=81, gb_free=39.6, wall=135090
2023-06-13 05:19:15 | INFO | train_inner | epoch 015:   4073 / 11284 loss=3.529, nll_loss=1.823, ppl=3.54, wps=69638.9, ups=1.17, wpb=59376, bsz=2196.9, num_updates=161900, lr=0.000248529, gnorm=0.312, loss_scale=2, train_wall=81, gb_free=39.5, wall=135176
2023-06-13 05:20:40 | INFO | train_inner | epoch 015:   4173 / 11284 loss=3.529, nll_loss=1.823, ppl=3.54, wps=69686, ups=1.18, wpb=59224.9, bsz=2118.5, num_updates=162000, lr=0.000248452, gnorm=0.309, loss_scale=2, train_wall=81, gb_free=39.5, wall=135261
2023-06-13 05:21:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 05:22:07 | INFO | train_inner | epoch 015:   4274 / 11284 loss=3.542, nll_loss=1.837, ppl=3.57, wps=68609.6, ups=1.16, wpb=59366.1, bsz=2327.8, num_updates=162100, lr=0.000248375, gnorm=0.325, loss_scale=2, train_wall=83, gb_free=39.5, wall=135347
2023-06-13 05:23:31 | INFO | train_inner | epoch 015:   4374 / 11284 loss=3.549, nll_loss=1.845, ppl=3.59, wps=70342.3, ups=1.18, wpb=59440.4, bsz=2169.1, num_updates=162200, lr=0.000248299, gnorm=0.313, loss_scale=2, train_wall=81, gb_free=39.6, wall=135432
2023-06-13 05:24:56 | INFO | train_inner | epoch 015:   4474 / 11284 loss=3.543, nll_loss=1.838, ppl=3.57, wps=69697.8, ups=1.17, wpb=59330.8, bsz=2153.1, num_updates=162300, lr=0.000248222, gnorm=0.33, loss_scale=2, train_wall=81, gb_free=39.6, wall=135517
2023-06-13 05:26:21 | INFO | train_inner | epoch 015:   4574 / 11284 loss=3.558, nll_loss=1.855, ppl=3.62, wps=70018.2, ups=1.18, wpb=59507.3, bsz=2220.4, num_updates=162400, lr=0.000248146, gnorm=0.313, loss_scale=2, train_wall=81, gb_free=39.6, wall=135602
2023-06-13 05:27:46 | INFO | train_inner | epoch 015:   4674 / 11284 loss=3.54, nll_loss=1.835, ppl=3.57, wps=70263.9, ups=1.18, wpb=59507.4, bsz=2243.2, num_updates=162500, lr=0.000248069, gnorm=0.308, loss_scale=2, train_wall=81, gb_free=39.6, wall=135687
2023-06-13 05:29:11 | INFO | train_inner | epoch 015:   4774 / 11284 loss=3.525, nll_loss=1.818, ppl=3.53, wps=69998.5, ups=1.18, wpb=59487.8, bsz=2177.6, num_updates=162600, lr=0.000247993, gnorm=0.319, loss_scale=2, train_wall=81, gb_free=39.6, wall=135772
2023-06-13 05:30:34 | INFO | train_inner | epoch 015:   4874 / 11284 loss=3.529, nll_loss=1.823, ppl=3.54, wps=71771.2, ups=1.21, wpb=59518.3, bsz=2347.8, num_updates=162700, lr=0.000247917, gnorm=0.314, loss_scale=2, train_wall=79, gb_free=39.5, wall=135854
2023-06-13 05:31:57 | INFO | train_inner | epoch 015:   4974 / 11284 loss=3.538, nll_loss=1.833, ppl=3.56, wps=71432.9, ups=1.2, wpb=59703.8, bsz=2269.1, num_updates=162800, lr=0.000247841, gnorm=0.32, loss_scale=2, train_wall=80, gb_free=39.5, wall=135938
2023-06-13 05:33:19 | INFO | train_inner | epoch 015:   5074 / 11284 loss=3.537, nll_loss=1.832, ppl=3.56, wps=72789.9, ups=1.22, wpb=59604, bsz=2283.4, num_updates=162900, lr=0.000247765, gnorm=0.326, loss_scale=2, train_wall=78, gb_free=39.6, wall=136020
2023-06-13 05:34:42 | INFO | train_inner | epoch 015:   5174 / 11284 loss=3.538, nll_loss=1.833, ppl=3.56, wps=72005.1, ups=1.21, wpb=59533.9, bsz=2291.9, num_updates=163000, lr=0.000247689, gnorm=0.318, loss_scale=2, train_wall=79, gb_free=39.6, wall=136103
2023-06-13 05:35:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 05:36:06 | INFO | train_inner | epoch 015:   5275 / 11284 loss=3.547, nll_loss=1.842, ppl=3.59, wps=70648.4, ups=1.19, wpb=59552.8, bsz=2218.5, num_updates=163100, lr=0.000247613, gnorm=0.322, loss_scale=2, train_wall=80, gb_free=39.6, wall=136187
2023-06-13 05:37:29 | INFO | train_inner | epoch 015:   5375 / 11284 loss=3.544, nll_loss=1.839, ppl=3.58, wps=71405.9, ups=1.21, wpb=59236.3, bsz=2237.5, num_updates=163200, lr=0.000247537, gnorm=0.333, loss_scale=2, train_wall=79, gb_free=39.6, wall=136270
2023-06-13 05:38:53 | INFO | train_inner | epoch 015:   5475 / 11284 loss=3.549, nll_loss=1.846, ppl=3.59, wps=71407.3, ups=1.2, wpb=59546.6, bsz=2215.6, num_updates=163300, lr=0.000247461, gnorm=0.311, loss_scale=2, train_wall=79, gb_free=39.6, wall=136353
2023-06-13 05:40:16 | INFO | train_inner | epoch 015:   5575 / 11284 loss=3.532, nll_loss=1.826, ppl=3.55, wps=71644, ups=1.21, wpb=59450.9, bsz=2233.1, num_updates=163400, lr=0.000247385, gnorm=0.311, loss_scale=2, train_wall=79, gb_free=39.6, wall=136436
2023-06-13 05:41:39 | INFO | train_inner | epoch 015:   5675 / 11284 loss=3.541, nll_loss=1.836, ppl=3.57, wps=71808, ups=1.2, wpb=59598.3, bsz=2235.1, num_updates=163500, lr=0.00024731, gnorm=0.307, loss_scale=2, train_wall=79, gb_free=39.5, wall=136519
2023-06-13 05:43:02 | INFO | train_inner | epoch 015:   5775 / 11284 loss=3.531, nll_loss=1.825, ppl=3.54, wps=71506.6, ups=1.2, wpb=59479.5, bsz=2221.4, num_updates=163600, lr=0.000247234, gnorm=0.314, loss_scale=2, train_wall=79, gb_free=39.5, wall=136602
2023-06-13 05:44:27 | INFO | train_inner | epoch 015:   5875 / 11284 loss=3.536, nll_loss=1.83, ppl=3.56, wps=69535.6, ups=1.18, wpb=59109.7, bsz=2253.2, num_updates=163700, lr=0.000247159, gnorm=0.308, loss_scale=2, train_wall=81, gb_free=39.6, wall=136687
2023-06-13 05:45:50 | INFO | train_inner | epoch 015:   5975 / 11284 loss=3.53, nll_loss=1.824, ppl=3.54, wps=71473.5, ups=1.2, wpb=59574, bsz=2190, num_updates=163800, lr=0.000247083, gnorm=0.32, loss_scale=2, train_wall=79, gb_free=39.7, wall=136771
2023-06-13 05:47:13 | INFO | train_inner | epoch 015:   6075 / 11284 loss=3.544, nll_loss=1.84, ppl=3.58, wps=71749.6, ups=1.2, wpb=59610.8, bsz=2232.1, num_updates=163900, lr=0.000247008, gnorm=0.324, loss_scale=2, train_wall=79, gb_free=39.6, wall=136854
2023-06-13 05:48:40 | INFO | train_inner | epoch 015:   6175 / 11284 loss=3.531, nll_loss=1.825, ppl=3.54, wps=68986.4, ups=1.16, wpb=59637.3, bsz=2194.3, num_updates=164000, lr=0.000246932, gnorm=0.315, loss_scale=2, train_wall=83, gb_free=39.6, wall=136940
2023-06-13 05:50:05 | INFO | train_inner | epoch 015:   6275 / 11284 loss=3.534, nll_loss=1.829, ppl=3.55, wps=69786.4, ups=1.17, wpb=59573.2, bsz=2261.8, num_updates=164100, lr=0.000246857, gnorm=0.32, loss_scale=4, train_wall=82, gb_free=39.5, wall=137026
2023-06-13 05:50:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 05:51:31 | INFO | train_inner | epoch 015:   6376 / 11284 loss=3.539, nll_loss=1.834, ppl=3.57, wps=69372.4, ups=1.16, wpb=59622, bsz=2155.4, num_updates=164200, lr=0.000246782, gnorm=0.318, loss_scale=2, train_wall=82, gb_free=39.6, wall=137112
2023-06-13 05:52:57 | INFO | train_inner | epoch 015:   6476 / 11284 loss=3.533, nll_loss=1.828, ppl=3.55, wps=69597.9, ups=1.17, wpb=59527, bsz=2227.8, num_updates=164300, lr=0.000246707, gnorm=0.31, loss_scale=2, train_wall=82, gb_free=39.6, wall=137197
2023-06-13 05:54:21 | INFO | train_inner | epoch 015:   6576 / 11284 loss=3.537, nll_loss=1.832, ppl=3.56, wps=69829.3, ups=1.18, wpb=59080.2, bsz=2200.2, num_updates=164400, lr=0.000246632, gnorm=0.331, loss_scale=2, train_wall=81, gb_free=39.5, wall=137282
2023-06-13 05:55:46 | INFO | train_inner | epoch 015:   6676 / 11284 loss=3.547, nll_loss=1.843, ppl=3.59, wps=69669.4, ups=1.17, wpb=59409.1, bsz=2276.8, num_updates=164500, lr=0.000246557, gnorm=0.317, loss_scale=2, train_wall=81, gb_free=39.6, wall=137367
2023-06-13 05:57:12 | INFO | train_inner | epoch 015:   6776 / 11284 loss=3.536, nll_loss=1.831, ppl=3.56, wps=69143, ups=1.17, wpb=59292.2, bsz=2166.1, num_updates=164600, lr=0.000246482, gnorm=0.315, loss_scale=2, train_wall=82, gb_free=39.5, wall=137453
2023-06-13 05:58:38 | INFO | train_inner | epoch 015:   6876 / 11284 loss=3.537, nll_loss=1.832, ppl=3.56, wps=69440.9, ups=1.17, wpb=59504.3, bsz=2318.8, num_updates=164700, lr=0.000246407, gnorm=0.316, loss_scale=2, train_wall=82, gb_free=39.6, wall=137538
2023-06-13 06:00:03 | INFO | train_inner | epoch 015:   6976 / 11284 loss=3.53, nll_loss=1.824, ppl=3.54, wps=69684.3, ups=1.17, wpb=59499.8, bsz=2260.6, num_updates=164800, lr=0.000246332, gnorm=0.317, loss_scale=2, train_wall=82, gb_free=39.5, wall=137624
2023-06-13 06:01:28 | INFO | train_inner | epoch 015:   7076 / 11284 loss=3.535, nll_loss=1.83, ppl=3.56, wps=70610.2, ups=1.18, wpb=59783.9, bsz=2186.7, num_updates=164900, lr=0.000246258, gnorm=0.315, loss_scale=2, train_wall=81, gb_free=39.6, wall=137709
2023-06-13 06:02:53 | INFO | train_inner | epoch 015:   7176 / 11284 loss=3.539, nll_loss=1.834, ppl=3.57, wps=70140.5, ups=1.18, wpb=59590.5, bsz=2211.1, num_updates=165000, lr=0.000246183, gnorm=0.315, loss_scale=2, train_wall=81, gb_free=39.6, wall=137793
2023-06-13 06:04:17 | INFO | train_inner | epoch 015:   7276 / 11284 loss=3.535, nll_loss=1.829, ppl=3.55, wps=70553.4, ups=1.19, wpb=59422.9, bsz=2141, num_updates=165100, lr=0.000246108, gnorm=0.314, loss_scale=2, train_wall=80, gb_free=39.5, wall=137878
2023-06-13 06:05:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 06:05:43 | INFO | train_inner | epoch 015:   7377 / 11284 loss=3.532, nll_loss=1.827, ppl=3.55, wps=69286.5, ups=1.17, wpb=59438.2, bsz=2296.9, num_updates=165200, lr=0.000246034, gnorm=0.321, loss_scale=2, train_wall=82, gb_free=39.6, wall=137963
2023-06-13 06:07:08 | INFO | train_inner | epoch 015:   7477 / 11284 loss=3.526, nll_loss=1.819, ppl=3.53, wps=70104.2, ups=1.17, wpb=59774.4, bsz=2209.1, num_updates=165300, lr=0.000245959, gnorm=0.31, loss_scale=2, train_wall=81, gb_free=39.6, wall=138049
2023-06-13 06:08:34 | INFO | train_inner | epoch 015:   7577 / 11284 loss=3.552, nll_loss=1.849, ppl=3.6, wps=69584.2, ups=1.17, wpb=59649.1, bsz=2268, num_updates=165400, lr=0.000245885, gnorm=0.304, loss_scale=2, train_wall=81, gb_free=39.5, wall=138134
2023-06-13 06:09:59 | INFO | train_inner | epoch 015:   7677 / 11284 loss=3.538, nll_loss=1.833, ppl=3.56, wps=69813.7, ups=1.18, wpb=59408.2, bsz=2229.1, num_updates=165500, lr=0.000245811, gnorm=0.321, loss_scale=2, train_wall=81, gb_free=39.5, wall=138220
2023-06-13 06:11:24 | INFO | train_inner | epoch 015:   7777 / 11284 loss=3.541, nll_loss=1.836, ppl=3.57, wps=69481.5, ups=1.17, wpb=59350.2, bsz=2257.8, num_updates=165600, lr=0.000245737, gnorm=0.319, loss_scale=2, train_wall=81, gb_free=39.6, wall=138305
2023-06-13 06:12:49 | INFO | train_inner | epoch 015:   7877 / 11284 loss=3.534, nll_loss=1.829, ppl=3.55, wps=70050.5, ups=1.18, wpb=59512.7, bsz=2144.4, num_updates=165700, lr=0.000245662, gnorm=0.315, loss_scale=2, train_wall=81, gb_free=39.6, wall=138390
2023-06-13 06:14:14 | INFO | train_inner | epoch 015:   7977 / 11284 loss=3.538, nll_loss=1.833, ppl=3.56, wps=70151, ups=1.18, wpb=59668.7, bsz=2246.2, num_updates=165800, lr=0.000245588, gnorm=0.311, loss_scale=2, train_wall=81, gb_free=39.6, wall=138475
2023-06-13 06:15:40 | INFO | train_inner | epoch 015:   8077 / 11284 loss=3.534, nll_loss=1.829, ppl=3.55, wps=69806.4, ups=1.17, wpb=59562.9, bsz=2247.1, num_updates=165900, lr=0.000245514, gnorm=0.309, loss_scale=2, train_wall=81, gb_free=39.5, wall=138560
2023-06-13 06:17:05 | INFO | train_inner | epoch 015:   8177 / 11284 loss=3.537, nll_loss=1.832, ppl=3.56, wps=69430.5, ups=1.17, wpb=59423.5, bsz=2173.4, num_updates=166000, lr=0.00024544, gnorm=0.311, loss_scale=2, train_wall=82, gb_free=39.6, wall=138646
2023-06-13 06:18:31 | INFO | train_inner | epoch 015:   8277 / 11284 loss=3.548, nll_loss=1.844, ppl=3.59, wps=69948.4, ups=1.17, wpb=59711.3, bsz=2291.1, num_updates=166100, lr=0.000245366, gnorm=0.324, loss_scale=2, train_wall=81, gb_free=39.5, wall=138731
2023-06-13 06:19:55 | INFO | train_inner | epoch 015:   8377 / 11284 loss=3.53, nll_loss=1.824, ppl=3.54, wps=70604, ups=1.18, wpb=59592.1, bsz=2196.9, num_updates=166200, lr=0.000245293, gnorm=0.319, loss_scale=4, train_wall=81, gb_free=39.6, wall=138816
2023-06-13 06:20:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 06:21:22 | INFO | train_inner | epoch 015:   8478 / 11284 loss=3.521, nll_loss=1.814, ppl=3.52, wps=68834.8, ups=1.16, wpb=59542.3, bsz=2291.8, num_updates=166300, lr=0.000245219, gnorm=0.314, loss_scale=2, train_wall=83, gb_free=39.6, wall=138902
2023-06-13 06:22:47 | INFO | train_inner | epoch 015:   8578 / 11284 loss=3.532, nll_loss=1.826, ppl=3.55, wps=69666.1, ups=1.17, wpb=59590.6, bsz=2288.8, num_updates=166400, lr=0.000245145, gnorm=0.314, loss_scale=2, train_wall=82, gb_free=39.6, wall=138988
2023-06-13 06:24:12 | INFO | train_inner | epoch 015:   8678 / 11284 loss=3.534, nll_loss=1.829, ppl=3.55, wps=69984, ups=1.18, wpb=59473.9, bsz=2243.8, num_updates=166500, lr=0.000245072, gnorm=0.32, loss_scale=2, train_wall=81, gb_free=39.6, wall=139073
2023-06-13 06:25:37 | INFO | train_inner | epoch 015:   8778 / 11284 loss=3.549, nll_loss=1.845, ppl=3.59, wps=70001.3, ups=1.18, wpb=59324.3, bsz=2195.8, num_updates=166600, lr=0.000244998, gnorm=0.318, loss_scale=2, train_wall=81, gb_free=39.5, wall=139157
2023-06-13 06:27:02 | INFO | train_inner | epoch 015:   8878 / 11284 loss=3.525, nll_loss=1.818, ppl=3.53, wps=69981.7, ups=1.17, wpb=59622, bsz=2210.3, num_updates=166700, lr=0.000244924, gnorm=0.31, loss_scale=2, train_wall=81, gb_free=39.6, wall=139243
2023-06-13 06:28:27 | INFO | train_inner | epoch 015:   8978 / 11284 loss=3.529, nll_loss=1.823, ppl=3.54, wps=70047.5, ups=1.17, wpb=59715.8, bsz=2228.9, num_updates=166800, lr=0.000244851, gnorm=0.318, loss_scale=2, train_wall=81, gb_free=39.3, wall=139328
2023-06-13 06:29:52 | INFO | train_inner | epoch 015:   9078 / 11284 loss=3.544, nll_loss=1.84, ppl=3.58, wps=70231.6, ups=1.18, wpb=59464.2, bsz=2329, num_updates=166900, lr=0.000244778, gnorm=0.33, loss_scale=2, train_wall=81, gb_free=39.5, wall=139413
2023-06-13 06:31:16 | INFO | train_inner | epoch 015:   9178 / 11284 loss=3.542, nll_loss=1.837, ppl=3.57, wps=70176.5, ups=1.18, wpb=59224.8, bsz=2272.4, num_updates=167000, lr=0.000244704, gnorm=0.327, loss_scale=2, train_wall=80, gb_free=39.6, wall=139497
2023-06-13 06:32:42 | INFO | train_inner | epoch 015:   9278 / 11284 loss=3.515, nll_loss=1.808, ppl=3.5, wps=69504.7, ups=1.17, wpb=59646, bsz=2166.5, num_updates=167100, lr=0.000244631, gnorm=0.312, loss_scale=2, train_wall=82, gb_free=39.6, wall=139583
2023-06-13 06:34:07 | INFO | train_inner | epoch 015:   9378 / 11284 loss=3.528, nll_loss=1.822, ppl=3.53, wps=70088.6, ups=1.18, wpb=59555.2, bsz=2269.5, num_updates=167200, lr=0.000244558, gnorm=0.307, loss_scale=2, train_wall=81, gb_free=39.6, wall=139668
2023-06-13 06:35:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 06:35:32 | INFO | train_inner | epoch 015:   9479 / 11284 loss=3.535, nll_loss=1.83, ppl=3.56, wps=70613.6, ups=1.18, wpb=59624.6, bsz=2293.8, num_updates=167300, lr=0.000244485, gnorm=0.301, loss_scale=2, train_wall=80, gb_free=39.6, wall=139752
2023-06-13 06:36:54 | INFO | train_inner | epoch 015:   9579 / 11284 loss=3.542, nll_loss=1.837, ppl=3.57, wps=71987.5, ups=1.21, wpb=59543, bsz=2155.2, num_updates=167400, lr=0.000244412, gnorm=0.317, loss_scale=2, train_wall=79, gb_free=39.6, wall=139835
2023-06-13 06:38:16 | INFO | train_inner | epoch 015:   9679 / 11284 loss=3.534, nll_loss=1.829, ppl=3.55, wps=73280.7, ups=1.23, wpb=59667.2, bsz=2248.6, num_updates=167500, lr=0.000244339, gnorm=0.326, loss_scale=2, train_wall=78, gb_free=39.6, wall=139916
2023-06-13 06:39:39 | INFO | train_inner | epoch 015:   9779 / 11284 loss=3.542, nll_loss=1.838, ppl=3.58, wps=71668.5, ups=1.2, wpb=59499.1, bsz=2237.9, num_updates=167600, lr=0.000244266, gnorm=0.318, loss_scale=2, train_wall=79, gb_free=39.5, wall=139999
2023-06-13 06:41:01 | INFO | train_inner | epoch 015:   9879 / 11284 loss=3.537, nll_loss=1.832, ppl=3.56, wps=71846.5, ups=1.21, wpb=59406.3, bsz=2257.6, num_updates=167700, lr=0.000244193, gnorm=0.318, loss_scale=2, train_wall=79, gb_free=39.5, wall=140082
2023-06-13 06:42:24 | INFO | train_inner | epoch 015:   9979 / 11284 loss=3.541, nll_loss=1.836, ppl=3.57, wps=72459.2, ups=1.22, wpb=59496.8, bsz=2163.5, num_updates=167800, lr=0.00024412, gnorm=0.321, loss_scale=2, train_wall=78, gb_free=39.6, wall=140164
2023-06-13 06:43:46 | INFO | train_inner | epoch 015:  10079 / 11284 loss=3.541, nll_loss=1.837, ppl=3.57, wps=72040.7, ups=1.21, wpb=59701.5, bsz=2194.1, num_updates=167900, lr=0.000244048, gnorm=0.32, loss_scale=2, train_wall=79, gb_free=39.6, wall=140247
2023-06-13 06:45:10 | INFO | train_inner | epoch 015:  10179 / 11284 loss=3.53, nll_loss=1.824, ppl=3.54, wps=71644.5, ups=1.2, wpb=59752.7, bsz=2196.1, num_updates=168000, lr=0.000243975, gnorm=0.331, loss_scale=2, train_wall=79, gb_free=39.3, wall=140330
2023-06-13 06:46:32 | INFO | train_inner | epoch 015:  10279 / 11284 loss=3.531, nll_loss=1.825, ppl=3.54, wps=72236.6, ups=1.21, wpb=59664.3, bsz=2344.4, num_updates=168100, lr=0.000243902, gnorm=0.305, loss_scale=2, train_wall=79, gb_free=39.6, wall=140413
2023-06-13 06:47:56 | INFO | train_inner | epoch 015:  10379 / 11284 loss=3.549, nll_loss=1.846, ppl=3.59, wps=71058.7, ups=1.19, wpb=59576.4, bsz=2283.2, num_updates=168200, lr=0.00024383, gnorm=0.323, loss_scale=2, train_wall=79, gb_free=39.5, wall=140497
2023-06-13 06:49:20 | INFO | train_inner | epoch 015:  10479 / 11284 loss=3.529, nll_loss=1.823, ppl=3.54, wps=70803.3, ups=1.19, wpb=59517.5, bsz=2181.2, num_updates=168300, lr=0.000243757, gnorm=0.319, loss_scale=2, train_wall=80, gb_free=39.6, wall=140581
2023-06-13 06:50:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 06:50:44 | INFO | train_inner | epoch 015:  10580 / 11284 loss=3.535, nll_loss=1.83, ppl=3.55, wps=71090.5, ups=1.2, wpb=59475.8, bsz=2240.1, num_updates=168400, lr=0.000243685, gnorm=0.317, loss_scale=2, train_wall=79, gb_free=39.5, wall=140665
2023-06-13 06:52:07 | INFO | train_inner | epoch 015:  10680 / 11284 loss=3.521, nll_loss=1.814, ppl=3.52, wps=71566.4, ups=1.2, wpb=59617.3, bsz=2291.1, num_updates=168500, lr=0.000243613, gnorm=0.311, loss_scale=2, train_wall=79, gb_free=39.6, wall=140748
2023-06-13 06:53:30 | INFO | train_inner | epoch 015:  10780 / 11284 loss=3.546, nll_loss=1.842, ppl=3.59, wps=71868.9, ups=1.21, wpb=59627.3, bsz=2221.5, num_updates=168600, lr=0.000243541, gnorm=0.313, loss_scale=2, train_wall=79, gb_free=39.6, wall=140831
2023-06-13 06:54:54 | INFO | train_inner | epoch 015:  10880 / 11284 loss=3.533, nll_loss=1.827, ppl=3.55, wps=71457.7, ups=1.2, wpb=59715.1, bsz=2206.2, num_updates=168700, lr=0.000243468, gnorm=0.31, loss_scale=2, train_wall=80, gb_free=39.5, wall=140914
2023-06-13 06:56:17 | INFO | train_inner | epoch 015:  10980 / 11284 loss=3.544, nll_loss=1.84, ppl=3.58, wps=71637.5, ups=1.2, wpb=59583.8, bsz=2194.4, num_updates=168800, lr=0.000243396, gnorm=0.331, loss_scale=2, train_wall=79, gb_free=39.6, wall=140998
2023-06-13 06:57:40 | INFO | train_inner | epoch 015:  11080 / 11284 loss=3.545, nll_loss=1.841, ppl=3.58, wps=71539.2, ups=1.21, wpb=59215.9, bsz=2218.8, num_updates=168900, lr=0.000243324, gnorm=0.326, loss_scale=2, train_wall=79, gb_free=39.6, wall=141080
2023-06-13 06:59:04 | INFO | train_inner | epoch 015:  11180 / 11284 loss=3.54, nll_loss=1.836, ppl=3.57, wps=70842.3, ups=1.19, wpb=59342.8, bsz=2275.7, num_updates=169000, lr=0.000243252, gnorm=0.316, loss_scale=2, train_wall=80, gb_free=39.5, wall=141164
2023-06-13 07:00:26 | INFO | train_inner | epoch 015:  11280 / 11284 loss=3.55, nll_loss=1.847, ppl=3.6, wps=72351.3, ups=1.21, wpb=59740.9, bsz=2222, num_updates=169100, lr=0.00024318, gnorm=0.313, loss_scale=2, train_wall=79, gb_free=39.6, wall=141247
2023-06-13 07:00:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-13 07:00:47 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 4.317 | nll_loss 2.64 | ppl 6.23 | bleu 20.86 | wps 3693.5 | wpb 2397.5 | bsz 71.5 | num_updates 169104 | best_loss 4.317
2023-06-13 07:00:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 169104 updates
2023-06-13 07:00:47 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint15.pt
2023-06-13 07:00:49 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint15.pt
2023-06-13 07:00:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint15.pt (epoch 15 @ 169104 updates, score 4.317) (writing took 7.053376358933747 seconds)
2023-06-13 07:00:54 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-06-13 07:00:54 | INFO | train | epoch 015 | loss 3.536 | nll_loss 1.831 | ppl 3.56 | wps 70673 | ups 1.19 | wpb 59500.5 | bsz 2227.6 | num_updates 169104 | lr 0.000243177 | gnorm 0.317 | loss_scale 2 | train_wall 9016 | gb_free 39.5 | wall 141275
2023-06-13 07:00:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-13 07:00:55 | INFO | fairseq.trainer | begin training epoch 16
2023-06-13 07:00:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-13 07:02:16 | INFO | train_inner | epoch 016:     96 / 11284 loss=3.517, nll_loss=1.809, ppl=3.5, wps=53830.8, ups=0.91, wpb=59159.6, bsz=2232.1, num_updates=169200, lr=0.000243108, gnorm=0.322, loss_scale=2, train_wall=80, gb_free=39.5, wall=141357
2023-06-13 07:03:39 | INFO | train_inner | epoch 016:    196 / 11284 loss=3.521, nll_loss=1.813, ppl=3.51, wps=71858.2, ups=1.21, wpb=59393.1, bsz=2280.4, num_updates=169300, lr=0.000243037, gnorm=0.322, loss_scale=2, train_wall=78, gb_free=39.6, wall=141439
2023-06-13 07:05:02 | INFO | train_inner | epoch 016:    296 / 11284 loss=3.519, nll_loss=1.811, ppl=3.51, wps=71545.4, ups=1.21, wpb=59341.9, bsz=2321.8, num_updates=169400, lr=0.000242965, gnorm=0.304, loss_scale=4, train_wall=79, gb_free=39.5, wall=141522
2023-06-13 07:06:24 | INFO | train_inner | epoch 016:    396 / 11284 loss=3.53, nll_loss=1.824, ppl=3.54, wps=72557, ups=1.22, wpb=59488.4, bsz=2156.7, num_updates=169500, lr=0.000242893, gnorm=0.323, loss_scale=4, train_wall=78, gb_free=39.5, wall=141604
2023-06-13 07:07:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 07:07:48 | INFO | train_inner | epoch 016:    497 / 11284 loss=3.529, nll_loss=1.822, ppl=3.54, wps=71019.7, ups=1.19, wpb=59571.7, bsz=2177.2, num_updates=169600, lr=0.000242821, gnorm=0.322, loss_scale=2, train_wall=80, gb_free=39.6, wall=141688
2023-06-13 07:09:10 | INFO | train_inner | epoch 016:    597 / 11284 loss=3.532, nll_loss=1.826, ppl=3.55, wps=72056.8, ups=1.21, wpb=59524.9, bsz=2164.4, num_updates=169700, lr=0.00024275, gnorm=0.32, loss_scale=2, train_wall=79, gb_free=39.6, wall=141771
2023-06-13 07:10:32 | INFO | train_inner | epoch 016:    697 / 11284 loss=3.537, nll_loss=1.831, ppl=3.56, wps=72360, ups=1.22, wpb=59378.4, bsz=2272, num_updates=169800, lr=0.000242678, gnorm=0.315, loss_scale=2, train_wall=78, gb_free=39.6, wall=141853
2023-06-13 07:11:54 | INFO | train_inner | epoch 016:    797 / 11284 loss=3.518, nll_loss=1.811, ppl=3.51, wps=73019.3, ups=1.22, wpb=59705.7, bsz=2229.6, num_updates=169900, lr=0.000242607, gnorm=0.344, loss_scale=2, train_wall=78, gb_free=39.5, wall=141935
2023-06-13 07:13:16 | INFO | train_inner | epoch 016:    897 / 11284 loss=3.527, nll_loss=1.82, ppl=3.53, wps=72657.5, ups=1.22, wpb=59678.2, bsz=2267.7, num_updates=170000, lr=0.000242536, gnorm=0.311, loss_scale=2, train_wall=78, gb_free=39.6, wall=142017
2023-06-13 07:14:39 | INFO | train_inner | epoch 016:    997 / 11284 loss=3.53, nll_loss=1.823, ppl=3.54, wps=71065.7, ups=1.2, wpb=59219.8, bsz=2267.4, num_updates=170100, lr=0.000242464, gnorm=0.33, loss_scale=2, train_wall=79, gb_free=39.5, wall=142100
2023-06-13 07:16:03 | INFO | train_inner | epoch 016:   1097 / 11284 loss=3.524, nll_loss=1.817, ppl=3.52, wps=71708.9, ups=1.2, wpb=59596.3, bsz=2346.7, num_updates=170200, lr=0.000242393, gnorm=0.32, loss_scale=2, train_wall=79, gb_free=39.6, wall=142183
2023-06-13 07:17:26 | INFO | train_inner | epoch 016:   1197 / 11284 loss=3.52, nll_loss=1.812, ppl=3.51, wps=71656.1, ups=1.2, wpb=59686, bsz=2264.2, num_updates=170300, lr=0.000242322, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.5, wall=142266
2023-06-13 07:18:49 | INFO | train_inner | epoch 016:   1297 / 11284 loss=3.531, nll_loss=1.825, ppl=3.54, wps=71540, ups=1.2, wpb=59490.6, bsz=2168.4, num_updates=170400, lr=0.000242251, gnorm=0.329, loss_scale=2, train_wall=79, gb_free=39.4, wall=142350
2023-06-13 07:20:12 | INFO | train_inner | epoch 016:   1397 / 11284 loss=3.529, nll_loss=1.823, ppl=3.54, wps=71862.3, ups=1.21, wpb=59487.1, bsz=2241.5, num_updates=170500, lr=0.00024218, gnorm=0.325, loss_scale=2, train_wall=79, gb_free=39.6, wall=142432
2023-06-13 07:21:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 07:21:35 | INFO | train_inner | epoch 016:   1498 / 11284 loss=3.537, nll_loss=1.832, ppl=3.56, wps=71921.8, ups=1.21, wpb=59503.6, bsz=2222.6, num_updates=170600, lr=0.000242109, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.5, wall=142515
2023-06-13 07:22:58 | INFO | train_inner | epoch 016:   1598 / 11284 loss=3.516, nll_loss=1.808, ppl=3.5, wps=71039.5, ups=1.2, wpb=59363.6, bsz=2233, num_updates=170700, lr=0.000242038, gnorm=0.319, loss_scale=2, train_wall=80, gb_free=39.6, wall=142599
2023-06-13 07:24:21 | INFO | train_inner | epoch 016:   1698 / 11284 loss=3.519, nll_loss=1.811, ppl=3.51, wps=72212.8, ups=1.21, wpb=59729.8, bsz=2216, num_updates=170800, lr=0.000241967, gnorm=0.318, loss_scale=2, train_wall=78, gb_free=39.6, wall=142681
2023-06-13 07:25:44 | INFO | train_inner | epoch 016:   1798 / 11284 loss=3.527, nll_loss=1.821, ppl=3.53, wps=71433, ups=1.2, wpb=59320.5, bsz=2200.6, num_updates=170900, lr=0.000241896, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.6, wall=142764
2023-06-13 07:27:07 | INFO | train_inner | epoch 016:   1898 / 11284 loss=3.526, nll_loss=1.82, ppl=3.53, wps=71729.6, ups=1.21, wpb=59459.2, bsz=2164.3, num_updates=171000, lr=0.000241825, gnorm=0.31, loss_scale=2, train_wall=79, gb_free=39.6, wall=142847
2023-06-13 07:28:30 | INFO | train_inner | epoch 016:   1998 / 11284 loss=3.535, nll_loss=1.829, ppl=3.55, wps=71191.8, ups=1.2, wpb=59545.4, bsz=2286.5, num_updates=171100, lr=0.000241755, gnorm=0.317, loss_scale=2, train_wall=79, gb_free=39.4, wall=142931
2023-06-13 07:29:53 | INFO | train_inner | epoch 016:   2098 / 11284 loss=3.527, nll_loss=1.82, ppl=3.53, wps=72044.4, ups=1.21, wpb=59588, bsz=2173, num_updates=171200, lr=0.000241684, gnorm=0.317, loss_scale=2, train_wall=79, gb_free=39.6, wall=143014
2023-06-13 07:31:16 | INFO | train_inner | epoch 016:   2198 / 11284 loss=3.536, nll_loss=1.83, ppl=3.56, wps=72062.9, ups=1.21, wpb=59595.1, bsz=2220.3, num_updates=171300, lr=0.000241614, gnorm=0.322, loss_scale=2, train_wall=79, gb_free=39.6, wall=143096
2023-06-13 07:32:37 | INFO | train_inner | epoch 016:   2298 / 11284 loss=3.537, nll_loss=1.832, ppl=3.56, wps=73011.6, ups=1.22, wpb=59615.1, bsz=2190.1, num_updates=171400, lr=0.000241543, gnorm=0.329, loss_scale=2, train_wall=78, gb_free=39.6, wall=143178
2023-06-13 07:33:59 | INFO | train_inner | epoch 016:   2398 / 11284 loss=3.531, nll_loss=1.825, ppl=3.54, wps=72435.1, ups=1.22, wpb=59322.7, bsz=2269.5, num_updates=171500, lr=0.000241473, gnorm=0.317, loss_scale=2, train_wall=78, gb_free=39.5, wall=143260
2023-06-13 07:35:21 | INFO | train_inner | epoch 016:   2498 / 11284 loss=3.533, nll_loss=1.828, ppl=3.55, wps=72682.7, ups=1.23, wpb=59280.2, bsz=2328.6, num_updates=171600, lr=0.000241402, gnorm=0.305, loss_scale=2, train_wall=78, gb_free=39.6, wall=143341
2023-06-13 07:36:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 07:36:44 | INFO | train_inner | epoch 016:   2599 / 11284 loss=3.545, nll_loss=1.841, ppl=3.58, wps=71633.9, ups=1.21, wpb=59338.9, bsz=2235.7, num_updates=171700, lr=0.000241332, gnorm=0.333, loss_scale=2, train_wall=79, gb_free=39.6, wall=143424
2023-06-13 07:38:07 | INFO | train_inner | epoch 016:   2699 / 11284 loss=3.517, nll_loss=1.809, ppl=3.51, wps=71762.1, ups=1.2, wpb=59639.8, bsz=2212.2, num_updates=171800, lr=0.000241262, gnorm=0.316, loss_scale=2, train_wall=79, gb_free=39.6, wall=143507
2023-06-13 07:39:30 | INFO | train_inner | epoch 016:   2799 / 11284 loss=3.533, nll_loss=1.827, ppl=3.55, wps=71488.3, ups=1.2, wpb=59544, bsz=2220.9, num_updates=171900, lr=0.000241192, gnorm=0.332, loss_scale=2, train_wall=79, gb_free=39.5, wall=143591
2023-06-13 07:40:52 | INFO | train_inner | epoch 016:   2899 / 11284 loss=3.528, nll_loss=1.822, ppl=3.53, wps=72800.3, ups=1.22, wpb=59512.2, bsz=2249.2, num_updates=172000, lr=0.000241121, gnorm=0.322, loss_scale=2, train_wall=78, gb_free=39.6, wall=143672
2023-06-13 07:42:14 | INFO | train_inner | epoch 016:   2999 / 11284 loss=3.527, nll_loss=1.821, ppl=3.53, wps=72853.6, ups=1.22, wpb=59538, bsz=2237.8, num_updates=172100, lr=0.000241051, gnorm=0.325, loss_scale=2, train_wall=78, gb_free=39.5, wall=143754
2023-06-13 07:43:36 | INFO | train_inner | epoch 016:   3099 / 11284 loss=3.533, nll_loss=1.827, ppl=3.55, wps=72491.3, ups=1.22, wpb=59410, bsz=2164.9, num_updates=172200, lr=0.000240981, gnorm=0.323, loss_scale=2, train_wall=78, gb_free=39.5, wall=143836
2023-06-13 07:44:58 | INFO | train_inner | epoch 016:   3199 / 11284 loss=3.531, nll_loss=1.825, ppl=3.54, wps=72251, ups=1.21, wpb=59522.8, bsz=2213.2, num_updates=172300, lr=0.000240911, gnorm=0.319, loss_scale=2, train_wall=79, gb_free=39.5, wall=143919
2023-06-13 07:46:21 | INFO | train_inner | epoch 016:   3299 / 11284 loss=3.536, nll_loss=1.831, ppl=3.56, wps=71502.8, ups=1.2, wpb=59700.3, bsz=2256.9, num_updates=172400, lr=0.000240842, gnorm=0.309, loss_scale=2, train_wall=79, gb_free=39.6, wall=144002
2023-06-13 07:47:46 | INFO | train_inner | epoch 016:   3399 / 11284 loss=3.523, nll_loss=1.816, ppl=3.52, wps=70364.7, ups=1.18, wpb=59498.2, bsz=2295.6, num_updates=172500, lr=0.000240772, gnorm=0.323, loss_scale=2, train_wall=80, gb_free=39.6, wall=144087
2023-06-13 07:49:12 | INFO | train_inner | epoch 016:   3499 / 11284 loss=3.547, nll_loss=1.842, ppl=3.59, wps=69544.8, ups=1.17, wpb=59661.9, bsz=2271.1, num_updates=172600, lr=0.000240702, gnorm=0.318, loss_scale=2, train_wall=82, gb_free=39.6, wall=144172
2023-06-13 07:50:37 | INFO | train_inner | epoch 016:   3599 / 11284 loss=3.535, nll_loss=1.83, ppl=3.56, wps=69473.2, ups=1.17, wpb=59507.1, bsz=2232.1, num_updates=172700, lr=0.000240632, gnorm=0.325, loss_scale=4, train_wall=82, gb_free=39.6, wall=144258
2023-06-13 07:51:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 07:52:03 | INFO | train_inner | epoch 016:   3700 / 11284 loss=3.523, nll_loss=1.816, ppl=3.52, wps=69256.4, ups=1.16, wpb=59454.2, bsz=2271.1, num_updates=172800, lr=0.000240563, gnorm=0.317, loss_scale=2, train_wall=82, gb_free=39.5, wall=144344
2023-06-13 07:53:29 | INFO | train_inner | epoch 016:   3800 / 11284 loss=3.527, nll_loss=1.821, ppl=3.53, wps=69553.1, ups=1.17, wpb=59366.8, bsz=2206.4, num_updates=172900, lr=0.000240493, gnorm=0.318, loss_scale=2, train_wall=82, gb_free=39.6, wall=144429
2023-06-13 07:54:54 | INFO | train_inner | epoch 016:   3900 / 11284 loss=3.53, nll_loss=1.824, ppl=3.54, wps=70000.5, ups=1.17, wpb=59781, bsz=2210.3, num_updates=173000, lr=0.000240424, gnorm=0.32, loss_scale=2, train_wall=82, gb_free=39.6, wall=144515
2023-06-13 07:56:20 | INFO | train_inner | epoch 016:   4000 / 11284 loss=3.545, nll_loss=1.841, ppl=3.58, wps=69484.9, ups=1.17, wpb=59484.8, bsz=2232.2, num_updates=173100, lr=0.000240354, gnorm=0.322, loss_scale=2, train_wall=82, gb_free=39.6, wall=144600
2023-06-13 07:57:45 | INFO | train_inner | epoch 016:   4100 / 11284 loss=3.534, nll_loss=1.828, ppl=3.55, wps=70100.8, ups=1.18, wpb=59586.6, bsz=2204.4, num_updates=173200, lr=0.000240285, gnorm=0.315, loss_scale=2, train_wall=81, gb_free=39.6, wall=144685
2023-06-13 07:59:09 | INFO | train_inner | epoch 016:   4200 / 11284 loss=3.541, nll_loss=1.836, ppl=3.57, wps=70904.9, ups=1.19, wpb=59659.1, bsz=2194.8, num_updates=173300, lr=0.000240215, gnorm=0.32, loss_scale=2, train_wall=80, gb_free=39.6, wall=144769
2023-06-13 08:00:32 | INFO | train_inner | epoch 016:   4300 / 11284 loss=3.534, nll_loss=1.828, ppl=3.55, wps=71211.6, ups=1.2, wpb=59446.8, bsz=2308.4, num_updates=173400, lr=0.000240146, gnorm=0.31, loss_scale=2, train_wall=79, gb_free=39.5, wall=144853
2023-06-13 08:01:57 | INFO | train_inner | epoch 016:   4400 / 11284 loss=3.534, nll_loss=1.828, ppl=3.55, wps=70678.1, ups=1.19, wpb=59512.6, bsz=2236.5, num_updates=173500, lr=0.000240077, gnorm=0.325, loss_scale=2, train_wall=80, gb_free=39.6, wall=144937
2023-06-13 08:03:19 | INFO | train_inner | epoch 016:   4500 / 11284 loss=3.536, nll_loss=1.831, ppl=3.56, wps=72246.2, ups=1.21, wpb=59540.7, bsz=2246.3, num_updates=173600, lr=0.000240008, gnorm=0.314, loss_scale=2, train_wall=78, gb_free=39.6, wall=145020
2023-06-13 08:04:41 | INFO | train_inner | epoch 016:   4600 / 11284 loss=3.53, nll_loss=1.824, ppl=3.54, wps=72407, ups=1.22, wpb=59435.8, bsz=2328.2, num_updates=173700, lr=0.000239939, gnorm=0.328, loss_scale=2, train_wall=78, gb_free=39.6, wall=145102
2023-06-13 08:06:03 | INFO | train_inner | epoch 016:   4700 / 11284 loss=3.534, nll_loss=1.828, ppl=3.55, wps=72617.3, ups=1.22, wpb=59641.3, bsz=2176.6, num_updates=173800, lr=0.00023987, gnorm=0.32, loss_scale=4, train_wall=78, gb_free=39.6, wall=145184
2023-06-13 08:06:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 08:07:26 | INFO | train_inner | epoch 016:   4801 / 11284 loss=3.541, nll_loss=1.836, ppl=3.57, wps=71703.9, ups=1.2, wpb=59523.2, bsz=2230.2, num_updates=173900, lr=0.000239801, gnorm=0.321, loss_scale=2, train_wall=79, gb_free=39.6, wall=145267
2023-06-13 08:08:50 | INFO | train_inner | epoch 016:   4901 / 11284 loss=3.527, nll_loss=1.821, ppl=3.53, wps=70644.7, ups=1.19, wpb=59316.8, bsz=2182.9, num_updates=174000, lr=0.000239732, gnorm=0.309, loss_scale=2, train_wall=80, gb_free=39.6, wall=145351
2023-06-13 08:10:16 | INFO | train_inner | epoch 016:   5001 / 11284 loss=3.53, nll_loss=1.824, ppl=3.54, wps=69400.4, ups=1.17, wpb=59287.7, bsz=2218.5, num_updates=174100, lr=0.000239663, gnorm=0.32, loss_scale=2, train_wall=81, gb_free=39.6, wall=145436
2023-06-13 08:11:41 | INFO | train_inner | epoch 016:   5101 / 11284 loss=3.524, nll_loss=1.817, ppl=3.52, wps=69772.5, ups=1.17, wpb=59514.2, bsz=2218.3, num_updates=174200, lr=0.000239594, gnorm=0.314, loss_scale=2, train_wall=81, gb_free=39.6, wall=145521
2023-06-13 08:13:07 | INFO | train_inner | epoch 016:   5201 / 11284 loss=3.519, nll_loss=1.812, ppl=3.51, wps=68937.1, ups=1.16, wpb=59598.6, bsz=2323.5, num_updates=174300, lr=0.000239525, gnorm=0.324, loss_scale=2, train_wall=82, gb_free=39.6, wall=145608
2023-06-13 08:14:33 | INFO | train_inner | epoch 016:   5301 / 11284 loss=3.536, nll_loss=1.831, ppl=3.56, wps=69505.7, ups=1.17, wpb=59382.9, bsz=2322.1, num_updates=174400, lr=0.000239457, gnorm=0.327, loss_scale=2, train_wall=82, gb_free=39.6, wall=145693
2023-06-13 08:15:57 | INFO | train_inner | epoch 016:   5401 / 11284 loss=3.535, nll_loss=1.829, ppl=3.55, wps=70723.6, ups=1.19, wpb=59653.3, bsz=2316.2, num_updates=174500, lr=0.000239388, gnorm=0.322, loss_scale=2, train_wall=80, gb_free=39.6, wall=145778
2023-06-13 08:17:21 | INFO | train_inner | epoch 016:   5501 / 11284 loss=3.519, nll_loss=1.811, ppl=3.51, wps=70977.3, ups=1.19, wpb=59649.8, bsz=2306.8, num_updates=174600, lr=0.000239319, gnorm=0.322, loss_scale=2, train_wall=80, gb_free=39.5, wall=145862
2023-06-13 08:18:46 | INFO | train_inner | epoch 016:   5601 / 11284 loss=3.531, nll_loss=1.825, ppl=3.54, wps=70450.9, ups=1.18, wpb=59618.7, bsz=2121.2, num_updates=174700, lr=0.000239251, gnorm=0.319, loss_scale=2, train_wall=81, gb_free=39.6, wall=145946
2023-06-13 08:20:10 | INFO | train_inner | epoch 016:   5701 / 11284 loss=3.534, nll_loss=1.828, ppl=3.55, wps=70264.5, ups=1.18, wpb=59521.9, bsz=2195, num_updates=174800, lr=0.000239182, gnorm=0.315, loss_scale=2, train_wall=81, gb_free=39.6, wall=146031
2023-06-13 08:21:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 08:21:37 | INFO | train_inner | epoch 016:   5802 / 11284 loss=3.529, nll_loss=1.823, ppl=3.54, wps=69049.2, ups=1.16, wpb=59472.9, bsz=2143.8, num_updates=174900, lr=0.000239114, gnorm=0.324, loss_scale=2, train_wall=82, gb_free=39.6, wall=146117
2023-06-13 08:23:02 | INFO | train_inner | epoch 016:   5902 / 11284 loss=3.53, nll_loss=1.824, ppl=3.54, wps=69674.6, ups=1.17, wpb=59312.3, bsz=2173.1, num_updates=175000, lr=0.000239046, gnorm=0.326, loss_scale=2, train_wall=81, gb_free=39.6, wall=146202
2023-06-13 08:24:27 | INFO | train_inner | epoch 016:   6002 / 11284 loss=3.533, nll_loss=1.827, ppl=3.55, wps=69550.7, ups=1.17, wpb=59422.5, bsz=2156.5, num_updates=175100, lr=0.000238977, gnorm=0.314, loss_scale=2, train_wall=82, gb_free=37.8, wall=146288
2023-06-13 08:25:52 | INFO | train_inner | epoch 016:   6102 / 11284 loss=3.519, nll_loss=1.811, ppl=3.51, wps=70275.2, ups=1.17, wpb=59826.6, bsz=2247.7, num_updates=175200, lr=0.000238909, gnorm=0.314, loss_scale=2, train_wall=81, gb_free=39.6, wall=146373
2023-06-13 08:27:18 | INFO | train_inner | epoch 016:   6202 / 11284 loss=3.517, nll_loss=1.81, ppl=3.51, wps=69213.8, ups=1.16, wpb=59473.6, bsz=2223.4, num_updates=175300, lr=0.000238841, gnorm=0.315, loss_scale=2, train_wall=82, gb_free=39, wall=146459
2023-06-13 08:28:44 | INFO | train_inner | epoch 016:   6302 / 11284 loss=3.531, nll_loss=1.825, ppl=3.54, wps=69685.3, ups=1.17, wpb=59607.7, bsz=2275.6, num_updates=175400, lr=0.000238773, gnorm=0.324, loss_scale=2, train_wall=82, gb_free=39.6, wall=146544
2023-06-13 08:30:09 | INFO | train_inner | epoch 016:   6402 / 11284 loss=3.544, nll_loss=1.84, ppl=3.58, wps=70220.8, ups=1.18, wpb=59560.4, bsz=2242.8, num_updates=175500, lr=0.000238705, gnorm=0.324, loss_scale=2, train_wall=81, gb_free=39.6, wall=146629
2023-06-13 08:31:31 | INFO | train_inner | epoch 016:   6502 / 11284 loss=3.531, nll_loss=1.825, ppl=3.54, wps=71654.7, ups=1.21, wpb=59354.3, bsz=2149.2, num_updates=175600, lr=0.000238637, gnorm=0.317, loss_scale=2, train_wall=79, gb_free=39.5, wall=146712
2023-06-13 08:32:55 | INFO | train_inner | epoch 016:   6602 / 11284 loss=3.541, nll_loss=1.837, ppl=3.57, wps=71694.6, ups=1.2, wpb=59609.9, bsz=2200.4, num_updates=175700, lr=0.000238569, gnorm=0.33, loss_scale=2, train_wall=79, gb_free=39.6, wall=146795
2023-06-13 08:34:17 | INFO | train_inner | epoch 016:   6702 / 11284 loss=3.54, nll_loss=1.835, ppl=3.57, wps=71433.7, ups=1.21, wpb=59195.2, bsz=2194.1, num_updates=175800, lr=0.000238501, gnorm=0.329, loss_scale=2, train_wall=79, gb_free=39.6, wall=146878
2023-06-13 08:35:41 | INFO | train_inner | epoch 016:   6802 / 11284 loss=3.523, nll_loss=1.817, ppl=3.52, wps=71211, ups=1.2, wpb=59565.7, bsz=2206.8, num_updates=175900, lr=0.000238433, gnorm=0.32, loss_scale=2, train_wall=80, gb_free=39.6, wall=146962
2023-06-13 08:36:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 08:37:04 | INFO | train_inner | epoch 016:   6903 / 11284 loss=3.516, nll_loss=1.808, ppl=3.5, wps=71424.4, ups=1.2, wpb=59524.1, bsz=2127.2, num_updates=176000, lr=0.000238366, gnorm=0.318, loss_scale=2, train_wall=79, gb_free=39.5, wall=147045
2023-06-13 08:38:27 | INFO | train_inner | epoch 016:   7003 / 11284 loss=3.533, nll_loss=1.828, ppl=3.55, wps=72002, ups=1.21, wpb=59719.3, bsz=2247.6, num_updates=176100, lr=0.000238298, gnorm=0.311, loss_scale=2, train_wall=79, gb_free=39.6, wall=147128
2023-06-13 08:39:51 | INFO | train_inner | epoch 016:   7103 / 11284 loss=3.531, nll_loss=1.826, ppl=3.54, wps=71458.8, ups=1.2, wpb=59519.8, bsz=2159, num_updates=176200, lr=0.00023823, gnorm=0.328, loss_scale=2, train_wall=79, gb_free=39.5, wall=147211
2023-06-13 08:41:15 | INFO | train_inner | epoch 016:   7203 / 11284 loss=3.519, nll_loss=1.813, ppl=3.51, wps=70345.9, ups=1.18, wpb=59657.3, bsz=2284.3, num_updates=176300, lr=0.000238163, gnorm=0.321, loss_scale=2, train_wall=81, gb_free=39.5, wall=147296
2023-06-13 08:42:40 | INFO | train_inner | epoch 016:   7303 / 11284 loss=3.54, nll_loss=1.835, ppl=3.57, wps=70641.7, ups=1.19, wpb=59516.2, bsz=2171.3, num_updates=176400, lr=0.000238095, gnorm=0.318, loss_scale=2, train_wall=80, gb_free=39.5, wall=147380
2023-06-13 08:44:03 | INFO | train_inner | epoch 016:   7403 / 11284 loss=3.543, nll_loss=1.839, ppl=3.58, wps=71800.6, ups=1.2, wpb=59791.4, bsz=2216.7, num_updates=176500, lr=0.000238028, gnorm=0.321, loss_scale=2, train_wall=80, gb_free=39.6, wall=147464
2023-06-13 08:45:26 | INFO | train_inner | epoch 016:   7503 / 11284 loss=3.525, nll_loss=1.819, ppl=3.53, wps=71975.2, ups=1.21, wpb=59509.3, bsz=2203.1, num_updates=176600, lr=0.00023796, gnorm=0.319, loss_scale=2, train_wall=79, gb_free=39.6, wall=147546
2023-06-13 08:46:47 | INFO | train_inner | epoch 016:   7603 / 11284 loss=3.538, nll_loss=1.834, ppl=3.56, wps=72719.7, ups=1.22, wpb=59421.5, bsz=2238.8, num_updates=176700, lr=0.000237893, gnorm=0.33, loss_scale=2, train_wall=78, gb_free=39.5, wall=147628
2023-06-13 08:48:09 | INFO | train_inner | epoch 016:   7703 / 11284 loss=3.538, nll_loss=1.833, ppl=3.56, wps=72429, ups=1.22, wpb=59382.9, bsz=2237.8, num_updates=176800, lr=0.000237826, gnorm=0.324, loss_scale=2, train_wall=78, gb_free=39.5, wall=147710
2023-06-13 08:49:32 | INFO | train_inner | epoch 016:   7803 / 11284 loss=3.528, nll_loss=1.822, ppl=3.54, wps=72364.5, ups=1.22, wpb=59483.9, bsz=2178.1, num_updates=176900, lr=0.000237759, gnorm=0.323, loss_scale=2, train_wall=78, gb_free=39.5, wall=147792
2023-06-13 08:50:54 | INFO | train_inner | epoch 016:   7903 / 11284 loss=3.534, nll_loss=1.829, ppl=3.55, wps=72053.7, ups=1.22, wpb=59227.4, bsz=2190.5, num_updates=177000, lr=0.000237691, gnorm=0.325, loss_scale=4, train_wall=78, gb_free=39.6, wall=147874
2023-06-13 08:51:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 08:52:17 | INFO | train_inner | epoch 016:   8004 / 11284 loss=3.536, nll_loss=1.831, ppl=3.56, wps=71186.9, ups=1.2, wpb=59502.8, bsz=2210.9, num_updates=177100, lr=0.000237624, gnorm=0.326, loss_scale=2, train_wall=79, gb_free=39.6, wall=147958
2023-06-13 08:53:40 | INFO | train_inner | epoch 016:   8104 / 11284 loss=3.533, nll_loss=1.827, ppl=3.55, wps=71998.9, ups=1.21, wpb=59370.6, bsz=2180.4, num_updates=177200, lr=0.000237557, gnorm=0.319, loss_scale=2, train_wall=78, gb_free=39.5, wall=148040
2023-06-13 08:55:03 | INFO | train_inner | epoch 016:   8204 / 11284 loss=3.537, nll_loss=1.832, ppl=3.56, wps=71454.4, ups=1.2, wpb=59742.4, bsz=2268.8, num_updates=177300, lr=0.00023749, gnorm=0.309, loss_scale=2, train_wall=79, gb_free=39.6, wall=148124
2023-06-13 08:56:26 | INFO | train_inner | epoch 016:   8304 / 11284 loss=3.551, nll_loss=1.847, ppl=3.6, wps=71748.3, ups=1.21, wpb=59517.3, bsz=2157.9, num_updates=177400, lr=0.000237423, gnorm=0.318, loss_scale=2, train_wall=79, gb_free=39.6, wall=148207
2023-06-13 08:57:50 | INFO | train_inner | epoch 016:   8404 / 11284 loss=3.523, nll_loss=1.817, ppl=3.52, wps=71464.3, ups=1.2, wpb=59376.2, bsz=2270.1, num_updates=177500, lr=0.000237356, gnorm=0.313, loss_scale=2, train_wall=79, gb_free=39.6, wall=148290
2023-06-13 08:59:13 | INFO | train_inner | epoch 016:   8504 / 11284 loss=3.526, nll_loss=1.82, ppl=3.53, wps=71328.7, ups=1.19, wpb=59698.2, bsz=2229.8, num_updates=177600, lr=0.000237289, gnorm=0.325, loss_scale=2, train_wall=80, gb_free=39.5, wall=148374
2023-06-13 09:00:35 | INFO | train_inner | epoch 016:   8604 / 11284 loss=3.545, nll_loss=1.841, ppl=3.58, wps=72297.2, ups=1.22, wpb=59488.6, bsz=2294.9, num_updates=177700, lr=0.000237223, gnorm=0.315, loss_scale=2, train_wall=78, gb_free=39.4, wall=148456
2023-06-13 09:01:59 | INFO | train_inner | epoch 016:   8704 / 11284 loss=3.527, nll_loss=1.821, ppl=3.53, wps=71201.1, ups=1.2, wpb=59264.4, bsz=2265.4, num_updates=177800, lr=0.000237156, gnorm=0.335, loss_scale=2, train_wall=79, gb_free=39.5, wall=148539
2023-06-13 09:03:22 | INFO | train_inner | epoch 016:   8804 / 11284 loss=3.53, nll_loss=1.825, ppl=3.54, wps=71660, ups=1.21, wpb=59407.8, bsz=2190.2, num_updates=177900, lr=0.000237089, gnorm=0.319, loss_scale=2, train_wall=79, gb_free=38.9, wall=148622
2023-06-13 09:04:44 | INFO | train_inner | epoch 016:   8904 / 11284 loss=3.537, nll_loss=1.832, ppl=3.56, wps=71715.9, ups=1.21, wpb=59394.9, bsz=2169.1, num_updates=178000, lr=0.000237023, gnorm=0.325, loss_scale=2, train_wall=79, gb_free=39.6, wall=148705
2023-06-13 09:05:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 09:06:08 | INFO | train_inner | epoch 016:   9005 / 11284 loss=3.545, nll_loss=1.841, ppl=3.58, wps=70865.6, ups=1.19, wpb=59372.9, bsz=2263.6, num_updates=178100, lr=0.000236956, gnorm=0.324, loss_scale=2, train_wall=79, gb_free=39.6, wall=148789
2023-06-13 09:07:31 | INFO | train_inner | epoch 016:   9105 / 11284 loss=3.546, nll_loss=1.842, ppl=3.59, wps=71503, ups=1.2, wpb=59349.1, bsz=2198.9, num_updates=178200, lr=0.00023689, gnorm=0.319, loss_scale=2, train_wall=79, gb_free=39.6, wall=148872
2023-06-13 09:08:55 | INFO | train_inner | epoch 016:   9205 / 11284 loss=3.516, nll_loss=1.809, ppl=3.5, wps=71359.8, ups=1.2, wpb=59541, bsz=2253, num_updates=178300, lr=0.000236823, gnorm=0.317, loss_scale=2, train_wall=79, gb_free=39.6, wall=148955
2023-06-13 09:10:18 | INFO | train_inner | epoch 016:   9305 / 11284 loss=3.528, nll_loss=1.822, ppl=3.54, wps=71189.9, ups=1.2, wpb=59407.7, bsz=2199.5, num_updates=178400, lr=0.000236757, gnorm=0.321, loss_scale=2, train_wall=80, gb_free=39.5, wall=149039
2023-06-13 09:11:40 | INFO | train_inner | epoch 016:   9405 / 11284 loss=3.531, nll_loss=1.826, ppl=3.55, wps=72327.5, ups=1.22, wpb=59309.2, bsz=2157.7, num_updates=178500, lr=0.000236691, gnorm=0.315, loss_scale=2, train_wall=78, gb_free=39.6, wall=149121
2023-06-13 09:13:02 | INFO | train_inner | epoch 016:   9505 / 11284 loss=3.533, nll_loss=1.827, ppl=3.55, wps=72874.2, ups=1.23, wpb=59371.3, bsz=2192.6, num_updates=178600, lr=0.000236624, gnorm=0.329, loss_scale=2, train_wall=77, gb_free=39.6, wall=149202
2023-06-13 09:14:24 | INFO | train_inner | epoch 016:   9605 / 11284 loss=3.545, nll_loss=1.841, ppl=3.58, wps=72534.7, ups=1.22, wpb=59477.7, bsz=2249.6, num_updates=178700, lr=0.000236558, gnorm=0.318, loss_scale=2, train_wall=78, gb_free=39.4, wall=149284
2023-06-13 09:15:46 | INFO | train_inner | epoch 016:   9705 / 11284 loss=3.546, nll_loss=1.842, ppl=3.59, wps=72588.2, ups=1.22, wpb=59548.1, bsz=2313.1, num_updates=178800, lr=0.000236492, gnorm=0.315, loss_scale=2, train_wall=78, gb_free=39.5, wall=149366
2023-06-13 09:17:08 | INFO | train_inner | epoch 016:   9805 / 11284 loss=3.533, nll_loss=1.828, ppl=3.55, wps=72482.9, ups=1.21, wpb=59661.8, bsz=2270.4, num_updates=178900, lr=0.000236426, gnorm=0.309, loss_scale=2, train_wall=78, gb_free=39.6, wall=149449
2023-06-13 09:18:31 | INFO | train_inner | epoch 016:   9905 / 11284 loss=3.525, nll_loss=1.818, ppl=3.53, wps=71474.7, ups=1.2, wpb=59411.6, bsz=2206.3, num_updates=179000, lr=0.00023636, gnorm=0.312, loss_scale=2, train_wall=79, gb_free=39.5, wall=149532
2023-06-13 09:19:54 | INFO | train_inner | epoch 016:  10005 / 11284 loss=3.53, nll_loss=1.824, ppl=3.54, wps=71584.5, ups=1.2, wpb=59508.2, bsz=2164.8, num_updates=179100, lr=0.000236294, gnorm=0.325, loss_scale=4, train_wall=79, gb_free=39.6, wall=149615
2023-06-13 09:20:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 09:21:18 | INFO | train_inner | epoch 016:  10106 / 11284 loss=3.53, nll_loss=1.824, ppl=3.54, wps=71077.5, ups=1.19, wpb=59484.3, bsz=2161.4, num_updates=179200, lr=0.000236228, gnorm=0.319, loss_scale=2, train_wall=80, gb_free=39.6, wall=149698
2023-06-13 09:22:41 | INFO | train_inner | epoch 016:  10206 / 11284 loss=3.524, nll_loss=1.818, ppl=3.52, wps=71723.7, ups=1.21, wpb=59385.3, bsz=2167.9, num_updates=179300, lr=0.000236162, gnorm=0.322, loss_scale=2, train_wall=79, gb_free=39.6, wall=149781
2023-06-13 09:24:04 | INFO | train_inner | epoch 016:  10306 / 11284 loss=3.522, nll_loss=1.816, ppl=3.52, wps=71312.2, ups=1.2, wpb=59579.4, bsz=2220.6, num_updates=179400, lr=0.000236096, gnorm=0.318, loss_scale=2, train_wall=80, gb_free=39.6, wall=149865
2023-06-13 09:25:27 | INFO | train_inner | epoch 016:  10406 / 11284 loss=3.518, nll_loss=1.811, ppl=3.51, wps=72439, ups=1.21, wpb=59698.7, bsz=2170.8, num_updates=179500, lr=0.00023603, gnorm=0.331, loss_scale=2, train_wall=78, gb_free=39.6, wall=149947
2023-06-13 09:26:50 | INFO | train_inner | epoch 016:  10506 / 11284 loss=3.547, nll_loss=1.843, ppl=3.59, wps=71463.3, ups=1.2, wpb=59599.4, bsz=2261.3, num_updates=179600, lr=0.000235965, gnorm=0.314, loss_scale=2, train_wall=79, gb_free=39.5, wall=150031
2023-06-13 09:28:15 | INFO | train_inner | epoch 016:  10606 / 11284 loss=3.547, nll_loss=1.843, ppl=3.59, wps=69943.3, ups=1.18, wpb=59326.1, bsz=2271.8, num_updates=179700, lr=0.000235899, gnorm=0.318, loss_scale=2, train_wall=81, gb_free=39.6, wall=150115
2023-06-13 09:29:41 | INFO | train_inner | epoch 016:  10706 / 11284 loss=3.523, nll_loss=1.816, ppl=3.52, wps=69488.6, ups=1.17, wpb=59555, bsz=2273, num_updates=179800, lr=0.000235833, gnorm=0.322, loss_scale=2, train_wall=82, gb_free=39.5, wall=150201
2023-06-13 09:31:04 | INFO | train_inner | epoch 016:  10806 / 11284 loss=3.538, nll_loss=1.833, ppl=3.56, wps=71106.2, ups=1.2, wpb=59311.9, bsz=2289.2, num_updates=179900, lr=0.000235768, gnorm=0.328, loss_scale=2, train_wall=79, gb_free=38.8, wall=150285
2023-06-13 09:32:26 | INFO | train_inner | epoch 016:  10906 / 11284 loss=3.543, nll_loss=1.839, ppl=3.58, wps=72946.9, ups=1.22, wpb=59650.6, bsz=2269.9, num_updates=180000, lr=0.000235702, gnorm=0.317, loss_scale=2, train_wall=78, gb_free=39.5, wall=150366
2023-06-13 09:33:49 | INFO | train_inner | epoch 016:  11006 / 11284 loss=3.525, nll_loss=1.819, ppl=3.53, wps=71559.9, ups=1.2, wpb=59450.8, bsz=2210.2, num_updates=180100, lr=0.000235637, gnorm=0.326, loss_scale=2, train_wall=79, gb_free=39.5, wall=150449
2023-06-13 09:34:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 09:35:13 | INFO | train_inner | epoch 016:  11107 / 11284 loss=3.533, nll_loss=1.828, ppl=3.55, wps=71108.5, ups=1.19, wpb=59846.4, bsz=2250.7, num_updates=180200, lr=0.000235571, gnorm=0.323, loss_scale=2, train_wall=80, gb_free=39.5, wall=150534
2023-06-13 09:36:37 | INFO | train_inner | epoch 016:  11207 / 11284 loss=3.543, nll_loss=1.838, ppl=3.58, wps=70997.4, ups=1.2, wpb=59361.4, bsz=2276.2, num_updates=180300, lr=0.000235506, gnorm=0.321, loss_scale=2, train_wall=79, gb_free=39.6, wall=150617
2023-06-13 09:37:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-13 09:37:58 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 4.327 | nll_loss 2.648 | ppl 6.27 | bleu 20.83 | wps 3794.9 | wpb 2397.5 | bsz 71.5 | num_updates 180377 | best_loss 4.317
2023-06-13 09:37:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 180377 updates
2023-06-13 09:37:58 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint16.pt
2023-06-13 09:38:00 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint16.pt
2023-06-13 09:38:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint16.pt (epoch 16 @ 180377 updates, score 4.327) (writing took 4.861708211712539 seconds)
2023-06-13 09:38:03 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-06-13 09:38:03 | INFO | train | epoch 016 | loss 3.531 | nll_loss 1.826 | ppl 3.54 | wps 71139.7 | ups 1.2 | wpb 59500.8 | bsz 2227.6 | num_updates 180377 | lr 0.000235456 | gnorm 0.32 | loss_scale 2 | train_wall 8953 | gb_free 39.6 | wall 150704
2023-06-13 09:38:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-13 09:38:03 | INFO | fairseq.trainer | begin training epoch 17
2023-06-13 09:38:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-13 09:38:23 | INFO | train_inner | epoch 017:     23 / 11284 loss=3.544, nll_loss=1.84, ppl=3.58, wps=55974.4, ups=0.94, wpb=59345.2, bsz=2176.6, num_updates=180400, lr=0.000235441, gnorm=0.319, loss_scale=2, train_wall=79, gb_free=39.6, wall=150723
2023-06-13 09:39:45 | INFO | train_inner | epoch 017:    123 / 11284 loss=3.517, nll_loss=1.809, ppl=3.51, wps=72415.6, ups=1.22, wpb=59499.8, bsz=2242.3, num_updates=180500, lr=0.000235376, gnorm=0.31, loss_scale=2, train_wall=78, gb_free=39.6, wall=150805
2023-06-13 09:41:06 | INFO | train_inner | epoch 017:    223 / 11284 loss=3.519, nll_loss=1.812, ppl=3.51, wps=73294.4, ups=1.23, wpb=59676.3, bsz=2136.5, num_updates=180600, lr=0.00023531, gnorm=0.322, loss_scale=2, train_wall=78, gb_free=39.6, wall=150887
2023-06-13 09:42:28 | INFO | train_inner | epoch 017:    323 / 11284 loss=3.524, nll_loss=1.817, ppl=3.52, wps=72696.4, ups=1.22, wpb=59487.8, bsz=2164.1, num_updates=180700, lr=0.000235245, gnorm=0.326, loss_scale=2, train_wall=78, gb_free=39.6, wall=150969
2023-06-13 09:43:51 | INFO | train_inner | epoch 017:    423 / 11284 loss=3.52, nll_loss=1.813, ppl=3.51, wps=71477, ups=1.2, wpb=59595, bsz=2274.4, num_updates=180800, lr=0.00023518, gnorm=0.323, loss_scale=2, train_wall=79, gb_free=39.5, wall=151052
2023-06-13 09:45:14 | INFO | train_inner | epoch 017:    523 / 11284 loss=3.511, nll_loss=1.803, ppl=3.49, wps=72614.1, ups=1.22, wpb=59587, bsz=2247.8, num_updates=180900, lr=0.000235115, gnorm=0.317, loss_scale=2, train_wall=78, gb_free=39.6, wall=151134
2023-06-13 09:46:36 | INFO | train_inner | epoch 017:    623 / 11284 loss=3.534, nll_loss=1.828, ppl=3.55, wps=71738.5, ups=1.21, wpb=59468.4, bsz=2276.8, num_updates=181000, lr=0.00023505, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.5, wall=151217
2023-06-13 09:48:00 | INFO | train_inner | epoch 017:    723 / 11284 loss=3.53, nll_loss=1.823, ppl=3.54, wps=71211.3, ups=1.2, wpb=59418.6, bsz=2315.9, num_updates=181100, lr=0.000234985, gnorm=0.326, loss_scale=2, train_wall=80, gb_free=39.5, wall=151300
2023-06-13 09:49:23 | INFO | train_inner | epoch 017:    823 / 11284 loss=3.529, nll_loss=1.823, ppl=3.54, wps=71711.9, ups=1.21, wpb=59494.7, bsz=2220.9, num_updates=181200, lr=0.00023492, gnorm=0.322, loss_scale=4, train_wall=79, gb_free=39.6, wall=151383
2023-06-13 09:49:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 09:50:47 | INFO | train_inner | epoch 017:    924 / 11284 loss=3.515, nll_loss=1.807, ppl=3.5, wps=70762.5, ups=1.19, wpb=59512.9, bsz=2256.7, num_updates=181300, lr=0.000234856, gnorm=0.338, loss_scale=2, train_wall=80, gb_free=39.6, wall=151467
2023-06-13 09:52:10 | INFO | train_inner | epoch 017:   1024 / 11284 loss=3.527, nll_loss=1.821, ppl=3.53, wps=71498.9, ups=1.2, wpb=59405.4, bsz=2149.6, num_updates=181400, lr=0.000234791, gnorm=0.321, loss_scale=2, train_wall=79, gb_free=39.4, wall=151551
2023-06-13 09:53:33 | INFO | train_inner | epoch 017:   1124 / 11284 loss=3.519, nll_loss=1.812, ppl=3.51, wps=71663.9, ups=1.2, wpb=59558.7, bsz=2176, num_updates=181500, lr=0.000234726, gnorm=0.314, loss_scale=2, train_wall=79, gb_free=39.6, wall=151634
2023-06-13 09:54:56 | INFO | train_inner | epoch 017:   1224 / 11284 loss=3.52, nll_loss=1.813, ppl=3.51, wps=71449.2, ups=1.2, wpb=59483, bsz=2194.3, num_updates=181600, lr=0.000234662, gnorm=0.326, loss_scale=2, train_wall=79, gb_free=39.6, wall=151717
2023-06-13 09:56:19 | INFO | train_inner | epoch 017:   1324 / 11284 loss=3.519, nll_loss=1.811, ppl=3.51, wps=72479.7, ups=1.22, wpb=59606.4, bsz=2273, num_updates=181700, lr=0.000234597, gnorm=0.323, loss_scale=2, train_wall=78, gb_free=39.6, wall=151799
2023-06-13 09:57:41 | INFO | train_inner | epoch 017:   1424 / 11284 loss=3.515, nll_loss=1.807, ppl=3.5, wps=71912.6, ups=1.21, wpb=59559.7, bsz=2221.5, num_updates=181800, lr=0.000234533, gnorm=0.335, loss_scale=2, train_wall=79, gb_free=39.6, wall=151882
2023-06-13 09:59:05 | INFO | train_inner | epoch 017:   1524 / 11284 loss=3.525, nll_loss=1.818, ppl=3.53, wps=70779.2, ups=1.19, wpb=59453.9, bsz=2210.1, num_updates=181900, lr=0.000234468, gnorm=0.317, loss_scale=2, train_wall=80, gb_free=39.6, wall=151966
2023-06-13 10:00:29 | INFO | train_inner | epoch 017:   1624 / 11284 loss=3.511, nll_loss=1.803, ppl=3.49, wps=71246.5, ups=1.2, wpb=59469.3, bsz=2212.2, num_updates=182000, lr=0.000234404, gnorm=0.322, loss_scale=2, train_wall=80, gb_free=39.6, wall=152049
2023-06-13 10:01:52 | INFO | train_inner | epoch 017:   1724 / 11284 loss=3.503, nll_loss=1.793, ppl=3.47, wps=71316.7, ups=1.2, wpb=59590.7, bsz=2253.3, num_updates=182100, lr=0.000234339, gnorm=0.322, loss_scale=2, train_wall=79, gb_free=39.4, wall=152133
2023-06-13 10:03:15 | INFO | train_inner | epoch 017:   1824 / 11284 loss=3.523, nll_loss=1.816, ppl=3.52, wps=72537.3, ups=1.22, wpb=59668.8, bsz=2252.3, num_updates=182200, lr=0.000234275, gnorm=0.318, loss_scale=2, train_wall=78, gb_free=39.6, wall=152215
2023-06-13 10:04:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 10:04:39 | INFO | train_inner | epoch 017:   1925 / 11284 loss=3.532, nll_loss=1.826, ppl=3.55, wps=70881.9, ups=1.19, wpb=59405.1, bsz=2282.5, num_updates=182300, lr=0.000234211, gnorm=0.32, loss_scale=2, train_wall=80, gb_free=39.4, wall=152299
2023-06-13 10:06:02 | INFO | train_inner | epoch 017:   2025 / 11284 loss=3.509, nll_loss=1.801, ppl=3.48, wps=71150.7, ups=1.19, wpb=59548.9, bsz=2162.6, num_updates=182400, lr=0.000234146, gnorm=0.318, loss_scale=2, train_wall=80, gb_free=39.6, wall=152383
2023-06-13 10:07:25 | INFO | train_inner | epoch 017:   2125 / 11284 loss=3.533, nll_loss=1.827, ppl=3.55, wps=71833.6, ups=1.21, wpb=59360.3, bsz=2185.3, num_updates=182500, lr=0.000234082, gnorm=0.33, loss_scale=2, train_wall=79, gb_free=39.6, wall=152465
2023-06-13 10:08:47 | INFO | train_inner | epoch 017:   2225 / 11284 loss=3.533, nll_loss=1.827, ppl=3.55, wps=72671.5, ups=1.22, wpb=59646.6, bsz=2255.5, num_updates=182600, lr=0.000234018, gnorm=0.306, loss_scale=2, train_wall=78, gb_free=39.5, wall=152548
2023-06-13 10:10:09 | INFO | train_inner | epoch 017:   2325 / 11284 loss=3.521, nll_loss=1.814, ppl=3.52, wps=72555.2, ups=1.22, wpb=59636.2, bsz=2227.9, num_updates=182700, lr=0.000233954, gnorm=0.316, loss_scale=2, train_wall=78, gb_free=39.6, wall=152630
2023-06-13 10:11:31 | INFO | train_inner | epoch 017:   2425 / 11284 loss=3.535, nll_loss=1.829, ppl=3.55, wps=72718.9, ups=1.22, wpb=59572.2, bsz=2221.6, num_updates=182800, lr=0.00023389, gnorm=0.309, loss_scale=2, train_wall=78, gb_free=39.5, wall=152712
2023-06-13 10:12:54 | INFO | train_inner | epoch 017:   2525 / 11284 loss=3.515, nll_loss=1.807, ppl=3.5, wps=71991.6, ups=1.21, wpb=59383.1, bsz=2386.5, num_updates=182900, lr=0.000233826, gnorm=0.33, loss_scale=2, train_wall=78, gb_free=39.6, wall=152794
2023-06-13 10:14:16 | INFO | train_inner | epoch 017:   2625 / 11284 loss=3.521, nll_loss=1.814, ppl=3.52, wps=72296, ups=1.21, wpb=59531.5, bsz=2285.2, num_updates=183000, lr=0.000233762, gnorm=0.331, loss_scale=2, train_wall=78, gb_free=39.6, wall=152876
2023-06-13 10:15:40 | INFO | train_inner | epoch 017:   2725 / 11284 loss=3.52, nll_loss=1.812, ppl=3.51, wps=70469.3, ups=1.19, wpb=59455.2, bsz=2222.6, num_updates=183100, lr=0.000233698, gnorm=0.316, loss_scale=2, train_wall=81, gb_free=39.6, wall=152961
2023-06-13 10:17:04 | INFO | train_inner | epoch 017:   2825 / 11284 loss=3.535, nll_loss=1.83, ppl=3.56, wps=71363.6, ups=1.2, wpb=59455.4, bsz=2302.8, num_updates=183200, lr=0.000233635, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.6, wall=153044
2023-06-13 10:18:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 10:18:28 | INFO | train_inner | epoch 017:   2926 / 11284 loss=3.527, nll_loss=1.821, ppl=3.53, wps=70535.3, ups=1.18, wpb=59600.7, bsz=2232.9, num_updates=183300, lr=0.000233571, gnorm=0.319, loss_scale=2, train_wall=81, gb_free=39.6, wall=153129
2023-06-13 10:19:51 | INFO | train_inner | epoch 017:   3026 / 11284 loss=3.531, nll_loss=1.825, ppl=3.54, wps=71253, ups=1.2, wpb=59364.5, bsz=2153.6, num_updates=183400, lr=0.000233507, gnorm=0.317, loss_scale=2, train_wall=79, gb_free=39.5, wall=153212
2023-06-13 10:21:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-06-13 10:21:16 | INFO | train_inner | epoch 017:   3127 / 11284 loss=3.535, nll_loss=1.83, ppl=3.55, wps=70250.4, ups=1.18, wpb=59370.6, bsz=2223.6, num_updates=183500, lr=0.000233444, gnorm=0.319, loss_scale=1, train_wall=80, gb_free=39.6, wall=153296
2023-06-13 10:22:40 | INFO | train_inner | epoch 017:   3227 / 11284 loss=3.525, nll_loss=1.818, ppl=3.53, wps=71300.3, ups=1.19, wpb=59676.2, bsz=2281, num_updates=183600, lr=0.00023338, gnorm=0.32, loss_scale=1, train_wall=80, gb_free=39.6, wall=153380
2023-06-13 10:24:03 | INFO | train_inner | epoch 017:   3327 / 11284 loss=3.516, nll_loss=1.808, ppl=3.5, wps=71951.3, ups=1.2, wpb=59742.9, bsz=2242.9, num_updates=183700, lr=0.000233316, gnorm=0.332, loss_scale=1, train_wall=79, gb_free=39.5, wall=153463
2023-06-13 10:25:24 | INFO | train_inner | epoch 017:   3427 / 11284 loss=3.548, nll_loss=1.844, ppl=3.59, wps=72604.6, ups=1.23, wpb=59264, bsz=2154.3, num_updates=183800, lr=0.000233253, gnorm=0.324, loss_scale=1, train_wall=78, gb_free=39.6, wall=153545
2023-06-13 10:26:48 | INFO | train_inner | epoch 017:   3527 / 11284 loss=3.514, nll_loss=1.806, ppl=3.5, wps=70984.9, ups=1.2, wpb=59319.5, bsz=2166.2, num_updates=183900, lr=0.00023319, gnorm=0.318, loss_scale=1, train_wall=80, gb_free=39.6, wall=153628
2023-06-13 10:28:11 | INFO | train_inner | epoch 017:   3627 / 11284 loss=3.527, nll_loss=1.821, ppl=3.53, wps=71550.6, ups=1.2, wpb=59510.4, bsz=2266.3, num_updates=184000, lr=0.000233126, gnorm=0.331, loss_scale=1, train_wall=79, gb_free=39, wall=153712
2023-06-13 10:29:35 | INFO | train_inner | epoch 017:   3727 / 11284 loss=3.513, nll_loss=1.805, ppl=3.5, wps=71527.9, ups=1.2, wpb=59749.9, bsz=2241.8, num_updates=184100, lr=0.000233063, gnorm=0.33, loss_scale=1, train_wall=80, gb_free=39.5, wall=153795
2023-06-13 10:30:58 | INFO | train_inner | epoch 017:   3827 / 11284 loss=3.539, nll_loss=1.834, ppl=3.56, wps=71121.7, ups=1.2, wpb=59477.4, bsz=2272.4, num_updates=184200, lr=0.000233, gnorm=0.342, loss_scale=1, train_wall=79, gb_free=39.6, wall=153879
2023-06-13 10:32:21 | INFO | train_inner | epoch 017:   3927 / 11284 loss=3.532, nll_loss=1.826, ppl=3.55, wps=71552.1, ups=1.2, wpb=59510, bsz=2194.1, num_updates=184300, lr=0.000232936, gnorm=0.33, loss_scale=1, train_wall=79, gb_free=39.5, wall=153962
2023-06-13 10:33:45 | INFO | train_inner | epoch 017:   4027 / 11284 loss=3.529, nll_loss=1.823, ppl=3.54, wps=71305.4, ups=1.2, wpb=59561.8, bsz=2235.6, num_updates=184400, lr=0.000232873, gnorm=0.321, loss_scale=1, train_wall=80, gb_free=39.5, wall=154045
2023-06-13 10:35:08 | INFO | train_inner | epoch 017:   4127 / 11284 loss=3.53, nll_loss=1.824, ppl=3.54, wps=71378.3, ups=1.2, wpb=59530.8, bsz=2193.8, num_updates=184500, lr=0.00023281, gnorm=0.335, loss_scale=1, train_wall=79, gb_free=39.6, wall=154129
2023-06-13 10:36:31 | INFO | train_inner | epoch 017:   4227 / 11284 loss=3.536, nll_loss=1.831, ppl=3.56, wps=72174.7, ups=1.21, wpb=59707.7, bsz=2193.6, num_updates=184600, lr=0.000232747, gnorm=0.317, loss_scale=2, train_wall=79, gb_free=39.5, wall=154212
2023-06-13 10:37:54 | INFO | train_inner | epoch 017:   4327 / 11284 loss=3.525, nll_loss=1.818, ppl=3.53, wps=71658.1, ups=1.2, wpb=59577.2, bsz=2214.1, num_updates=184700, lr=0.000232684, gnorm=0.314, loss_scale=2, train_wall=79, gb_free=39.6, wall=154295
2023-06-13 10:39:16 | INFO | train_inner | epoch 017:   4427 / 11284 loss=3.532, nll_loss=1.826, ppl=3.55, wps=72289.9, ups=1.22, wpb=59480.7, bsz=2255.8, num_updates=184800, lr=0.000232621, gnorm=0.335, loss_scale=2, train_wall=78, gb_free=39.6, wall=154377
2023-06-13 10:40:40 | INFO | train_inner | epoch 017:   4527 / 11284 loss=3.515, nll_loss=1.807, ppl=3.5, wps=71566.1, ups=1.2, wpb=59500.6, bsz=2240.5, num_updates=184900, lr=0.000232558, gnorm=0.314, loss_scale=2, train_wall=79, gb_free=39.5, wall=154460
2023-06-13 10:42:03 | INFO | train_inner | epoch 017:   4627 / 11284 loss=3.533, nll_loss=1.827, ppl=3.55, wps=70992.4, ups=1.2, wpb=59259.7, bsz=2273.8, num_updates=185000, lr=0.000232495, gnorm=0.323, loss_scale=2, train_wall=79, gb_free=39.5, wall=154544
2023-06-13 10:43:25 | INFO | train_inner | epoch 017:   4727 / 11284 loss=3.524, nll_loss=1.817, ppl=3.52, wps=72318.3, ups=1.22, wpb=59489.6, bsz=2329.8, num_updates=185100, lr=0.000232432, gnorm=0.319, loss_scale=2, train_wall=78, gb_free=39.6, wall=154626
2023-06-13 10:44:48 | INFO | train_inner | epoch 017:   4827 / 11284 loss=3.523, nll_loss=1.816, ppl=3.52, wps=71785.6, ups=1.21, wpb=59505.1, bsz=2201.6, num_updates=185200, lr=0.00023237, gnorm=0.32, loss_scale=2, train_wall=79, gb_free=39.5, wall=154709
2023-06-13 10:46:12 | INFO | train_inner | epoch 017:   4927 / 11284 loss=3.523, nll_loss=1.816, ppl=3.52, wps=71506.7, ups=1.2, wpb=59700.8, bsz=2214.2, num_updates=185300, lr=0.000232307, gnorm=0.325, loss_scale=2, train_wall=80, gb_free=39.6, wall=154792
2023-06-13 10:47:35 | INFO | train_inner | epoch 017:   5027 / 11284 loss=3.532, nll_loss=1.826, ppl=3.55, wps=70931.8, ups=1.19, wpb=59386.6, bsz=2235.1, num_updates=185400, lr=0.000232244, gnorm=0.322, loss_scale=2, train_wall=80, gb_free=39.5, wall=154876
2023-06-13 10:48:59 | INFO | train_inner | epoch 017:   5127 / 11284 loss=3.525, nll_loss=1.819, ppl=3.53, wps=71323.6, ups=1.2, wpb=59585.8, bsz=2224.5, num_updates=185500, lr=0.000232182, gnorm=0.316, loss_scale=2, train_wall=79, gb_free=39.6, wall=154960
2023-06-13 10:50:23 | INFO | train_inner | epoch 017:   5227 / 11284 loss=3.536, nll_loss=1.831, ppl=3.56, wps=71203.7, ups=1.19, wpb=59612.5, bsz=2204.8, num_updates=185600, lr=0.000232119, gnorm=0.325, loss_scale=4, train_wall=80, gb_free=39.5, wall=155043
2023-06-13 10:50:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 10:51:46 | INFO | train_inner | epoch 017:   5328 / 11284 loss=3.516, nll_loss=1.809, ppl=3.5, wps=70686.5, ups=1.19, wpb=59216.8, bsz=2178.8, num_updates=185700, lr=0.000232057, gnorm=0.32, loss_scale=2, train_wall=80, gb_free=39.4, wall=155127
2023-06-13 10:53:10 | INFO | train_inner | epoch 017:   5428 / 11284 loss=3.529, nll_loss=1.823, ppl=3.54, wps=71768.7, ups=1.2, wpb=59611.8, bsz=2142, num_updates=185800, lr=0.000231994, gnorm=0.324, loss_scale=2, train_wall=79, gb_free=39.6, wall=155210
2023-06-13 10:54:33 | INFO | train_inner | epoch 017:   5528 / 11284 loss=3.541, nll_loss=1.836, ppl=3.57, wps=71302.7, ups=1.2, wpb=59267, bsz=2183.3, num_updates=185900, lr=0.000231932, gnorm=0.321, loss_scale=2, train_wall=79, gb_free=39.6, wall=155293
2023-06-13 10:55:56 | INFO | train_inner | epoch 017:   5628 / 11284 loss=3.514, nll_loss=1.807, ppl=3.5, wps=71718.7, ups=1.2, wpb=59725.5, bsz=2226.3, num_updates=186000, lr=0.000231869, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.6, wall=155377
2023-06-13 10:57:19 | INFO | train_inner | epoch 017:   5728 / 11284 loss=3.523, nll_loss=1.816, ppl=3.52, wps=71779.6, ups=1.2, wpb=59824.1, bsz=2217.5, num_updates=186100, lr=0.000231807, gnorm=0.307, loss_scale=2, train_wall=79, gb_free=39.6, wall=155460
2023-06-13 10:58:43 | INFO | train_inner | epoch 017:   5828 / 11284 loss=3.532, nll_loss=1.827, ppl=3.55, wps=71051.6, ups=1.2, wpb=59220.6, bsz=2271.7, num_updates=186200, lr=0.000231745, gnorm=0.331, loss_scale=2, train_wall=79, gb_free=39.6, wall=155543
2023-06-13 11:00:06 | INFO | train_inner | epoch 017:   5928 / 11284 loss=3.54, nll_loss=1.835, ppl=3.57, wps=70974.5, ups=1.2, wpb=59104.3, bsz=2237.7, num_updates=186300, lr=0.000231683, gnorm=0.328, loss_scale=2, train_wall=79, gb_free=39.6, wall=155626
2023-06-13 11:01:30 | INFO | train_inner | epoch 017:   6028 / 11284 loss=3.534, nll_loss=1.829, ppl=3.55, wps=70954.1, ups=1.2, wpb=59375.8, bsz=2228, num_updates=186400, lr=0.000231621, gnorm=0.323, loss_scale=2, train_wall=80, gb_free=39.5, wall=155710
2023-06-13 11:02:52 | INFO | train_inner | epoch 017:   6128 / 11284 loss=3.526, nll_loss=1.82, ppl=3.53, wps=72445.7, ups=1.22, wpb=59559.3, bsz=2206.9, num_updates=186500, lr=0.000231558, gnorm=0.329, loss_scale=2, train_wall=78, gb_free=39.5, wall=155792
2023-06-13 11:04:15 | INFO | train_inner | epoch 017:   6228 / 11284 loss=3.542, nll_loss=1.838, ppl=3.57, wps=71184.7, ups=1.2, wpb=59345.2, bsz=2214.2, num_updates=186600, lr=0.000231496, gnorm=0.33, loss_scale=2, train_wall=79, gb_free=39.3, wall=155876
2023-06-13 11:04:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 11:05:39 | INFO | train_inner | epoch 017:   6329 / 11284 loss=3.539, nll_loss=1.834, ppl=3.57, wps=70777.4, ups=1.19, wpb=59487.9, bsz=2251, num_updates=186700, lr=0.000231434, gnorm=0.326, loss_scale=2, train_wall=80, gb_free=39.6, wall=155960
2023-06-13 11:07:01 | INFO | train_inner | epoch 017:   6429 / 11284 loss=3.521, nll_loss=1.815, ppl=3.52, wps=72722.4, ups=1.22, wpb=59607.2, bsz=2216.9, num_updates=186800, lr=0.000231372, gnorm=0.316, loss_scale=2, train_wall=78, gb_free=39.5, wall=156042
2023-06-13 11:08:24 | INFO | train_inner | epoch 017:   6529 / 11284 loss=3.523, nll_loss=1.816, ppl=3.52, wps=71951.5, ups=1.21, wpb=59474.1, bsz=2190.4, num_updates=186900, lr=0.000231311, gnorm=0.325, loss_scale=2, train_wall=79, gb_free=39.5, wall=156124
2023-06-13 11:09:47 | INFO | train_inner | epoch 017:   6629 / 11284 loss=3.535, nll_loss=1.83, ppl=3.56, wps=71339.1, ups=1.2, wpb=59634.3, bsz=2265.9, num_updates=187000, lr=0.000231249, gnorm=0.317, loss_scale=2, train_wall=79, gb_free=39.6, wall=156208
2023-06-13 11:11:11 | INFO | train_inner | epoch 017:   6729 / 11284 loss=3.534, nll_loss=1.829, ppl=3.55, wps=71514.5, ups=1.2, wpb=59501.9, bsz=2234.6, num_updates=187100, lr=0.000231187, gnorm=0.325, loss_scale=2, train_wall=79, gb_free=39.6, wall=156291
2023-06-13 11:12:34 | INFO | train_inner | epoch 017:   6829 / 11284 loss=3.514, nll_loss=1.806, ppl=3.5, wps=71493.9, ups=1.2, wpb=59539.7, bsz=2164, num_updates=187200, lr=0.000231125, gnorm=0.316, loss_scale=2, train_wall=80, gb_free=39.6, wall=156374
2023-06-13 11:13:57 | INFO | train_inner | epoch 017:   6929 / 11284 loss=3.526, nll_loss=1.819, ppl=3.53, wps=71395.2, ups=1.2, wpb=59585.1, bsz=2224.3, num_updates=187300, lr=0.000231063, gnorm=0.328, loss_scale=2, train_wall=79, gb_free=39.6, wall=156458
2023-06-13 11:15:19 | INFO | train_inner | epoch 017:   7029 / 11284 loss=3.545, nll_loss=1.841, ppl=3.58, wps=72583.5, ups=1.22, wpb=59266.3, bsz=2233.4, num_updates=187400, lr=0.000231002, gnorm=0.327, loss_scale=2, train_wall=77, gb_free=39.6, wall=156540
2023-06-13 11:16:42 | INFO | train_inner | epoch 017:   7129 / 11284 loss=3.527, nll_loss=1.821, ppl=3.53, wps=71990.8, ups=1.21, wpb=59408, bsz=2140.2, num_updates=187500, lr=0.00023094, gnorm=0.325, loss_scale=2, train_wall=79, gb_free=39.6, wall=156622
2023-06-13 11:18:05 | INFO | train_inner | epoch 017:   7229 / 11284 loss=3.532, nll_loss=1.827, ppl=3.55, wps=71178.2, ups=1.2, wpb=59367.3, bsz=2216.5, num_updates=187600, lr=0.000230879, gnorm=0.322, loss_scale=2, train_wall=79, gb_free=39.6, wall=156706
2023-06-13 11:19:28 | INFO | train_inner | epoch 017:   7329 / 11284 loss=3.525, nll_loss=1.819, ppl=3.53, wps=71227.8, ups=1.2, wpb=59316.6, bsz=2277.8, num_updates=187700, lr=0.000230817, gnorm=0.328, loss_scale=4, train_wall=79, gb_free=39.6, wall=156789
2023-06-13 11:20:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 11:20:52 | INFO | train_inner | epoch 017:   7430 / 11284 loss=3.521, nll_loss=1.814, ppl=3.52, wps=70953.2, ups=1.19, wpb=59711.8, bsz=2202, num_updates=187800, lr=0.000230756, gnorm=0.317, loss_scale=2, train_wall=80, gb_free=39.6, wall=156873
2023-06-13 11:22:16 | INFO | train_inner | epoch 017:   7530 / 11284 loss=3.525, nll_loss=1.819, ppl=3.53, wps=71341.8, ups=1.2, wpb=59321, bsz=2208.1, num_updates=187900, lr=0.000230694, gnorm=0.324, loss_scale=2, train_wall=79, gb_free=39.6, wall=156956
2023-06-13 11:23:39 | INFO | train_inner | epoch 017:   7630 / 11284 loss=3.533, nll_loss=1.827, ppl=3.55, wps=71399.5, ups=1.2, wpb=59574.5, bsz=2194.4, num_updates=188000, lr=0.000230633, gnorm=0.331, loss_scale=2, train_wall=79, gb_free=39.6, wall=157040
2023-06-13 11:25:02 | INFO | train_inner | epoch 017:   7730 / 11284 loss=3.531, nll_loss=1.826, ppl=3.55, wps=71250.5, ups=1.2, wpb=59418.4, bsz=2293.8, num_updates=188100, lr=0.000230571, gnorm=0.315, loss_scale=2, train_wall=80, gb_free=39.6, wall=157123
2023-06-13 11:26:25 | INFO | train_inner | epoch 017:   7830 / 11284 loss=3.52, nll_loss=1.813, ppl=3.51, wps=71819.1, ups=1.21, wpb=59547.4, bsz=2259.7, num_updates=188200, lr=0.00023051, gnorm=0.325, loss_scale=2, train_wall=79, gb_free=39.6, wall=157206
2023-06-13 11:27:49 | INFO | train_inner | epoch 017:   7930 / 11284 loss=3.526, nll_loss=1.82, ppl=3.53, wps=71183.6, ups=1.19, wpb=59599.9, bsz=2332, num_updates=188300, lr=0.000230449, gnorm=0.326, loss_scale=2, train_wall=80, gb_free=39.6, wall=157290
2023-06-13 11:29:13 | INFO | train_inner | epoch 017:   8030 / 11284 loss=3.531, nll_loss=1.825, ppl=3.54, wps=71053.5, ups=1.2, wpb=59320.3, bsz=2169.5, num_updates=188400, lr=0.000230388, gnorm=0.332, loss_scale=2, train_wall=80, gb_free=39.6, wall=157373
2023-06-13 11:30:36 | INFO | train_inner | epoch 017:   8130 / 11284 loss=3.521, nll_loss=1.814, ppl=3.52, wps=71371.6, ups=1.2, wpb=59389.9, bsz=2260.5, num_updates=188500, lr=0.000230327, gnorm=0.331, loss_scale=2, train_wall=79, gb_free=39.6, wall=157456
2023-06-13 11:31:58 | INFO | train_inner | epoch 017:   8230 / 11284 loss=3.535, nll_loss=1.829, ppl=3.55, wps=72462.3, ups=1.22, wpb=59471.5, bsz=2232.8, num_updates=188600, lr=0.000230266, gnorm=0.317, loss_scale=2, train_wall=78, gb_free=39.5, wall=157538
2023-06-13 11:33:21 | INFO | train_inner | epoch 017:   8330 / 11284 loss=3.528, nll_loss=1.822, ppl=3.54, wps=71704.3, ups=1.2, wpb=59542.6, bsz=2220.4, num_updates=188700, lr=0.000230205, gnorm=0.312, loss_scale=2, train_wall=79, gb_free=39.5, wall=157621
2023-06-13 11:34:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 11:34:45 | INFO | train_inner | epoch 017:   8431 / 11284 loss=3.521, nll_loss=1.815, ppl=3.52, wps=70368.5, ups=1.18, wpb=59543, bsz=2270.7, num_updates=188800, lr=0.000230144, gnorm=0.313, loss_scale=2, train_wall=81, gb_free=39.6, wall=157706
2023-06-13 11:36:09 | INFO | train_inner | epoch 017:   8531 / 11284 loss=3.532, nll_loss=1.826, ppl=3.55, wps=71549.7, ups=1.2, wpb=59629.2, bsz=2161.8, num_updates=188900, lr=0.000230083, gnorm=0.32, loss_scale=2, train_wall=80, gb_free=39.6, wall=157789
2023-06-13 11:37:32 | INFO | train_inner | epoch 017:   8631 / 11284 loss=3.522, nll_loss=1.815, ppl=3.52, wps=71354.2, ups=1.2, wpb=59336.7, bsz=2272.9, num_updates=189000, lr=0.000230022, gnorm=0.319, loss_scale=2, train_wall=79, gb_free=39.6, wall=157873
2023-06-13 11:38:55 | INFO | train_inner | epoch 017:   8731 / 11284 loss=3.514, nll_loss=1.807, ppl=3.5, wps=71488.5, ups=1.2, wpb=59644, bsz=2220.7, num_updates=189100, lr=0.000229961, gnorm=0.309, loss_scale=2, train_wall=80, gb_free=39.6, wall=157956
2023-06-13 11:40:17 | INFO | train_inner | epoch 017:   8831 / 11284 loss=3.53, nll_loss=1.824, ppl=3.54, wps=72533, ups=1.22, wpb=59458, bsz=2211.4, num_updates=189200, lr=0.0002299, gnorm=0.34, loss_scale=2, train_wall=78, gb_free=39.6, wall=158038
2023-06-13 11:41:39 | INFO | train_inner | epoch 017:   8931 / 11284 loss=3.53, nll_loss=1.825, ppl=3.54, wps=72329.7, ups=1.22, wpb=59251.5, bsz=2160.6, num_updates=189300, lr=0.00022984, gnorm=0.33, loss_scale=2, train_wall=78, gb_free=39.5, wall=158120
2023-06-13 11:43:02 | INFO | train_inner | epoch 017:   9031 / 11284 loss=3.534, nll_loss=1.829, ppl=3.55, wps=72118.4, ups=1.21, wpb=59407.2, bsz=2247, num_updates=189400, lr=0.000229779, gnorm=0.327, loss_scale=2, train_wall=78, gb_free=39.6, wall=158202
2023-06-13 11:44:24 | INFO | train_inner | epoch 017:   9131 / 11284 loss=3.53, nll_loss=1.825, ppl=3.54, wps=72586.9, ups=1.22, wpb=59506.8, bsz=2128.1, num_updates=189500, lr=0.000229718, gnorm=0.31, loss_scale=2, train_wall=78, gb_free=39.5, wall=158284
2023-06-13 11:45:46 | INFO | train_inner | epoch 017:   9231 / 11284 loss=3.537, nll_loss=1.833, ppl=3.56, wps=72223.4, ups=1.22, wpb=59308.8, bsz=2232.6, num_updates=189600, lr=0.000229658, gnorm=0.321, loss_scale=2, train_wall=78, gb_free=39.6, wall=158366
2023-06-13 11:47:09 | INFO | train_inner | epoch 017:   9331 / 11284 loss=3.519, nll_loss=1.812, ppl=3.51, wps=71251.2, ups=1.2, wpb=59195.1, bsz=2124.7, num_updates=189700, lr=0.000229597, gnorm=0.323, loss_scale=2, train_wall=79, gb_free=39.6, wall=158449
2023-06-13 11:48:32 | INFO | train_inner | epoch 017:   9431 / 11284 loss=3.541, nll_loss=1.837, ppl=3.57, wps=71621.9, ups=1.2, wpb=59635.5, bsz=2171.2, num_updates=189800, lr=0.000229537, gnorm=0.331, loss_scale=2, train_wall=79, gb_free=39.5, wall=158533
2023-06-13 11:49:55 | INFO | train_inner | epoch 017:   9531 / 11284 loss=3.533, nll_loss=1.828, ppl=3.55, wps=71269.2, ups=1.2, wpb=59329.7, bsz=2188.2, num_updates=189900, lr=0.000229476, gnorm=0.326, loss_scale=4, train_wall=79, gb_free=39.6, wall=158616
2023-06-13 11:50:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 11:51:20 | INFO | train_inner | epoch 017:   9632 / 11284 loss=3.528, nll_loss=1.822, ppl=3.54, wps=70552.4, ups=1.18, wpb=59754.3, bsz=2190.1, num_updates=190000, lr=0.000229416, gnorm=0.334, loss_scale=2, train_wall=81, gb_free=39.5, wall=158701
2023-06-13 11:52:43 | INFO | train_inner | epoch 017:   9732 / 11284 loss=3.54, nll_loss=1.836, ppl=3.57, wps=71457.8, ups=1.2, wpb=59472.6, bsz=2294.7, num_updates=190100, lr=0.000229355, gnorm=0.326, loss_scale=2, train_wall=79, gb_free=39.6, wall=158784
2023-06-13 11:54:06 | INFO | train_inner | epoch 017:   9832 / 11284 loss=3.531, nll_loss=1.826, ppl=3.55, wps=72102, ups=1.2, wpb=59914.9, bsz=2294.2, num_updates=190200, lr=0.000229295, gnorm=0.327, loss_scale=2, train_wall=79, gb_free=39, wall=158867
2023-06-13 11:55:30 | INFO | train_inner | epoch 017:   9932 / 11284 loss=3.529, nll_loss=1.823, ppl=3.54, wps=71661.2, ups=1.2, wpb=59565.3, bsz=2238.2, num_updates=190300, lr=0.000229235, gnorm=0.338, loss_scale=2, train_wall=79, gb_free=39.3, wall=158950
2023-06-13 11:56:52 | INFO | train_inner | epoch 017:  10032 / 11284 loss=3.532, nll_loss=1.826, ppl=3.55, wps=71873.6, ups=1.21, wpb=59611.7, bsz=2289.1, num_updates=190400, lr=0.000229175, gnorm=0.329, loss_scale=2, train_wall=79, gb_free=39.6, wall=159033
2023-06-13 11:58:15 | INFO | train_inner | epoch 017:  10132 / 11284 loss=3.527, nll_loss=1.821, ppl=3.53, wps=72217.1, ups=1.21, wpb=59597.7, bsz=2208.1, num_updates=190500, lr=0.000229114, gnorm=0.318, loss_scale=2, train_wall=78, gb_free=39.6, wall=159116
2023-06-13 11:59:38 | INFO | train_inner | epoch 017:  10232 / 11284 loss=3.519, nll_loss=1.812, ppl=3.51, wps=71341.5, ups=1.2, wpb=59526.2, bsz=2249.7, num_updates=190600, lr=0.000229054, gnorm=0.319, loss_scale=2, train_wall=80, gb_free=39.5, wall=159199
2023-06-13 12:01:01 | INFO | train_inner | epoch 017:  10332 / 11284 loss=3.518, nll_loss=1.812, ppl=3.51, wps=71831.8, ups=1.21, wpb=59331.7, bsz=2209.9, num_updates=190700, lr=0.000228994, gnorm=0.317, loss_scale=2, train_wall=79, gb_free=38.8, wall=159282
2023-06-13 12:02:24 | INFO | train_inner | epoch 017:  10432 / 11284 loss=3.534, nll_loss=1.828, ppl=3.55, wps=72097.6, ups=1.21, wpb=59490, bsz=2176.4, num_updates=190800, lr=0.000228934, gnorm=0.323, loss_scale=2, train_wall=78, gb_free=39.5, wall=159364
2023-06-13 12:03:47 | INFO | train_inner | epoch 017:  10532 / 11284 loss=3.544, nll_loss=1.84, ppl=3.58, wps=70912.4, ups=1.19, wpb=59360.6, bsz=2282.3, num_updates=190900, lr=0.000228874, gnorm=0.313, loss_scale=2, train_wall=80, gb_free=39.6, wall=159448
2023-06-13 12:05:10 | INFO | train_inner | epoch 017:  10632 / 11284 loss=3.525, nll_loss=1.819, ppl=3.53, wps=71657.6, ups=1.21, wpb=59409.8, bsz=2227.2, num_updates=191000, lr=0.000228814, gnorm=0.321, loss_scale=4, train_wall=79, gb_free=39.1, wall=159531
2023-06-13 12:05:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 12:06:35 | INFO | train_inner | epoch 017:  10733 / 11284 loss=3.529, nll_loss=1.823, ppl=3.54, wps=70412.8, ups=1.18, wpb=59461.3, bsz=2223.2, num_updates=191100, lr=0.000228755, gnorm=0.325, loss_scale=2, train_wall=80, gb_free=39.5, wall=159615
2023-06-13 12:07:58 | INFO | train_inner | epoch 017:  10833 / 11284 loss=3.528, nll_loss=1.823, ppl=3.54, wps=71180.6, ups=1.2, wpb=59511.7, bsz=2306.8, num_updates=191200, lr=0.000228695, gnorm=0.327, loss_scale=2, train_wall=80, gb_free=39.6, wall=159699
2023-06-13 12:09:21 | INFO | train_inner | epoch 017:  10933 / 11284 loss=3.542, nll_loss=1.838, ppl=3.57, wps=72093, ups=1.21, wpb=59448.7, bsz=2223.1, num_updates=191300, lr=0.000228635, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.6, wall=159781
2023-06-13 12:10:44 | INFO | train_inner | epoch 017:  11033 / 11284 loss=3.531, nll_loss=1.825, ppl=3.54, wps=71519.1, ups=1.2, wpb=59723.6, bsz=2206.6, num_updates=191400, lr=0.000228575, gnorm=0.314, loss_scale=2, train_wall=80, gb_free=38.7, wall=159865
2023-06-13 12:12:08 | INFO | train_inner | epoch 017:  11133 / 11284 loss=3.524, nll_loss=1.818, ppl=3.53, wps=71609.5, ups=1.2, wpb=59742.2, bsz=2246.2, num_updates=191500, lr=0.000228515, gnorm=0.321, loss_scale=2, train_wall=79, gb_free=39.5, wall=159948
2023-06-13 12:13:32 | INFO | train_inner | epoch 017:  11233 / 11284 loss=3.521, nll_loss=1.814, ppl=3.52, wps=71231.3, ups=1.19, wpb=59856.1, bsz=2268.5, num_updates=191600, lr=0.000228456, gnorm=0.322, loss_scale=2, train_wall=80, gb_free=39.6, wall=160032
2023-06-13 12:14:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-13 12:14:33 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 4.311 | nll_loss 2.632 | ppl 6.2 | bleu 21.04 | wps 3499.2 | wpb 2397.5 | bsz 71.5 | num_updates 191651 | best_loss 4.311
2023-06-13 12:14:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 191651 updates
2023-06-13 12:14:33 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint17.pt
2023-06-13 12:14:35 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint17.pt
2023-06-13 12:14:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint17.pt (epoch 17 @ 191651 updates, score 4.311) (writing took 6.961038066074252 seconds)
2023-06-13 12:14:40 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-06-13 12:14:40 | INFO | train | epoch 017 | loss 3.527 | nll_loss 1.821 | ppl 3.53 | wps 71388.2 | ups 1.2 | wpb 59501 | bsz 2227.4 | num_updates 191651 | lr 0.000228425 | gnorm 0.323 | loss_scale 2 | train_wall 8918 | gb_free 39.6 | wall 160100
2023-06-13 12:14:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-13 12:14:40 | INFO | fairseq.trainer | begin training epoch 18
2023-06-13 12:14:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-13 12:15:22 | INFO | train_inner | epoch 018:     49 / 11284 loss=3.522, nll_loss=1.815, ppl=3.52, wps=53726.4, ups=0.91, wpb=59227.6, bsz=2248.4, num_updates=191700, lr=0.000228396, gnorm=0.335, loss_scale=2, train_wall=80, gb_free=39.5, wall=160142
2023-06-13 12:16:47 | INFO | train_inner | epoch 018:    149 / 11284 loss=3.517, nll_loss=1.809, ppl=3.5, wps=69987.2, ups=1.17, wpb=59675.3, bsz=2250.8, num_updates=191800, lr=0.000228337, gnorm=0.316, loss_scale=2, train_wall=81, gb_free=39.5, wall=160228
2023-06-13 12:18:11 | INFO | train_inner | epoch 018:    249 / 11284 loss=3.516, nll_loss=1.808, ppl=3.5, wps=71455.7, ups=1.2, wpb=59596.2, bsz=2149.4, num_updates=191900, lr=0.000228277, gnorm=0.331, loss_scale=2, train_wall=80, gb_free=39.5, wall=160311
2023-06-13 12:19:34 | INFO | train_inner | epoch 018:    349 / 11284 loss=3.506, nll_loss=1.797, ppl=3.48, wps=71385.2, ups=1.2, wpb=59589.1, bsz=2249.5, num_updates=192000, lr=0.000228218, gnorm=0.32, loss_scale=2, train_wall=80, gb_free=39.5, wall=160395
2023-06-13 12:20:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 12:20:59 | INFO | train_inner | epoch 018:    450 / 11284 loss=3.516, nll_loss=1.809, ppl=3.5, wps=70205.4, ups=1.18, wpb=59493.1, bsz=2249.8, num_updates=192100, lr=0.000228158, gnorm=0.316, loss_scale=2, train_wall=81, gb_free=39.5, wall=160479
2023-06-13 12:22:22 | INFO | train_inner | epoch 018:    550 / 11284 loss=3.507, nll_loss=1.798, ppl=3.48, wps=71835.1, ups=1.21, wpb=59427, bsz=2238.4, num_updates=192200, lr=0.000228099, gnorm=0.316, loss_scale=2, train_wall=79, gb_free=39.6, wall=160562
2023-06-13 12:23:45 | INFO | train_inner | epoch 018:    650 / 11284 loss=3.519, nll_loss=1.811, ppl=3.51, wps=71506.7, ups=1.2, wpb=59509.8, bsz=2182.6, num_updates=192300, lr=0.00022804, gnorm=0.321, loss_scale=2, train_wall=80, gb_free=39.6, wall=160645
2023-06-13 12:25:08 | INFO | train_inner | epoch 018:    750 / 11284 loss=3.526, nll_loss=1.82, ppl=3.53, wps=71457.6, ups=1.2, wpb=59522.2, bsz=2198.3, num_updates=192400, lr=0.00022798, gnorm=0.324, loss_scale=2, train_wall=80, gb_free=39.5, wall=160729
2023-06-13 12:26:32 | INFO | train_inner | epoch 018:    850 / 11284 loss=3.517, nll_loss=1.81, ppl=3.51, wps=70930.6, ups=1.19, wpb=59476.1, bsz=2365.5, num_updates=192500, lr=0.000227921, gnorm=0.338, loss_scale=2, train_wall=80, gb_free=39.6, wall=160812
2023-06-13 12:27:55 | INFO | train_inner | epoch 018:    950 / 11284 loss=3.511, nll_loss=1.803, ppl=3.49, wps=71582.3, ups=1.2, wpb=59601.7, bsz=2190.7, num_updates=192600, lr=0.000227862, gnorm=0.324, loss_scale=2, train_wall=80, gb_free=39.6, wall=160896
2023-06-13 12:29:19 | INFO | train_inner | epoch 018:   1050 / 11284 loss=3.521, nll_loss=1.814, ppl=3.52, wps=71025.5, ups=1.2, wpb=59402, bsz=2154.1, num_updates=192700, lr=0.000227803, gnorm=0.323, loss_scale=2, train_wall=80, gb_free=39.6, wall=160979
2023-06-13 12:30:42 | INFO | train_inner | epoch 018:   1150 / 11284 loss=3.51, nll_loss=1.801, ppl=3.49, wps=71568.9, ups=1.2, wpb=59422.9, bsz=2239.3, num_updates=192800, lr=0.000227744, gnorm=0.324, loss_scale=2, train_wall=79, gb_free=39.5, wall=161062
2023-06-13 12:32:06 | INFO | train_inner | epoch 018:   1250 / 11284 loss=3.512, nll_loss=1.803, ppl=3.49, wps=71184.2, ups=1.19, wpb=59620.6, bsz=2263.9, num_updates=192900, lr=0.000227685, gnorm=0.318, loss_scale=2, train_wall=80, gb_free=39.6, wall=161146
2023-06-13 12:33:29 | INFO | train_inner | epoch 018:   1350 / 11284 loss=3.519, nll_loss=1.812, ppl=3.51, wps=71049.8, ups=1.19, wpb=59471.4, bsz=2354.7, num_updates=193000, lr=0.000227626, gnorm=0.337, loss_scale=2, train_wall=80, gb_free=39.5, wall=161230
2023-06-13 12:34:53 | INFO | train_inner | epoch 018:   1450 / 11284 loss=3.52, nll_loss=1.813, ppl=3.51, wps=71586.9, ups=1.2, wpb=59648.2, bsz=2285.1, num_updates=193100, lr=0.000227567, gnorm=0.319, loss_scale=4, train_wall=79, gb_free=39.6, wall=161313
2023-06-13 12:35:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 12:36:17 | INFO | train_inner | epoch 018:   1551 / 11284 loss=3.524, nll_loss=1.817, ppl=3.52, wps=70573.6, ups=1.18, wpb=59597.7, bsz=2263, num_updates=193200, lr=0.000227508, gnorm=0.337, loss_scale=2, train_wall=80, gb_free=39.6, wall=161398
2023-06-13 12:37:40 | INFO | train_inner | epoch 018:   1651 / 11284 loss=3.508, nll_loss=1.8, ppl=3.48, wps=71616, ups=1.2, wpb=59474.9, bsz=2208.8, num_updates=193300, lr=0.000227449, gnorm=0.323, loss_scale=2, train_wall=79, gb_free=39.6, wall=161481
2023-06-13 12:39:03 | INFO | train_inner | epoch 018:   1751 / 11284 loss=3.527, nll_loss=1.82, ppl=3.53, wps=71422.7, ups=1.2, wpb=59360.8, bsz=2212.5, num_updates=193400, lr=0.00022739, gnorm=0.343, loss_scale=2, train_wall=79, gb_free=39.5, wall=161564
2023-06-13 12:40:27 | INFO | train_inner | epoch 018:   1851 / 11284 loss=3.51, nll_loss=1.802, ppl=3.49, wps=71552.2, ups=1.2, wpb=59735.6, bsz=2191.2, num_updates=193500, lr=0.000227331, gnorm=0.324, loss_scale=2, train_wall=79, gb_free=39.6, wall=161647
2023-06-13 12:41:50 | INFO | train_inner | epoch 018:   1951 / 11284 loss=3.519, nll_loss=1.812, ppl=3.51, wps=71541.2, ups=1.2, wpb=59519.3, bsz=2329.6, num_updates=193600, lr=0.000227273, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.6, wall=161730
2023-06-13 12:43:13 | INFO | train_inner | epoch 018:   2051 / 11284 loss=3.529, nll_loss=1.823, ppl=3.54, wps=71700.3, ups=1.21, wpb=59427.2, bsz=2217.6, num_updates=193700, lr=0.000227214, gnorm=0.329, loss_scale=2, train_wall=79, gb_free=39.6, wall=161813
2023-06-13 12:44:36 | INFO | train_inner | epoch 018:   2151 / 11284 loss=3.531, nll_loss=1.825, ppl=3.54, wps=71238.4, ups=1.2, wpb=59469.6, bsz=2235.2, num_updates=193800, lr=0.000227155, gnorm=0.336, loss_scale=2, train_wall=80, gb_free=39.6, wall=161897
2023-06-13 12:45:59 | INFO | train_inner | epoch 018:   2251 / 11284 loss=3.52, nll_loss=1.813, ppl=3.51, wps=71733.6, ups=1.21, wpb=59517.6, bsz=2192.1, num_updates=193900, lr=0.000227097, gnorm=0.322, loss_scale=2, train_wall=79, gb_free=39.6, wall=161980
2023-06-13 12:47:22 | INFO | train_inner | epoch 018:   2351 / 11284 loss=3.512, nll_loss=1.804, ppl=3.49, wps=71929.4, ups=1.21, wpb=59612.4, bsz=2257.7, num_updates=194000, lr=0.000227038, gnorm=0.323, loss_scale=2, train_wall=79, gb_free=39.6, wall=162063
2023-06-13 12:48:45 | INFO | train_inner | epoch 018:   2451 / 11284 loss=3.536, nll_loss=1.831, ppl=3.56, wps=71953.6, ups=1.21, wpb=59457.8, bsz=2176.1, num_updates=194100, lr=0.00022698, gnorm=0.33, loss_scale=2, train_wall=79, gb_free=39.5, wall=162145
2023-06-13 12:49:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 12:50:09 | INFO | train_inner | epoch 018:   2552 / 11284 loss=3.521, nll_loss=1.814, ppl=3.52, wps=70770.4, ups=1.19, wpb=59532.4, bsz=2185.3, num_updates=194200, lr=0.000226921, gnorm=0.319, loss_scale=2, train_wall=80, gb_free=39.6, wall=162229
2023-06-13 12:51:32 | INFO | train_inner | epoch 018:   2652 / 11284 loss=3.521, nll_loss=1.814, ppl=3.52, wps=71187.4, ups=1.2, wpb=59479.4, bsz=2275.7, num_updates=194300, lr=0.000226863, gnorm=0.319, loss_scale=2, train_wall=80, gb_free=39.6, wall=162313
2023-06-13 12:52:56 | INFO | train_inner | epoch 018:   2752 / 11284 loss=3.521, nll_loss=1.814, ppl=3.52, wps=71761.2, ups=1.2, wpb=59668.6, bsz=2239.9, num_updates=194400, lr=0.000226805, gnorm=0.321, loss_scale=2, train_wall=79, gb_free=39.5, wall=162396
2023-06-13 12:54:18 | INFO | train_inner | epoch 018:   2852 / 11284 loss=3.523, nll_loss=1.816, ppl=3.52, wps=72229.7, ups=1.21, wpb=59489.9, bsz=2276.7, num_updates=194500, lr=0.000226746, gnorm=0.332, loss_scale=2, train_wall=78, gb_free=39.6, wall=162479
2023-06-13 12:55:40 | INFO | train_inner | epoch 018:   2952 / 11284 loss=3.522, nll_loss=1.815, ppl=3.52, wps=72806, ups=1.22, wpb=59622.5, bsz=2193.4, num_updates=194600, lr=0.000226688, gnorm=0.331, loss_scale=2, train_wall=78, gb_free=39.6, wall=162560
2023-06-13 12:57:02 | INFO | train_inner | epoch 018:   3052 / 11284 loss=3.531, nll_loss=1.825, ppl=3.54, wps=72582, ups=1.22, wpb=59497.6, bsz=2273.6, num_updates=194700, lr=0.00022663, gnorm=0.319, loss_scale=2, train_wall=78, gb_free=39.5, wall=162642
2023-06-13 12:58:25 | INFO | train_inner | epoch 018:   3152 / 11284 loss=3.534, nll_loss=1.828, ppl=3.55, wps=71701.2, ups=1.21, wpb=59499.6, bsz=2262, num_updates=194800, lr=0.000226572, gnorm=0.322, loss_scale=2, train_wall=79, gb_free=39.6, wall=162725
2023-06-13 12:59:48 | INFO | train_inner | epoch 018:   3252 / 11284 loss=3.518, nll_loss=1.81, ppl=3.51, wps=71751.9, ups=1.2, wpb=59550.1, bsz=2210.1, num_updates=194900, lr=0.000226513, gnorm=0.329, loss_scale=2, train_wall=79, gb_free=39.6, wall=162808
2023-06-13 13:01:10 | INFO | train_inner | epoch 018:   3352 / 11284 loss=3.525, nll_loss=1.818, ppl=3.53, wps=72528.4, ups=1.22, wpb=59609.8, bsz=2218.5, num_updates=195000, lr=0.000226455, gnorm=0.325, loss_scale=2, train_wall=78, gb_free=39.6, wall=162891
2023-06-13 13:02:33 | INFO | train_inner | epoch 018:   3452 / 11284 loss=3.532, nll_loss=1.826, ppl=3.55, wps=71551, ups=1.2, wpb=59626.9, bsz=2236.4, num_updates=195100, lr=0.000226397, gnorm=0.334, loss_scale=2, train_wall=79, gb_free=39.6, wall=162974
2023-06-13 13:03:57 | INFO | train_inner | epoch 018:   3552 / 11284 loss=3.52, nll_loss=1.813, ppl=3.51, wps=71021.7, ups=1.2, wpb=59335.6, bsz=2177.4, num_updates=195200, lr=0.000226339, gnorm=0.326, loss_scale=4, train_wall=79, gb_free=39.6, wall=163057
2023-06-13 13:05:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 13:05:20 | INFO | train_inner | epoch 018:   3653 / 11284 loss=3.513, nll_loss=1.805, ppl=3.5, wps=71789.1, ups=1.2, wpb=59628.5, bsz=2207.4, num_updates=195300, lr=0.000226281, gnorm=0.319, loss_scale=2, train_wall=79, gb_free=39.6, wall=163140
2023-06-13 13:06:42 | INFO | train_inner | epoch 018:   3753 / 11284 loss=3.502, nll_loss=1.793, ppl=3.47, wps=72616, ups=1.22, wpb=59578.3, bsz=2173.2, num_updates=195400, lr=0.000226224, gnorm=0.317, loss_scale=2, train_wall=78, gb_free=39.6, wall=163223
2023-06-13 13:08:04 | INFO | train_inner | epoch 018:   3853 / 11284 loss=3.536, nll_loss=1.831, ppl=3.56, wps=72371, ups=1.21, wpb=59672.5, bsz=2290.6, num_updates=195500, lr=0.000226166, gnorm=0.33, loss_scale=2, train_wall=78, gb_free=39.6, wall=163305
2023-06-13 13:09:28 | INFO | train_inner | epoch 018:   3953 / 11284 loss=3.518, nll_loss=1.81, ppl=3.51, wps=71064.7, ups=1.19, wpb=59502.6, bsz=2271.5, num_updates=195600, lr=0.000226108, gnorm=0.325, loss_scale=2, train_wall=80, gb_free=39.6, wall=163389
2023-06-13 13:10:52 | INFO | train_inner | epoch 018:   4053 / 11284 loss=3.527, nll_loss=1.82, ppl=3.53, wps=71308.5, ups=1.2, wpb=59521.2, bsz=2210.4, num_updates=195700, lr=0.00022605, gnorm=0.324, loss_scale=2, train_wall=80, gb_free=39.6, wall=163472
2023-06-13 13:12:15 | INFO | train_inner | epoch 018:   4153 / 11284 loss=3.53, nll_loss=1.825, ppl=3.54, wps=71013.6, ups=1.2, wpb=59372.7, bsz=2185.1, num_updates=195800, lr=0.000225992, gnorm=0.327, loss_scale=2, train_wall=80, gb_free=39.6, wall=163556
2023-06-13 13:13:39 | INFO | train_inner | epoch 018:   4253 / 11284 loss=3.522, nll_loss=1.816, ppl=3.52, wps=71740.8, ups=1.2, wpb=59841.4, bsz=2302.3, num_updates=195900, lr=0.000225935, gnorm=0.328, loss_scale=2, train_wall=80, gb_free=39.6, wall=163639
2023-06-13 13:15:02 | INFO | train_inner | epoch 018:   4353 / 11284 loss=3.52, nll_loss=1.813, ppl=3.51, wps=71391.3, ups=1.2, wpb=59487.3, bsz=2179, num_updates=196000, lr=0.000225877, gnorm=0.322, loss_scale=2, train_wall=79, gb_free=39.6, wall=163723
2023-06-13 13:16:24 | INFO | train_inner | epoch 018:   4453 / 11284 loss=3.517, nll_loss=1.81, ppl=3.51, wps=72864.6, ups=1.22, wpb=59660.2, bsz=2277.5, num_updates=196100, lr=0.000225819, gnorm=0.319, loss_scale=2, train_wall=78, gb_free=39.5, wall=163804
2023-06-13 13:17:46 | INFO | train_inner | epoch 018:   4553 / 11284 loss=3.529, nll_loss=1.823, ppl=3.54, wps=72601.8, ups=1.22, wpb=59630.9, bsz=2197.2, num_updates=196200, lr=0.000225762, gnorm=0.312, loss_scale=2, train_wall=78, gb_free=39.6, wall=163887
2023-06-13 13:19:09 | INFO | train_inner | epoch 018:   4653 / 11284 loss=3.523, nll_loss=1.816, ppl=3.52, wps=71565.5, ups=1.2, wpb=59595.1, bsz=2204.2, num_updates=196300, lr=0.000225704, gnorm=0.324, loss_scale=2, train_wall=79, gb_free=39.6, wall=163970
2023-06-13 13:20:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 13:20:33 | INFO | train_inner | epoch 018:   4754 / 11284 loss=3.534, nll_loss=1.829, ppl=3.55, wps=70746, ups=1.19, wpb=59581.6, bsz=2218.5, num_updates=196400, lr=0.000225647, gnorm=0.327, loss_scale=2, train_wall=80, gb_free=39.6, wall=164054
2023-06-13 13:21:57 | INFO | train_inner | epoch 018:   4854 / 11284 loss=3.527, nll_loss=1.821, ppl=3.53, wps=71472.6, ups=1.2, wpb=59562.7, bsz=2246, num_updates=196500, lr=0.000225589, gnorm=0.32, loss_scale=2, train_wall=79, gb_free=39.6, wall=164137
2023-06-13 13:23:20 | INFO | train_inner | epoch 018:   4954 / 11284 loss=3.524, nll_loss=1.818, ppl=3.52, wps=71635.7, ups=1.21, wpb=59418.6, bsz=2228.6, num_updates=196600, lr=0.000225532, gnorm=0.334, loss_scale=2, train_wall=79, gb_free=39.6, wall=164220
2023-06-13 13:24:42 | INFO | train_inner | epoch 018:   5054 / 11284 loss=3.514, nll_loss=1.806, ppl=3.5, wps=72587.3, ups=1.22, wpb=59560.9, bsz=2181.5, num_updates=196700, lr=0.000225475, gnorm=0.32, loss_scale=2, train_wall=78, gb_free=39.5, wall=164302
2023-06-13 13:26:05 | INFO | train_inner | epoch 018:   5154 / 11284 loss=3.53, nll_loss=1.825, ppl=3.54, wps=72031.5, ups=1.21, wpb=59683.9, bsz=2304.2, num_updates=196800, lr=0.000225417, gnorm=0.319, loss_scale=2, train_wall=78, gb_free=39.6, wall=164385
2023-06-13 13:27:28 | INFO | train_inner | epoch 018:   5254 / 11284 loss=3.519, nll_loss=1.812, ppl=3.51, wps=71485, ups=1.2, wpb=59383.8, bsz=2211.6, num_updates=196900, lr=0.00022536, gnorm=0.326, loss_scale=2, train_wall=79, gb_free=39.6, wall=164468
2023-06-13 13:28:51 | INFO | train_inner | epoch 018:   5354 / 11284 loss=3.534, nll_loss=1.829, ppl=3.55, wps=71662.8, ups=1.2, wpb=59527.6, bsz=2204.5, num_updates=197000, lr=0.000225303, gnorm=0.334, loss_scale=2, train_wall=79, gb_free=39.5, wall=164551
2023-06-13 13:30:14 | INFO | train_inner | epoch 018:   5454 / 11284 loss=3.515, nll_loss=1.808, ppl=3.5, wps=71988.4, ups=1.21, wpb=59631.9, bsz=2239.1, num_updates=197100, lr=0.000225246, gnorm=0.32, loss_scale=2, train_wall=79, gb_free=39.6, wall=164634
2023-06-13 13:31:35 | INFO | train_inner | epoch 018:   5554 / 11284 loss=3.516, nll_loss=1.809, ppl=3.5, wps=72777.8, ups=1.22, wpb=59536.7, bsz=2196.6, num_updates=197200, lr=0.000225189, gnorm=0.327, loss_scale=2, train_wall=78, gb_free=39.6, wall=164716
2023-06-13 13:32:57 | INFO | train_inner | epoch 018:   5654 / 11284 loss=3.518, nll_loss=1.811, ppl=3.51, wps=72862, ups=1.22, wpb=59555, bsz=2231.3, num_updates=197300, lr=0.000225132, gnorm=0.318, loss_scale=2, train_wall=78, gb_free=39.6, wall=164798
2023-06-13 13:34:19 | INFO | train_inner | epoch 018:   5754 / 11284 loss=3.526, nll_loss=1.819, ppl=3.53, wps=72452.5, ups=1.22, wpb=59528.4, bsz=2229.5, num_updates=197400, lr=0.000225075, gnorm=0.332, loss_scale=4, train_wall=78, gb_free=39.6, wall=164880
2023-06-13 13:34:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 13:35:43 | INFO | train_inner | epoch 018:   5855 / 11284 loss=3.533, nll_loss=1.827, ppl=3.55, wps=70891.4, ups=1.19, wpb=59533.1, bsz=2183.8, num_updates=197500, lr=0.000225018, gnorm=0.325, loss_scale=2, train_wall=80, gb_free=39.6, wall=164964
2023-06-13 13:37:07 | INFO | train_inner | epoch 018:   5955 / 11284 loss=3.523, nll_loss=1.817, ppl=3.52, wps=71284.7, ups=1.2, wpb=59522.9, bsz=2272.7, num_updates=197600, lr=0.000224961, gnorm=0.341, loss_scale=2, train_wall=79, gb_free=39.6, wall=165047
2023-06-13 13:38:29 | INFO | train_inner | epoch 018:   6055 / 11284 loss=3.527, nll_loss=1.821, ppl=3.53, wps=72178.8, ups=1.21, wpb=59628.9, bsz=2175.8, num_updates=197700, lr=0.000224904, gnorm=0.322, loss_scale=2, train_wall=78, gb_free=39.6, wall=165130
2023-06-13 13:39:53 | INFO | train_inner | epoch 018:   6155 / 11284 loss=3.513, nll_loss=1.806, ppl=3.5, wps=71401.8, ups=1.2, wpb=59582, bsz=2299.2, num_updates=197800, lr=0.000224847, gnorm=0.326, loss_scale=2, train_wall=79, gb_free=39.5, wall=165213
2023-06-13 13:41:15 | INFO | train_inner | epoch 018:   6255 / 11284 loss=3.531, nll_loss=1.825, ppl=3.54, wps=72720.6, ups=1.22, wpb=59476.3, bsz=2263.4, num_updates=197900, lr=0.00022479, gnorm=0.325, loss_scale=2, train_wall=78, gb_free=39.6, wall=165295
2023-06-13 13:42:37 | INFO | train_inner | epoch 018:   6355 / 11284 loss=3.53, nll_loss=1.824, ppl=3.54, wps=72459, ups=1.22, wpb=59484.6, bsz=2238.3, num_updates=198000, lr=0.000224733, gnorm=0.331, loss_scale=2, train_wall=78, gb_free=39.6, wall=165377
2023-06-13 13:44:01 | INFO | train_inner | epoch 018:   6455 / 11284 loss=3.539, nll_loss=1.835, ppl=3.57, wps=70877.2, ups=1.19, wpb=59428.3, bsz=2306.6, num_updates=198100, lr=0.000224677, gnorm=0.335, loss_scale=2, train_wall=80, gb_free=39.6, wall=165461
2023-06-13 13:45:24 | INFO | train_inner | epoch 018:   6555 / 11284 loss=3.514, nll_loss=1.807, ppl=3.5, wps=71170.8, ups=1.19, wpb=59619.5, bsz=2370.7, num_updates=198200, lr=0.00022462, gnorm=0.319, loss_scale=2, train_wall=80, gb_free=39.6, wall=165545
2023-06-13 13:46:47 | INFO | train_inner | epoch 018:   6655 / 11284 loss=3.525, nll_loss=1.819, ppl=3.53, wps=71820.4, ups=1.21, wpb=59265.7, bsz=2191.6, num_updates=198300, lr=0.000224563, gnorm=0.33, loss_scale=2, train_wall=79, gb_free=39.6, wall=165628
2023-06-13 13:48:10 | INFO | train_inner | epoch 018:   6755 / 11284 loss=3.523, nll_loss=1.817, ppl=3.52, wps=71725.1, ups=1.2, wpb=59576.5, bsz=2151.1, num_updates=198400, lr=0.000224507, gnorm=0.31, loss_scale=2, train_wall=79, gb_free=39.6, wall=165711
2023-06-13 13:48:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 13:49:33 | INFO | train_inner | epoch 018:   6856 / 11284 loss=3.534, nll_loss=1.829, ppl=3.55, wps=71963.7, ups=1.21, wpb=59573, bsz=2300.4, num_updates=198500, lr=0.00022445, gnorm=0.317, loss_scale=2, train_wall=79, gb_free=39.6, wall=165793
2023-06-13 13:50:55 | INFO | train_inner | epoch 018:   6956 / 11284 loss=3.516, nll_loss=1.809, ppl=3.5, wps=72240.3, ups=1.22, wpb=59147.3, bsz=2170.4, num_updates=198600, lr=0.000224394, gnorm=0.319, loss_scale=2, train_wall=78, gb_free=39.6, wall=165875
2023-06-13 13:52:18 | INFO | train_inner | epoch 018:   7056 / 11284 loss=3.537, nll_loss=1.832, ppl=3.56, wps=71306.7, ups=1.2, wpb=59477.7, bsz=2310.8, num_updates=198700, lr=0.000224337, gnorm=0.333, loss_scale=2, train_wall=80, gb_free=39.6, wall=165959
2023-06-13 13:53:42 | INFO | train_inner | epoch 018:   7156 / 11284 loss=3.531, nll_loss=1.825, ppl=3.54, wps=71309.2, ups=1.2, wpb=59566.6, bsz=2264.6, num_updates=198800, lr=0.000224281, gnorm=0.324, loss_scale=2, train_wall=79, gb_free=39.6, wall=166042
2023-06-13 13:55:04 | INFO | train_inner | epoch 018:   7256 / 11284 loss=3.532, nll_loss=1.827, ppl=3.55, wps=72327.5, ups=1.22, wpb=59423.4, bsz=2261.7, num_updates=198900, lr=0.000224224, gnorm=0.338, loss_scale=2, train_wall=78, gb_free=39.5, wall=166124
2023-06-13 13:56:26 | INFO | train_inner | epoch 018:   7356 / 11284 loss=3.524, nll_loss=1.818, ppl=3.53, wps=72271.5, ups=1.21, wpb=59590.9, bsz=2198.1, num_updates=199000, lr=0.000224168, gnorm=0.33, loss_scale=2, train_wall=79, gb_free=39.5, wall=166207
2023-06-13 13:57:49 | INFO | train_inner | epoch 018:   7456 / 11284 loss=3.539, nll_loss=1.835, ppl=3.57, wps=71846, ups=1.2, wpb=59701.1, bsz=2158.6, num_updates=199100, lr=0.000224112, gnorm=0.321, loss_scale=2, train_wall=79, gb_free=39.6, wall=166290
2023-06-13 13:59:12 | INFO | train_inner | epoch 018:   7556 / 11284 loss=3.507, nll_loss=1.799, ppl=3.48, wps=71837.4, ups=1.21, wpb=59389.7, bsz=2346.2, num_updates=199200, lr=0.000224055, gnorm=0.323, loss_scale=2, train_wall=78, gb_free=39.6, wall=166373
2023-06-13 14:00:34 | INFO | train_inner | epoch 018:   7656 / 11284 loss=3.53, nll_loss=1.824, ppl=3.54, wps=72555.3, ups=1.22, wpb=59519.2, bsz=2212.5, num_updates=199300, lr=0.000223999, gnorm=0.328, loss_scale=2, train_wall=78, gb_free=39.5, wall=166455
2023-06-13 14:01:57 | INFO | train_inner | epoch 018:   7756 / 11284 loss=3.516, nll_loss=1.809, ppl=3.5, wps=71963, ups=1.21, wpb=59394.1, bsz=2218.1, num_updates=199400, lr=0.000223943, gnorm=0.328, loss_scale=2, train_wall=79, gb_free=39.6, wall=166537
2023-06-13 14:03:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 14:03:21 | INFO | train_inner | epoch 018:   7857 / 11284 loss=3.528, nll_loss=1.822, ppl=3.54, wps=70353.8, ups=1.18, wpb=59545.5, bsz=2206.6, num_updates=199500, lr=0.000223887, gnorm=0.324, loss_scale=2, train_wall=81, gb_free=39.5, wall=166622
2023-06-13 14:04:43 | INFO | train_inner | epoch 018:   7957 / 11284 loss=3.537, nll_loss=1.833, ppl=3.56, wps=72326.9, ups=1.22, wpb=59324.1, bsz=2280.3, num_updates=199600, lr=0.000223831, gnorm=0.355, loss_scale=2, train_wall=78, gb_free=39.6, wall=166704
2023-06-13 14:06:05 | INFO | train_inner | epoch 018:   8057 / 11284 loss=3.522, nll_loss=1.816, ppl=3.52, wps=72566.8, ups=1.22, wpb=59449.1, bsz=2156.6, num_updates=199700, lr=0.000223775, gnorm=0.329, loss_scale=2, train_wall=78, gb_free=38.9, wall=166786
2023-06-13 14:07:28 | INFO | train_inner | epoch 018:   8157 / 11284 loss=3.538, nll_loss=1.833, ppl=3.56, wps=71697, ups=1.2, wpb=59605.3, bsz=2202, num_updates=199800, lr=0.000223719, gnorm=0.323, loss_scale=2, train_wall=79, gb_free=39.6, wall=166869
2023-06-13 14:08:51 | INFO | train_inner | epoch 018:   8257 / 11284 loss=3.528, nll_loss=1.822, ppl=3.54, wps=71660.1, ups=1.21, wpb=59383.9, bsz=2194.9, num_updates=199900, lr=0.000223663, gnorm=0.322, loss_scale=2, train_wall=79, gb_free=39.6, wall=166952
2023-06-13 14:10:14 | INFO | train_inner | epoch 018:   8357 / 11284 loss=3.515, nll_loss=1.808, ppl=3.5, wps=71589.3, ups=1.2, wpb=59439.7, bsz=2262.2, num_updates=200000, lr=0.000223607, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.6, wall=167035
2023-06-13 14:11:36 | INFO | train_inner | epoch 018:   8457 / 11284 loss=3.538, nll_loss=1.834, ppl=3.56, wps=72031.8, ups=1.22, wpb=59263.7, bsz=2256.7, num_updates=200100, lr=0.000223551, gnorm=0.325, loss_scale=2, train_wall=78, gb_free=39.6, wall=167117
2023-06-13 14:12:59 | INFO | train_inner | epoch 018:   8557 / 11284 loss=3.52, nll_loss=1.813, ppl=3.51, wps=72325.1, ups=1.22, wpb=59510.3, bsz=2197.6, num_updates=200200, lr=0.000223495, gnorm=0.322, loss_scale=2, train_wall=78, gb_free=39.5, wall=167199
2023-06-13 14:14:21 | INFO | train_inner | epoch 018:   8657 / 11284 loss=3.518, nll_loss=1.811, ppl=3.51, wps=71960, ups=1.21, wpb=59340.1, bsz=2147.6, num_updates=200300, lr=0.000223439, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=167282
2023-06-13 14:15:45 | INFO | train_inner | epoch 018:   8757 / 11284 loss=3.512, nll_loss=1.804, ppl=3.49, wps=71066.8, ups=1.19, wpb=59474.5, bsz=2273.2, num_updates=200400, lr=0.000223384, gnorm=0.322, loss_scale=2, train_wall=80, gb_free=39.5, wall=167365
2023-06-13 14:17:09 | INFO | train_inner | epoch 018:   8857 / 11284 loss=3.527, nll_loss=1.821, ppl=3.53, wps=71115.1, ups=1.2, wpb=59493.6, bsz=2235.1, num_updates=200500, lr=0.000223328, gnorm=0.33, loss_scale=2, train_wall=80, gb_free=39.6, wall=167449
2023-06-13 14:18:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 14:18:33 | INFO | train_inner | epoch 018:   8958 / 11284 loss=3.518, nll_loss=1.811, ppl=3.51, wps=70359.1, ups=1.18, wpb=59397.5, bsz=2245.3, num_updates=200600, lr=0.000223272, gnorm=0.312, loss_scale=2, train_wall=80, gb_free=39.3, wall=167534
2023-06-13 14:19:56 | INFO | train_inner | epoch 018:   9058 / 11284 loss=3.524, nll_loss=1.818, ppl=3.53, wps=71237.8, ups=1.2, wpb=59313.2, bsz=2195.5, num_updates=200700, lr=0.000223217, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.6, wall=167617
2023-06-13 14:21:19 | INFO | train_inner | epoch 018:   9158 / 11284 loss=3.526, nll_loss=1.82, ppl=3.53, wps=71284.1, ups=1.2, wpb=59347.7, bsz=2210.5, num_updates=200800, lr=0.000223161, gnorm=0.323, loss_scale=2, train_wall=79, gb_free=39.6, wall=167700
2023-06-13 14:22:43 | INFO | train_inner | epoch 018:   9258 / 11284 loss=3.517, nll_loss=1.81, ppl=3.51, wps=71462.7, ups=1.2, wpb=59573.6, bsz=2130.1, num_updates=200900, lr=0.000223105, gnorm=0.316, loss_scale=2, train_wall=80, gb_free=39.6, wall=167783
2023-06-13 14:24:06 | INFO | train_inner | epoch 018:   9358 / 11284 loss=3.527, nll_loss=1.821, ppl=3.53, wps=71501.2, ups=1.2, wpb=59582.5, bsz=2304.4, num_updates=201000, lr=0.00022305, gnorm=0.32, loss_scale=2, train_wall=79, gb_free=39.6, wall=167867
2023-06-13 14:25:29 | INFO | train_inner | epoch 018:   9458 / 11284 loss=3.539, nll_loss=1.835, ppl=3.57, wps=71304.9, ups=1.2, wpb=59336.3, bsz=2223.5, num_updates=201100, lr=0.000222994, gnorm=0.333, loss_scale=2, train_wall=79, gb_free=39.6, wall=167950
2023-06-13 14:26:52 | INFO | train_inner | epoch 018:   9558 / 11284 loss=3.524, nll_loss=1.817, ppl=3.52, wps=71675.3, ups=1.21, wpb=59296.6, bsz=2337.5, num_updates=201200, lr=0.000222939, gnorm=0.343, loss_scale=2, train_wall=79, gb_free=39.6, wall=168033
2023-06-13 14:28:14 | INFO | train_inner | epoch 018:   9658 / 11284 loss=3.527, nll_loss=1.821, ppl=3.53, wps=72540.8, ups=1.22, wpb=59390.8, bsz=2282.6, num_updates=201300, lr=0.000222884, gnorm=0.326, loss_scale=2, train_wall=78, gb_free=39.6, wall=168115
2023-06-13 14:29:38 | INFO | train_inner | epoch 018:   9758 / 11284 loss=3.526, nll_loss=1.82, ppl=3.53, wps=70582.8, ups=1.19, wpb=59297.5, bsz=2207.1, num_updates=201400, lr=0.000222828, gnorm=0.325, loss_scale=2, train_wall=80, gb_free=39.6, wall=168199
2023-06-13 14:31:02 | INFO | train_inner | epoch 018:   9858 / 11284 loss=3.522, nll_loss=1.816, ppl=3.52, wps=70924.7, ups=1.19, wpb=59470.6, bsz=2186.4, num_updates=201500, lr=0.000222773, gnorm=0.326, loss_scale=2, train_wall=80, gb_free=39.6, wall=168282
2023-06-13 14:32:24 | INFO | train_inner | epoch 018:   9958 / 11284 loss=3.525, nll_loss=1.82, ppl=3.53, wps=72073.5, ups=1.21, wpb=59419.4, bsz=2237.6, num_updates=201600, lr=0.000222718, gnorm=0.325, loss_scale=4, train_wall=78, gb_free=39.6, wall=168365
2023-06-13 14:32:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 14:33:47 | INFO | train_inner | epoch 018:  10059 / 11284 loss=3.514, nll_loss=1.806, ppl=3.5, wps=72019.8, ups=1.21, wpb=59492.6, bsz=2204.7, num_updates=201700, lr=0.000222662, gnorm=0.325, loss_scale=2, train_wall=78, gb_free=39.4, wall=168448
2023-06-13 14:35:09 | INFO | train_inner | epoch 018:  10159 / 11284 loss=3.516, nll_loss=1.809, ppl=3.5, wps=72299, ups=1.22, wpb=59467.3, bsz=2190.1, num_updates=201800, lr=0.000222607, gnorm=0.324, loss_scale=2, train_wall=78, gb_free=39.6, wall=168530
2023-06-13 14:36:31 | INFO | train_inner | epoch 018:  10259 / 11284 loss=3.525, nll_loss=1.819, ppl=3.53, wps=72422.4, ups=1.22, wpb=59530.7, bsz=2103.6, num_updates=201900, lr=0.000222552, gnorm=0.329, loss_scale=2, train_wall=78, gb_free=39.6, wall=168612
2023-06-13 14:37:54 | INFO | train_inner | epoch 018:  10359 / 11284 loss=3.527, nll_loss=1.821, ppl=3.53, wps=72025.3, ups=1.21, wpb=59443.9, bsz=2091.9, num_updates=202000, lr=0.000222497, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.6, wall=168694
2023-06-13 14:39:16 | INFO | train_inner | epoch 018:  10459 / 11284 loss=3.514, nll_loss=1.806, ppl=3.5, wps=72605.9, ups=1.22, wpb=59596.1, bsz=2325.5, num_updates=202100, lr=0.000222442, gnorm=0.329, loss_scale=2, train_wall=78, gb_free=39.5, wall=168777
2023-06-13 14:40:39 | INFO | train_inner | epoch 018:  10559 / 11284 loss=3.533, nll_loss=1.828, ppl=3.55, wps=71714.2, ups=1.21, wpb=59449.8, bsz=2265.7, num_updates=202200, lr=0.000222387, gnorm=0.329, loss_scale=2, train_wall=79, gb_free=39.6, wall=168859
2023-06-13 14:42:02 | INFO | train_inner | epoch 018:  10659 / 11284 loss=3.511, nll_loss=1.803, ppl=3.49, wps=71618.5, ups=1.2, wpb=59528.8, bsz=2201.5, num_updates=202300, lr=0.000222332, gnorm=0.329, loss_scale=2, train_wall=79, gb_free=39.6, wall=168943
2023-06-13 14:43:25 | INFO | train_inner | epoch 018:  10759 / 11284 loss=3.533, nll_loss=1.828, ppl=3.55, wps=71304.1, ups=1.2, wpb=59406, bsz=2177, num_updates=202400, lr=0.000222277, gnorm=0.327, loss_scale=2, train_wall=79, gb_free=39.6, wall=169026
2023-06-13 14:44:48 | INFO | train_inner | epoch 018:  10859 / 11284 loss=3.536, nll_loss=1.831, ppl=3.56, wps=71462.9, ups=1.21, wpb=59300.3, bsz=2178.6, num_updates=202500, lr=0.000222222, gnorm=0.325, loss_scale=2, train_wall=79, gb_free=39.6, wall=169109
2023-06-13 14:46:11 | INFO | train_inner | epoch 018:  10959 / 11284 loss=3.509, nll_loss=1.802, ppl=3.49, wps=71644.3, ups=1.2, wpb=59565.5, bsz=2158.5, num_updates=202600, lr=0.000222167, gnorm=0.339, loss_scale=2, train_wall=79, gb_free=39.6, wall=169192
2023-06-13 14:47:35 | INFO | train_inner | epoch 018:  11059 / 11284 loss=3.525, nll_loss=1.819, ppl=3.53, wps=71111.5, ups=1.2, wpb=59463, bsz=2206.1, num_updates=202700, lr=0.000222113, gnorm=0.323, loss_scale=4, train_wall=80, gb_free=39, wall=169276
2023-06-13 14:48:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 14:48:59 | INFO | train_inner | epoch 018:  11160 / 11284 loss=3.51, nll_loss=1.802, ppl=3.49, wps=70757.7, ups=1.19, wpb=59648.3, bsz=2203.1, num_updates=202800, lr=0.000222058, gnorm=0.318, loss_scale=2, train_wall=80, gb_free=39.6, wall=169360
2023-06-13 14:50:23 | INFO | train_inner | epoch 018:  11260 / 11284 loss=3.532, nll_loss=1.827, ppl=3.55, wps=71221.7, ups=1.2, wpb=59309.1, bsz=2117.5, num_updates=202900, lr=0.000222003, gnorm=0.329, loss_scale=2, train_wall=80, gb_free=39.6, wall=169443
2023-06-13 14:50:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-13 14:51:01 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 4.309 | nll_loss 2.628 | ppl 6.18 | bleu 20.56 | wps 3586.9 | wpb 2397.5 | bsz 71.5 | num_updates 202924 | best_loss 4.309
2023-06-13 14:51:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 202924 updates
2023-06-13 14:51:01 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint18.pt
2023-06-13 14:51:03 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint18.pt
2023-06-13 14:51:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint18.pt (epoch 18 @ 202924 updates, score 4.309) (writing took 7.108284485526383 seconds)
2023-06-13 14:51:08 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-06-13 14:51:08 | INFO | train | epoch 018 | loss 3.523 | nll_loss 1.816 | ppl 3.52 | wps 71446.5 | ups 1.2 | wpb 59501.1 | bsz 2227.4 | num_updates 202924 | lr 0.00022199 | gnorm 0.326 | loss_scale 2 | train_wall 8908 | gb_free 39.5 | wall 169489
2023-06-13 14:51:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-13 14:51:08 | INFO | fairseq.trainer | begin training epoch 19
2023-06-13 14:51:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-13 14:52:11 | INFO | train_inner | epoch 019:     76 / 11284 loss=3.515, nll_loss=1.808, ppl=3.5, wps=54656.9, ups=0.92, wpb=59255.3, bsz=2185.9, num_updates=203000, lr=0.000221948, gnorm=0.327, loss_scale=2, train_wall=78, gb_free=39.6, wall=169552
2023-06-13 14:53:33 | INFO | train_inner | epoch 019:    176 / 11284 loss=3.514, nll_loss=1.806, ppl=3.5, wps=72375.5, ups=1.22, wpb=59425.6, bsz=2264.4, num_updates=203100, lr=0.000221894, gnorm=0.347, loss_scale=2, train_wall=78, gb_free=39.6, wall=169634
2023-06-13 14:54:56 | INFO | train_inner | epoch 019:    276 / 11284 loss=3.523, nll_loss=1.816, ppl=3.52, wps=71573.9, ups=1.2, wpb=59407.7, bsz=2239.1, num_updates=203200, lr=0.000221839, gnorm=0.324, loss_scale=2, train_wall=79, gb_free=39.6, wall=169717
2023-06-13 14:56:19 | INFO | train_inner | epoch 019:    376 / 11284 loss=3.505, nll_loss=1.796, ppl=3.47, wps=72204.9, ups=1.21, wpb=59580.3, bsz=2275.9, num_updates=203300, lr=0.000221785, gnorm=0.318, loss_scale=2, train_wall=78, gb_free=39.6, wall=169799
2023-06-13 14:57:41 | INFO | train_inner | epoch 019:    476 / 11284 loss=3.521, nll_loss=1.814, ppl=3.52, wps=71981.1, ups=1.21, wpb=59429.2, bsz=2165.6, num_updates=203400, lr=0.00022173, gnorm=0.325, loss_scale=2, train_wall=79, gb_free=39.5, wall=169882
2023-06-13 14:59:05 | INFO | train_inner | epoch 019:    576 / 11284 loss=3.506, nll_loss=1.798, ppl=3.48, wps=71004.8, ups=1.2, wpb=59124.4, bsz=2207.4, num_updates=203500, lr=0.000221676, gnorm=0.325, loss_scale=2, train_wall=79, gb_free=39.6, wall=169965
2023-06-13 15:00:27 | INFO | train_inner | epoch 019:    676 / 11284 loss=3.509, nll_loss=1.8, ppl=3.48, wps=72510.6, ups=1.21, wpb=59802.4, bsz=2183, num_updates=203600, lr=0.000221621, gnorm=0.313, loss_scale=2, train_wall=79, gb_free=39.6, wall=170048
2023-06-13 15:01:49 | INFO | train_inner | epoch 019:    776 / 11284 loss=3.508, nll_loss=1.8, ppl=3.48, wps=72794.6, ups=1.22, wpb=59529.4, bsz=2221.7, num_updates=203700, lr=0.000221567, gnorm=0.333, loss_scale=2, train_wall=78, gb_free=39.5, wall=170129
2023-06-13 15:03:12 | INFO | train_inner | epoch 019:    876 / 11284 loss=3.52, nll_loss=1.813, ppl=3.51, wps=71536.5, ups=1.21, wpb=59305.3, bsz=2216.2, num_updates=203800, lr=0.000221512, gnorm=0.335, loss_scale=2, train_wall=79, gb_free=39.6, wall=170212
2023-06-13 15:03:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 15:04:35 | INFO | train_inner | epoch 019:    977 / 11284 loss=3.52, nll_loss=1.813, ppl=3.51, wps=71743.2, ups=1.2, wpb=59679.7, bsz=2341, num_updates=203900, lr=0.000221458, gnorm=0.316, loss_scale=2, train_wall=79, gb_free=39.6, wall=170295
2023-06-13 15:05:57 | INFO | train_inner | epoch 019:   1077 / 11284 loss=3.518, nll_loss=1.811, ppl=3.51, wps=72751.9, ups=1.22, wpb=59569, bsz=2197.2, num_updates=204000, lr=0.000221404, gnorm=0.321, loss_scale=2, train_wall=78, gb_free=39.6, wall=170377
2023-06-13 15:07:19 | INFO | train_inner | epoch 019:   1177 / 11284 loss=3.523, nll_loss=1.817, ppl=3.52, wps=71986.4, ups=1.21, wpb=59286.2, bsz=2229.6, num_updates=204100, lr=0.000221349, gnorm=0.32, loss_scale=2, train_wall=78, gb_free=39.6, wall=170460
2023-06-13 15:08:43 | INFO | train_inner | epoch 019:   1277 / 11284 loss=3.513, nll_loss=1.805, ppl=3.49, wps=71076.8, ups=1.19, wpb=59506.9, bsz=2322.8, num_updates=204200, lr=0.000221295, gnorm=0.323, loss_scale=2, train_wall=80, gb_free=39.6, wall=170543
2023-06-13 15:10:06 | INFO | train_inner | epoch 019:   1377 / 11284 loss=3.51, nll_loss=1.801, ppl=3.49, wps=71166.8, ups=1.2, wpb=59345.3, bsz=2196.1, num_updates=204300, lr=0.000221241, gnorm=0.325, loss_scale=2, train_wall=79, gb_free=39.6, wall=170627
2023-06-13 15:11:30 | INFO | train_inner | epoch 019:   1477 / 11284 loss=3.524, nll_loss=1.818, ppl=3.53, wps=71450.4, ups=1.2, wpb=59629.2, bsz=2243.2, num_updates=204400, lr=0.000221187, gnorm=0.327, loss_scale=2, train_wall=80, gb_free=39.6, wall=170710
2023-06-13 15:12:53 | INFO | train_inner | epoch 019:   1577 / 11284 loss=3.507, nll_loss=1.798, ppl=3.48, wps=71429.3, ups=1.2, wpb=59714.2, bsz=2276.2, num_updates=204500, lr=0.000221133, gnorm=0.321, loss_scale=2, train_wall=79, gb_free=39.5, wall=170794
2023-06-13 15:14:16 | INFO | train_inner | epoch 019:   1677 / 11284 loss=3.515, nll_loss=1.807, ppl=3.5, wps=71569.2, ups=1.2, wpb=59505.6, bsz=2224, num_updates=204600, lr=0.000221079, gnorm=0.335, loss_scale=2, train_wall=79, gb_free=39.6, wall=170877
2023-06-13 15:15:39 | INFO | train_inner | epoch 019:   1777 / 11284 loss=3.521, nll_loss=1.815, ppl=3.52, wps=72156.1, ups=1.21, wpb=59415.4, bsz=2209.7, num_updates=204700, lr=0.000221025, gnorm=0.337, loss_scale=2, train_wall=78, gb_free=39.6, wall=170959
2023-06-13 15:17:02 | INFO | train_inner | epoch 019:   1877 / 11284 loss=3.514, nll_loss=1.806, ppl=3.5, wps=71414.5, ups=1.2, wpb=59612.2, bsz=2249.5, num_updates=204800, lr=0.000220971, gnorm=0.311, loss_scale=2, train_wall=79, gb_free=39.6, wall=171043
2023-06-13 15:18:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 15:18:28 | INFO | train_inner | epoch 019:   1978 / 11284 loss=3.512, nll_loss=1.804, ppl=3.49, wps=69483.7, ups=1.17, wpb=59592.1, bsz=2264.4, num_updates=204900, lr=0.000220917, gnorm=0.334, loss_scale=2, train_wall=82, gb_free=39.6, wall=171129
2023-06-13 15:19:53 | INFO | train_inner | epoch 019:   2078 / 11284 loss=3.512, nll_loss=1.804, ppl=3.49, wps=70382.6, ups=1.18, wpb=59620.4, bsz=2214.2, num_updates=205000, lr=0.000220863, gnorm=0.323, loss_scale=2, train_wall=81, gb_free=39.6, wall=171213
2023-06-13 15:21:19 | INFO | train_inner | epoch 019:   2178 / 11284 loss=3.519, nll_loss=1.811, ppl=3.51, wps=69029.7, ups=1.16, wpb=59356.2, bsz=2178.1, num_updates=205100, lr=0.000220809, gnorm=0.335, loss_scale=2, train_wall=82, gb_free=39.6, wall=171299
2023-06-13 15:22:44 | INFO | train_inner | epoch 019:   2278 / 11284 loss=3.524, nll_loss=1.817, ppl=3.52, wps=70066.5, ups=1.18, wpb=59472.4, bsz=2265.5, num_updates=205200, lr=0.000220755, gnorm=0.335, loss_scale=2, train_wall=81, gb_free=39.6, wall=171384
2023-06-13 15:24:08 | INFO | train_inner | epoch 019:   2378 / 11284 loss=3.522, nll_loss=1.815, ppl=3.52, wps=70511.9, ups=1.19, wpb=59391.3, bsz=2203.7, num_updates=205300, lr=0.000220702, gnorm=0.332, loss_scale=2, train_wall=80, gb_free=39.6, wall=171468
2023-06-13 15:25:33 | INFO | train_inner | epoch 019:   2478 / 11284 loss=3.509, nll_loss=1.801, ppl=3.48, wps=69883.3, ups=1.17, wpb=59493, bsz=2243.2, num_updates=205400, lr=0.000220648, gnorm=0.33, loss_scale=2, train_wall=81, gb_free=39.5, wall=171554
2023-06-13 15:26:58 | INFO | train_inner | epoch 019:   2578 / 11284 loss=3.513, nll_loss=1.805, ppl=3.49, wps=69867.5, ups=1.17, wpb=59593.2, bsz=2257.9, num_updates=205500, lr=0.000220594, gnorm=0.319, loss_scale=2, train_wall=81, gb_free=39.6, wall=171639
2023-06-13 15:28:24 | INFO | train_inner | epoch 019:   2678 / 11284 loss=3.524, nll_loss=1.818, ppl=3.52, wps=69798.9, ups=1.17, wpb=59508, bsz=2266.6, num_updates=205600, lr=0.000220541, gnorm=0.337, loss_scale=2, train_wall=81, gb_free=39.6, wall=171724
2023-06-13 15:29:49 | INFO | train_inner | epoch 019:   2778 / 11284 loss=3.518, nll_loss=1.811, ppl=3.51, wps=69947.9, ups=1.17, wpb=59700.4, bsz=2253, num_updates=205700, lr=0.000220487, gnorm=0.32, loss_scale=2, train_wall=81, gb_free=39.6, wall=171809
2023-06-13 15:31:13 | INFO | train_inner | epoch 019:   2878 / 11284 loss=3.538, nll_loss=1.833, ppl=3.56, wps=70529.6, ups=1.18, wpb=59557.9, bsz=2212.3, num_updates=205800, lr=0.000220433, gnorm=0.326, loss_scale=2, train_wall=80, gb_free=39.6, wall=171894
2023-06-13 15:32:38 | INFO | train_inner | epoch 019:   2978 / 11284 loss=3.514, nll_loss=1.806, ppl=3.5, wps=70551, ups=1.18, wpb=59640, bsz=2203, num_updates=205900, lr=0.00022038, gnorm=0.313, loss_scale=2, train_wall=81, gb_free=39.6, wall=171978
2023-06-13 15:33:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 15:34:04 | INFO | train_inner | epoch 019:   3079 / 11284 loss=3.537, nll_loss=1.832, ppl=3.56, wps=69062.6, ups=1.16, wpb=59441, bsz=2158.5, num_updates=206000, lr=0.000220326, gnorm=0.327, loss_scale=2, train_wall=82, gb_free=39.6, wall=172064
2023-06-13 15:35:28 | INFO | train_inner | epoch 019:   3179 / 11284 loss=3.524, nll_loss=1.818, ppl=3.53, wps=70440.7, ups=1.18, wpb=59458.4, bsz=2197.1, num_updates=206100, lr=0.000220273, gnorm=0.327, loss_scale=2, train_wall=81, gb_free=39.6, wall=172149
2023-06-13 15:36:53 | INFO | train_inner | epoch 019:   3279 / 11284 loss=3.529, nll_loss=1.823, ppl=3.54, wps=70174.7, ups=1.18, wpb=59568.8, bsz=2229.5, num_updates=206200, lr=0.000220219, gnorm=0.317, loss_scale=2, train_wall=81, gb_free=39.6, wall=172234
2023-06-13 15:38:18 | INFO | train_inner | epoch 019:   3379 / 11284 loss=3.51, nll_loss=1.802, ppl=3.49, wps=69868.2, ups=1.17, wpb=59485.9, bsz=2135.4, num_updates=206300, lr=0.000220166, gnorm=0.323, loss_scale=2, train_wall=81, gb_free=39.6, wall=172319
2023-06-13 15:39:43 | INFO | train_inner | epoch 019:   3479 / 11284 loss=3.508, nll_loss=1.799, ppl=3.48, wps=69982.7, ups=1.18, wpb=59450.5, bsz=2305.6, num_updates=206400, lr=0.000220113, gnorm=0.324, loss_scale=2, train_wall=81, gb_free=39.6, wall=172404
2023-06-13 15:41:08 | INFO | train_inner | epoch 019:   3579 / 11284 loss=3.522, nll_loss=1.816, ppl=3.52, wps=70412.5, ups=1.19, wpb=59385.2, bsz=2243.3, num_updates=206500, lr=0.000220059, gnorm=0.315, loss_scale=2, train_wall=81, gb_free=39.6, wall=172488
2023-06-13 15:42:33 | INFO | train_inner | epoch 019:   3679 / 11284 loss=3.518, nll_loss=1.811, ppl=3.51, wps=69739.4, ups=1.17, wpb=59663.3, bsz=2289, num_updates=206600, lr=0.000220006, gnorm=0.318, loss_scale=2, train_wall=81, gb_free=39.6, wall=172574
2023-06-13 15:43:58 | INFO | train_inner | epoch 019:   3779 / 11284 loss=3.52, nll_loss=1.813, ppl=3.51, wps=70008.3, ups=1.18, wpb=59211.9, bsz=2175.9, num_updates=206700, lr=0.000219953, gnorm=0.33, loss_scale=2, train_wall=81, gb_free=39.6, wall=172658
2023-06-13 15:45:23 | INFO | train_inner | epoch 019:   3879 / 11284 loss=3.511, nll_loss=1.803, ppl=3.49, wps=70268.4, ups=1.18, wpb=59793.8, bsz=2205.8, num_updates=206800, lr=0.0002199, gnorm=0.329, loss_scale=2, train_wall=81, gb_free=39.6, wall=172743
2023-06-13 15:46:46 | INFO | train_inner | epoch 019:   3979 / 11284 loss=3.531, nll_loss=1.825, ppl=3.54, wps=71863.7, ups=1.21, wpb=59551.5, bsz=2137.5, num_updates=206900, lr=0.000219847, gnorm=0.324, loss_scale=2, train_wall=79, gb_free=39.6, wall=172826
2023-06-13 15:48:08 | INFO | train_inner | epoch 019:   4079 / 11284 loss=3.524, nll_loss=1.817, ppl=3.52, wps=71943.2, ups=1.21, wpb=59475.7, bsz=2188.3, num_updates=207000, lr=0.000219793, gnorm=0.318, loss_scale=4, train_wall=79, gb_free=39.5, wall=172909
2023-06-13 15:48:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 15:49:32 | INFO | train_inner | epoch 019:   4180 / 11284 loss=3.526, nll_loss=1.82, ppl=3.53, wps=71115.6, ups=1.2, wpb=59333.8, bsz=2190, num_updates=207100, lr=0.00021974, gnorm=0.33, loss_scale=2, train_wall=79, gb_free=39.6, wall=172992
2023-06-13 15:50:54 | INFO | train_inner | epoch 019:   4280 / 11284 loss=3.519, nll_loss=1.812, ppl=3.51, wps=72975.9, ups=1.22, wpb=59604.8, bsz=2311, num_updates=207200, lr=0.000219687, gnorm=0.321, loss_scale=2, train_wall=78, gb_free=39.6, wall=173074
2023-06-13 15:52:15 | INFO | train_inner | epoch 019:   4380 / 11284 loss=3.519, nll_loss=1.812, ppl=3.51, wps=72597.9, ups=1.22, wpb=59503.2, bsz=2195.1, num_updates=207300, lr=0.000219634, gnorm=0.323, loss_scale=2, train_wall=78, gb_free=39.6, wall=173156
2023-06-13 15:53:38 | INFO | train_inner | epoch 019:   4480 / 11284 loss=3.512, nll_loss=1.805, ppl=3.49, wps=72718, ups=1.22, wpb=59661.1, bsz=2168.8, num_updates=207400, lr=0.000219581, gnorm=0.321, loss_scale=2, train_wall=78, gb_free=39.5, wall=173238
2023-06-13 15:55:00 | INFO | train_inner | epoch 019:   4580 / 11284 loss=3.529, nll_loss=1.823, ppl=3.54, wps=72024.6, ups=1.21, wpb=59526.1, bsz=2279.7, num_updates=207500, lr=0.000219529, gnorm=0.319, loss_scale=2, train_wall=78, gb_free=39.6, wall=173321
2023-06-13 15:56:23 | INFO | train_inner | epoch 019:   4680 / 11284 loss=3.517, nll_loss=1.81, ppl=3.51, wps=72043.6, ups=1.21, wpb=59696.5, bsz=2284.9, num_updates=207600, lr=0.000219476, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=173404
2023-06-13 15:57:47 | INFO | train_inner | epoch 019:   4780 / 11284 loss=3.524, nll_loss=1.818, ppl=3.53, wps=71062.8, ups=1.2, wpb=59462.9, bsz=2218.8, num_updates=207700, lr=0.000219423, gnorm=0.328, loss_scale=2, train_wall=80, gb_free=39.6, wall=173487
2023-06-13 15:59:10 | INFO | train_inner | epoch 019:   4880 / 11284 loss=3.513, nll_loss=1.805, ppl=3.49, wps=71714.2, ups=1.21, wpb=59503.2, bsz=2176.5, num_updates=207800, lr=0.00021937, gnorm=0.32, loss_scale=2, train_wall=79, gb_free=39.6, wall=173570
2023-06-13 16:00:33 | INFO | train_inner | epoch 019:   4980 / 11284 loss=3.516, nll_loss=1.808, ppl=3.5, wps=71581.7, ups=1.21, wpb=59358.7, bsz=2141.2, num_updates=207900, lr=0.000219317, gnorm=0.32, loss_scale=2, train_wall=79, gb_free=39.6, wall=173653
2023-06-13 16:01:56 | INFO | train_inner | epoch 019:   5080 / 11284 loss=3.509, nll_loss=1.801, ppl=3.48, wps=71421.6, ups=1.2, wpb=59493.2, bsz=2270.4, num_updates=208000, lr=0.000219265, gnorm=0.32, loss_scale=2, train_wall=79, gb_free=39.6, wall=173737
2023-06-13 16:03:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 16:03:19 | INFO | train_inner | epoch 019:   5181 / 11284 loss=3.52, nll_loss=1.813, ppl=3.51, wps=72138.3, ups=1.21, wpb=59671.6, bsz=2283.4, num_updates=208100, lr=0.000219212, gnorm=0.329, loss_scale=2, train_wall=78, gb_free=39.6, wall=173819
2023-06-13 16:04:41 | INFO | train_inner | epoch 019:   5281 / 11284 loss=3.509, nll_loss=1.801, ppl=3.49, wps=72249.2, ups=1.21, wpb=59618.2, bsz=2199.2, num_updates=208200, lr=0.000219159, gnorm=0.319, loss_scale=2, train_wall=79, gb_free=39.5, wall=173902
2023-06-13 16:06:03 | INFO | train_inner | epoch 019:   5381 / 11284 loss=3.525, nll_loss=1.819, ppl=3.53, wps=72321.5, ups=1.22, wpb=59336.6, bsz=2274.6, num_updates=208300, lr=0.000219107, gnorm=0.322, loss_scale=2, train_wall=78, gb_free=39.6, wall=173984
2023-06-13 16:07:26 | INFO | train_inner | epoch 019:   5481 / 11284 loss=3.515, nll_loss=1.808, ppl=3.5, wps=71353.4, ups=1.2, wpb=59251.1, bsz=2230, num_updates=208400, lr=0.000219054, gnorm=0.33, loss_scale=2, train_wall=79, gb_free=39.6, wall=174067
2023-06-13 16:08:50 | INFO | train_inner | epoch 019:   5581 / 11284 loss=3.513, nll_loss=1.806, ppl=3.5, wps=71321, ups=1.2, wpb=59562.8, bsz=2307.7, num_updates=208500, lr=0.000219001, gnorm=0.325, loss_scale=2, train_wall=79, gb_free=39.5, wall=174150
2023-06-13 16:10:12 | INFO | train_inner | epoch 019:   5681 / 11284 loss=3.512, nll_loss=1.804, ppl=3.49, wps=72121.5, ups=1.21, wpb=59643.7, bsz=2210.2, num_updates=208600, lr=0.000218949, gnorm=0.326, loss_scale=2, train_wall=79, gb_free=39.6, wall=174233
2023-06-13 16:11:35 | INFO | train_inner | epoch 019:   5781 / 11284 loss=3.519, nll_loss=1.812, ppl=3.51, wps=71757.1, ups=1.21, wpb=59527.8, bsz=2222.3, num_updates=208700, lr=0.000218896, gnorm=0.333, loss_scale=2, train_wall=79, gb_free=39.5, wall=174316
2023-06-13 16:12:59 | INFO | train_inner | epoch 019:   5881 / 11284 loss=3.525, nll_loss=1.819, ppl=3.53, wps=71588.3, ups=1.2, wpb=59479.1, bsz=2249.4, num_updates=208800, lr=0.000218844, gnorm=0.332, loss_scale=2, train_wall=79, gb_free=39.5, wall=174399
2023-06-13 16:14:22 | INFO | train_inner | epoch 019:   5981 / 11284 loss=3.527, nll_loss=1.822, ppl=3.53, wps=71607.3, ups=1.2, wpb=59474, bsz=2163.9, num_updates=208900, lr=0.000218792, gnorm=0.329, loss_scale=2, train_wall=79, gb_free=39.5, wall=174482
2023-06-13 16:15:45 | INFO | train_inner | epoch 019:   6081 / 11284 loss=3.507, nll_loss=1.799, ppl=3.48, wps=71276.6, ups=1.2, wpb=59427.9, bsz=2186.7, num_updates=209000, lr=0.000218739, gnorm=0.328, loss_scale=2, train_wall=79, gb_free=39.5, wall=174566
2023-06-13 16:17:08 | INFO | train_inner | epoch 019:   6181 / 11284 loss=3.534, nll_loss=1.829, ppl=3.55, wps=71331.7, ups=1.2, wpb=59572, bsz=2286.1, num_updates=209100, lr=0.000218687, gnorm=0.328, loss_scale=2, train_wall=80, gb_free=39.5, wall=174649
2023-06-13 16:17:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 16:18:33 | INFO | train_inner | epoch 019:   6282 / 11284 loss=3.499, nll_loss=1.791, ppl=3.46, wps=70339.6, ups=1.18, wpb=59434.5, bsz=2287.5, num_updates=209200, lr=0.000218635, gnorm=0.332, loss_scale=2, train_wall=80, gb_free=39.6, wall=174734
2023-06-13 16:19:57 | INFO | train_inner | epoch 019:   6382 / 11284 loss=3.512, nll_loss=1.805, ppl=3.49, wps=70848.3, ups=1.19, wpb=59451.6, bsz=2223.3, num_updates=209300, lr=0.000218582, gnorm=0.319, loss_scale=2, train_wall=80, gb_free=39.5, wall=174817
2023-06-13 16:21:21 | INFO | train_inner | epoch 019:   6482 / 11284 loss=3.521, nll_loss=1.814, ppl=3.52, wps=70965.9, ups=1.2, wpb=59347.9, bsz=2335.9, num_updates=209400, lr=0.00021853, gnorm=0.328, loss_scale=2, train_wall=80, gb_free=38.9, wall=174901
2023-06-13 16:22:42 | INFO | train_inner | epoch 019:   6582 / 11284 loss=3.526, nll_loss=1.82, ppl=3.53, wps=72803, ups=1.22, wpb=59435.9, bsz=2193.7, num_updates=209500, lr=0.000218478, gnorm=0.326, loss_scale=2, train_wall=78, gb_free=39.5, wall=174983
2023-06-13 16:24:04 | INFO | train_inner | epoch 019:   6682 / 11284 loss=3.524, nll_loss=1.818, ppl=3.53, wps=72951, ups=1.22, wpb=59746.9, bsz=2214.4, num_updates=209600, lr=0.000218426, gnorm=0.333, loss_scale=2, train_wall=78, gb_free=39.4, wall=175065
2023-06-13 16:25:26 | INFO | train_inner | epoch 019:   6782 / 11284 loss=3.521, nll_loss=1.814, ppl=3.52, wps=72651.5, ups=1.22, wpb=59663.7, bsz=2238.5, num_updates=209700, lr=0.000218374, gnorm=0.335, loss_scale=2, train_wall=78, gb_free=39.6, wall=175147
2023-06-13 16:26:48 | INFO | train_inner | epoch 019:   6882 / 11284 loss=3.525, nll_loss=1.819, ppl=3.53, wps=72644.1, ups=1.22, wpb=59651.5, bsz=2216.6, num_updates=209800, lr=0.000218322, gnorm=0.335, loss_scale=2, train_wall=78, gb_free=39.6, wall=175229
2023-06-13 16:28:10 | INFO | train_inner | epoch 019:   6982 / 11284 loss=3.509, nll_loss=1.801, ppl=3.48, wps=72770.9, ups=1.22, wpb=59733.1, bsz=2307.2, num_updates=209900, lr=0.00021827, gnorm=0.334, loss_scale=2, train_wall=78, gb_free=39.6, wall=175311
2023-06-13 16:29:34 | INFO | train_inner | epoch 019:   7082 / 11284 loss=3.521, nll_loss=1.815, ppl=3.52, wps=71330.8, ups=1.2, wpb=59354.6, bsz=2255.2, num_updates=210000, lr=0.000218218, gnorm=0.341, loss_scale=2, train_wall=79, gb_free=39.6, wall=175394
2023-06-13 16:30:55 | INFO | train_inner | epoch 019:   7182 / 11284 loss=3.522, nll_loss=1.816, ppl=3.52, wps=73131, ups=1.23, wpb=59687.1, bsz=2194.7, num_updates=210100, lr=0.000218166, gnorm=0.324, loss_scale=2, train_wall=78, gb_free=39.5, wall=175476
2023-06-13 16:31:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 16:32:18 | INFO | train_inner | epoch 019:   7283 / 11284 loss=3.52, nll_loss=1.814, ppl=3.52, wps=71525.9, ups=1.2, wpb=59416.5, bsz=2222.7, num_updates=210200, lr=0.000218114, gnorm=0.326, loss_scale=2, train_wall=79, gb_free=39.6, wall=175559
2023-06-13 16:33:41 | INFO | train_inner | epoch 019:   7383 / 11284 loss=3.513, nll_loss=1.805, ppl=3.49, wps=71800.1, ups=1.2, wpb=59626.5, bsz=2223.8, num_updates=210300, lr=0.000218062, gnorm=0.331, loss_scale=2, train_wall=79, gb_free=39.6, wall=175642
2023-06-13 16:35:05 | INFO | train_inner | epoch 019:   7483 / 11284 loss=3.533, nll_loss=1.828, ppl=3.55, wps=71425.2, ups=1.2, wpb=59582.5, bsz=2200.2, num_updates=210400, lr=0.00021801, gnorm=0.324, loss_scale=2, train_wall=80, gb_free=39.5, wall=175725
2023-06-13 16:36:28 | INFO | train_inner | epoch 019:   7583 / 11284 loss=3.512, nll_loss=1.804, ppl=3.49, wps=71530, ups=1.2, wpb=59437.6, bsz=2186.7, num_updates=210500, lr=0.000217959, gnorm=0.318, loss_scale=2, train_wall=79, gb_free=39.6, wall=175808
2023-06-13 16:37:51 | INFO | train_inner | epoch 019:   7683 / 11284 loss=3.509, nll_loss=1.801, ppl=3.48, wps=71640.6, ups=1.21, wpb=59383.6, bsz=2283.8, num_updates=210600, lr=0.000217907, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.6, wall=175891
2023-06-13 16:39:13 | INFO | train_inner | epoch 019:   7783 / 11284 loss=3.518, nll_loss=1.811, ppl=3.51, wps=71919.4, ups=1.22, wpb=59073.8, bsz=2238.8, num_updates=210700, lr=0.000217855, gnorm=0.333, loss_scale=2, train_wall=78, gb_free=39.6, wall=175973
2023-06-13 16:40:36 | INFO | train_inner | epoch 019:   7883 / 11284 loss=3.512, nll_loss=1.805, ppl=3.49, wps=71652.2, ups=1.2, wpb=59604.4, bsz=2211.5, num_updates=210800, lr=0.000217803, gnorm=0.316, loss_scale=2, train_wall=79, gb_free=39.6, wall=176057
2023-06-13 16:42:00 | INFO | train_inner | epoch 019:   7983 / 11284 loss=3.502, nll_loss=1.793, ppl=3.47, wps=71351.9, ups=1.2, wpb=59586.6, bsz=2166.3, num_updates=210900, lr=0.000217752, gnorm=0.336, loss_scale=2, train_wall=80, gb_free=39.6, wall=176140
2023-06-13 16:43:23 | INFO | train_inner | epoch 019:   8083 / 11284 loss=3.527, nll_loss=1.822, ppl=3.54, wps=71478.5, ups=1.2, wpb=59594.7, bsz=2266.9, num_updates=211000, lr=0.0002177, gnorm=0.331, loss_scale=2, train_wall=79, gb_free=39.6, wall=176224
2023-06-13 16:44:46 | INFO | train_inner | epoch 019:   8183 / 11284 loss=3.538, nll_loss=1.833, ppl=3.56, wps=71295.3, ups=1.2, wpb=59415.5, bsz=2165.3, num_updates=211100, lr=0.000217649, gnorm=0.334, loss_scale=2, train_wall=80, gb_free=39.6, wall=176307
2023-06-13 16:46:10 | INFO | train_inner | epoch 019:   8283 / 11284 loss=3.517, nll_loss=1.81, ppl=3.51, wps=71210.1, ups=1.2, wpb=59500.6, bsz=2194.6, num_updates=211200, lr=0.000217597, gnorm=0.337, loss_scale=4, train_wall=79, gb_free=39.6, wall=176390
2023-06-13 16:46:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 16:47:34 | INFO | train_inner | epoch 019:   8384 / 11284 loss=3.521, nll_loss=1.815, ppl=3.52, wps=70944.4, ups=1.19, wpb=59703.6, bsz=2204.9, num_updates=211300, lr=0.000217546, gnorm=0.322, loss_scale=2, train_wall=80, gb_free=39.6, wall=176475
2023-06-13 16:48:57 | INFO | train_inner | epoch 019:   8484 / 11284 loss=3.514, nll_loss=1.807, ppl=3.5, wps=71523.6, ups=1.2, wpb=59514.4, bsz=2200.8, num_updates=211400, lr=0.000217494, gnorm=0.324, loss_scale=2, train_wall=79, gb_free=39.6, wall=176558
2023-06-13 16:50:20 | INFO | train_inner | epoch 019:   8584 / 11284 loss=3.515, nll_loss=1.808, ppl=3.5, wps=72196.2, ups=1.21, wpb=59601.8, bsz=2191, num_updates=211500, lr=0.000217443, gnorm=0.318, loss_scale=2, train_wall=78, gb_free=39.3, wall=176640
2023-06-13 16:51:43 | INFO | train_inner | epoch 019:   8684 / 11284 loss=3.526, nll_loss=1.821, ppl=3.53, wps=71060.3, ups=1.2, wpb=59213.6, bsz=2297.5, num_updates=211600, lr=0.000217391, gnorm=0.327, loss_scale=2, train_wall=79, gb_free=39.6, wall=176724
2023-06-13 16:53:06 | INFO | train_inner | epoch 019:   8784 / 11284 loss=3.524, nll_loss=1.818, ppl=3.53, wps=71689.4, ups=1.2, wpb=59607, bsz=2167.5, num_updates=211700, lr=0.00021734, gnorm=0.317, loss_scale=2, train_wall=79, gb_free=39.6, wall=176807
2023-06-13 16:54:30 | INFO | train_inner | epoch 019:   8884 / 11284 loss=3.527, nll_loss=1.822, ppl=3.53, wps=71130.9, ups=1.2, wpb=59486.1, bsz=2254.7, num_updates=211800, lr=0.000217289, gnorm=0.34, loss_scale=2, train_wall=80, gb_free=39.5, wall=176890
2023-06-13 16:55:53 | INFO | train_inner | epoch 019:   8984 / 11284 loss=3.532, nll_loss=1.826, ppl=3.55, wps=71621.5, ups=1.2, wpb=59470, bsz=2284.6, num_updates=211900, lr=0.000217237, gnorm=0.324, loss_scale=2, train_wall=79, gb_free=39.6, wall=176973
2023-06-13 16:57:17 | INFO | train_inner | epoch 019:   9084 / 11284 loss=3.539, nll_loss=1.835, ppl=3.57, wps=70765.5, ups=1.19, wpb=59390.8, bsz=2221, num_updates=212000, lr=0.000217186, gnorm=0.321, loss_scale=2, train_wall=80, gb_free=39.5, wall=177057
2023-06-13 16:58:39 | INFO | train_inner | epoch 019:   9184 / 11284 loss=3.518, nll_loss=1.811, ppl=3.51, wps=72258, ups=1.22, wpb=59445.2, bsz=2200.4, num_updates=212100, lr=0.000217135, gnorm=0.322, loss_scale=2, train_wall=78, gb_free=39.5, wall=177140
2023-06-13 17:00:02 | INFO | train_inner | epoch 019:   9284 / 11284 loss=3.533, nll_loss=1.828, ppl=3.55, wps=71830.5, ups=1.21, wpb=59465.7, bsz=2239.4, num_updates=212200, lr=0.000217084, gnorm=0.327, loss_scale=2, train_wall=79, gb_free=39.6, wall=177222
2023-06-13 17:01:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 17:01:26 | INFO | train_inner | epoch 019:   9385 / 11284 loss=3.527, nll_loss=1.822, ppl=3.53, wps=70766.4, ups=1.19, wpb=59374.1, bsz=2221.7, num_updates=212300, lr=0.000217033, gnorm=0.33, loss_scale=2, train_wall=80, gb_free=39.6, wall=177306
2023-06-13 17:02:50 | INFO | train_inner | epoch 019:   9485 / 11284 loss=3.509, nll_loss=1.802, ppl=3.49, wps=70925, ups=1.19, wpb=59555.9, bsz=2275.8, num_updates=212400, lr=0.000216982, gnorm=0.333, loss_scale=2, train_wall=80, gb_free=39.5, wall=177390
2023-06-13 17:04:13 | INFO | train_inner | epoch 019:   9585 / 11284 loss=3.522, nll_loss=1.815, ppl=3.52, wps=71891.7, ups=1.21, wpb=59589.8, bsz=2252, num_updates=212500, lr=0.00021693, gnorm=0.328, loss_scale=2, train_wall=79, gb_free=39.5, wall=177473
2023-06-13 17:05:35 | INFO | train_inner | epoch 019:   9685 / 11284 loss=3.52, nll_loss=1.814, ppl=3.52, wps=72579.7, ups=1.22, wpb=59414, bsz=2295.6, num_updates=212600, lr=0.000216879, gnorm=0.328, loss_scale=2, train_wall=78, gb_free=39.4, wall=177555
2023-06-13 17:06:57 | INFO | train_inner | epoch 019:   9785 / 11284 loss=3.505, nll_loss=1.797, ppl=3.48, wps=72252.8, ups=1.21, wpb=59520.8, bsz=2314.7, num_updates=212700, lr=0.000216828, gnorm=0.335, loss_scale=2, train_wall=78, gb_free=39.6, wall=177637
2023-06-13 17:08:20 | INFO | train_inner | epoch 019:   9885 / 11284 loss=3.523, nll_loss=1.816, ppl=3.52, wps=72085.8, ups=1.21, wpb=59664.9, bsz=2175.1, num_updates=212800, lr=0.000216777, gnorm=0.314, loss_scale=2, train_wall=79, gb_free=39.6, wall=177720
2023-06-13 17:09:43 | INFO | train_inner | epoch 019:   9985 / 11284 loss=3.526, nll_loss=1.82, ppl=3.53, wps=71138.3, ups=1.19, wpb=59550.8, bsz=2320.3, num_updates=212900, lr=0.000216727, gnorm=0.324, loss_scale=2, train_wall=80, gb_free=39.6, wall=177804
2023-06-13 17:11:06 | INFO | train_inner | epoch 019:  10085 / 11284 loss=3.543, nll_loss=1.84, ppl=3.58, wps=71656.2, ups=1.21, wpb=59325.9, bsz=2160.9, num_updates=213000, lr=0.000216676, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.6, wall=177887
2023-06-13 17:12:29 | INFO | train_inner | epoch 019:  10185 / 11284 loss=3.526, nll_loss=1.82, ppl=3.53, wps=72045.3, ups=1.21, wpb=59422.8, bsz=2245.9, num_updates=213100, lr=0.000216625, gnorm=0.339, loss_scale=2, train_wall=78, gb_free=39.6, wall=177969
2023-06-13 17:13:50 | INFO | train_inner | epoch 019:  10285 / 11284 loss=3.522, nll_loss=1.816, ppl=3.52, wps=72556.6, ups=1.22, wpb=59327.3, bsz=2175.9, num_updates=213200, lr=0.000216574, gnorm=0.339, loss_scale=2, train_wall=78, gb_free=39.5, wall=178051
2023-06-13 17:15:12 | INFO | train_inner | epoch 019:  10385 / 11284 loss=3.532, nll_loss=1.827, ppl=3.55, wps=73214.1, ups=1.23, wpb=59728.5, bsz=2171.5, num_updates=213300, lr=0.000216523, gnorm=0.341, loss_scale=2, train_wall=78, gb_free=39.6, wall=178133
2023-06-13 17:15:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 17:16:35 | INFO | train_inner | epoch 019:  10486 / 11284 loss=3.509, nll_loss=1.801, ppl=3.48, wps=71634.4, ups=1.2, wpb=59621.8, bsz=2213, num_updates=213400, lr=0.000216473, gnorm=0.334, loss_scale=2, train_wall=79, gb_free=39.6, wall=178216
2023-06-13 17:17:57 | INFO | train_inner | epoch 019:  10586 / 11284 loss=3.516, nll_loss=1.809, ppl=3.5, wps=72473.6, ups=1.22, wpb=59480.4, bsz=2202.8, num_updates=213500, lr=0.000216422, gnorm=0.34, loss_scale=2, train_wall=78, gb_free=39.6, wall=178298
2023-06-13 17:19:21 | INFO | train_inner | epoch 019:  10686 / 11284 loss=3.506, nll_loss=1.798, ppl=3.48, wps=71111, ups=1.2, wpb=59483.7, bsz=2194.2, num_updates=213600, lr=0.000216371, gnorm=0.316, loss_scale=2, train_wall=80, gb_free=39.6, wall=178382
2023-06-13 17:20:45 | INFO | train_inner | epoch 019:  10786 / 11284 loss=3.534, nll_loss=1.829, ppl=3.55, wps=70897.8, ups=1.2, wpb=59291.1, bsz=2304.1, num_updates=213700, lr=0.000216321, gnorm=0.34, loss_scale=2, train_wall=80, gb_free=39.6, wall=178465
2023-06-13 17:22:09 | INFO | train_inner | epoch 019:  10886 / 11284 loss=3.52, nll_loss=1.813, ppl=3.51, wps=70384, ups=1.18, wpb=59550.7, bsz=2212, num_updates=213800, lr=0.00021627, gnorm=0.321, loss_scale=2, train_wall=81, gb_free=39.5, wall=178550
2023-06-13 17:23:32 | INFO | train_inner | epoch 019:  10986 / 11284 loss=3.538, nll_loss=1.834, ppl=3.56, wps=71870.6, ups=1.21, wpb=59409, bsz=2161, num_updates=213900, lr=0.000216219, gnorm=0.349, loss_scale=2, train_wall=79, gb_free=39.5, wall=178632
2023-06-13 17:24:55 | INFO | train_inner | epoch 019:  11086 / 11284 loss=3.507, nll_loss=1.799, ppl=3.48, wps=71331.4, ups=1.2, wpb=59510.2, bsz=2161.4, num_updates=214000, lr=0.000216169, gnorm=0.324, loss_scale=2, train_wall=80, gb_free=39.6, wall=178716
2023-06-13 17:26:19 | INFO | train_inner | epoch 019:  11186 / 11284 loss=3.516, nll_loss=1.809, ppl=3.5, wps=71149.9, ups=1.2, wpb=59535.8, bsz=2213.2, num_updates=214100, lr=0.000216118, gnorm=0.322, loss_scale=2, train_wall=80, gb_free=38.2, wall=178800
2023-06-13 17:27:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-13 17:28:00 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 4.309 | nll_loss 2.629 | ppl 6.19 | bleu 21.3 | wps 3524.2 | wpb 2397.5 | bsz 71.5 | num_updates 214198 | best_loss 4.309
2023-06-13 17:28:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 214198 updates
2023-06-13 17:28:00 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint19.pt
2023-06-13 17:28:02 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint19.pt
2023-06-13 17:28:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint19.pt (epoch 19 @ 214198 updates, score 4.309) (writing took 7.881209900602698 seconds)
2023-06-13 17:28:07 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-06-13 17:28:07 | INFO | train | epoch 019 | loss 3.519 | nll_loss 1.812 | ppl 3.51 | wps 71216.1 | ups 1.2 | wpb 59501.2 | bsz 2227.4 | num_updates 214198 | lr 0.000216069 | gnorm 0.327 | loss_scale 2 | train_wall 8936 | gb_free 39.6 | wall 178908
2023-06-13 17:28:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-13 17:28:08 | INFO | fairseq.trainer | begin training epoch 20
2023-06-13 17:28:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-13 17:28:10 | INFO | train_inner | epoch 020:      2 / 11284 loss=3.522, nll_loss=1.816, ppl=3.52, wps=53427.5, ups=0.9, wpb=59113.1, bsz=2168.3, num_updates=214200, lr=0.000216068, gnorm=0.329, loss_scale=2, train_wall=79, gb_free=39.6, wall=178910
2023-06-13 17:29:35 | INFO | train_inner | epoch 020:    102 / 11284 loss=3.512, nll_loss=1.804, ppl=3.49, wps=70489.4, ups=1.18, wpb=59859.3, bsz=2291.9, num_updates=214300, lr=0.000216017, gnorm=0.324, loss_scale=2, train_wall=81, gb_free=39.5, wall=178995
2023-06-13 17:30:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 17:30:59 | INFO | train_inner | epoch 020:    203 / 11284 loss=3.52, nll_loss=1.812, ppl=3.51, wps=70533.5, ups=1.18, wpb=59639.6, bsz=2256.2, num_updates=214400, lr=0.000215967, gnorm=0.326, loss_scale=2, train_wall=80, gb_free=39.6, wall=179080
2023-06-13 17:32:24 | INFO | train_inner | epoch 020:    303 / 11284 loss=3.51, nll_loss=1.801, ppl=3.49, wps=70237.1, ups=1.18, wpb=59528.2, bsz=2194.8, num_updates=214500, lr=0.000215917, gnorm=0.342, loss_scale=2, train_wall=81, gb_free=39.6, wall=179164
2023-06-13 17:33:49 | INFO | train_inner | epoch 020:    403 / 11284 loss=3.501, nll_loss=1.792, ppl=3.46, wps=69728.4, ups=1.17, wpb=59593.7, bsz=2220.2, num_updates=214600, lr=0.000215866, gnorm=0.327, loss_scale=2, train_wall=81, gb_free=39.5, wall=179250
2023-06-13 17:35:13 | INFO | train_inner | epoch 020:    503 / 11284 loss=3.515, nll_loss=1.808, ppl=3.5, wps=70532.1, ups=1.19, wpb=59302.2, bsz=2215.8, num_updates=214700, lr=0.000215816, gnorm=0.328, loss_scale=2, train_wall=80, gb_free=39.3, wall=179334
2023-06-13 17:36:37 | INFO | train_inner | epoch 020:    603 / 11284 loss=3.515, nll_loss=1.808, ppl=3.5, wps=71112.7, ups=1.19, wpb=59548.9, bsz=2257.4, num_updates=214800, lr=0.000215766, gnorm=0.323, loss_scale=2, train_wall=80, gb_free=39.6, wall=179418
2023-06-13 17:38:02 | INFO | train_inner | epoch 020:    703 / 11284 loss=3.508, nll_loss=1.8, ppl=3.48, wps=70510.8, ups=1.18, wpb=59640.1, bsz=2261.5, num_updates=214900, lr=0.000215716, gnorm=0.328, loss_scale=2, train_wall=81, gb_free=39.5, wall=179502
2023-06-13 17:39:27 | INFO | train_inner | epoch 020:    803 / 11284 loss=3.496, nll_loss=1.786, ppl=3.45, wps=69963.9, ups=1.17, wpb=59725.5, bsz=2214.5, num_updates=215000, lr=0.000215666, gnorm=0.335, loss_scale=2, train_wall=82, gb_free=39.6, wall=179588
2023-06-13 17:40:52 | INFO | train_inner | epoch 020:    903 / 11284 loss=3.514, nll_loss=1.806, ppl=3.5, wps=69999, ups=1.18, wpb=59376.8, bsz=2216.5, num_updates=215100, lr=0.000215615, gnorm=0.328, loss_scale=2, train_wall=81, gb_free=39.5, wall=179672
2023-06-13 17:42:17 | INFO | train_inner | epoch 020:   1003 / 11284 loss=3.508, nll_loss=1.799, ppl=3.48, wps=70375.1, ups=1.18, wpb=59534.8, bsz=2200.6, num_updates=215200, lr=0.000215565, gnorm=0.33, loss_scale=2, train_wall=81, gb_free=39.5, wall=179757
2023-06-13 17:43:41 | INFO | train_inner | epoch 020:   1103 / 11284 loss=3.507, nll_loss=1.799, ppl=3.48, wps=70892.3, ups=1.19, wpb=59703.3, bsz=2175.2, num_updates=215300, lr=0.000215515, gnorm=0.325, loss_scale=2, train_wall=81, gb_free=39.6, wall=179841
2023-06-13 17:45:06 | INFO | train_inner | epoch 020:   1203 / 11284 loss=3.504, nll_loss=1.795, ppl=3.47, wps=69896.7, ups=1.17, wpb=59696.2, bsz=2261.4, num_updates=215400, lr=0.000215465, gnorm=0.315, loss_scale=4, train_wall=81, gb_free=39.6, wall=179927
2023-06-13 17:45:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 17:46:32 | INFO | train_inner | epoch 020:   1304 / 11284 loss=3.506, nll_loss=1.797, ppl=3.48, wps=69234.2, ups=1.17, wpb=59426.5, bsz=2167, num_updates=215500, lr=0.000215415, gnorm=0.327, loss_scale=2, train_wall=82, gb_free=39.6, wall=180013
2023-06-13 17:47:56 | INFO | train_inner | epoch 020:   1404 / 11284 loss=3.52, nll_loss=1.813, ppl=3.51, wps=70263.1, ups=1.19, wpb=59273.5, bsz=2231, num_updates=215600, lr=0.000215365, gnorm=0.332, loss_scale=2, train_wall=80, gb_free=39.6, wall=180097
2023-06-13 17:49:21 | INFO | train_inner | epoch 020:   1504 / 11284 loss=3.511, nll_loss=1.803, ppl=3.49, wps=70312.8, ups=1.18, wpb=59576.3, bsz=2357.7, num_updates=215700, lr=0.000215315, gnorm=0.332, loss_scale=2, train_wall=81, gb_free=39.6, wall=180182
2023-06-13 17:50:46 | INFO | train_inner | epoch 020:   1604 / 11284 loss=3.505, nll_loss=1.797, ppl=3.47, wps=70216.2, ups=1.18, wpb=59652.9, bsz=2208, num_updates=215800, lr=0.000215265, gnorm=0.318, loss_scale=2, train_wall=81, gb_free=39, wall=180267
2023-06-13 17:52:11 | INFO | train_inner | epoch 020:   1704 / 11284 loss=3.505, nll_loss=1.796, ppl=3.47, wps=70316.9, ups=1.18, wpb=59559.1, bsz=2238.1, num_updates=215900, lr=0.000215216, gnorm=0.321, loss_scale=2, train_wall=81, gb_free=39.5, wall=180351
2023-06-13 17:53:36 | INFO | train_inner | epoch 020:   1804 / 11284 loss=3.515, nll_loss=1.807, ppl=3.5, wps=69654.8, ups=1.17, wpb=59300.8, bsz=2242.9, num_updates=216000, lr=0.000215166, gnorm=0.328, loss_scale=2, train_wall=81, gb_free=39.6, wall=180436
2023-06-13 17:55:00 | INFO | train_inner | epoch 020:   1904 / 11284 loss=3.522, nll_loss=1.815, ppl=3.52, wps=70525.8, ups=1.18, wpb=59664.5, bsz=2168.7, num_updates=216100, lr=0.000215116, gnorm=0.318, loss_scale=2, train_wall=81, gb_free=39.6, wall=180521
2023-06-13 17:56:24 | INFO | train_inner | epoch 020:   2004 / 11284 loss=3.521, nll_loss=1.814, ppl=3.52, wps=70972.3, ups=1.19, wpb=59495.6, bsz=2327.1, num_updates=216200, lr=0.000215066, gnorm=0.334, loss_scale=2, train_wall=80, gb_free=39.5, wall=180605
2023-06-13 17:57:49 | INFO | train_inner | epoch 020:   2104 / 11284 loss=3.521, nll_loss=1.814, ppl=3.52, wps=69718.2, ups=1.18, wpb=59320.3, bsz=2125, num_updates=216300, lr=0.000215016, gnorm=0.339, loss_scale=2, train_wall=81, gb_free=39.6, wall=180690
2023-06-13 17:59:15 | INFO | train_inner | epoch 020:   2204 / 11284 loss=3.519, nll_loss=1.813, ppl=3.51, wps=70085.9, ups=1.17, wpb=59846.4, bsz=2219, num_updates=216400, lr=0.000214967, gnorm=0.331, loss_scale=2, train_wall=81, gb_free=39.6, wall=180775
2023-06-13 18:00:41 | INFO | train_inner | epoch 020:   2304 / 11284 loss=3.512, nll_loss=1.804, ppl=3.49, wps=68701, ups=1.16, wpb=59422.3, bsz=2207, num_updates=216500, lr=0.000214917, gnorm=0.316, loss_scale=4, train_wall=82, gb_free=39.6, wall=180862
2023-06-13 18:01:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 18:02:05 | INFO | train_inner | epoch 020:   2405 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=70762.5, ups=1.19, wpb=59514.9, bsz=2172.5, num_updates=216600, lr=0.000214868, gnorm=0.327, loss_scale=2, train_wall=80, gb_free=39.6, wall=180946
2023-06-13 18:03:29 | INFO | train_inner | epoch 020:   2505 / 11284 loss=3.517, nll_loss=1.81, ppl=3.51, wps=71214.2, ups=1.2, wpb=59224.1, bsz=2253.6, num_updates=216700, lr=0.000214818, gnorm=0.33, loss_scale=2, train_wall=79, gb_free=39.6, wall=181029
2023-06-13 18:04:51 | INFO | train_inner | epoch 020:   2605 / 11284 loss=3.513, nll_loss=1.805, ppl=3.49, wps=71929.2, ups=1.21, wpb=59320.1, bsz=2220.4, num_updates=216800, lr=0.000214768, gnorm=0.327, loss_scale=2, train_wall=78, gb_free=39.6, wall=181112
2023-06-13 18:06:13 | INFO | train_inner | epoch 020:   2705 / 11284 loss=3.508, nll_loss=1.8, ppl=3.48, wps=72309.4, ups=1.22, wpb=59454, bsz=2112.8, num_updates=216900, lr=0.000214719, gnorm=0.336, loss_scale=2, train_wall=78, gb_free=39.6, wall=181194
2023-06-13 18:07:36 | INFO | train_inner | epoch 020:   2805 / 11284 loss=3.511, nll_loss=1.803, ppl=3.49, wps=72380.5, ups=1.21, wpb=59621.3, bsz=2239, num_updates=217000, lr=0.000214669, gnorm=0.334, loss_scale=2, train_wall=78, gb_free=39.6, wall=181276
2023-06-13 18:08:59 | INFO | train_inner | epoch 020:   2905 / 11284 loss=3.528, nll_loss=1.822, ppl=3.54, wps=71664.2, ups=1.21, wpb=59452.1, bsz=2155.5, num_updates=217100, lr=0.00021462, gnorm=0.323, loss_scale=2, train_wall=79, gb_free=39.4, wall=181359
2023-06-13 18:10:22 | INFO | train_inner | epoch 020:   3005 / 11284 loss=3.511, nll_loss=1.804, ppl=3.49, wps=71246.2, ups=1.2, wpb=59573.9, bsz=2205.7, num_updates=217200, lr=0.000214571, gnorm=0.323, loss_scale=2, train_wall=80, gb_free=39.6, wall=181443
2023-06-13 18:11:46 | INFO | train_inner | epoch 020:   3105 / 11284 loss=3.517, nll_loss=1.809, ppl=3.5, wps=71511.8, ups=1.2, wpb=59620.6, bsz=2179.6, num_updates=217300, lr=0.000214521, gnorm=0.325, loss_scale=2, train_wall=79, gb_free=39.6, wall=181526
2023-06-13 18:13:09 | INFO | train_inner | epoch 020:   3205 / 11284 loss=3.529, nll_loss=1.824, ppl=3.54, wps=71102.4, ups=1.2, wpb=59406.6, bsz=2230.6, num_updates=217400, lr=0.000214472, gnorm=0.33, loss_scale=2, train_wall=79, gb_free=39.6, wall=181610
2023-06-13 18:14:33 | INFO | train_inner | epoch 020:   3305 / 11284 loss=3.512, nll_loss=1.804, ppl=3.49, wps=70835.8, ups=1.19, wpb=59388.9, bsz=2264.9, num_updates=217500, lr=0.000214423, gnorm=0.319, loss_scale=2, train_wall=80, gb_free=39.5, wall=181694
2023-06-13 18:15:57 | INFO | train_inner | epoch 020:   3405 / 11284 loss=3.51, nll_loss=1.802, ppl=3.49, wps=71292.9, ups=1.2, wpb=59591.7, bsz=2228.5, num_updates=217600, lr=0.000214373, gnorm=0.327, loss_scale=4, train_wall=80, gb_free=39.6, wall=181777
2023-06-13 18:17:20 | INFO | train_inner | epoch 020:   3505 / 11284 loss=3.523, nll_loss=1.816, ppl=3.52, wps=71561, ups=1.21, wpb=59381.6, bsz=2284.1, num_updates=217700, lr=0.000214324, gnorm=0.321, loss_scale=4, train_wall=79, gb_free=39.6, wall=181860
2023-06-13 18:17:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 18:18:43 | INFO | train_inner | epoch 020:   3606 / 11284 loss=3.499, nll_loss=1.79, ppl=3.46, wps=71140.7, ups=1.19, wpb=59577.9, bsz=2209.2, num_updates=217800, lr=0.000214275, gnorm=0.319, loss_scale=2, train_wall=80, gb_free=39.6, wall=181944
2023-06-13 18:20:07 | INFO | train_inner | epoch 020:   3706 / 11284 loss=3.526, nll_loss=1.82, ppl=3.53, wps=71239.7, ups=1.2, wpb=59426.7, bsz=2197, num_updates=217900, lr=0.000214226, gnorm=0.343, loss_scale=2, train_wall=80, gb_free=39.6, wall=182027
2023-06-13 18:21:30 | INFO | train_inner | epoch 020:   3806 / 11284 loss=3.529, nll_loss=1.824, ppl=3.54, wps=71831.7, ups=1.21, wpb=59593.6, bsz=2175, num_updates=218000, lr=0.000214176, gnorm=0.323, loss_scale=2, train_wall=79, gb_free=39.6, wall=182110
2023-06-13 18:22:52 | INFO | train_inner | epoch 020:   3906 / 11284 loss=3.522, nll_loss=1.815, ppl=3.52, wps=71788.9, ups=1.21, wpb=59399.2, bsz=2205.8, num_updates=218100, lr=0.000214127, gnorm=0.323, loss_scale=2, train_wall=79, gb_free=39.6, wall=182193
2023-06-13 18:24:14 | INFO | train_inner | epoch 020:   4006 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=72791.2, ups=1.22, wpb=59472.3, bsz=2191.8, num_updates=218200, lr=0.000214078, gnorm=0.322, loss_scale=2, train_wall=78, gb_free=39.5, wall=182275
2023-06-13 18:25:36 | INFO | train_inner | epoch 020:   4106 / 11284 loss=3.516, nll_loss=1.809, ppl=3.5, wps=72689.8, ups=1.22, wpb=59488.2, bsz=2232.7, num_updates=218300, lr=0.000214029, gnorm=0.32, loss_scale=2, train_wall=78, gb_free=39.4, wall=182357
2023-06-13 18:26:59 | INFO | train_inner | epoch 020:   4206 / 11284 loss=3.516, nll_loss=1.809, ppl=3.5, wps=71868.5, ups=1.21, wpb=59588.2, bsz=2297.8, num_updates=218400, lr=0.00021398, gnorm=0.325, loss_scale=2, train_wall=78, gb_free=39.6, wall=182439
2023-06-13 18:28:21 | INFO | train_inner | epoch 020:   4306 / 11284 loss=3.506, nll_loss=1.797, ppl=3.48, wps=72589.1, ups=1.22, wpb=59577.6, bsz=2251.7, num_updates=218500, lr=0.000213931, gnorm=0.329, loss_scale=2, train_wall=78, gb_free=39.7, wall=182522
2023-06-13 18:29:43 | INFO | train_inner | epoch 020:   4406 / 11284 loss=3.519, nll_loss=1.812, ppl=3.51, wps=72758.2, ups=1.22, wpb=59444.4, bsz=2165.6, num_updates=218600, lr=0.000213882, gnorm=0.326, loss_scale=2, train_wall=78, gb_free=39.5, wall=182603
2023-06-13 18:31:05 | INFO | train_inner | epoch 020:   4506 / 11284 loss=3.514, nll_loss=1.807, ppl=3.5, wps=71932.3, ups=1.21, wpb=59567, bsz=2252.2, num_updates=218700, lr=0.000213833, gnorm=0.323, loss_scale=2, train_wall=79, gb_free=39.5, wall=182686
2023-06-13 18:32:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 18:32:30 | INFO | train_inner | epoch 020:   4607 / 11284 loss=3.527, nll_loss=1.821, ppl=3.53, wps=70463.8, ups=1.18, wpb=59465.2, bsz=2258.7, num_updates=218800, lr=0.000213785, gnorm=0.325, loss_scale=2, train_wall=80, gb_free=39.6, wall=182770
2023-06-13 18:33:53 | INFO | train_inner | epoch 020:   4707 / 11284 loss=3.525, nll_loss=1.819, ppl=3.53, wps=71173.7, ups=1.2, wpb=59392.3, bsz=2202.1, num_updates=218900, lr=0.000213736, gnorm=0.329, loss_scale=2, train_wall=79, gb_free=39.6, wall=182854
2023-06-13 18:35:16 | INFO | train_inner | epoch 020:   4807 / 11284 loss=3.517, nll_loss=1.81, ppl=3.51, wps=71766.2, ups=1.21, wpb=59436.2, bsz=2172, num_updates=219000, lr=0.000213687, gnorm=0.331, loss_scale=2, train_wall=79, gb_free=39.6, wall=182937
2023-06-13 18:36:40 | INFO | train_inner | epoch 020:   4907 / 11284 loss=3.521, nll_loss=1.814, ppl=3.52, wps=71245.1, ups=1.2, wpb=59579.6, bsz=2255.3, num_updates=219100, lr=0.000213638, gnorm=0.339, loss_scale=2, train_wall=80, gb_free=39.6, wall=183020
2023-06-13 18:38:02 | INFO | train_inner | epoch 020:   5007 / 11284 loss=3.515, nll_loss=1.807, ppl=3.5, wps=71884, ups=1.21, wpb=59443.1, bsz=2235.2, num_updates=219200, lr=0.000213589, gnorm=0.326, loss_scale=2, train_wall=79, gb_free=39.6, wall=183103
2023-06-13 18:39:26 | INFO | train_inner | epoch 020:   5107 / 11284 loss=3.51, nll_loss=1.802, ppl=3.49, wps=70800.2, ups=1.19, wpb=59296.2, bsz=2259.3, num_updates=219300, lr=0.000213541, gnorm=0.342, loss_scale=2, train_wall=80, gb_free=39.6, wall=183187
2023-06-13 18:40:49 | INFO | train_inner | epoch 020:   5207 / 11284 loss=3.515, nll_loss=1.808, ppl=3.5, wps=71856.3, ups=1.2, wpb=59747.1, bsz=2316.3, num_updates=219400, lr=0.000213492, gnorm=0.328, loss_scale=2, train_wall=79, gb_free=39.6, wall=183270
2023-06-13 18:42:13 | INFO | train_inner | epoch 020:   5307 / 11284 loss=3.535, nll_loss=1.83, ppl=3.55, wps=71008, ups=1.19, wpb=59466.8, bsz=2214.2, num_updates=219500, lr=0.000213443, gnorm=0.34, loss_scale=2, train_wall=80, gb_free=39.6, wall=183354
2023-06-13 18:43:36 | INFO | train_inner | epoch 020:   5407 / 11284 loss=3.506, nll_loss=1.798, ppl=3.48, wps=72168, ups=1.21, wpb=59769.7, bsz=2216, num_updates=219600, lr=0.000213395, gnorm=0.328, loss_scale=2, train_wall=79, gb_free=39.6, wall=183436
2023-06-13 18:44:59 | INFO | train_inner | epoch 020:   5507 / 11284 loss=3.503, nll_loss=1.794, ppl=3.47, wps=71337, ups=1.2, wpb=59484.7, bsz=2181, num_updates=219700, lr=0.000213346, gnorm=0.324, loss_scale=2, train_wall=80, gb_free=39.5, wall=183520
2023-06-13 18:46:22 | INFO | train_inner | epoch 020:   5607 / 11284 loss=3.507, nll_loss=1.799, ppl=3.48, wps=72218.1, ups=1.21, wpb=59672, bsz=2245.9, num_updates=219800, lr=0.000213298, gnorm=0.325, loss_scale=4, train_wall=78, gb_free=39.6, wall=183602
2023-06-13 18:47:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 18:47:46 | INFO | train_inner | epoch 020:   5708 / 11284 loss=3.511, nll_loss=1.804, ppl=3.49, wps=70361, ups=1.19, wpb=59311.2, bsz=2255, num_updates=219900, lr=0.000213249, gnorm=0.326, loss_scale=2, train_wall=80, gb_free=39.6, wall=183687
2023-06-13 18:49:10 | INFO | train_inner | epoch 020:   5808 / 11284 loss=3.504, nll_loss=1.795, ppl=3.47, wps=71382.6, ups=1.2, wpb=59656.4, bsz=2267.1, num_updates=220000, lr=0.000213201, gnorm=0.332, loss_scale=2, train_wall=80, gb_free=39.6, wall=183770
2023-06-13 18:50:33 | INFO | train_inner | epoch 020:   5908 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71300.1, ups=1.2, wpb=59654.7, bsz=2250, num_updates=220100, lr=0.000213152, gnorm=0.32, loss_scale=2, train_wall=80, gb_free=39.6, wall=183854
2023-06-13 18:51:57 | INFO | train_inner | epoch 020:   6008 / 11284 loss=3.522, nll_loss=1.816, ppl=3.52, wps=71858.7, ups=1.2, wpb=59692.1, bsz=2205.2, num_updates=220200, lr=0.000213104, gnorm=0.336, loss_scale=2, train_wall=79, gb_free=39.5, wall=183937
2023-06-13 18:53:19 | INFO | train_inner | epoch 020:   6108 / 11284 loss=3.515, nll_loss=1.807, ppl=3.5, wps=72372.5, ups=1.22, wpb=59449, bsz=2225.4, num_updates=220300, lr=0.000213056, gnorm=0.327, loss_scale=2, train_wall=78, gb_free=39.6, wall=184019
2023-06-13 18:54:42 | INFO | train_inner | epoch 020:   6208 / 11284 loss=3.522, nll_loss=1.816, ppl=3.52, wps=71891.5, ups=1.21, wpb=59606.3, bsz=2254.7, num_updates=220400, lr=0.000213007, gnorm=0.325, loss_scale=2, train_wall=79, gb_free=39.6, wall=184102
2023-06-13 18:56:05 | INFO | train_inner | epoch 020:   6308 / 11284 loss=3.51, nll_loss=1.802, ppl=3.49, wps=71707.3, ups=1.2, wpb=59690.7, bsz=2145.8, num_updates=220500, lr=0.000212959, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.6, wall=184185
2023-06-13 18:57:28 | INFO | train_inner | epoch 020:   6408 / 11284 loss=3.522, nll_loss=1.816, ppl=3.52, wps=71773.7, ups=1.2, wpb=59630.4, bsz=2182.2, num_updates=220600, lr=0.000212911, gnorm=0.323, loss_scale=2, train_wall=79, gb_free=39.6, wall=184268
2023-06-13 18:58:50 | INFO | train_inner | epoch 020:   6508 / 11284 loss=3.516, nll_loss=1.809, ppl=3.5, wps=72432.5, ups=1.21, wpb=59641.7, bsz=2136.9, num_updates=220700, lr=0.000212862, gnorm=0.322, loss_scale=2, train_wall=78, gb_free=39.6, wall=184351
2023-06-13 19:00:12 | INFO | train_inner | epoch 020:   6608 / 11284 loss=3.522, nll_loss=1.816, ppl=3.52, wps=72605.4, ups=1.22, wpb=59506.1, bsz=2219.7, num_updates=220800, lr=0.000212814, gnorm=0.338, loss_scale=2, train_wall=78, gb_free=39.6, wall=184433
2023-06-13 19:01:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 19:01:35 | INFO | train_inner | epoch 020:   6709 / 11284 loss=3.507, nll_loss=1.799, ppl=3.48, wps=72415.1, ups=1.21, wpb=59639.7, bsz=2156.1, num_updates=220900, lr=0.000212766, gnorm=0.33, loss_scale=2, train_wall=78, gb_free=39.6, wall=184515
2023-06-13 19:02:56 | INFO | train_inner | epoch 020:   6809 / 11284 loss=3.528, nll_loss=1.822, ppl=3.54, wps=72556.9, ups=1.22, wpb=59441.4, bsz=2201.5, num_updates=221000, lr=0.000212718, gnorm=0.335, loss_scale=2, train_wall=78, gb_free=39.5, wall=184597
2023-06-13 19:04:19 | INFO | train_inner | epoch 020:   6909 / 11284 loss=3.51, nll_loss=1.803, ppl=3.49, wps=71561.6, ups=1.2, wpb=59390.8, bsz=2262.9, num_updates=221100, lr=0.00021267, gnorm=0.329, loss_scale=2, train_wall=79, gb_free=39.6, wall=184680
2023-06-13 19:05:43 | INFO | train_inner | epoch 020:   7009 / 11284 loss=3.517, nll_loss=1.81, ppl=3.51, wps=71441.3, ups=1.2, wpb=59662.4, bsz=2358.9, num_updates=221200, lr=0.000212622, gnorm=0.335, loss_scale=2, train_wall=79, gb_free=39.6, wall=184764
2023-06-13 19:07:06 | INFO | train_inner | epoch 020:   7109 / 11284 loss=3.524, nll_loss=1.818, ppl=3.53, wps=71430.1, ups=1.2, wpb=59538.4, bsz=2262.1, num_updates=221300, lr=0.000212574, gnorm=0.336, loss_scale=2, train_wall=79, gb_free=39.6, wall=184847
2023-06-13 19:08:30 | INFO | train_inner | epoch 020:   7209 / 11284 loss=3.524, nll_loss=1.818, ppl=3.53, wps=70765, ups=1.19, wpb=59385.4, bsz=2250.1, num_updates=221400, lr=0.000212526, gnorm=0.325, loss_scale=2, train_wall=80, gb_free=39.5, wall=184931
2023-06-13 19:09:54 | INFO | train_inner | epoch 020:   7309 / 11284 loss=3.521, nll_loss=1.815, ppl=3.52, wps=70923.2, ups=1.19, wpb=59394.8, bsz=2230, num_updates=221500, lr=0.000212478, gnorm=0.33, loss_scale=2, train_wall=80, gb_free=39.4, wall=185015
2023-06-13 19:11:18 | INFO | train_inner | epoch 020:   7409 / 11284 loss=3.525, nll_loss=1.819, ppl=3.53, wps=70869.4, ups=1.19, wpb=59539.3, bsz=2338.2, num_updates=221600, lr=0.00021243, gnorm=0.318, loss_scale=2, train_wall=80, gb_free=39.6, wall=185099
2023-06-13 19:12:42 | INFO | train_inner | epoch 020:   7509 / 11284 loss=3.516, nll_loss=1.809, ppl=3.5, wps=71257.5, ups=1.2, wpb=59533.9, bsz=2272.8, num_updates=221700, lr=0.000212382, gnorm=0.322, loss_scale=2, train_wall=80, gb_free=39.5, wall=185182
2023-06-13 19:14:05 | INFO | train_inner | epoch 020:   7609 / 11284 loss=3.509, nll_loss=1.801, ppl=3.49, wps=71555.5, ups=1.21, wpb=59349.1, bsz=2235.3, num_updates=221800, lr=0.000212334, gnorm=0.322, loss_scale=2, train_wall=79, gb_free=39.5, wall=185265
2023-06-13 19:15:27 | INFO | train_inner | epoch 020:   7709 / 11284 loss=3.534, nll_loss=1.829, ppl=3.55, wps=71722.2, ups=1.21, wpb=59433.8, bsz=2173.1, num_updates=221900, lr=0.000212286, gnorm=0.325, loss_scale=2, train_wall=79, gb_free=39.6, wall=185348
2023-06-13 19:16:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 19:16:52 | INFO | train_inner | epoch 020:   7810 / 11284 loss=3.518, nll_loss=1.811, ppl=3.51, wps=70199, ups=1.18, wpb=59599.4, bsz=2203.4, num_updates=222000, lr=0.000212238, gnorm=0.326, loss_scale=2, train_wall=81, gb_free=39.6, wall=185433
2023-06-13 19:18:16 | INFO | train_inner | epoch 020:   7910 / 11284 loss=3.515, nll_loss=1.808, ppl=3.5, wps=70782.9, ups=1.19, wpb=59527.3, bsz=2193.9, num_updates=222100, lr=0.00021219, gnorm=0.318, loss_scale=2, train_wall=80, gb_free=39.6, wall=185517
2023-06-13 19:19:39 | INFO | train_inner | epoch 020:   8010 / 11284 loss=3.541, nll_loss=1.837, ppl=3.57, wps=72160.8, ups=1.21, wpb=59415, bsz=2314.8, num_updates=222200, lr=0.000212143, gnorm=0.328, loss_scale=2, train_wall=78, gb_free=39.5, wall=185599
2023-06-13 19:21:02 | INFO | train_inner | epoch 020:   8110 / 11284 loss=3.501, nll_loss=1.792, ppl=3.46, wps=71244.9, ups=1.2, wpb=59296.8, bsz=2184.7, num_updates=222300, lr=0.000212095, gnorm=0.336, loss_scale=2, train_wall=79, gb_free=39.5, wall=185683
2023-06-13 19:22:25 | INFO | train_inner | epoch 020:   8210 / 11284 loss=3.517, nll_loss=1.81, ppl=3.51, wps=71235.9, ups=1.2, wpb=59397.5, bsz=2290.2, num_updates=222400, lr=0.000212047, gnorm=0.333, loss_scale=2, train_wall=80, gb_free=39.6, wall=185766
2023-06-13 19:23:49 | INFO | train_inner | epoch 020:   8310 / 11284 loss=3.531, nll_loss=1.825, ppl=3.54, wps=71318, ups=1.2, wpb=59517.2, bsz=2223.3, num_updates=222500, lr=0.000212, gnorm=0.33, loss_scale=2, train_wall=80, gb_free=39.5, wall=185849
2023-06-13 19:25:12 | INFO | train_inner | epoch 020:   8410 / 11284 loss=3.513, nll_loss=1.805, ppl=3.49, wps=71316.1, ups=1.2, wpb=59567.1, bsz=2199.4, num_updates=222600, lr=0.000211952, gnorm=0.333, loss_scale=2, train_wall=79, gb_free=39.6, wall=185933
2023-06-13 19:26:36 | INFO | train_inner | epoch 020:   8510 / 11284 loss=3.517, nll_loss=1.81, ppl=3.51, wps=71175.1, ups=1.2, wpb=59521.5, bsz=2273.9, num_updates=222700, lr=0.000211904, gnorm=0.323, loss_scale=2, train_wall=80, gb_free=39.5, wall=186017
2023-06-13 19:28:00 | INFO | train_inner | epoch 020:   8610 / 11284 loss=3.525, nll_loss=1.819, ppl=3.53, wps=71219.3, ups=1.19, wpb=59640, bsz=2200.7, num_updates=222800, lr=0.000211857, gnorm=0.332, loss_scale=2, train_wall=80, gb_free=39.6, wall=186100
2023-06-13 19:29:23 | INFO | train_inner | epoch 020:   8710 / 11284 loss=3.517, nll_loss=1.81, ppl=3.51, wps=71248.2, ups=1.19, wpb=59662.6, bsz=2191.4, num_updates=222900, lr=0.000211809, gnorm=0.327, loss_scale=2, train_wall=80, gb_free=39.6, wall=186184
2023-06-13 19:30:47 | INFO | train_inner | epoch 020:   8810 / 11284 loss=3.506, nll_loss=1.798, ppl=3.48, wps=71154.5, ups=1.2, wpb=59436.7, bsz=2297.3, num_updates=223000, lr=0.000211762, gnorm=0.342, loss_scale=4, train_wall=80, gb_free=39.6, wall=186268
2023-06-13 19:30:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 19:32:12 | INFO | train_inner | epoch 020:   8911 / 11284 loss=3.506, nll_loss=1.798, ppl=3.48, wps=70052, ups=1.18, wpb=59558.9, bsz=2263.7, num_updates=223100, lr=0.000211714, gnorm=0.329, loss_scale=2, train_wall=81, gb_free=39.6, wall=186353
2023-06-13 19:33:35 | INFO | train_inner | epoch 020:   9011 / 11284 loss=3.508, nll_loss=1.8, ppl=3.48, wps=71045.3, ups=1.2, wpb=59188, bsz=2208.2, num_updates=223200, lr=0.000211667, gnorm=0.336, loss_scale=2, train_wall=79, gb_free=39.5, wall=186436
2023-06-13 19:34:58 | INFO | train_inner | epoch 020:   9111 / 11284 loss=3.511, nll_loss=1.804, ppl=3.49, wps=71709.9, ups=1.21, wpb=59337.9, bsz=2241.3, num_updates=223300, lr=0.000211619, gnorm=0.329, loss_scale=2, train_wall=79, gb_free=38.9, wall=186519
2023-06-13 19:36:22 | INFO | train_inner | epoch 020:   9211 / 11284 loss=3.528, nll_loss=1.823, ppl=3.54, wps=71109.6, ups=1.19, wpb=59698.6, bsz=2267.9, num_updates=223400, lr=0.000211572, gnorm=0.322, loss_scale=2, train_wall=80, gb_free=39.6, wall=186603
2023-06-13 19:37:45 | INFO | train_inner | epoch 020:   9311 / 11284 loss=3.529, nll_loss=1.824, ppl=3.54, wps=71392.1, ups=1.2, wpb=59425.8, bsz=2312.1, num_updates=223500, lr=0.000211525, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.5, wall=186686
2023-06-13 19:39:07 | INFO | train_inner | epoch 020:   9411 / 11284 loss=3.51, nll_loss=1.802, ppl=3.49, wps=72456, ups=1.22, wpb=59424.6, bsz=2221.7, num_updates=223600, lr=0.000211477, gnorm=0.334, loss_scale=2, train_wall=78, gb_free=39.6, wall=186768
2023-06-13 19:40:29 | INFO | train_inner | epoch 020:   9511 / 11284 loss=3.52, nll_loss=1.813, ppl=3.51, wps=72497.4, ups=1.22, wpb=59271.9, bsz=2134.9, num_updates=223700, lr=0.00021143, gnorm=0.341, loss_scale=2, train_wall=78, gb_free=39.6, wall=186850
2023-06-13 19:41:52 | INFO | train_inner | epoch 020:   9611 / 11284 loss=3.511, nll_loss=1.804, ppl=3.49, wps=71823.5, ups=1.21, wpb=59405.3, bsz=2192.4, num_updates=223800, lr=0.000211383, gnorm=0.325, loss_scale=2, train_wall=79, gb_free=39.5, wall=186932
2023-06-13 19:43:15 | INFO | train_inner | epoch 020:   9711 / 11284 loss=3.519, nll_loss=1.813, ppl=3.51, wps=70988.6, ups=1.2, wpb=59333.2, bsz=2307.1, num_updates=223900, lr=0.000211336, gnorm=0.326, loss_scale=2, train_wall=80, gb_free=39.6, wall=187016
2023-06-13 19:44:39 | INFO | train_inner | epoch 020:   9811 / 11284 loss=3.521, nll_loss=1.815, ppl=3.52, wps=71328.5, ups=1.2, wpb=59416.1, bsz=2152.6, num_updates=224000, lr=0.000211289, gnorm=0.317, loss_scale=2, train_wall=79, gb_free=39.6, wall=187099
2023-06-13 19:45:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 19:46:02 | INFO | train_inner | epoch 020:   9912 / 11284 loss=3.506, nll_loss=1.798, ppl=3.48, wps=71419.5, ups=1.2, wpb=59327.5, bsz=2277, num_updates=224100, lr=0.000211241, gnorm=0.325, loss_scale=2, train_wall=79, gb_free=39.6, wall=187182
2023-06-13 19:47:24 | INFO | train_inner | epoch 020:  10012 / 11284 loss=3.521, nll_loss=1.814, ppl=3.52, wps=72440.3, ups=1.22, wpb=59531.5, bsz=2221.6, num_updates=224200, lr=0.000211194, gnorm=0.328, loss_scale=2, train_wall=78, gb_free=39.6, wall=187264
2023-06-13 19:48:47 | INFO | train_inner | epoch 020:  10112 / 11284 loss=3.524, nll_loss=1.818, ppl=3.53, wps=71846.1, ups=1.2, wpb=59743.4, bsz=2224.2, num_updates=224300, lr=0.000211147, gnorm=0.322, loss_scale=2, train_wall=79, gb_free=39.5, wall=187348
2023-06-13 19:50:10 | INFO | train_inner | epoch 020:  10212 / 11284 loss=3.523, nll_loss=1.817, ppl=3.52, wps=71174.7, ups=1.2, wpb=59388.6, bsz=2214.9, num_updates=224400, lr=0.0002111, gnorm=0.331, loss_scale=2, train_wall=79, gb_free=39.6, wall=187431
2023-06-13 19:51:34 | INFO | train_inner | epoch 020:  10312 / 11284 loss=3.522, nll_loss=1.816, ppl=3.52, wps=71074.4, ups=1.19, wpb=59554.7, bsz=2262.9, num_updates=224500, lr=0.000211053, gnorm=0.325, loss_scale=2, train_wall=80, gb_free=38.9, wall=187515
2023-06-13 19:53:00 | INFO | train_inner | epoch 020:  10412 / 11284 loss=3.509, nll_loss=1.801, ppl=3.48, wps=69111.6, ups=1.17, wpb=59323, bsz=2236.3, num_updates=224600, lr=0.000211006, gnorm=0.335, loss_scale=2, train_wall=82, gb_free=39.2, wall=187601
2023-06-13 19:54:26 | INFO | train_inner | epoch 020:  10512 / 11284 loss=3.524, nll_loss=1.818, ppl=3.53, wps=69705.2, ups=1.17, wpb=59567.4, bsz=2268.6, num_updates=224700, lr=0.000210959, gnorm=0.326, loss_scale=2, train_wall=82, gb_free=39.6, wall=187686
2023-06-13 19:55:51 | INFO | train_inner | epoch 020:  10612 / 11284 loss=3.52, nll_loss=1.813, ppl=3.51, wps=69266.4, ups=1.16, wpb=59502.8, bsz=2189.9, num_updates=224800, lr=0.000210912, gnorm=0.327, loss_scale=2, train_wall=82, gb_free=39.6, wall=187772
2023-06-13 19:57:16 | INFO | train_inner | epoch 020:  10712 / 11284 loss=3.521, nll_loss=1.815, ppl=3.52, wps=70022.6, ups=1.18, wpb=59444.9, bsz=2210.9, num_updates=224900, lr=0.000210865, gnorm=0.336, loss_scale=2, train_wall=81, gb_free=39.6, wall=187857
2023-06-13 19:58:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-06-13 19:58:42 | INFO | train_inner | epoch 020:  10813 / 11284 loss=3.516, nll_loss=1.809, ppl=3.5, wps=69550.9, ups=1.17, wpb=59528.3, bsz=2160.4, num_updates=225000, lr=0.000210819, gnorm=0.334, loss_scale=1, train_wall=82, gb_free=39.6, wall=187943
2023-06-13 20:00:06 | INFO | train_inner | epoch 020:  10913 / 11284 loss=3.521, nll_loss=1.814, ppl=3.52, wps=70371.8, ups=1.19, wpb=59315, bsz=2216.5, num_updates=225100, lr=0.000210772, gnorm=0.332, loss_scale=1, train_wall=80, gb_free=39.6, wall=188027
2023-06-13 20:01:30 | INFO | train_inner | epoch 020:  11013 / 11284 loss=3.505, nll_loss=1.796, ppl=3.47, wps=71245.8, ups=1.2, wpb=59416.9, bsz=2219.7, num_updates=225200, lr=0.000210725, gnorm=0.325, loss_scale=1, train_wall=79, gb_free=39.6, wall=188110
2023-06-13 20:02:53 | INFO | train_inner | epoch 020:  11113 / 11284 loss=3.522, nll_loss=1.816, ppl=3.52, wps=71461.5, ups=1.2, wpb=59420, bsz=2241.3, num_updates=225300, lr=0.000210678, gnorm=0.336, loss_scale=1, train_wall=79, gb_free=39.6, wall=188193
2023-06-13 20:04:16 | INFO | train_inner | epoch 020:  11213 / 11284 loss=3.516, nll_loss=1.809, ppl=3.5, wps=71512.6, ups=1.2, wpb=59412.3, bsz=2223.8, num_updates=225400, lr=0.000210631, gnorm=0.328, loss_scale=1, train_wall=79, gb_free=39.6, wall=188276
2023-06-13 20:05:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-13 20:05:32 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 4.302 | nll_loss 2.623 | ppl 6.16 | bleu 21.02 | wps 3698.8 | wpb 2397.5 | bsz 71.5 | num_updates 225471 | best_loss 4.302
2023-06-13 20:05:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 225471 updates
2023-06-13 20:05:32 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint20.pt
2023-06-13 20:05:35 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint20.pt
2023-06-13 20:05:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint20.pt (epoch 20 @ 225471 updates, score 4.302) (writing took 6.970303419046104 seconds)
2023-06-13 20:05:39 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-06-13 20:05:39 | INFO | train | epoch 020 | loss 3.516 | nll_loss 1.809 | ppl 3.5 | wps 70964.2 | ups 1.19 | wpb 59500.7 | bsz 2227.3 | num_updates 225471 | lr 0.000210598 | gnorm 0.328 | loss_scale 1 | train_wall 8971 | gb_free 39.5 | wall 188360
2023-06-13 20:05:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-13 20:05:40 | INFO | fairseq.trainer | begin training epoch 21
2023-06-13 20:05:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-13 20:06:05 | INFO | train_inner | epoch 021:     29 / 11284 loss=3.526, nll_loss=1.82, ppl=3.53, wps=54464.1, ups=0.92, wpb=59176, bsz=2216.1, num_updates=225500, lr=0.000210585, gnorm=0.335, loss_scale=1, train_wall=79, gb_free=39.6, wall=188385
2023-06-13 20:07:28 | INFO | train_inner | epoch 021:    129 / 11284 loss=3.5, nll_loss=1.79, ppl=3.46, wps=71801.5, ups=1.2, wpb=59610.7, bsz=2204.8, num_updates=225600, lr=0.000210538, gnorm=0.33, loss_scale=1, train_wall=79, gb_free=39.6, wall=188468
2023-06-13 20:08:50 | INFO | train_inner | epoch 021:    229 / 11284 loss=3.508, nll_loss=1.799, ppl=3.48, wps=72658.9, ups=1.22, wpb=59620.9, bsz=2160.4, num_updates=225700, lr=0.000210491, gnorm=0.339, loss_scale=1, train_wall=78, gb_free=39.6, wall=188550
2023-06-13 20:10:13 | INFO | train_inner | epoch 021:    329 / 11284 loss=3.499, nll_loss=1.79, ppl=3.46, wps=71944.7, ups=1.21, wpb=59672.1, bsz=2206.2, num_updates=225800, lr=0.000210445, gnorm=0.328, loss_scale=1, train_wall=79, gb_free=39.5, wall=188633
2023-06-13 20:11:36 | INFO | train_inner | epoch 021:    429 / 11284 loss=3.503, nll_loss=1.794, ppl=3.47, wps=71599.1, ups=1.2, wpb=59617.4, bsz=2216.8, num_updates=225900, lr=0.000210398, gnorm=0.342, loss_scale=1, train_wall=79, gb_free=39.5, wall=188716
2023-06-13 20:13:00 | INFO | train_inner | epoch 021:    529 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=71212.9, ups=1.19, wpb=59592.7, bsz=2284.5, num_updates=226000, lr=0.000210352, gnorm=0.325, loss_scale=2, train_wall=80, gb_free=39.6, wall=188800
2023-06-13 20:14:22 | INFO | train_inner | epoch 021:    629 / 11284 loss=3.507, nll_loss=1.799, ppl=3.48, wps=71702.6, ups=1.21, wpb=59362.1, bsz=2216.7, num_updates=226100, lr=0.000210305, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.6, wall=188883
2023-06-13 20:15:46 | INFO | train_inner | epoch 021:    729 / 11284 loss=3.507, nll_loss=1.798, ppl=3.48, wps=71219.6, ups=1.2, wpb=59485.7, bsz=2212.7, num_updates=226200, lr=0.000210259, gnorm=0.322, loss_scale=2, train_wall=80, gb_free=39.6, wall=188966
2023-06-13 20:17:10 | INFO | train_inner | epoch 021:    829 / 11284 loss=3.505, nll_loss=1.796, ppl=3.47, wps=70937.2, ups=1.19, wpb=59587.8, bsz=2309.7, num_updates=226300, lr=0.000210212, gnorm=0.324, loss_scale=2, train_wall=80, gb_free=39.6, wall=189050
2023-06-13 20:18:33 | INFO | train_inner | epoch 021:    929 / 11284 loss=3.519, nll_loss=1.812, ppl=3.51, wps=71423.4, ups=1.2, wpb=59565.2, bsz=2191.3, num_updates=226400, lr=0.000210166, gnorm=0.323, loss_scale=2, train_wall=80, gb_free=39.6, wall=189134
2023-06-13 20:19:57 | INFO | train_inner | epoch 021:   1029 / 11284 loss=3.504, nll_loss=1.795, ppl=3.47, wps=71245.9, ups=1.19, wpb=59669.3, bsz=2273.3, num_updates=226500, lr=0.000210119, gnorm=0.337, loss_scale=2, train_wall=80, gb_free=39.6, wall=189218
2023-06-13 20:21:20 | INFO | train_inner | epoch 021:   1129 / 11284 loss=3.507, nll_loss=1.798, ppl=3.48, wps=71119.5, ups=1.2, wpb=59375.8, bsz=2180.3, num_updates=226600, lr=0.000210073, gnorm=0.337, loss_scale=2, train_wall=80, gb_free=39.3, wall=189301
2023-06-13 20:22:43 | INFO | train_inner | epoch 021:   1229 / 11284 loss=3.519, nll_loss=1.812, ppl=3.51, wps=72464.8, ups=1.22, wpb=59584, bsz=2270, num_updates=226700, lr=0.000210027, gnorm=0.325, loss_scale=2, train_wall=78, gb_free=39.5, wall=189383
2023-06-13 20:24:06 | INFO | train_inner | epoch 021:   1329 / 11284 loss=3.498, nll_loss=1.789, ppl=3.45, wps=71204.3, ups=1.2, wpb=59466.1, bsz=2222.7, num_updates=226800, lr=0.00020998, gnorm=0.331, loss_scale=2, train_wall=80, gb_free=39.6, wall=189467
2023-06-13 20:25:30 | INFO | train_inner | epoch 021:   1429 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=71600.8, ups=1.2, wpb=59750.6, bsz=2316.6, num_updates=226900, lr=0.000209934, gnorm=0.321, loss_scale=2, train_wall=79, gb_free=39.5, wall=189550
2023-06-13 20:26:52 | INFO | train_inner | epoch 021:   1529 / 11284 loss=3.51, nll_loss=1.802, ppl=3.49, wps=71502.5, ups=1.21, wpb=59105.3, bsz=2110.6, num_updates=227000, lr=0.000209888, gnorm=0.333, loss_scale=2, train_wall=79, gb_free=39.6, wall=189633
2023-06-13 20:27:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 20:28:16 | INFO | train_inner | epoch 021:   1630 / 11284 loss=3.517, nll_loss=1.81, ppl=3.51, wps=70852.2, ups=1.19, wpb=59472.9, bsz=2206.4, num_updates=227100, lr=0.000209842, gnorm=0.332, loss_scale=2, train_wall=80, gb_free=38.7, wall=189717
2023-06-13 20:29:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-06-13 20:29:41 | INFO | train_inner | epoch 021:   1731 / 11284 loss=3.522, nll_loss=1.815, ppl=3.52, wps=70392.5, ups=1.18, wpb=59506.3, bsz=2263.2, num_updates=227200, lr=0.000209795, gnorm=0.343, loss_scale=1, train_wall=80, gb_free=39.6, wall=189801
2023-06-13 20:31:04 | INFO | train_inner | epoch 021:   1831 / 11284 loss=3.521, nll_loss=1.814, ppl=3.52, wps=71273.1, ups=1.2, wpb=59356.8, bsz=2219.5, num_updates=227300, lr=0.000209749, gnorm=0.341, loss_scale=1, train_wall=79, gb_free=39.5, wall=189885
2023-06-13 20:32:27 | INFO | train_inner | epoch 021:   1931 / 11284 loss=3.515, nll_loss=1.808, ppl=3.5, wps=71916.8, ups=1.21, wpb=59444.7, bsz=2184.6, num_updates=227400, lr=0.000209703, gnorm=0.331, loss_scale=1, train_wall=79, gb_free=39.5, wall=189967
2023-06-13 20:33:52 | INFO | train_inner | epoch 021:   2031 / 11284 loss=3.501, nll_loss=1.792, ppl=3.46, wps=70014.7, ups=1.17, wpb=59676.8, bsz=2298.7, num_updates=227500, lr=0.000209657, gnorm=0.325, loss_scale=1, train_wall=81, gb_free=39.6, wall=190053
2023-06-13 20:35:16 | INFO | train_inner | epoch 021:   2131 / 11284 loss=3.511, nll_loss=1.803, ppl=3.49, wps=70756.4, ups=1.19, wpb=59355.1, bsz=2191.4, num_updates=227600, lr=0.000209611, gnorm=0.327, loss_scale=1, train_wall=80, gb_free=39.6, wall=190136
2023-06-13 20:36:39 | INFO | train_inner | epoch 021:   2231 / 11284 loss=3.523, nll_loss=1.817, ppl=3.52, wps=71348.2, ups=1.2, wpb=59661.6, bsz=2193.9, num_updates=227700, lr=0.000209565, gnorm=0.323, loss_scale=1, train_wall=80, gb_free=39.6, wall=190220
2023-06-13 20:38:04 | INFO | train_inner | epoch 021:   2331 / 11284 loss=3.502, nll_loss=1.793, ppl=3.47, wps=70605.5, ups=1.19, wpb=59468.9, bsz=2360.6, num_updates=227800, lr=0.000209519, gnorm=0.326, loss_scale=1, train_wall=80, gb_free=39.5, wall=190304
2023-06-13 20:39:27 | INFO | train_inner | epoch 021:   2431 / 11284 loss=3.52, nll_loss=1.813, ppl=3.51, wps=71591.2, ups=1.2, wpb=59635.8, bsz=2203, num_updates=227900, lr=0.000209473, gnorm=0.326, loss_scale=1, train_wall=79, gb_free=39.6, wall=190388
2023-06-13 20:40:50 | INFO | train_inner | epoch 021:   2531 / 11284 loss=3.516, nll_loss=1.809, ppl=3.5, wps=71614.9, ups=1.2, wpb=59538.3, bsz=2291.2, num_updates=228000, lr=0.000209427, gnorm=0.33, loss_scale=1, train_wall=79, gb_free=39.6, wall=190471
2023-06-13 20:42:14 | INFO | train_inner | epoch 021:   2631 / 11284 loss=3.516, nll_loss=1.808, ppl=3.5, wps=71326.5, ups=1.2, wpb=59469.2, bsz=2218.2, num_updates=228100, lr=0.000209381, gnorm=0.338, loss_scale=1, train_wall=79, gb_free=39.6, wall=190554
2023-06-13 20:43:37 | INFO | train_inner | epoch 021:   2731 / 11284 loss=3.505, nll_loss=1.797, ppl=3.47, wps=71510.9, ups=1.2, wpb=59676.4, bsz=2178.3, num_updates=228200, lr=0.000209335, gnorm=0.327, loss_scale=1, train_wall=79, gb_free=39.5, wall=190638
2023-06-13 20:45:00 | INFO | train_inner | epoch 021:   2831 / 11284 loss=3.52, nll_loss=1.813, ppl=3.51, wps=71412.3, ups=1.2, wpb=59441.2, bsz=2175.4, num_updates=228300, lr=0.000209289, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.6, wall=190721
2023-06-13 20:46:24 | INFO | train_inner | epoch 021:   2931 / 11284 loss=3.514, nll_loss=1.806, ppl=3.5, wps=71143.8, ups=1.2, wpb=59391.6, bsz=2233.2, num_updates=228400, lr=0.000209243, gnorm=0.321, loss_scale=2, train_wall=80, gb_free=39.6, wall=190804
2023-06-13 20:47:46 | INFO | train_inner | epoch 021:   3031 / 11284 loss=3.508, nll_loss=1.8, ppl=3.48, wps=71981.9, ups=1.21, wpb=59339.9, bsz=2175.4, num_updates=228500, lr=0.000209198, gnorm=0.33, loss_scale=2, train_wall=79, gb_free=39.6, wall=190887
2023-06-13 20:49:09 | INFO | train_inner | epoch 021:   3131 / 11284 loss=3.511, nll_loss=1.803, ppl=3.49, wps=71689.8, ups=1.2, wpb=59505.1, bsz=2180.9, num_updates=228600, lr=0.000209152, gnorm=0.336, loss_scale=2, train_wall=79, gb_free=39.1, wall=190970
2023-06-13 20:50:33 | INFO | train_inner | epoch 021:   3231 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=71310.2, ups=1.2, wpb=59654.1, bsz=2197.6, num_updates=228700, lr=0.000209106, gnorm=0.341, loss_scale=2, train_wall=80, gb_free=39.6, wall=191053
2023-06-13 20:51:57 | INFO | train_inner | epoch 021:   3331 / 11284 loss=3.519, nll_loss=1.812, ppl=3.51, wps=71169, ups=1.19, wpb=59585.1, bsz=2263.6, num_updates=228800, lr=0.000209061, gnorm=0.334, loss_scale=2, train_wall=80, gb_free=39.6, wall=191137
2023-06-13 20:53:20 | INFO | train_inner | epoch 021:   3431 / 11284 loss=3.511, nll_loss=1.803, ppl=3.49, wps=71559.3, ups=1.2, wpb=59607.9, bsz=2203.3, num_updates=228900, lr=0.000209015, gnorm=0.33, loss_scale=2, train_wall=79, gb_free=39.6, wall=191220
2023-06-13 20:54:43 | INFO | train_inner | epoch 021:   3531 / 11284 loss=3.513, nll_loss=1.806, ppl=3.5, wps=71622.9, ups=1.2, wpb=59687.3, bsz=2231.1, num_updates=229000, lr=0.000208969, gnorm=0.326, loss_scale=2, train_wall=79, gb_free=39.5, wall=191304
2023-06-13 20:56:08 | INFO | train_inner | epoch 021:   3631 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=69762, ups=1.18, wpb=59240.3, bsz=2198.7, num_updates=229100, lr=0.000208924, gnorm=0.328, loss_scale=2, train_wall=81, gb_free=39.6, wall=191389
2023-06-13 20:57:32 | INFO | train_inner | epoch 021:   3731 / 11284 loss=3.526, nll_loss=1.82, ppl=3.53, wps=70764.5, ups=1.2, wpb=59209, bsz=2241.3, num_updates=229200, lr=0.000208878, gnorm=0.344, loss_scale=2, train_wall=80, gb_free=39.1, wall=191472
2023-06-13 20:58:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 20:58:56 | INFO | train_inner | epoch 021:   3832 / 11284 loss=3.519, nll_loss=1.812, ppl=3.51, wps=70640.8, ups=1.19, wpb=59472.3, bsz=2201.8, num_updates=229300, lr=0.000208832, gnorm=0.324, loss_scale=2, train_wall=80, gb_free=39.4, wall=191557
2023-06-13 21:00:18 | INFO | train_inner | epoch 021:   3932 / 11284 loss=3.511, nll_loss=1.803, ppl=3.49, wps=72871.8, ups=1.22, wpb=59815.4, bsz=2251.6, num_updates=229400, lr=0.000208787, gnorm=0.337, loss_scale=2, train_wall=78, gb_free=39.6, wall=191639
2023-06-13 21:01:41 | INFO | train_inner | epoch 021:   4032 / 11284 loss=3.513, nll_loss=1.805, ppl=3.49, wps=71576, ups=1.21, wpb=59291.7, bsz=2128.9, num_updates=229500, lr=0.000208741, gnorm=0.315, loss_scale=2, train_wall=79, gb_free=39.5, wall=191721
2023-06-13 21:03:04 | INFO | train_inner | epoch 021:   4132 / 11284 loss=3.517, nll_loss=1.811, ppl=3.51, wps=71246.2, ups=1.2, wpb=59579, bsz=2261.1, num_updates=229600, lr=0.000208696, gnorm=0.323, loss_scale=2, train_wall=80, gb_free=39.6, wall=191805
2023-06-13 21:04:28 | INFO | train_inner | epoch 021:   4232 / 11284 loss=3.519, nll_loss=1.813, ppl=3.51, wps=71219.3, ups=1.2, wpb=59443.1, bsz=2216.8, num_updates=229700, lr=0.000208651, gnorm=0.331, loss_scale=2, train_wall=79, gb_free=39.6, wall=191889
2023-06-13 21:05:51 | INFO | train_inner | epoch 021:   4332 / 11284 loss=3.51, nll_loss=1.802, ppl=3.49, wps=71345.8, ups=1.2, wpb=59351, bsz=2211.2, num_updates=229800, lr=0.000208605, gnorm=0.334, loss_scale=2, train_wall=80, gb_free=39.5, wall=191972
2023-06-13 21:07:14 | INFO | train_inner | epoch 021:   4432 / 11284 loss=3.516, nll_loss=1.809, ppl=3.5, wps=71697.3, ups=1.21, wpb=59466.8, bsz=2219.3, num_updates=229900, lr=0.00020856, gnorm=0.333, loss_scale=2, train_wall=79, gb_free=39.6, wall=192055
2023-06-13 21:08:37 | INFO | train_inner | epoch 021:   4532 / 11284 loss=3.513, nll_loss=1.806, ppl=3.5, wps=71527.8, ups=1.2, wpb=59515.9, bsz=2240.6, num_updates=230000, lr=0.000208514, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.6, wall=192138
2023-06-13 21:10:01 | INFO | train_inner | epoch 021:   4632 / 11284 loss=3.514, nll_loss=1.806, ppl=3.5, wps=71243.6, ups=1.2, wpb=59587.8, bsz=2256.7, num_updates=230100, lr=0.000208469, gnorm=0.327, loss_scale=2, train_wall=79, gb_free=39.5, wall=192222
2023-06-13 21:11:25 | INFO | train_inner | epoch 021:   4732 / 11284 loss=3.505, nll_loss=1.797, ppl=3.47, wps=71197.1, ups=1.19, wpb=59630.1, bsz=2206.6, num_updates=230200, lr=0.000208424, gnorm=0.323, loss_scale=2, train_wall=80, gb_free=39.6, wall=192305
2023-06-13 21:12:48 | INFO | train_inner | epoch 021:   4832 / 11284 loss=3.514, nll_loss=1.807, ppl=3.5, wps=71010, ups=1.2, wpb=59387.2, bsz=2162.1, num_updates=230300, lr=0.000208379, gnorm=0.328, loss_scale=4, train_wall=80, gb_free=39.6, wall=192389
2023-06-13 21:13:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 21:14:12 | INFO | train_inner | epoch 021:   4933 / 11284 loss=3.511, nll_loss=1.803, ppl=3.49, wps=70785.5, ups=1.19, wpb=59355.5, bsz=2275.7, num_updates=230400, lr=0.000208333, gnorm=0.334, loss_scale=2, train_wall=80, gb_free=39.6, wall=192473
2023-06-13 21:15:35 | INFO | train_inner | epoch 021:   5033 / 11284 loss=3.501, nll_loss=1.791, ppl=3.46, wps=71428.3, ups=1.2, wpb=59445.7, bsz=2168.2, num_updates=230500, lr=0.000208288, gnorm=0.325, loss_scale=2, train_wall=79, gb_free=39.6, wall=192556
2023-06-13 21:16:59 | INFO | train_inner | epoch 021:   5133 / 11284 loss=3.51, nll_loss=1.803, ppl=3.49, wps=71331, ups=1.2, wpb=59512.9, bsz=2346.9, num_updates=230600, lr=0.000208243, gnorm=0.325, loss_scale=2, train_wall=79, gb_free=39.6, wall=192639
2023-06-13 21:18:22 | INFO | train_inner | epoch 021:   5233 / 11284 loss=3.512, nll_loss=1.805, ppl=3.49, wps=71655.8, ups=1.2, wpb=59503.5, bsz=2244, num_updates=230700, lr=0.000208198, gnorm=0.325, loss_scale=2, train_wall=79, gb_free=39.6, wall=192722
2023-06-13 21:19:45 | INFO | train_inner | epoch 021:   5333 / 11284 loss=3.523, nll_loss=1.817, ppl=3.52, wps=71224.6, ups=1.2, wpb=59422, bsz=2216.1, num_updates=230800, lr=0.000208153, gnorm=0.333, loss_scale=2, train_wall=79, gb_free=39.5, wall=192806
2023-06-13 21:21:08 | INFO | train_inner | epoch 021:   5433 / 11284 loss=3.518, nll_loss=1.811, ppl=3.51, wps=71430, ups=1.2, wpb=59343.5, bsz=2179.9, num_updates=230900, lr=0.000208108, gnorm=0.338, loss_scale=2, train_wall=79, gb_free=39.6, wall=192889
2023-06-13 21:22:31 | INFO | train_inner | epoch 021:   5533 / 11284 loss=3.511, nll_loss=1.803, ppl=3.49, wps=71939, ups=1.21, wpb=59434.6, bsz=2236.9, num_updates=231000, lr=0.000208063, gnorm=0.334, loss_scale=2, train_wall=78, gb_free=39.6, wall=192972
2023-06-13 21:23:54 | INFO | train_inner | epoch 021:   5633 / 11284 loss=3.505, nll_loss=1.796, ppl=3.47, wps=71864.5, ups=1.21, wpb=59594.4, bsz=2245.3, num_updates=231100, lr=0.000208018, gnorm=0.343, loss_scale=2, train_wall=79, gb_free=39.6, wall=193055
2023-06-13 21:25:17 | INFO | train_inner | epoch 021:   5733 / 11284 loss=3.513, nll_loss=1.806, ppl=3.5, wps=71651.6, ups=1.21, wpb=59461.5, bsz=2183.6, num_updates=231200, lr=0.000207973, gnorm=0.327, loss_scale=2, train_wall=79, gb_free=39.5, wall=193138
2023-06-13 21:26:39 | INFO | train_inner | epoch 021:   5833 / 11284 loss=3.51, nll_loss=1.803, ppl=3.49, wps=72361.5, ups=1.22, wpb=59452.9, bsz=2254, num_updates=231300, lr=0.000207928, gnorm=0.334, loss_scale=2, train_wall=78, gb_free=39.5, wall=193220
2023-06-13 21:27:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 21:28:02 | INFO | train_inner | epoch 021:   5934 / 11284 loss=3.494, nll_loss=1.784, ppl=3.44, wps=71383.6, ups=1.2, wpb=59267.8, bsz=2174, num_updates=231400, lr=0.000207883, gnorm=0.331, loss_scale=2, train_wall=79, gb_free=39.5, wall=193303
2023-06-13 21:29:25 | INFO | train_inner | epoch 021:   6034 / 11284 loss=3.506, nll_loss=1.798, ppl=3.48, wps=71745.4, ups=1.2, wpb=59605.6, bsz=2175.8, num_updates=231500, lr=0.000207838, gnorm=0.334, loss_scale=2, train_wall=79, gb_free=39.6, wall=193386
2023-06-13 21:30:48 | INFO | train_inner | epoch 021:   6134 / 11284 loss=3.527, nll_loss=1.821, ppl=3.53, wps=71468.1, ups=1.2, wpb=59525.2, bsz=2178.4, num_updates=231600, lr=0.000207793, gnorm=0.337, loss_scale=2, train_wall=80, gb_free=39.6, wall=193469
2023-06-13 21:32:12 | INFO | train_inner | epoch 021:   6234 / 11284 loss=3.51, nll_loss=1.802, ppl=3.49, wps=71305, ups=1.2, wpb=59555.2, bsz=2178.5, num_updates=231700, lr=0.000207748, gnorm=0.337, loss_scale=2, train_wall=80, gb_free=39.5, wall=193553
2023-06-13 21:33:35 | INFO | train_inner | epoch 021:   6334 / 11284 loss=3.516, nll_loss=1.809, ppl=3.5, wps=71534.2, ups=1.21, wpb=59357.3, bsz=2182.2, num_updates=231800, lr=0.000207703, gnorm=0.343, loss_scale=2, train_wall=79, gb_free=39.6, wall=193636
2023-06-13 21:34:59 | INFO | train_inner | epoch 021:   6434 / 11284 loss=3.516, nll_loss=1.809, ppl=3.5, wps=71261.9, ups=1.19, wpb=59700.8, bsz=2259.3, num_updates=231900, lr=0.000207658, gnorm=0.318, loss_scale=2, train_wall=79, gb_free=39.6, wall=193719
2023-06-13 21:36:22 | INFO | train_inner | epoch 021:   6534 / 11284 loss=3.509, nll_loss=1.802, ppl=3.49, wps=70798.2, ups=1.2, wpb=59178.7, bsz=2280.1, num_updates=232000, lr=0.000207614, gnorm=0.335, loss_scale=2, train_wall=79, gb_free=39.5, wall=193803
2023-06-13 21:37:46 | INFO | train_inner | epoch 021:   6634 / 11284 loss=3.511, nll_loss=1.803, ppl=3.49, wps=71755.3, ups=1.2, wpb=59768.2, bsz=2195.9, num_updates=232100, lr=0.000207569, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.6, wall=193886
2023-06-13 21:39:09 | INFO | train_inner | epoch 021:   6734 / 11284 loss=3.516, nll_loss=1.809, ppl=3.51, wps=71319.6, ups=1.2, wpb=59339.3, bsz=2261.6, num_updates=232200, lr=0.000207524, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=39.6, wall=193969
2023-06-13 21:40:32 | INFO | train_inner | epoch 021:   6834 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=71562.2, ups=1.2, wpb=59481.6, bsz=2101.8, num_updates=232300, lr=0.00020748, gnorm=0.333, loss_scale=2, train_wall=79, gb_free=39.6, wall=194053
2023-06-13 21:41:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 21:41:56 | INFO | train_inner | epoch 021:   6935 / 11284 loss=3.519, nll_loss=1.812, ppl=3.51, wps=70828.4, ups=1.19, wpb=59416.1, bsz=2134.4, num_updates=232400, lr=0.000207435, gnorm=0.331, loss_scale=2, train_wall=80, gb_free=39.2, wall=194136
2023-06-13 21:43:19 | INFO | train_inner | epoch 021:   7035 / 11284 loss=3.509, nll_loss=1.801, ppl=3.48, wps=71148, ups=1.2, wpb=59425, bsz=2288.1, num_updates=232500, lr=0.00020739, gnorm=0.331, loss_scale=2, train_wall=79, gb_free=39.6, wall=194220
2023-06-13 21:44:42 | INFO | train_inner | epoch 021:   7135 / 11284 loss=3.512, nll_loss=1.804, ppl=3.49, wps=72265.5, ups=1.21, wpb=59482.9, bsz=2253.4, num_updates=232600, lr=0.000207346, gnorm=0.33, loss_scale=2, train_wall=78, gb_free=39.5, wall=194302
2023-06-13 21:46:04 | INFO | train_inner | epoch 021:   7235 / 11284 loss=3.495, nll_loss=1.785, ppl=3.45, wps=72726.1, ups=1.22, wpb=59506.7, bsz=2171.3, num_updates=232700, lr=0.000207301, gnorm=0.347, loss_scale=2, train_wall=78, gb_free=39.5, wall=194384
2023-06-13 21:47:25 | INFO | train_inner | epoch 021:   7335 / 11284 loss=3.495, nll_loss=1.785, ppl=3.45, wps=72192.5, ups=1.22, wpb=59075.7, bsz=2184.1, num_updates=232800, lr=0.000207257, gnorm=0.327, loss_scale=2, train_wall=78, gb_free=39.5, wall=194466
2023-06-13 21:48:49 | INFO | train_inner | epoch 021:   7435 / 11284 loss=3.522, nll_loss=1.816, ppl=3.52, wps=71122.3, ups=1.2, wpb=59502.2, bsz=2289.4, num_updates=232900, lr=0.000207212, gnorm=0.337, loss_scale=2, train_wall=80, gb_free=39.4, wall=194550
2023-06-13 21:50:12 | INFO | train_inner | epoch 021:   7535 / 11284 loss=3.508, nll_loss=1.8, ppl=3.48, wps=72055.5, ups=1.21, wpb=59787.5, bsz=2340.2, num_updates=233000, lr=0.000207168, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.6, wall=194633
2023-06-13 21:51:35 | INFO | train_inner | epoch 021:   7635 / 11284 loss=3.516, nll_loss=1.809, ppl=3.5, wps=71351, ups=1.2, wpb=59416.9, bsz=2352.2, num_updates=233100, lr=0.000207123, gnorm=0.348, loss_scale=2, train_wall=79, gb_free=39.6, wall=194716
2023-06-13 21:52:58 | INFO | train_inner | epoch 021:   7735 / 11284 loss=3.505, nll_loss=1.797, ppl=3.48, wps=71934.8, ups=1.2, wpb=59835.8, bsz=2173.2, num_updates=233200, lr=0.000207079, gnorm=0.325, loss_scale=2, train_wall=79, gb_free=39.5, wall=194799
2023-06-13 21:54:22 | INFO | train_inner | epoch 021:   7835 / 11284 loss=3.508, nll_loss=1.8, ppl=3.48, wps=71173.3, ups=1.2, wpb=59354.2, bsz=2254.6, num_updates=233300, lr=0.000207034, gnorm=0.333, loss_scale=2, train_wall=80, gb_free=39.6, wall=194882
2023-06-13 21:55:45 | INFO | train_inner | epoch 021:   7935 / 11284 loss=3.516, nll_loss=1.81, ppl=3.51, wps=71601.2, ups=1.2, wpb=59562.2, bsz=2254.5, num_updates=233400, lr=0.00020699, gnorm=0.326, loss_scale=2, train_wall=79, gb_free=39.6, wall=194966
2023-06-13 21:56:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 21:57:08 | INFO | train_inner | epoch 021:   8036 / 11284 loss=3.505, nll_loss=1.797, ppl=3.47, wps=71601, ups=1.2, wpb=59485.1, bsz=2203.2, num_updates=233500, lr=0.000206946, gnorm=0.335, loss_scale=2, train_wall=79, gb_free=39.5, wall=195049
2023-06-13 21:58:31 | INFO | train_inner | epoch 021:   8136 / 11284 loss=3.512, nll_loss=1.805, ppl=3.49, wps=71977, ups=1.21, wpb=59445.4, bsz=2193.7, num_updates=233600, lr=0.000206901, gnorm=0.329, loss_scale=2, train_wall=79, gb_free=39.6, wall=195131
2023-06-13 21:59:53 | INFO | train_inner | epoch 021:   8236 / 11284 loss=3.517, nll_loss=1.811, ppl=3.51, wps=72100.7, ups=1.21, wpb=59413.6, bsz=2190.2, num_updates=233700, lr=0.000206857, gnorm=0.337, loss_scale=2, train_wall=78, gb_free=39.6, wall=195214
2023-06-13 22:01:15 | INFO | train_inner | epoch 021:   8336 / 11284 loss=3.518, nll_loss=1.811, ppl=3.51, wps=72330.6, ups=1.22, wpb=59349.1, bsz=2279.9, num_updates=233800, lr=0.000206813, gnorm=0.336, loss_scale=2, train_wall=78, gb_free=39.6, wall=195296
2023-06-13 22:02:37 | INFO | train_inner | epoch 021:   8436 / 11284 loss=3.521, nll_loss=1.814, ppl=3.52, wps=72661.7, ups=1.22, wpb=59563.9, bsz=2253.1, num_updates=233900, lr=0.000206769, gnorm=0.33, loss_scale=2, train_wall=78, gb_free=39.6, wall=195378
2023-06-13 22:03:59 | INFO | train_inner | epoch 021:   8536 / 11284 loss=3.525, nll_loss=1.819, ppl=3.53, wps=72251.6, ups=1.22, wpb=59407.8, bsz=2267, num_updates=234000, lr=0.000206725, gnorm=0.344, loss_scale=2, train_wall=78, gb_free=39.6, wall=195460
2023-06-13 22:05:22 | INFO | train_inner | epoch 021:   8636 / 11284 loss=3.509, nll_loss=1.801, ppl=3.48, wps=72335.6, ups=1.21, wpb=59541.2, bsz=2183.5, num_updates=234100, lr=0.00020668, gnorm=0.326, loss_scale=2, train_wall=78, gb_free=39.5, wall=195542
2023-06-13 22:06:45 | INFO | train_inner | epoch 021:   8736 / 11284 loss=3.513, nll_loss=1.805, ppl=3.5, wps=71042, ups=1.19, wpb=59477.6, bsz=2307, num_updates=234200, lr=0.000206636, gnorm=0.335, loss_scale=2, train_wall=80, gb_free=39.6, wall=195626
2023-06-13 22:08:09 | INFO | train_inner | epoch 021:   8836 / 11284 loss=3.5, nll_loss=1.791, ppl=3.46, wps=71578.8, ups=1.2, wpb=59607.4, bsz=2281.4, num_updates=234300, lr=0.000206592, gnorm=0.324, loss_scale=2, train_wall=79, gb_free=39.5, wall=195709
2023-06-13 22:09:32 | INFO | train_inner | epoch 021:   8936 / 11284 loss=3.516, nll_loss=1.809, ppl=3.51, wps=70982.2, ups=1.2, wpb=59378.7, bsz=2231.5, num_updates=234400, lr=0.000206548, gnorm=0.328, loss_scale=2, train_wall=80, gb_free=39.6, wall=195793
2023-06-13 22:10:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 22:10:57 | INFO | train_inner | epoch 021:   9037 / 11284 loss=3.523, nll_loss=1.816, ppl=3.52, wps=70282.2, ups=1.18, wpb=59634.2, bsz=2250.2, num_updates=234500, lr=0.000206504, gnorm=0.327, loss_scale=2, train_wall=81, gb_free=39.6, wall=195878
2023-06-13 22:12:21 | INFO | train_inner | epoch 021:   9137 / 11284 loss=3.518, nll_loss=1.811, ppl=3.51, wps=71382.8, ups=1.2, wpb=59629.1, bsz=2209.5, num_updates=234600, lr=0.00020646, gnorm=0.324, loss_scale=2, train_wall=80, gb_free=39.6, wall=195961
2023-06-13 22:13:44 | INFO | train_inner | epoch 021:   9237 / 11284 loss=3.523, nll_loss=1.817, ppl=3.52, wps=71460.5, ups=1.2, wpb=59403.9, bsz=2226.7, num_updates=234700, lr=0.000206416, gnorm=0.332, loss_scale=2, train_wall=79, gb_free=39.6, wall=196044
2023-06-13 22:15:08 | INFO | train_inner | epoch 021:   9337 / 11284 loss=3.519, nll_loss=1.812, ppl=3.51, wps=70987, ups=1.19, wpb=59631.7, bsz=2221.3, num_updates=234800, lr=0.000206372, gnorm=0.326, loss_scale=2, train_wall=80, gb_free=39.6, wall=196128
2023-06-13 22:16:32 | INFO | train_inner | epoch 021:   9437 / 11284 loss=3.527, nll_loss=1.821, ppl=3.53, wps=70707.3, ups=1.19, wpb=59259.8, bsz=2245.4, num_updates=234900, lr=0.000206328, gnorm=0.343, loss_scale=2, train_wall=80, gb_free=39.5, wall=196212
2023-06-13 22:17:55 | INFO | train_inner | epoch 021:   9537 / 11284 loss=3.51, nll_loss=1.802, ppl=3.49, wps=71539.8, ups=1.2, wpb=59376.7, bsz=2277, num_updates=235000, lr=0.000206284, gnorm=0.338, loss_scale=2, train_wall=79, gb_free=39.5, wall=196295
2023-06-13 22:19:17 | INFO | train_inner | epoch 021:   9637 / 11284 loss=3.523, nll_loss=1.817, ppl=3.52, wps=72656.6, ups=1.22, wpb=59547.4, bsz=2226.8, num_updates=235100, lr=0.00020624, gnorm=0.321, loss_scale=2, train_wall=78, gb_free=39.5, wall=196377
2023-06-13 22:20:40 | INFO | train_inner | epoch 021:   9737 / 11284 loss=3.508, nll_loss=1.8, ppl=3.48, wps=71702.4, ups=1.2, wpb=59667.9, bsz=2252.5, num_updates=235200, lr=0.000206197, gnorm=0.325, loss_scale=2, train_wall=79, gb_free=39.6, wall=196460
2023-06-13 22:22:03 | INFO | train_inner | epoch 021:   9837 / 11284 loss=3.517, nll_loss=1.811, ppl=3.51, wps=71580.3, ups=1.2, wpb=59595.6, bsz=2210.1, num_updates=235300, lr=0.000206153, gnorm=0.335, loss_scale=2, train_wall=79, gb_free=39.6, wall=196544
2023-06-13 22:23:26 | INFO | train_inner | epoch 021:   9937 / 11284 loss=3.507, nll_loss=1.799, ppl=3.48, wps=71523.3, ups=1.2, wpb=59508.9, bsz=2163.2, num_updates=235400, lr=0.000206109, gnorm=0.333, loss_scale=2, train_wall=79, gb_free=39.5, wall=196627
2023-06-13 22:24:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 22:24:51 | INFO | train_inner | epoch 021:  10038 / 11284 loss=3.509, nll_loss=1.801, ppl=3.49, wps=70421, ups=1.18, wpb=59556.8, bsz=2215.3, num_updates=235500, lr=0.000206065, gnorm=0.323, loss_scale=2, train_wall=81, gb_free=39.5, wall=196711
2023-06-13 22:26:15 | INFO | train_inner | epoch 021:  10138 / 11284 loss=3.523, nll_loss=1.817, ppl=3.52, wps=71162.6, ups=1.19, wpb=59639.2, bsz=2301.8, num_updates=235600, lr=0.000206021, gnorm=0.333, loss_scale=2, train_wall=80, gb_free=39.6, wall=196795
2023-06-13 22:27:38 | INFO | train_inner | epoch 021:  10238 / 11284 loss=3.508, nll_loss=1.8, ppl=3.48, wps=71410.1, ups=1.2, wpb=59497, bsz=2196.4, num_updates=235700, lr=0.000205978, gnorm=0.329, loss_scale=2, train_wall=79, gb_free=39.5, wall=196879
2023-06-13 22:29:02 | INFO | train_inner | epoch 021:  10338 / 11284 loss=3.513, nll_loss=1.806, ppl=3.5, wps=71166.2, ups=1.2, wpb=59486.1, bsz=2230.8, num_updates=235800, lr=0.000205934, gnorm=0.333, loss_scale=2, train_wall=80, gb_free=39.6, wall=196962
2023-06-13 22:30:25 | INFO | train_inner | epoch 021:  10438 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=71614.4, ups=1.2, wpb=59797.3, bsz=2334.9, num_updates=235900, lr=0.00020589, gnorm=0.326, loss_scale=2, train_wall=79, gb_free=39.6, wall=197046
2023-06-13 22:31:48 | INFO | train_inner | epoch 021:  10538 / 11284 loss=3.523, nll_loss=1.817, ppl=3.52, wps=71488.1, ups=1.2, wpb=59577.6, bsz=2141.8, num_updates=236000, lr=0.000205847, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.6, wall=197129
2023-06-13 22:33:12 | INFO | train_inner | epoch 021:  10638 / 11284 loss=3.528, nll_loss=1.822, ppl=3.54, wps=71120.7, ups=1.2, wpb=59504.7, bsz=2340, num_updates=236100, lr=0.000205803, gnorm=0.335, loss_scale=2, train_wall=80, gb_free=39.6, wall=197213
2023-06-13 22:34:34 | INFO | train_inner | epoch 021:  10738 / 11284 loss=3.521, nll_loss=1.815, ppl=3.52, wps=72400.5, ups=1.21, wpb=59622.8, bsz=2204, num_updates=236200, lr=0.00020576, gnorm=0.334, loss_scale=2, train_wall=78, gb_free=39.6, wall=197295
2023-06-13 22:35:58 | INFO | train_inner | epoch 021:  10838 / 11284 loss=3.516, nll_loss=1.809, ppl=3.51, wps=71634.7, ups=1.2, wpb=59633.1, bsz=2187.7, num_updates=236300, lr=0.000205716, gnorm=0.336, loss_scale=2, train_wall=79, gb_free=39.5, wall=197378
2023-06-13 22:37:22 | INFO | train_inner | epoch 021:  10938 / 11284 loss=3.508, nll_loss=1.801, ppl=3.48, wps=70835.5, ups=1.19, wpb=59523.2, bsz=2212.7, num_updates=236400, lr=0.000205673, gnorm=0.325, loss_scale=2, train_wall=80, gb_free=39.5, wall=197462
2023-06-13 22:38:44 | INFO | train_inner | epoch 021:  11038 / 11284 loss=3.529, nll_loss=1.824, ppl=3.54, wps=72541.1, ups=1.22, wpb=59682.3, bsz=2240.9, num_updates=236500, lr=0.000205629, gnorm=0.322, loss_scale=2, train_wall=78, gb_free=39.6, wall=197545
2023-06-13 22:39:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 22:40:07 | INFO | train_inner | epoch 021:  11139 / 11284 loss=3.533, nll_loss=1.829, ppl=3.55, wps=71755.8, ups=1.21, wpb=59314.9, bsz=2201.2, num_updates=236600, lr=0.000205586, gnorm=0.341, loss_scale=2, train_wall=79, gb_free=39.6, wall=197627
2023-06-13 22:41:30 | INFO | train_inner | epoch 021:  11239 / 11284 loss=3.516, nll_loss=1.809, ppl=3.5, wps=70899.8, ups=1.19, wpb=59423.3, bsz=2319.6, num_updates=236700, lr=0.000205542, gnorm=0.334, loss_scale=2, train_wall=80, gb_free=39.6, wall=197711
2023-06-13 22:42:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-13 22:42:26 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 4.301 | nll_loss 2.619 | ppl 6.15 | bleu 20.92 | wps 3715.5 | wpb 2397.5 | bsz 71.5 | num_updates 236745 | best_loss 4.301
2023-06-13 22:42:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 236745 updates
2023-06-13 22:42:26 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint21.pt
2023-06-13 22:42:28 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint21.pt
2023-06-13 22:42:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint21.pt (epoch 21 @ 236745 updates, score 4.301) (writing took 6.885389693081379 seconds)
2023-06-13 22:42:33 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-06-13 22:42:33 | INFO | train | epoch 021 | loss 3.513 | nll_loss 1.805 | ppl 3.49 | wps 71259.5 | ups 1.2 | wpb 59500.5 | bsz 2227.6 | num_updates 236745 | lr 0.000205523 | gnorm 0.332 | loss_scale 2 | train_wall 8937 | gb_free 39.6 | wall 197774
2023-06-13 22:42:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-13 22:42:33 | INFO | fairseq.trainer | begin training epoch 22
2023-06-13 22:42:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-13 22:43:20 | INFO | train_inner | epoch 022:     55 / 11284 loss=3.495, nll_loss=1.785, ppl=3.45, wps=54215.6, ups=0.91, wpb=59401.8, bsz=2263.9, num_updates=236800, lr=0.000205499, gnorm=0.326, loss_scale=2, train_wall=80, gb_free=39.6, wall=197821
2023-06-13 22:44:44 | INFO | train_inner | epoch 022:    155 / 11284 loss=3.497, nll_loss=1.787, ppl=3.45, wps=71170.6, ups=1.2, wpb=59428.9, bsz=2167.1, num_updates=236900, lr=0.000205455, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.6, wall=197904
2023-06-13 22:46:07 | INFO | train_inner | epoch 022:    255 / 11284 loss=3.504, nll_loss=1.795, ppl=3.47, wps=71064.6, ups=1.19, wpb=59554.9, bsz=2318.9, num_updates=237000, lr=0.000205412, gnorm=0.322, loss_scale=2, train_wall=80, gb_free=39.6, wall=197988
2023-06-13 22:47:31 | INFO | train_inner | epoch 022:    355 / 11284 loss=3.508, nll_loss=1.8, ppl=3.48, wps=71383.3, ups=1.2, wpb=59482.6, bsz=2207.9, num_updates=237100, lr=0.000205369, gnorm=0.339, loss_scale=2, train_wall=79, gb_free=39.6, wall=198071
2023-06-13 22:48:54 | INFO | train_inner | epoch 022:    455 / 11284 loss=3.498, nll_loss=1.788, ppl=3.45, wps=71956.5, ups=1.21, wpb=59641.5, bsz=2271.6, num_updates=237200, lr=0.000205325, gnorm=0.324, loss_scale=2, train_wall=79, gb_free=39.6, wall=198154
2023-06-13 22:50:17 | INFO | train_inner | epoch 022:    555 / 11284 loss=3.511, nll_loss=1.803, ppl=3.49, wps=71125.6, ups=1.2, wpb=59310.8, bsz=2219.2, num_updates=237300, lr=0.000205282, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=198238
2023-06-13 22:51:40 | INFO | train_inner | epoch 022:    655 / 11284 loss=3.518, nll_loss=1.81, ppl=3.51, wps=71852, ups=1.21, wpb=59576.8, bsz=2248.3, num_updates=237400, lr=0.000205239, gnorm=0.327, loss_scale=2, train_wall=79, gb_free=39.6, wall=198320
2023-06-13 22:53:03 | INFO | train_inner | epoch 022:    755 / 11284 loss=3.522, nll_loss=1.815, ppl=3.52, wps=71889.9, ups=1.21, wpb=59599.8, bsz=2241, num_updates=237500, lr=0.000205196, gnorm=0.335, loss_scale=2, train_wall=79, gb_free=39.6, wall=198403
2023-06-13 22:53:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 22:54:27 | INFO | train_inner | epoch 022:    856 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=70618.7, ups=1.18, wpb=59635.9, bsz=2313, num_updates=237600, lr=0.000205152, gnorm=0.328, loss_scale=2, train_wall=81, gb_free=39.6, wall=198488
2023-06-13 22:55:51 | INFO | train_inner | epoch 022:    956 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=71609.1, ups=1.2, wpb=59686.3, bsz=2194, num_updates=237700, lr=0.000205109, gnorm=0.334, loss_scale=2, train_wall=80, gb_free=39.5, wall=198571
2023-06-13 22:57:13 | INFO | train_inner | epoch 022:   1056 / 11284 loss=3.511, nll_loss=1.803, ppl=3.49, wps=71774.4, ups=1.21, wpb=59498.8, bsz=2251.6, num_updates=237800, lr=0.000205066, gnorm=0.326, loss_scale=2, train_wall=79, gb_free=39.6, wall=198654
2023-06-13 22:58:36 | INFO | train_inner | epoch 022:   1156 / 11284 loss=3.499, nll_loss=1.789, ppl=3.46, wps=72403.3, ups=1.22, wpb=59534.3, bsz=2274.9, num_updates=237900, lr=0.000205023, gnorm=0.328, loss_scale=2, train_wall=78, gb_free=39.6, wall=198736
2023-06-13 22:59:59 | INFO | train_inner | epoch 022:   1256 / 11284 loss=3.506, nll_loss=1.797, ppl=3.48, wps=71931, ups=1.21, wpb=59691.8, bsz=2258.6, num_updates=238000, lr=0.00020498, gnorm=0.326, loss_scale=2, train_wall=79, gb_free=39.5, wall=198819
2023-06-13 23:01:23 | INFO | train_inner | epoch 022:   1356 / 11284 loss=3.503, nll_loss=1.794, ppl=3.47, wps=71143, ups=1.19, wpb=59627.1, bsz=2249, num_updates=238100, lr=0.000204937, gnorm=0.327, loss_scale=2, train_wall=80, gb_free=39.6, wall=198903
2023-06-13 23:02:45 | INFO | train_inner | epoch 022:   1456 / 11284 loss=3.5, nll_loss=1.791, ppl=3.46, wps=72006.5, ups=1.21, wpb=59562.1, bsz=2172.7, num_updates=238200, lr=0.000204894, gnorm=0.329, loss_scale=2, train_wall=79, gb_free=39.6, wall=198986
2023-06-13 23:04:09 | INFO | train_inner | epoch 022:   1556 / 11284 loss=3.503, nll_loss=1.794, ppl=3.47, wps=70822.6, ups=1.19, wpb=59509.8, bsz=2254.6, num_updates=238300, lr=0.000204851, gnorm=0.324, loss_scale=2, train_wall=80, gb_free=39.6, wall=199070
2023-06-13 23:05:33 | INFO | train_inner | epoch 022:   1656 / 11284 loss=3.509, nll_loss=1.801, ppl=3.48, wps=71125.2, ups=1.2, wpb=59460.2, bsz=2215.6, num_updates=238400, lr=0.000204808, gnorm=0.34, loss_scale=2, train_wall=80, gb_free=39.5, wall=199153
2023-06-13 23:06:56 | INFO | train_inner | epoch 022:   1756 / 11284 loss=3.5, nll_loss=1.791, ppl=3.46, wps=71964.1, ups=1.21, wpb=59536.3, bsz=2203.2, num_updates=238500, lr=0.000204765, gnorm=0.338, loss_scale=2, train_wall=79, gb_free=39.5, wall=199236
2023-06-13 23:08:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 23:08:20 | INFO | train_inner | epoch 022:   1857 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=70755.1, ups=1.19, wpb=59476, bsz=2282.9, num_updates=238600, lr=0.000204722, gnorm=0.343, loss_scale=2, train_wall=80, gb_free=39.6, wall=199320
2023-06-13 23:09:43 | INFO | train_inner | epoch 022:   1957 / 11284 loss=3.508, nll_loss=1.8, ppl=3.48, wps=71416.9, ups=1.2, wpb=59482.6, bsz=2225.8, num_updates=238700, lr=0.000204679, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.6, wall=199404
2023-06-13 23:11:05 | INFO | train_inner | epoch 022:   2057 / 11284 loss=3.491, nll_loss=1.781, ppl=3.44, wps=72677.8, ups=1.22, wpb=59631.5, bsz=2253.1, num_updates=238800, lr=0.000204636, gnorm=0.319, loss_scale=2, train_wall=78, gb_free=39.6, wall=199486
2023-06-13 23:12:27 | INFO | train_inner | epoch 022:   2157 / 11284 loss=3.526, nll_loss=1.819, ppl=3.53, wps=71985.6, ups=1.22, wpb=59205.4, bsz=2176.3, num_updates=238900, lr=0.000204594, gnorm=0.339, loss_scale=2, train_wall=78, gb_free=39.6, wall=199568
2023-06-13 23:13:49 | INFO | train_inner | epoch 022:   2257 / 11284 loss=3.499, nll_loss=1.79, ppl=3.46, wps=72518.9, ups=1.22, wpb=59612.1, bsz=2251, num_updates=239000, lr=0.000204551, gnorm=0.33, loss_scale=2, train_wall=78, gb_free=39.6, wall=199650
2023-06-13 23:15:12 | INFO | train_inner | epoch 022:   2357 / 11284 loss=3.501, nll_loss=1.792, ppl=3.46, wps=71992.8, ups=1.21, wpb=59438.5, bsz=2233.2, num_updates=239100, lr=0.000204508, gnorm=0.33, loss_scale=2, train_wall=78, gb_free=39.6, wall=199733
2023-06-13 23:16:34 | INFO | train_inner | epoch 022:   2457 / 11284 loss=3.505, nll_loss=1.797, ppl=3.47, wps=72113.5, ups=1.22, wpb=59310.1, bsz=2192.4, num_updates=239200, lr=0.000204465, gnorm=0.342, loss_scale=2, train_wall=78, gb_free=39.6, wall=199815
2023-06-13 23:17:57 | INFO | train_inner | epoch 022:   2557 / 11284 loss=3.513, nll_loss=1.806, ppl=3.5, wps=71700.5, ups=1.2, wpb=59535.4, bsz=2206.2, num_updates=239300, lr=0.000204422, gnorm=0.324, loss_scale=2, train_wall=79, gb_free=39.5, wall=199898
2023-06-13 23:19:20 | INFO | train_inner | epoch 022:   2657 / 11284 loss=3.512, nll_loss=1.805, ppl=3.49, wps=71532.9, ups=1.2, wpb=59438.2, bsz=2253.6, num_updates=239400, lr=0.00020438, gnorm=0.329, loss_scale=2, train_wall=79, gb_free=39.6, wall=199981
2023-06-13 23:20:44 | INFO | train_inner | epoch 022:   2757 / 11284 loss=3.505, nll_loss=1.797, ppl=3.47, wps=71148.9, ups=1.19, wpb=59567, bsz=2224.7, num_updates=239500, lr=0.000204337, gnorm=0.34, loss_scale=2, train_wall=80, gb_free=39.6, wall=200065
2023-06-13 23:22:06 | INFO | train_inner | epoch 022:   2857 / 11284 loss=3.493, nll_loss=1.783, ppl=3.44, wps=72211.8, ups=1.21, wpb=59440.6, bsz=2302.7, num_updates=239600, lr=0.000204294, gnorm=0.336, loss_scale=2, train_wall=78, gb_free=39.6, wall=200147
2023-06-13 23:22:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 23:23:29 | INFO | train_inner | epoch 022:   2958 / 11284 loss=3.506, nll_loss=1.798, ppl=3.48, wps=71717.1, ups=1.21, wpb=59505, bsz=2253.8, num_updates=239700, lr=0.000204252, gnorm=0.335, loss_scale=2, train_wall=79, gb_free=39.6, wall=200230
2023-06-13 23:24:51 | INFO | train_inner | epoch 022:   3058 / 11284 loss=3.504, nll_loss=1.795, ppl=3.47, wps=72923.8, ups=1.22, wpb=59537.2, bsz=2152.1, num_updates=239800, lr=0.000204209, gnorm=0.322, loss_scale=2, train_wall=78, gb_free=39.6, wall=200312
2023-06-13 23:26:14 | INFO | train_inner | epoch 022:   3158 / 11284 loss=3.499, nll_loss=1.79, ppl=3.46, wps=72108.8, ups=1.21, wpb=59458.5, bsz=2264.7, num_updates=239900, lr=0.000204167, gnorm=0.345, loss_scale=2, train_wall=78, gb_free=39.6, wall=200394
2023-06-13 23:27:37 | INFO | train_inner | epoch 022:   3258 / 11284 loss=3.51, nll_loss=1.802, ppl=3.49, wps=70648.1, ups=1.19, wpb=59305.8, bsz=2283.4, num_updates=240000, lr=0.000204124, gnorm=0.34, loss_scale=2, train_wall=80, gb_free=38.9, wall=200478
2023-06-13 23:29:01 | INFO | train_inner | epoch 022:   3358 / 11284 loss=3.506, nll_loss=1.797, ppl=3.48, wps=71171.7, ups=1.2, wpb=59467.7, bsz=2194.4, num_updates=240100, lr=0.000204082, gnorm=0.338, loss_scale=2, train_wall=80, gb_free=39.6, wall=200562
2023-06-13 23:30:24 | INFO | train_inner | epoch 022:   3458 / 11284 loss=3.514, nll_loss=1.807, ppl=3.5, wps=71277.5, ups=1.2, wpb=59460.9, bsz=2215.4, num_updates=240200, lr=0.000204039, gnorm=0.328, loss_scale=2, train_wall=79, gb_free=39.6, wall=200645
2023-06-13 23:31:47 | INFO | train_inner | epoch 022:   3558 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=72588.7, ups=1.21, wpb=59752.5, bsz=2233, num_updates=240300, lr=0.000203997, gnorm=0.332, loss_scale=2, train_wall=78, gb_free=39.5, wall=200727
2023-06-13 23:33:10 | INFO | train_inner | epoch 022:   3658 / 11284 loss=3.513, nll_loss=1.805, ppl=3.5, wps=71957.2, ups=1.21, wpb=59584.6, bsz=2357.4, num_updates=240400, lr=0.000203954, gnorm=0.338, loss_scale=2, train_wall=78, gb_free=39.6, wall=200810
2023-06-13 23:34:32 | INFO | train_inner | epoch 022:   3758 / 11284 loss=3.492, nll_loss=1.782, ppl=3.44, wps=71990.6, ups=1.21, wpb=59458.9, bsz=2205.2, num_updates=240500, lr=0.000203912, gnorm=0.329, loss_scale=2, train_wall=79, gb_free=39.5, wall=200893
2023-06-13 23:35:55 | INFO | train_inner | epoch 022:   3858 / 11284 loss=3.519, nll_loss=1.812, ppl=3.51, wps=71449.4, ups=1.2, wpb=59503.4, bsz=2228, num_updates=240600, lr=0.000203869, gnorm=0.335, loss_scale=2, train_wall=79, gb_free=39.5, wall=200976
2023-06-13 23:36:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 23:37:21 | INFO | train_inner | epoch 022:   3959 / 11284 loss=3.518, nll_loss=1.811, ppl=3.51, wps=69393.3, ups=1.17, wpb=59415.8, bsz=2210.8, num_updates=240700, lr=0.000203827, gnorm=0.332, loss_scale=2, train_wall=82, gb_free=39.6, wall=201062
2023-06-13 23:38:45 | INFO | train_inner | epoch 022:   4059 / 11284 loss=3.509, nll_loss=1.801, ppl=3.49, wps=70343.6, ups=1.18, wpb=59371.6, bsz=2166.8, num_updates=240800, lr=0.000203785, gnorm=0.336, loss_scale=2, train_wall=81, gb_free=39.5, wall=201146
2023-06-13 23:40:11 | INFO | train_inner | epoch 022:   4159 / 11284 loss=3.502, nll_loss=1.793, ppl=3.47, wps=69970, ups=1.17, wpb=59685.2, bsz=2324.3, num_updates=240900, lr=0.000203742, gnorm=0.322, loss_scale=2, train_wall=81, gb_free=39.6, wall=201231
2023-06-13 23:41:35 | INFO | train_inner | epoch 022:   4259 / 11284 loss=3.515, nll_loss=1.808, ppl=3.5, wps=70287.5, ups=1.19, wpb=59261.8, bsz=2266.3, num_updates=241000, lr=0.0002037, gnorm=0.328, loss_scale=2, train_wall=80, gb_free=39.6, wall=201316
2023-06-13 23:42:59 | INFO | train_inner | epoch 022:   4359 / 11284 loss=3.506, nll_loss=1.798, ppl=3.48, wps=70730.4, ups=1.19, wpb=59544.5, bsz=2158.4, num_updates=241100, lr=0.000203658, gnorm=0.331, loss_scale=2, train_wall=80, gb_free=39.5, wall=201400
2023-06-13 23:44:24 | INFO | train_inner | epoch 022:   4459 / 11284 loss=3.505, nll_loss=1.797, ppl=3.48, wps=70556.8, ups=1.19, wpb=59512, bsz=2231.7, num_updates=241200, lr=0.000203616, gnorm=0.329, loss_scale=2, train_wall=81, gb_free=39.6, wall=201484
2023-06-13 23:45:48 | INFO | train_inner | epoch 022:   4559 / 11284 loss=3.514, nll_loss=1.806, ppl=3.5, wps=70252.5, ups=1.18, wpb=59534.6, bsz=2221.9, num_updates=241300, lr=0.000203574, gnorm=0.331, loss_scale=2, train_wall=81, gb_free=39.6, wall=201569
2023-06-13 23:47:11 | INFO | train_inner | epoch 022:   4659 / 11284 loss=3.5, nll_loss=1.791, ppl=3.46, wps=72000, ups=1.21, wpb=59558.1, bsz=2308.3, num_updates=241400, lr=0.000203531, gnorm=0.339, loss_scale=2, train_wall=79, gb_free=39.6, wall=201652
2023-06-13 23:48:35 | INFO | train_inner | epoch 022:   4759 / 11284 loss=3.508, nll_loss=1.8, ppl=3.48, wps=70731.1, ups=1.19, wpb=59475.2, bsz=2162.3, num_updates=241500, lr=0.000203489, gnorm=0.336, loss_scale=2, train_wall=80, gb_free=39.6, wall=201736
2023-06-13 23:50:00 | INFO | train_inner | epoch 022:   4859 / 11284 loss=3.501, nll_loss=1.792, ppl=3.46, wps=69856, ups=1.18, wpb=59444.7, bsz=2299.8, num_updates=241600, lr=0.000203447, gnorm=0.33, loss_scale=2, train_wall=81, gb_free=39.6, wall=201821
2023-06-13 23:51:25 | INFO | train_inner | epoch 022:   4959 / 11284 loss=3.513, nll_loss=1.806, ppl=3.5, wps=70137.6, ups=1.18, wpb=59385.7, bsz=2188.4, num_updates=241700, lr=0.000203405, gnorm=0.328, loss_scale=4, train_wall=81, gb_free=39.6, wall=201906
2023-06-13 23:51:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-13 23:52:49 | INFO | train_inner | epoch 022:   5060 / 11284 loss=3.518, nll_loss=1.811, ppl=3.51, wps=70728.6, ups=1.19, wpb=59406.5, bsz=2328.1, num_updates=241800, lr=0.000203363, gnorm=0.338, loss_scale=2, train_wall=80, gb_free=39.5, wall=201990
2023-06-13 23:54:12 | INFO | train_inner | epoch 022:   5160 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=71403.5, ups=1.2, wpb=59491.3, bsz=2211.7, num_updates=241900, lr=0.000203321, gnorm=0.331, loss_scale=2, train_wall=79, gb_free=39.6, wall=202073
2023-06-13 23:55:35 | INFO | train_inner | epoch 022:   5260 / 11284 loss=3.505, nll_loss=1.796, ppl=3.47, wps=71492.7, ups=1.2, wpb=59482.2, bsz=2210.3, num_updates=242000, lr=0.000203279, gnorm=0.331, loss_scale=2, train_wall=80, gb_free=39.6, wall=202156
2023-06-13 23:56:59 | INFO | train_inner | epoch 022:   5360 / 11284 loss=3.521, nll_loss=1.815, ppl=3.52, wps=71298.6, ups=1.2, wpb=59406, bsz=2210.7, num_updates=242100, lr=0.000203237, gnorm=0.339, loss_scale=2, train_wall=79, gb_free=39.5, wall=202239
2023-06-13 23:58:20 | INFO | train_inner | epoch 022:   5460 / 11284 loss=3.508, nll_loss=1.8, ppl=3.48, wps=72917.3, ups=1.22, wpb=59589.7, bsz=2231.3, num_updates=242200, lr=0.000203195, gnorm=0.34, loss_scale=2, train_wall=78, gb_free=39.6, wall=202321
2023-06-13 23:59:42 | INFO | train_inner | epoch 022:   5560 / 11284 loss=3.518, nll_loss=1.811, ppl=3.51, wps=72873.4, ups=1.22, wpb=59501.8, bsz=2189.3, num_updates=242300, lr=0.000203153, gnorm=0.332, loss_scale=2, train_wall=78, gb_free=39.6, wall=202403
2023-06-14 00:01:05 | INFO | train_inner | epoch 022:   5660 / 11284 loss=3.517, nll_loss=1.81, ppl=3.51, wps=72110.1, ups=1.21, wpb=59436.7, bsz=2213, num_updates=242400, lr=0.000203111, gnorm=0.335, loss_scale=2, train_wall=78, gb_free=39.6, wall=202485
2023-06-14 00:02:28 | INFO | train_inner | epoch 022:   5760 / 11284 loss=3.512, nll_loss=1.804, ppl=3.49, wps=71491, ups=1.2, wpb=59595.4, bsz=2251.8, num_updates=242500, lr=0.000203069, gnorm=0.336, loss_scale=2, train_wall=80, gb_free=39.6, wall=202569
2023-06-14 00:03:51 | INFO | train_inner | epoch 022:   5860 / 11284 loss=3.51, nll_loss=1.803, ppl=3.49, wps=71292.9, ups=1.2, wpb=59168.4, bsz=2318.4, num_updates=242600, lr=0.000203027, gnorm=0.343, loss_scale=2, train_wall=79, gb_free=39.5, wall=202652
2023-06-14 00:05:15 | INFO | train_inner | epoch 022:   5960 / 11284 loss=3.504, nll_loss=1.795, ppl=3.47, wps=71090.8, ups=1.2, wpb=59459.4, bsz=2193.7, num_updates=242700, lr=0.000202986, gnorm=0.336, loss_scale=2, train_wall=80, gb_free=39.5, wall=202735
2023-06-14 00:06:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 00:06:39 | INFO | train_inner | epoch 022:   6061 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=70188.8, ups=1.18, wpb=59544, bsz=2170, num_updates=242800, lr=0.000202944, gnorm=0.326, loss_scale=2, train_wall=81, gb_free=39.6, wall=202820
2023-06-14 00:08:03 | INFO | train_inner | epoch 022:   6161 / 11284 loss=3.521, nll_loss=1.815, ppl=3.52, wps=70862.4, ups=1.19, wpb=59399.4, bsz=2182.2, num_updates=242900, lr=0.000202902, gnorm=0.344, loss_scale=2, train_wall=80, gb_free=39.6, wall=202904
2023-06-14 00:09:26 | INFO | train_inner | epoch 022:   6261 / 11284 loss=3.515, nll_loss=1.808, ppl=3.5, wps=71048, ups=1.2, wpb=59143.1, bsz=2212.2, num_updates=243000, lr=0.00020286, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.5, wall=202987
2023-06-14 00:10:49 | INFO | train_inner | epoch 022:   6361 / 11284 loss=3.509, nll_loss=1.802, ppl=3.49, wps=71865.9, ups=1.21, wpb=59579.8, bsz=2195.1, num_updates=243100, lr=0.000202818, gnorm=0.324, loss_scale=2, train_wall=79, gb_free=39.6, wall=203070
2023-06-14 00:12:13 | INFO | train_inner | epoch 022:   6461 / 11284 loss=3.517, nll_loss=1.811, ppl=3.51, wps=71147.3, ups=1.2, wpb=59378.6, bsz=2216.9, num_updates=243200, lr=0.000202777, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.6, wall=203153
2023-06-14 00:13:36 | INFO | train_inner | epoch 022:   6561 / 11284 loss=3.511, nll_loss=1.804, ppl=3.49, wps=71934.6, ups=1.21, wpb=59562.5, bsz=2299.4, num_updates=243300, lr=0.000202735, gnorm=0.327, loss_scale=2, train_wall=79, gb_free=39.3, wall=203236
2023-06-14 00:14:59 | INFO | train_inner | epoch 022:   6661 / 11284 loss=3.498, nll_loss=1.789, ppl=3.45, wps=70870.2, ups=1.19, wpb=59317.1, bsz=2285.2, num_updates=243400, lr=0.000202693, gnorm=0.33, loss_scale=2, train_wall=80, gb_free=39.6, wall=203320
2023-06-14 00:16:23 | INFO | train_inner | epoch 022:   6761 / 11284 loss=3.5, nll_loss=1.791, ppl=3.46, wps=71472.8, ups=1.2, wpb=59531.5, bsz=2208.5, num_updates=243500, lr=0.000202652, gnorm=0.349, loss_scale=2, train_wall=79, gb_free=39.5, wall=203403
2023-06-14 00:17:46 | INFO | train_inner | epoch 022:   6861 / 11284 loss=3.516, nll_loss=1.809, ppl=3.5, wps=71560.5, ups=1.2, wpb=59590.9, bsz=2218.1, num_updates=243600, lr=0.00020261, gnorm=0.326, loss_scale=2, train_wall=79, gb_free=39.5, wall=203486
2023-06-14 00:19:12 | INFO | train_inner | epoch 022:   6961 / 11284 loss=3.504, nll_loss=1.795, ppl=3.47, wps=69330.9, ups=1.16, wpb=59544.4, bsz=2342.7, num_updates=243700, lr=0.000202569, gnorm=0.323, loss_scale=2, train_wall=82, gb_free=39.5, wall=203572
2023-06-14 00:20:35 | INFO | train_inner | epoch 022:   7061 / 11284 loss=3.507, nll_loss=1.799, ppl=3.48, wps=71381.1, ups=1.2, wpb=59409.9, bsz=2252.9, num_updates=243800, lr=0.000202527, gnorm=0.332, loss_scale=4, train_wall=79, gb_free=39.6, wall=203656
2023-06-14 00:21:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 00:21:59 | INFO | train_inner | epoch 022:   7162 / 11284 loss=3.514, nll_loss=1.807, ppl=3.5, wps=70501.7, ups=1.19, wpb=59435.9, bsz=2221.2, num_updates=243900, lr=0.000202486, gnorm=0.339, loss_scale=2, train_wall=80, gb_free=39.5, wall=203740
2023-06-14 00:23:23 | INFO | train_inner | epoch 022:   7262 / 11284 loss=3.508, nll_loss=1.8, ppl=3.48, wps=71360, ups=1.2, wpb=59402.7, bsz=2272, num_updates=244000, lr=0.000202444, gnorm=0.333, loss_scale=2, train_wall=79, gb_free=39.6, wall=203823
2023-06-14 00:24:46 | INFO | train_inner | epoch 022:   7362 / 11284 loss=3.509, nll_loss=1.802, ppl=3.49, wps=71762.4, ups=1.2, wpb=59760.7, bsz=2164.2, num_updates=244100, lr=0.000202403, gnorm=0.339, loss_scale=2, train_wall=79, gb_free=39.6, wall=203906
2023-06-14 00:26:09 | INFO | train_inner | epoch 022:   7462 / 11284 loss=3.512, nll_loss=1.805, ppl=3.49, wps=71572.6, ups=1.2, wpb=59451.8, bsz=2232.3, num_updates=244200, lr=0.000202361, gnorm=0.323, loss_scale=2, train_wall=79, gb_free=39.5, wall=203990
2023-06-14 00:27:33 | INFO | train_inner | epoch 022:   7562 / 11284 loss=3.516, nll_loss=1.809, ppl=3.5, wps=70810.9, ups=1.19, wpb=59507.3, bsz=2240.9, num_updates=244300, lr=0.00020232, gnorm=0.344, loss_scale=2, train_wall=80, gb_free=39.6, wall=204074
2023-06-14 00:28:56 | INFO | train_inner | epoch 022:   7662 / 11284 loss=3.508, nll_loss=1.8, ppl=3.48, wps=71583.6, ups=1.21, wpb=59354.2, bsz=2230.5, num_updates=244400, lr=0.000202278, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=204156
2023-06-14 00:30:19 | INFO | train_inner | epoch 022:   7762 / 11284 loss=3.532, nll_loss=1.827, ppl=3.55, wps=71202.2, ups=1.2, wpb=59437.1, bsz=2266.8, num_updates=244500, lr=0.000202237, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.6, wall=204240
2023-06-14 00:31:43 | INFO | train_inner | epoch 022:   7862 / 11284 loss=3.521, nll_loss=1.815, ppl=3.52, wps=71590, ups=1.2, wpb=59594.1, bsz=2154.2, num_updates=244600, lr=0.000202196, gnorm=0.325, loss_scale=2, train_wall=79, gb_free=39.1, wall=204323
2023-06-14 00:33:06 | INFO | train_inner | epoch 022:   7962 / 11284 loss=3.506, nll_loss=1.798, ppl=3.48, wps=71484.2, ups=1.2, wpb=59691.6, bsz=2305.1, num_updates=244700, lr=0.000202154, gnorm=0.339, loss_scale=2, train_wall=80, gb_free=39.5, wall=204407
2023-06-14 00:34:30 | INFO | train_inner | epoch 022:   8062 / 11284 loss=3.498, nll_loss=1.79, ppl=3.46, wps=71366.7, ups=1.19, wpb=59814.1, bsz=2299.7, num_updates=244800, lr=0.000202113, gnorm=0.333, loss_scale=2, train_wall=80, gb_free=39.6, wall=204491
2023-06-14 00:35:53 | INFO | train_inner | epoch 022:   8162 / 11284 loss=3.508, nll_loss=1.8, ppl=3.48, wps=71621.2, ups=1.2, wpb=59768.6, bsz=2261.6, num_updates=244900, lr=0.000202072, gnorm=0.326, loss_scale=4, train_wall=80, gb_free=39.5, wall=204574
2023-06-14 00:36:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 00:37:18 | INFO | train_inner | epoch 022:   8263 / 11284 loss=3.514, nll_loss=1.807, ppl=3.5, wps=70803.5, ups=1.19, wpb=59603.9, bsz=2190.1, num_updates=245000, lr=0.000202031, gnorm=0.329, loss_scale=2, train_wall=80, gb_free=39.6, wall=204658
2023-06-14 00:38:41 | INFO | train_inner | epoch 022:   8363 / 11284 loss=3.526, nll_loss=1.82, ppl=3.53, wps=71488.7, ups=1.2, wpb=59473.5, bsz=2295.8, num_updates=245100, lr=0.000201989, gnorm=0.336, loss_scale=2, train_wall=79, gb_free=38.9, wall=204741
2023-06-14 00:40:04 | INFO | train_inner | epoch 022:   8463 / 11284 loss=3.508, nll_loss=1.8, ppl=3.48, wps=71563.3, ups=1.2, wpb=59547.2, bsz=2202.5, num_updates=245200, lr=0.000201948, gnorm=0.334, loss_scale=2, train_wall=79, gb_free=39.6, wall=204825
2023-06-14 00:41:27 | INFO | train_inner | epoch 022:   8563 / 11284 loss=3.494, nll_loss=1.784, ppl=3.44, wps=71512.8, ups=1.2, wpb=59713.5, bsz=2134.3, num_updates=245300, lr=0.000201907, gnorm=0.326, loss_scale=2, train_wall=80, gb_free=39.6, wall=204908
2023-06-14 00:42:50 | INFO | train_inner | epoch 022:   8663 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=72018.2, ups=1.21, wpb=59674, bsz=2227.6, num_updates=245400, lr=0.000201866, gnorm=0.324, loss_scale=2, train_wall=79, gb_free=39.5, wall=204991
2023-06-14 00:44:12 | INFO | train_inner | epoch 022:   8763 / 11284 loss=3.521, nll_loss=1.815, ppl=3.52, wps=72801.1, ups=1.22, wpb=59539.4, bsz=2165.1, num_updates=245500, lr=0.000201825, gnorm=0.333, loss_scale=2, train_wall=78, gb_free=39.5, wall=205073
2023-06-14 00:45:34 | INFO | train_inner | epoch 022:   8863 / 11284 loss=3.512, nll_loss=1.805, ppl=3.49, wps=72990.9, ups=1.23, wpb=59563.3, bsz=2309.1, num_updates=245600, lr=0.000201784, gnorm=0.322, loss_scale=2, train_wall=77, gb_free=39.6, wall=205154
2023-06-14 00:46:55 | INFO | train_inner | epoch 022:   8963 / 11284 loss=3.513, nll_loss=1.806, ppl=3.5, wps=73054.5, ups=1.23, wpb=59548.2, bsz=2235.1, num_updates=245700, lr=0.000201743, gnorm=0.326, loss_scale=2, train_wall=77, gb_free=39.5, wall=205236
2023-06-14 00:48:18 | INFO | train_inner | epoch 022:   9063 / 11284 loss=3.526, nll_loss=1.821, ppl=3.53, wps=71960.1, ups=1.21, wpb=59636.6, bsz=2174.7, num_updates=245800, lr=0.000201701, gnorm=0.324, loss_scale=2, train_wall=79, gb_free=39.5, wall=205319
2023-06-14 00:49:41 | INFO | train_inner | epoch 022:   9163 / 11284 loss=3.523, nll_loss=1.817, ppl=3.52, wps=71485, ups=1.2, wpb=59563.1, bsz=2242.4, num_updates=245900, lr=0.00020166, gnorm=0.333, loss_scale=2, train_wall=79, gb_free=39.6, wall=205402
2023-06-14 00:51:05 | INFO | train_inner | epoch 022:   9263 / 11284 loss=3.521, nll_loss=1.814, ppl=3.52, wps=71386.8, ups=1.2, wpb=59435, bsz=2190.8, num_updates=246000, lr=0.000201619, gnorm=0.339, loss_scale=4, train_wall=79, gb_free=39.6, wall=205485
2023-06-14 00:51:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 00:52:28 | INFO | train_inner | epoch 022:   9364 / 11284 loss=3.519, nll_loss=1.812, ppl=3.51, wps=70991.6, ups=1.2, wpb=59338.6, bsz=2184.5, num_updates=246100, lr=0.000201578, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.6, wall=205569
2023-06-14 00:53:52 | INFO | train_inner | epoch 022:   9464 / 11284 loss=3.514, nll_loss=1.807, ppl=3.5, wps=70470.2, ups=1.19, wpb=59314.4, bsz=2129.2, num_updates=246200, lr=0.000201538, gnorm=0.332, loss_scale=2, train_wall=80, gb_free=39.6, wall=205653
2023-06-14 00:55:16 | INFO | train_inner | epoch 022:   9564 / 11284 loss=3.507, nll_loss=1.8, ppl=3.48, wps=70854.6, ups=1.19, wpb=59355.3, bsz=2292.1, num_updates=246300, lr=0.000201497, gnorm=0.333, loss_scale=2, train_wall=80, gb_free=39.6, wall=205737
2023-06-14 00:56:39 | INFO | train_inner | epoch 022:   9664 / 11284 loss=3.509, nll_loss=1.801, ppl=3.49, wps=71426, ups=1.2, wpb=59453.8, bsz=2265.3, num_updates=246400, lr=0.000201456, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.5, wall=205820
2023-06-14 00:58:04 | INFO | train_inner | epoch 022:   9764 / 11284 loss=3.531, nll_loss=1.826, ppl=3.55, wps=70467.5, ups=1.18, wpb=59555.7, bsz=2187.4, num_updates=246500, lr=0.000201415, gnorm=0.327, loss_scale=2, train_wall=81, gb_free=39.6, wall=205905
2023-06-14 00:59:27 | INFO | train_inner | epoch 022:   9864 / 11284 loss=3.525, nll_loss=1.819, ppl=3.53, wps=71164.2, ups=1.2, wpb=59346.6, bsz=2153.1, num_updates=246600, lr=0.000201374, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.6, wall=205988
2023-06-14 01:00:51 | INFO | train_inner | epoch 022:   9964 / 11284 loss=3.513, nll_loss=1.805, ppl=3.5, wps=71010.5, ups=1.19, wpb=59547.5, bsz=2186, num_updates=246700, lr=0.000201333, gnorm=0.325, loss_scale=2, train_wall=80, gb_free=39.6, wall=206072
2023-06-14 01:02:13 | INFO | train_inner | epoch 022:  10064 / 11284 loss=3.506, nll_loss=1.799, ppl=3.48, wps=72452.6, ups=1.22, wpb=59421.3, bsz=2122.7, num_updates=246800, lr=0.000201292, gnorm=0.35, loss_scale=2, train_wall=78, gb_free=39.6, wall=206154
2023-06-14 01:03:36 | INFO | train_inner | epoch 022:  10164 / 11284 loss=3.515, nll_loss=1.808, ppl=3.5, wps=71589.2, ups=1.2, wpb=59482.9, bsz=2238.3, num_updates=246900, lr=0.000201252, gnorm=0.333, loss_scale=2, train_wall=79, gb_free=39.6, wall=206237
2023-06-14 01:04:59 | INFO | train_inner | epoch 022:  10264 / 11284 loss=3.5, nll_loss=1.791, ppl=3.46, wps=71387.8, ups=1.2, wpb=59365.9, bsz=2096.6, num_updates=247000, lr=0.000201211, gnorm=0.343, loss_scale=2, train_wall=79, gb_free=39.5, wall=206320
2023-06-14 01:06:23 | INFO | train_inner | epoch 022:  10364 / 11284 loss=3.52, nll_loss=1.813, ppl=3.51, wps=71308.3, ups=1.2, wpb=59436.9, bsz=2236.7, num_updates=247100, lr=0.00020117, gnorm=0.337, loss_scale=4, train_wall=79, gb_free=39.6, wall=206403
2023-06-14 01:06:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 01:07:47 | INFO | train_inner | epoch 022:  10465 / 11284 loss=3.507, nll_loss=1.799, ppl=3.48, wps=70785.2, ups=1.19, wpb=59373.8, bsz=2193.8, num_updates=247200, lr=0.000201129, gnorm=0.331, loss_scale=2, train_wall=80, gb_free=39.6, wall=206487
2023-06-14 01:09:10 | INFO | train_inner | epoch 022:  10565 / 11284 loss=3.505, nll_loss=1.796, ppl=3.47, wps=71495.9, ups=1.2, wpb=59533.3, bsz=2195, num_updates=247300, lr=0.000201089, gnorm=0.34, loss_scale=2, train_wall=80, gb_free=39.6, wall=206571
2023-06-14 01:10:33 | INFO | train_inner | epoch 022:  10665 / 11284 loss=3.514, nll_loss=1.807, ppl=3.5, wps=71535.8, ups=1.2, wpb=59566.1, bsz=2257.3, num_updates=247400, lr=0.000201048, gnorm=0.322, loss_scale=2, train_wall=80, gb_free=39.5, wall=206654
2023-06-14 01:11:57 | INFO | train_inner | epoch 022:  10765 / 11284 loss=3.514, nll_loss=1.807, ppl=3.5, wps=71539.4, ups=1.2, wpb=59594.3, bsz=2134.3, num_updates=247500, lr=0.000201008, gnorm=0.343, loss_scale=2, train_wall=79, gb_free=39.6, wall=206737
2023-06-14 01:13:20 | INFO | train_inner | epoch 022:  10865 / 11284 loss=3.517, nll_loss=1.81, ppl=3.51, wps=71335.7, ups=1.2, wpb=59524.9, bsz=2220.8, num_updates=247600, lr=0.000200967, gnorm=0.334, loss_scale=2, train_wall=79, gb_free=39.6, wall=206821
2023-06-14 01:14:43 | INFO | train_inner | epoch 022:  10965 / 11284 loss=3.521, nll_loss=1.815, ppl=3.52, wps=71712.2, ups=1.2, wpb=59657.2, bsz=2290.4, num_updates=247700, lr=0.000200926, gnorm=0.324, loss_scale=2, train_wall=79, gb_free=39.6, wall=206904
2023-06-14 01:16:06 | INFO | train_inner | epoch 022:  11065 / 11284 loss=3.519, nll_loss=1.812, ppl=3.51, wps=72196.4, ups=1.21, wpb=59490.2, bsz=2153.5, num_updates=247800, lr=0.000200886, gnorm=0.344, loss_scale=2, train_wall=78, gb_free=39.5, wall=206986
2023-06-14 01:17:29 | INFO | train_inner | epoch 022:  11165 / 11284 loss=3.515, nll_loss=1.808, ppl=3.5, wps=71552.4, ups=1.2, wpb=59496.5, bsz=2083.7, num_updates=247900, lr=0.000200845, gnorm=0.336, loss_scale=2, train_wall=79, gb_free=39.5, wall=207069
2023-06-14 01:18:53 | INFO | train_inner | epoch 022:  11265 / 11284 loss=3.514, nll_loss=1.806, ppl=3.5, wps=70896.8, ups=1.19, wpb=59463.8, bsz=2285.8, num_updates=248000, lr=0.000200805, gnorm=0.341, loss_scale=2, train_wall=80, gb_free=39.5, wall=207153
2023-06-14 01:19:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-14 01:19:26 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 4.305 | nll_loss 2.623 | ppl 6.16 | bleu 20.91 | wps 3787.7 | wpb 2397.5 | bsz 71.5 | num_updates 248019 | best_loss 4.301
2023-06-14 01:19:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 248019 updates
2023-06-14 01:19:26 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint22.pt
2023-06-14 01:19:29 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint22.pt
2023-06-14 01:19:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint22.pt (epoch 22 @ 248019 updates, score 4.305) (writing took 7.700930027291179 seconds)
2023-06-14 01:19:34 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-06-14 01:19:34 | INFO | train | epoch 022 | loss 3.509 | nll_loss 1.802 | ppl 3.49 | wps 71204.3 | ups 1.2 | wpb 59499.6 | bsz 2227.3 | num_updates 248019 | lr 0.000200797 | gnorm 0.333 | loss_scale 2 | train_wall 8942 | gb_free 39.6 | wall 207194
2023-06-14 01:19:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-14 01:19:34 | INFO | fairseq.trainer | begin training epoch 23
2023-06-14 01:19:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-14 01:20:41 | INFO | train_inner | epoch 023:     81 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=54485, ups=0.92, wpb=59152.5, bsz=2197.9, num_updates=248100, lr=0.000200764, gnorm=0.334, loss_scale=2, train_wall=79, gb_free=39.5, wall=207262
2023-06-14 01:22:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 01:22:04 | INFO | train_inner | epoch 023:    182 / 11284 loss=3.504, nll_loss=1.795, ppl=3.47, wps=71792.4, ups=1.21, wpb=59276.7, bsz=2288.7, num_updates=248200, lr=0.000200724, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.6, wall=207344
2023-06-14 01:23:26 | INFO | train_inner | epoch 023:    282 / 11284 loss=3.496, nll_loss=1.786, ppl=3.45, wps=71992, ups=1.21, wpb=59452.3, bsz=2148.5, num_updates=248300, lr=0.000200683, gnorm=0.346, loss_scale=2, train_wall=78, gb_free=39.6, wall=207427
2023-06-14 01:24:52 | INFO | train_inner | epoch 023:    382 / 11284 loss=3.494, nll_loss=1.784, ppl=3.44, wps=70024.9, ups=1.17, wpb=59841.6, bsz=2260.1, num_updates=248400, lr=0.000200643, gnorm=0.328, loss_scale=2, train_wall=81, gb_free=39.6, wall=207512
2023-06-14 01:26:16 | INFO | train_inner | epoch 023:    482 / 11284 loss=3.505, nll_loss=1.796, ppl=3.47, wps=70960, ups=1.19, wpb=59614.6, bsz=2148, num_updates=248500, lr=0.000200603, gnorm=0.336, loss_scale=2, train_wall=80, gb_free=39.6, wall=207596
2023-06-14 01:27:39 | INFO | train_inner | epoch 023:    582 / 11284 loss=3.504, nll_loss=1.795, ppl=3.47, wps=71348, ups=1.2, wpb=59489.2, bsz=2241.2, num_updates=248600, lr=0.000200562, gnorm=0.33, loss_scale=2, train_wall=79, gb_free=39.6, wall=207680
2023-06-14 01:29:03 | INFO | train_inner | epoch 023:    682 / 11284 loss=3.507, nll_loss=1.798, ppl=3.48, wps=71370.6, ups=1.2, wpb=59514.6, bsz=2223.5, num_updates=248700, lr=0.000200522, gnorm=0.339, loss_scale=2, train_wall=79, gb_free=39.6, wall=207763
2023-06-14 01:30:26 | INFO | train_inner | epoch 023:    782 / 11284 loss=3.493, nll_loss=1.782, ppl=3.44, wps=71820.7, ups=1.2, wpb=59622, bsz=2213.5, num_updates=248800, lr=0.000200482, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.6, wall=207846
2023-06-14 01:31:49 | INFO | train_inner | epoch 023:    882 / 11284 loss=3.509, nll_loss=1.801, ppl=3.48, wps=71181.4, ups=1.19, wpb=59588.8, bsz=2294.3, num_updates=248900, lr=0.000200441, gnorm=0.334, loss_scale=2, train_wall=80, gb_free=39.5, wall=207930
2023-06-14 01:33:13 | INFO | train_inner | epoch 023:    982 / 11284 loss=3.495, nll_loss=1.785, ppl=3.45, wps=71264.5, ups=1.19, wpb=59728.6, bsz=2227.5, num_updates=249000, lr=0.000200401, gnorm=0.329, loss_scale=2, train_wall=80, gb_free=39.6, wall=208014
2023-06-14 01:34:37 | INFO | train_inner | epoch 023:   1082 / 11284 loss=3.519, nll_loss=1.812, ppl=3.51, wps=71270.9, ups=1.2, wpb=59411.8, bsz=2317.1, num_updates=249100, lr=0.000200361, gnorm=0.333, loss_scale=2, train_wall=79, gb_free=39.5, wall=208097
2023-06-14 01:36:00 | INFO | train_inner | epoch 023:   1182 / 11284 loss=3.504, nll_loss=1.795, ppl=3.47, wps=71465.3, ups=1.2, wpb=59540.1, bsz=2286.4, num_updates=249200, lr=0.000200321, gnorm=0.341, loss_scale=2, train_wall=79, gb_free=39.6, wall=208180
2023-06-14 01:36:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 01:37:24 | INFO | train_inner | epoch 023:   1283 / 11284 loss=3.518, nll_loss=1.811, ppl=3.51, wps=71124.4, ups=1.19, wpb=59585.4, bsz=2185.9, num_updates=249300, lr=0.000200281, gnorm=0.325, loss_scale=2, train_wall=80, gb_free=39.6, wall=208264
2023-06-14 01:38:47 | INFO | train_inner | epoch 023:   1383 / 11284 loss=3.507, nll_loss=1.799, ppl=3.48, wps=71142.2, ups=1.2, wpb=59446.1, bsz=2306.8, num_updates=249400, lr=0.00020024, gnorm=0.34, loss_scale=2, train_wall=80, gb_free=39.6, wall=208348
2023-06-14 01:40:11 | INFO | train_inner | epoch 023:   1483 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=71372.2, ups=1.2, wpb=59619.4, bsz=2287.6, num_updates=249500, lr=0.0002002, gnorm=0.339, loss_scale=2, train_wall=80, gb_free=39.6, wall=208431
2023-06-14 01:41:34 | INFO | train_inner | epoch 023:   1583 / 11284 loss=3.504, nll_loss=1.795, ppl=3.47, wps=71304.4, ups=1.2, wpb=59520.1, bsz=2252, num_updates=249600, lr=0.00020016, gnorm=0.332, loss_scale=2, train_wall=80, gb_free=39.5, wall=208515
2023-06-14 01:42:58 | INFO | train_inner | epoch 023:   1683 / 11284 loss=3.507, nll_loss=1.799, ppl=3.48, wps=71312.7, ups=1.2, wpb=59565.3, bsz=2249.3, num_updates=249700, lr=0.00020012, gnorm=0.33, loss_scale=2, train_wall=79, gb_free=39.6, wall=208598
2023-06-14 01:44:20 | INFO | train_inner | epoch 023:   1783 / 11284 loss=3.508, nll_loss=1.8, ppl=3.48, wps=71971.2, ups=1.21, wpb=59257.6, bsz=2295.3, num_updates=249800, lr=0.00020008, gnorm=0.333, loss_scale=2, train_wall=78, gb_free=39.6, wall=208681
2023-06-14 01:45:43 | INFO | train_inner | epoch 023:   1883 / 11284 loss=3.491, nll_loss=1.781, ppl=3.44, wps=72086, ups=1.21, wpb=59452.5, bsz=2247.1, num_updates=249900, lr=0.00020004, gnorm=0.33, loss_scale=2, train_wall=78, gb_free=39.5, wall=208763
2023-06-14 01:47:05 | INFO | train_inner | epoch 023:   1983 / 11284 loss=3.499, nll_loss=1.789, ppl=3.46, wps=71373.7, ups=1.21, wpb=59189.7, bsz=2139.3, num_updates=250000, lr=0.0002, gnorm=0.338, loss_scale=2, train_wall=79, gb_free=39.5, wall=208846
2023-06-14 01:48:29 | INFO | train_inner | epoch 023:   2083 / 11284 loss=3.503, nll_loss=1.794, ppl=3.47, wps=71452.5, ups=1.2, wpb=59487.6, bsz=2163.7, num_updates=250100, lr=0.00019996, gnorm=0.331, loss_scale=2, train_wall=79, gb_free=39.6, wall=208929
2023-06-14 01:49:51 | INFO | train_inner | epoch 023:   2183 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=72402.2, ups=1.21, wpb=59836, bsz=2267.8, num_updates=250200, lr=0.00019992, gnorm=0.333, loss_scale=2, train_wall=79, gb_free=39.6, wall=209012
2023-06-14 01:51:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 01:51:15 | INFO | train_inner | epoch 023:   2284 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=70558.6, ups=1.19, wpb=59369.7, bsz=2252.3, num_updates=250300, lr=0.00019988, gnorm=0.334, loss_scale=2, train_wall=80, gb_free=39.6, wall=209096
2023-06-14 01:52:39 | INFO | train_inner | epoch 023:   2384 / 11284 loss=3.499, nll_loss=1.79, ppl=3.46, wps=71375.9, ups=1.2, wpb=59598.8, bsz=2235.8, num_updates=250400, lr=0.00019984, gnorm=0.331, loss_scale=2, train_wall=80, gb_free=39.6, wall=209180
2023-06-14 01:54:02 | INFO | train_inner | epoch 023:   2484 / 11284 loss=3.511, nll_loss=1.803, ppl=3.49, wps=71887.7, ups=1.21, wpb=59634, bsz=2229.6, num_updates=250500, lr=0.0001998, gnorm=0.322, loss_scale=2, train_wall=79, gb_free=39.6, wall=209263
2023-06-14 01:55:24 | INFO | train_inner | epoch 023:   2584 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=72079.7, ups=1.21, wpb=59448.9, bsz=2244.1, num_updates=250600, lr=0.00019976, gnorm=0.331, loss_scale=2, train_wall=78, gb_free=39.5, wall=209345
2023-06-14 01:56:46 | INFO | train_inner | epoch 023:   2684 / 11284 loss=3.504, nll_loss=1.795, ppl=3.47, wps=73103.8, ups=1.23, wpb=59544.2, bsz=2138.7, num_updates=250700, lr=0.000199721, gnorm=0.324, loss_scale=2, train_wall=78, gb_free=39.5, wall=209426
2023-06-14 01:58:08 | INFO | train_inner | epoch 023:   2784 / 11284 loss=3.513, nll_loss=1.805, ppl=3.49, wps=71812.4, ups=1.21, wpb=59306.3, bsz=2231.1, num_updates=250800, lr=0.000199681, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.6, wall=209509
2023-06-14 01:59:32 | INFO | train_inner | epoch 023:   2884 / 11284 loss=3.513, nll_loss=1.806, ppl=3.5, wps=71529.5, ups=1.2, wpb=59591.7, bsz=2266.2, num_updates=250900, lr=0.000199641, gnorm=0.325, loss_scale=2, train_wall=79, gb_free=39.6, wall=209592
2023-06-14 02:00:55 | INFO | train_inner | epoch 023:   2984 / 11284 loss=3.506, nll_loss=1.797, ppl=3.48, wps=71482.8, ups=1.2, wpb=59527.7, bsz=2217.7, num_updates=251000, lr=0.000199601, gnorm=0.327, loss_scale=2, train_wall=79, gb_free=39.6, wall=209676
2023-06-14 02:02:19 | INFO | train_inner | epoch 023:   3084 / 11284 loss=3.515, nll_loss=1.807, ppl=3.5, wps=70796.7, ups=1.19, wpb=59266.3, bsz=2321.2, num_updates=251100, lr=0.000199561, gnorm=0.337, loss_scale=2, train_wall=80, gb_free=39.4, wall=209759
2023-06-14 02:03:42 | INFO | train_inner | epoch 023:   3184 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71188.9, ups=1.2, wpb=59539.5, bsz=2229.6, num_updates=251200, lr=0.000199522, gnorm=0.34, loss_scale=2, train_wall=80, gb_free=39.6, wall=209843
2023-06-14 02:05:06 | INFO | train_inner | epoch 023:   3284 / 11284 loss=3.512, nll_loss=1.805, ppl=3.49, wps=71664.5, ups=1.2, wpb=59672.3, bsz=2269.7, num_updates=251300, lr=0.000199482, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.6, wall=209926
2023-06-14 02:05:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 02:06:30 | INFO | train_inner | epoch 023:   3385 / 11284 loss=3.519, nll_loss=1.812, ppl=3.51, wps=70547.7, ups=1.19, wpb=59433.6, bsz=2187.4, num_updates=251400, lr=0.000199442, gnorm=0.332, loss_scale=2, train_wall=80, gb_free=39.6, wall=210010
2023-06-14 02:07:53 | INFO | train_inner | epoch 023:   3485 / 11284 loss=3.509, nll_loss=1.801, ppl=3.49, wps=71050.7, ups=1.2, wpb=59145.8, bsz=2189.1, num_updates=251500, lr=0.000199403, gnorm=0.346, loss_scale=2, train_wall=80, gb_free=39.5, wall=210094
2023-06-14 02:09:17 | INFO | train_inner | epoch 023:   3585 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=71493.8, ups=1.2, wpb=59667.4, bsz=2243.3, num_updates=251600, lr=0.000199363, gnorm=0.334, loss_scale=2, train_wall=79, gb_free=39.6, wall=210177
2023-06-14 02:10:40 | INFO | train_inner | epoch 023:   3685 / 11284 loss=3.505, nll_loss=1.797, ppl=3.47, wps=71806.4, ups=1.21, wpb=59530.1, bsz=2180, num_updates=251700, lr=0.000199323, gnorm=0.336, loss_scale=2, train_wall=79, gb_free=39.6, wall=210260
2023-06-14 02:12:03 | INFO | train_inner | epoch 023:   3785 / 11284 loss=3.515, nll_loss=1.809, ppl=3.5, wps=71352.5, ups=1.2, wpb=59466.2, bsz=2230.4, num_updates=251800, lr=0.000199284, gnorm=0.377, loss_scale=2, train_wall=79, gb_free=39.6, wall=210343
2023-06-14 02:13:26 | INFO | train_inner | epoch 023:   3885 / 11284 loss=3.511, nll_loss=1.803, ppl=3.49, wps=70792.2, ups=1.2, wpb=59053.6, bsz=2143.3, num_updates=251900, lr=0.000199244, gnorm=0.339, loss_scale=2, train_wall=80, gb_free=39.6, wall=210427
2023-06-14 02:14:49 | INFO | train_inner | epoch 023:   3985 / 11284 loss=3.523, nll_loss=1.817, ppl=3.52, wps=71585.9, ups=1.21, wpb=59293.4, bsz=2086.9, num_updates=252000, lr=0.000199205, gnorm=0.329, loss_scale=2, train_wall=79, gb_free=39.6, wall=210510
2023-06-14 02:16:12 | INFO | train_inner | epoch 023:   4085 / 11284 loss=3.499, nll_loss=1.79, ppl=3.46, wps=71783, ups=1.2, wpb=59672.6, bsz=2178.6, num_updates=252100, lr=0.000199165, gnorm=0.334, loss_scale=2, train_wall=79, gb_free=39.6, wall=210593
2023-06-14 02:17:36 | INFO | train_inner | epoch 023:   4185 / 11284 loss=3.518, nll_loss=1.811, ppl=3.51, wps=71280.2, ups=1.2, wpb=59376.6, bsz=2208, num_updates=252200, lr=0.000199126, gnorm=0.339, loss_scale=2, train_wall=79, gb_free=39.5, wall=210676
2023-06-14 02:18:59 | INFO | train_inner | epoch 023:   4285 / 11284 loss=3.523, nll_loss=1.817, ppl=3.52, wps=71126.4, ups=1.2, wpb=59179.7, bsz=2220.5, num_updates=252300, lr=0.000199086, gnorm=0.333, loss_scale=2, train_wall=79, gb_free=39.6, wall=210759
2023-06-14 02:20:22 | INFO | train_inner | epoch 023:   4385 / 11284 loss=3.506, nll_loss=1.798, ppl=3.48, wps=71165.1, ups=1.2, wpb=59353.2, bsz=2276.2, num_updates=252400, lr=0.000199047, gnorm=0.336, loss_scale=4, train_wall=79, gb_free=39.6, wall=210843
2023-06-14 02:20:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 02:21:46 | INFO | train_inner | epoch 023:   4486 / 11284 loss=3.513, nll_loss=1.806, ppl=3.5, wps=70805.1, ups=1.19, wpb=59400.4, bsz=2227.9, num_updates=252500, lr=0.000199007, gnorm=0.335, loss_scale=2, train_wall=80, gb_free=39.6, wall=210927
2023-06-14 02:23:10 | INFO | train_inner | epoch 023:   4586 / 11284 loss=3.501, nll_loss=1.792, ppl=3.46, wps=71253.9, ups=1.19, wpb=59653.8, bsz=2292.2, num_updates=252600, lr=0.000198968, gnorm=0.328, loss_scale=2, train_wall=80, gb_free=38.2, wall=211010
2023-06-14 02:24:33 | INFO | train_inner | epoch 023:   4686 / 11284 loss=3.515, nll_loss=1.807, ppl=3.5, wps=71170.6, ups=1.2, wpb=59151.2, bsz=2207.6, num_updates=252700, lr=0.000198929, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=211093
2023-06-14 02:25:57 | INFO | train_inner | epoch 023:   4786 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=71049.6, ups=1.19, wpb=59469.4, bsz=2246, num_updates=252800, lr=0.000198889, gnorm=0.329, loss_scale=2, train_wall=80, gb_free=39.6, wall=211177
2023-06-14 02:27:20 | INFO | train_inner | epoch 023:   4886 / 11284 loss=3.508, nll_loss=1.801, ppl=3.48, wps=71067.4, ups=1.19, wpb=59570.7, bsz=2254.6, num_updates=252900, lr=0.00019885, gnorm=0.329, loss_scale=2, train_wall=80, gb_free=39.6, wall=211261
2023-06-14 02:28:43 | INFO | train_inner | epoch 023:   4986 / 11284 loss=3.508, nll_loss=1.8, ppl=3.48, wps=72370.2, ups=1.21, wpb=59643.9, bsz=2278.4, num_updates=253000, lr=0.000198811, gnorm=0.34, loss_scale=2, train_wall=78, gb_free=39.6, wall=211343
2023-06-14 02:30:06 | INFO | train_inner | epoch 023:   5086 / 11284 loss=3.511, nll_loss=1.804, ppl=3.49, wps=71785.9, ups=1.2, wpb=59635.1, bsz=2220.2, num_updates=253100, lr=0.000198771, gnorm=0.327, loss_scale=2, train_wall=79, gb_free=39.6, wall=211426
2023-06-14 02:31:29 | INFO | train_inner | epoch 023:   5186 / 11284 loss=3.513, nll_loss=1.806, ppl=3.5, wps=71059.6, ups=1.2, wpb=59373.2, bsz=2308.5, num_updates=253200, lr=0.000198732, gnorm=0.333, loss_scale=2, train_wall=80, gb_free=39.6, wall=211510
2023-06-14 02:32:52 | INFO | train_inner | epoch 023:   5286 / 11284 loss=3.506, nll_loss=1.798, ppl=3.48, wps=72332.9, ups=1.21, wpb=59667.5, bsz=2281.2, num_updates=253300, lr=0.000198693, gnorm=0.318, loss_scale=2, train_wall=78, gb_free=39.5, wall=211593
2023-06-14 02:34:16 | INFO | train_inner | epoch 023:   5386 / 11284 loss=3.506, nll_loss=1.797, ppl=3.48, wps=71103.7, ups=1.2, wpb=59477.1, bsz=2276.6, num_updates=253400, lr=0.000198654, gnorm=0.344, loss_scale=2, train_wall=80, gb_free=39.6, wall=211676
2023-06-14 02:35:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 02:35:40 | INFO | train_inner | epoch 023:   5487 / 11284 loss=3.508, nll_loss=1.8, ppl=3.48, wps=70617.6, ups=1.19, wpb=59413.1, bsz=2190.9, num_updates=253500, lr=0.000198615, gnorm=0.335, loss_scale=2, train_wall=80, gb_free=39.6, wall=211760
2023-06-14 02:37:02 | INFO | train_inner | epoch 023:   5587 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=72473.3, ups=1.22, wpb=59455.3, bsz=2087.3, num_updates=253600, lr=0.000198575, gnorm=0.335, loss_scale=2, train_wall=78, gb_free=39.5, wall=211842
2023-06-14 02:38:24 | INFO | train_inner | epoch 023:   5687 / 11284 loss=3.498, nll_loss=1.79, ppl=3.46, wps=72347.6, ups=1.21, wpb=59570.6, bsz=2169.7, num_updates=253700, lr=0.000198536, gnorm=0.35, loss_scale=2, train_wall=78, gb_free=39.5, wall=211925
2023-06-14 02:39:47 | INFO | train_inner | epoch 023:   5787 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71822.3, ups=1.21, wpb=59534.9, bsz=2304.7, num_updates=253800, lr=0.000198497, gnorm=0.335, loss_scale=2, train_wall=78, gb_free=39.6, wall=212008
2023-06-14 02:41:10 | INFO | train_inner | epoch 023:   5887 / 11284 loss=3.519, nll_loss=1.812, ppl=3.51, wps=71606.8, ups=1.2, wpb=59605.9, bsz=2236.4, num_updates=253900, lr=0.000198458, gnorm=0.332, loss_scale=2, train_wall=79, gb_free=39.6, wall=212091
2023-06-14 02:42:33 | INFO | train_inner | epoch 023:   5987 / 11284 loss=3.501, nll_loss=1.792, ppl=3.46, wps=71638.3, ups=1.2, wpb=59628.3, bsz=2246.8, num_updates=254000, lr=0.000198419, gnorm=0.332, loss_scale=2, train_wall=79, gb_free=39.6, wall=212174
2023-06-14 02:43:57 | INFO | train_inner | epoch 023:   6087 / 11284 loss=3.498, nll_loss=1.789, ppl=3.45, wps=71083.7, ups=1.19, wpb=59560.7, bsz=2198.9, num_updates=254100, lr=0.00019838, gnorm=0.327, loss_scale=2, train_wall=80, gb_free=39.6, wall=212258
2023-06-14 02:45:20 | INFO | train_inner | epoch 023:   6187 / 11284 loss=3.499, nll_loss=1.791, ppl=3.46, wps=71732.7, ups=1.21, wpb=59302, bsz=2216.5, num_updates=254200, lr=0.000198341, gnorm=0.343, loss_scale=2, train_wall=78, gb_free=39.6, wall=212341
2023-06-14 02:46:42 | INFO | train_inner | epoch 023:   6287 / 11284 loss=3.503, nll_loss=1.794, ppl=3.47, wps=71987.8, ups=1.21, wpb=59393.7, bsz=2284.5, num_updates=254300, lr=0.000198302, gnorm=0.341, loss_scale=2, train_wall=79, gb_free=39.5, wall=212423
2023-06-14 02:48:05 | INFO | train_inner | epoch 023:   6387 / 11284 loss=3.505, nll_loss=1.796, ppl=3.47, wps=72211.1, ups=1.21, wpb=59534.9, bsz=2165.9, num_updates=254400, lr=0.000198263, gnorm=0.326, loss_scale=2, train_wall=79, gb_free=39.6, wall=212505
2023-06-14 02:49:27 | INFO | train_inner | epoch 023:   6487 / 11284 loss=3.505, nll_loss=1.797, ppl=3.47, wps=72692, ups=1.22, wpb=59553.3, bsz=2228.6, num_updates=254500, lr=0.000198224, gnorm=0.328, loss_scale=4, train_wall=78, gb_free=39.6, wall=212587
2023-06-14 02:49:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 02:50:49 | INFO | train_inner | epoch 023:   6588 / 11284 loss=3.5, nll_loss=1.791, ppl=3.46, wps=72236.7, ups=1.21, wpb=59704.9, bsz=2169.3, num_updates=254600, lr=0.000198185, gnorm=0.352, loss_scale=2, train_wall=78, gb_free=39.6, wall=212670
2023-06-14 02:52:11 | INFO | train_inner | epoch 023:   6688 / 11284 loss=3.523, nll_loss=1.817, ppl=3.52, wps=72814.2, ups=1.22, wpb=59653.8, bsz=2199.1, num_updates=254700, lr=0.000198146, gnorm=0.334, loss_scale=2, train_wall=78, gb_free=39.6, wall=212752
2023-06-14 02:53:34 | INFO | train_inner | epoch 023:   6788 / 11284 loss=3.513, nll_loss=1.806, ppl=3.5, wps=71940.7, ups=1.21, wpb=59683.9, bsz=2269.9, num_updates=254800, lr=0.000198107, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.6, wall=212835
2023-06-14 02:54:57 | INFO | train_inner | epoch 023:   6888 / 11284 loss=3.501, nll_loss=1.793, ppl=3.46, wps=71561.6, ups=1.2, wpb=59473.2, bsz=2287.4, num_updates=254900, lr=0.000198068, gnorm=0.339, loss_scale=2, train_wall=79, gb_free=39.6, wall=212918
2023-06-14 02:56:21 | INFO | train_inner | epoch 023:   6988 / 11284 loss=3.521, nll_loss=1.814, ppl=3.52, wps=71292.2, ups=1.2, wpb=59469.8, bsz=2236.7, num_updates=255000, lr=0.00019803, gnorm=0.337, loss_scale=2, train_wall=80, gb_free=39.6, wall=213001
2023-06-14 02:57:44 | INFO | train_inner | epoch 023:   7088 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=71523, ups=1.2, wpb=59552.9, bsz=2246.7, num_updates=255100, lr=0.000197991, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.5, wall=213085
2023-06-14 02:59:07 | INFO | train_inner | epoch 023:   7188 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=71526.9, ups=1.2, wpb=59568, bsz=2173.4, num_updates=255200, lr=0.000197952, gnorm=0.334, loss_scale=2, train_wall=79, gb_free=39.6, wall=213168
2023-06-14 03:00:31 | INFO | train_inner | epoch 023:   7288 / 11284 loss=3.511, nll_loss=1.803, ppl=3.49, wps=71341, ups=1.2, wpb=59550.2, bsz=2249.7, num_updates=255300, lr=0.000197913, gnorm=0.336, loss_scale=2, train_wall=80, gb_free=39.6, wall=213252
2023-06-14 03:01:54 | INFO | train_inner | epoch 023:   7388 / 11284 loss=3.509, nll_loss=1.801, ppl=3.48, wps=71333.8, ups=1.2, wpb=59206.9, bsz=2201.1, num_updates=255400, lr=0.000197874, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.6, wall=213335
2023-06-14 03:03:17 | INFO | train_inner | epoch 023:   7488 / 11284 loss=3.529, nll_loss=1.824, ppl=3.54, wps=71677.2, ups=1.2, wpb=59512.2, bsz=2231.3, num_updates=255500, lr=0.000197836, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.5, wall=213418
2023-06-14 03:04:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 03:04:41 | INFO | train_inner | epoch 023:   7589 / 11284 loss=3.523, nll_loss=1.817, ppl=3.52, wps=70740.5, ups=1.19, wpb=59642.2, bsz=2282, num_updates=255600, lr=0.000197797, gnorm=0.333, loss_scale=2, train_wall=80, gb_free=39.6, wall=213502
2023-06-14 03:06:04 | INFO | train_inner | epoch 023:   7689 / 11284 loss=3.492, nll_loss=1.782, ppl=3.44, wps=71966.6, ups=1.21, wpb=59499, bsz=2171.6, num_updates=255700, lr=0.000197758, gnorm=0.33, loss_scale=2, train_wall=78, gb_free=39.6, wall=213585
2023-06-14 03:07:26 | INFO | train_inner | epoch 023:   7789 / 11284 loss=3.529, nll_loss=1.824, ppl=3.54, wps=72546.3, ups=1.22, wpb=59670.9, bsz=2152.5, num_updates=255800, lr=0.00019772, gnorm=0.352, loss_scale=2, train_wall=78, gb_free=39.6, wall=213667
2023-06-14 03:08:48 | INFO | train_inner | epoch 023:   7889 / 11284 loss=3.499, nll_loss=1.79, ppl=3.46, wps=72657.9, ups=1.22, wpb=59455.4, bsz=2248.5, num_updates=255900, lr=0.000197681, gnorm=0.325, loss_scale=2, train_wall=78, gb_free=39.5, wall=213749
2023-06-14 03:10:11 | INFO | train_inner | epoch 023:   7989 / 11284 loss=3.51, nll_loss=1.802, ppl=3.49, wps=72024.4, ups=1.21, wpb=59510.2, bsz=2184.9, num_updates=256000, lr=0.000197642, gnorm=0.338, loss_scale=2, train_wall=79, gb_free=39.7, wall=213831
2023-06-14 03:11:34 | INFO | train_inner | epoch 023:   8089 / 11284 loss=3.516, nll_loss=1.809, ppl=3.51, wps=71256, ups=1.2, wpb=59251.9, bsz=2178.1, num_updates=256100, lr=0.000197604, gnorm=0.329, loss_scale=2, train_wall=79, gb_free=39.6, wall=213914
2023-06-14 03:12:57 | INFO | train_inner | epoch 023:   8189 / 11284 loss=3.5, nll_loss=1.791, ppl=3.46, wps=71542.3, ups=1.2, wpb=59673.1, bsz=2283.5, num_updates=256200, lr=0.000197565, gnorm=0.335, loss_scale=2, train_wall=80, gb_free=39.6, wall=213998
2023-06-14 03:14:21 | INFO | train_inner | epoch 023:   8289 / 11284 loss=3.517, nll_loss=1.811, ppl=3.51, wps=71452.1, ups=1.2, wpb=59675.6, bsz=2233.7, num_updates=256300, lr=0.000197527, gnorm=0.335, loss_scale=2, train_wall=80, gb_free=39.6, wall=214081
2023-06-14 03:15:44 | INFO | train_inner | epoch 023:   8389 / 11284 loss=3.511, nll_loss=1.804, ppl=3.49, wps=71448.9, ups=1.2, wpb=59318.5, bsz=2129.2, num_updates=256400, lr=0.000197488, gnorm=0.334, loss_scale=2, train_wall=79, gb_free=39.6, wall=214164
2023-06-14 03:17:06 | INFO | train_inner | epoch 023:   8489 / 11284 loss=3.514, nll_loss=1.807, ppl=3.5, wps=72606.8, ups=1.22, wpb=59485.7, bsz=2323.8, num_updates=256500, lr=0.00019745, gnorm=0.342, loss_scale=2, train_wall=78, gb_free=39.6, wall=214246
2023-06-14 03:18:29 | INFO | train_inner | epoch 023:   8589 / 11284 loss=3.515, nll_loss=1.808, ppl=3.5, wps=71886.5, ups=1.2, wpb=59802.6, bsz=2228.7, num_updates=256600, lr=0.000197411, gnorm=0.331, loss_scale=2, train_wall=79, gb_free=39.6, wall=214329
2023-06-14 03:19:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 03:19:53 | INFO | train_inner | epoch 023:   8690 / 11284 loss=3.499, nll_loss=1.79, ppl=3.46, wps=70574.7, ups=1.19, wpb=59474.1, bsz=2234.3, num_updates=256700, lr=0.000197373, gnorm=0.342, loss_scale=2, train_wall=80, gb_free=39.5, wall=214414
2023-06-14 03:21:16 | INFO | train_inner | epoch 023:   8790 / 11284 loss=3.512, nll_loss=1.805, ppl=3.49, wps=71615.4, ups=1.2, wpb=59446.6, bsz=2161.6, num_updates=256800, lr=0.000197334, gnorm=0.338, loss_scale=2, train_wall=79, gb_free=39.6, wall=214497
2023-06-14 03:22:39 | INFO | train_inner | epoch 023:   8890 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=71744.2, ups=1.21, wpb=59335.9, bsz=2170.3, num_updates=256900, lr=0.000197296, gnorm=0.33, loss_scale=2, train_wall=79, gb_free=39.6, wall=214579
2023-06-14 03:24:02 | INFO | train_inner | epoch 023:   8990 / 11284 loss=3.489, nll_loss=1.779, ppl=3.43, wps=71527, ups=1.2, wpb=59587.9, bsz=2283.1, num_updates=257000, lr=0.000197257, gnorm=0.326, loss_scale=2, train_wall=79, gb_free=39.5, wall=214663
2023-06-14 03:25:25 | INFO | train_inner | epoch 023:   9090 / 11284 loss=3.514, nll_loss=1.807, ppl=3.5, wps=71787.9, ups=1.21, wpb=59540.5, bsz=2178.5, num_updates=257100, lr=0.000197219, gnorm=0.33, loss_scale=2, train_wall=79, gb_free=39.6, wall=214746
2023-06-14 03:26:48 | INFO | train_inner | epoch 023:   9190 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71676.3, ups=1.2, wpb=59675.4, bsz=2208.9, num_updates=257200, lr=0.000197181, gnorm=0.338, loss_scale=2, train_wall=80, gb_free=39.6, wall=214829
2023-06-14 03:28:11 | INFO | train_inner | epoch 023:   9290 / 11284 loss=3.492, nll_loss=1.782, ppl=3.44, wps=71741.4, ups=1.2, wpb=59560.7, bsz=2214.8, num_updates=257300, lr=0.000197142, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.6, wall=214912
2023-06-14 03:29:33 | INFO | train_inner | epoch 023:   9390 / 11284 loss=3.517, nll_loss=1.81, ppl=3.51, wps=73050.4, ups=1.23, wpb=59555.5, bsz=2161.5, num_updates=257400, lr=0.000197104, gnorm=0.337, loss_scale=2, train_wall=77, gb_free=39.6, wall=214994
2023-06-14 03:30:55 | INFO | train_inner | epoch 023:   9490 / 11284 loss=3.507, nll_loss=1.8, ppl=3.48, wps=72971.1, ups=1.23, wpb=59549.3, bsz=2223.3, num_updates=257500, lr=0.000197066, gnorm=0.332, loss_scale=2, train_wall=78, gb_free=39.5, wall=215075
2023-06-14 03:32:17 | INFO | train_inner | epoch 023:   9590 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=72012.8, ups=1.21, wpb=59615.8, bsz=2145.1, num_updates=257600, lr=0.000197028, gnorm=0.332, loss_scale=2, train_wall=79, gb_free=39.5, wall=215158
2023-06-14 03:33:40 | INFO | train_inner | epoch 023:   9690 / 11284 loss=3.488, nll_loss=1.779, ppl=3.43, wps=71985.3, ups=1.21, wpb=59573.5, bsz=2149.3, num_updates=257700, lr=0.000196989, gnorm=0.335, loss_scale=2, train_wall=79, gb_free=39.5, wall=215241
2023-06-14 03:35:03 | INFO | train_inner | epoch 023:   9790 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=71621.9, ups=1.21, wpb=59430.6, bsz=2193.3, num_updates=257800, lr=0.000196951, gnorm=0.335, loss_scale=4, train_wall=79, gb_free=39.6, wall=215324
2023-06-14 03:35:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 03:36:27 | INFO | train_inner | epoch 023:   9891 / 11284 loss=3.499, nll_loss=1.79, ppl=3.46, wps=70801.8, ups=1.19, wpb=59572.3, bsz=2247.8, num_updates=257900, lr=0.000196913, gnorm=0.328, loss_scale=2, train_wall=80, gb_free=39.6, wall=215408
2023-06-14 03:37:50 | INFO | train_inner | epoch 023:   9991 / 11284 loss=3.519, nll_loss=1.813, ppl=3.51, wps=71609.2, ups=1.2, wpb=59475.4, bsz=2268.8, num_updates=258000, lr=0.000196875, gnorm=0.332, loss_scale=2, train_wall=79, gb_free=39.6, wall=215491
2023-06-14 03:38:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-06-14 03:39:15 | INFO | train_inner | epoch 023:  10092 / 11284 loss=3.515, nll_loss=1.808, ppl=3.5, wps=70588, ups=1.19, wpb=59527.7, bsz=2307.5, num_updates=258100, lr=0.000196837, gnorm=0.339, loss_scale=1, train_wall=80, gb_free=39.6, wall=215575
2023-06-14 03:40:38 | INFO | train_inner | epoch 023:  10192 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=71145.9, ups=1.2, wpb=59249, bsz=2285.8, num_updates=258200, lr=0.000196799, gnorm=0.333, loss_scale=1, train_wall=79, gb_free=39.5, wall=215658
2023-06-14 03:42:01 | INFO | train_inner | epoch 023:  10292 / 11284 loss=3.514, nll_loss=1.807, ppl=3.5, wps=71591.3, ups=1.2, wpb=59715.9, bsz=2261.4, num_updates=258300, lr=0.00019676, gnorm=0.335, loss_scale=1, train_wall=79, gb_free=39.5, wall=215742
2023-06-14 03:43:25 | INFO | train_inner | epoch 023:  10392 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=71177.6, ups=1.2, wpb=59457.7, bsz=2269.9, num_updates=258400, lr=0.000196722, gnorm=0.356, loss_scale=1, train_wall=79, gb_free=39.6, wall=215825
2023-06-14 03:44:48 | INFO | train_inner | epoch 023:  10492 / 11284 loss=3.516, nll_loss=1.81, ppl=3.51, wps=71594, ups=1.2, wpb=59769.9, bsz=2298.6, num_updates=258500, lr=0.000196684, gnorm=0.33, loss_scale=1, train_wall=80, gb_free=39.5, wall=215909
2023-06-14 03:46:11 | INFO | train_inner | epoch 023:  10592 / 11284 loss=3.514, nll_loss=1.808, ppl=3.5, wps=71609.3, ups=1.2, wpb=59530.3, bsz=2270.1, num_updates=258600, lr=0.000196646, gnorm=0.347, loss_scale=1, train_wall=79, gb_free=39.6, wall=215992
2023-06-14 03:47:35 | INFO | train_inner | epoch 023:  10692 / 11284 loss=3.517, nll_loss=1.81, ppl=3.51, wps=71450.6, ups=1.2, wpb=59612.6, bsz=2256.9, num_updates=258700, lr=0.000196608, gnorm=0.336, loss_scale=1, train_wall=79, gb_free=39.6, wall=216075
2023-06-14 03:48:58 | INFO | train_inner | epoch 023:  10792 / 11284 loss=3.51, nll_loss=1.803, ppl=3.49, wps=71548.2, ups=1.2, wpb=59400.1, bsz=2252.7, num_updates=258800, lr=0.00019657, gnorm=0.346, loss_scale=1, train_wall=79, gb_free=39.6, wall=216158
2023-06-14 03:50:21 | INFO | train_inner | epoch 023:  10892 / 11284 loss=3.508, nll_loss=1.8, ppl=3.48, wps=71601.9, ups=1.2, wpb=59473.8, bsz=2171.6, num_updates=258900, lr=0.000196532, gnorm=0.339, loss_scale=1, train_wall=79, gb_free=39.6, wall=216242
2023-06-14 03:51:44 | INFO | train_inner | epoch 023:  10992 / 11284 loss=3.506, nll_loss=1.799, ppl=3.48, wps=71446.2, ups=1.2, wpb=59473, bsz=2233.5, num_updates=259000, lr=0.000196494, gnorm=0.329, loss_scale=1, train_wall=79, gb_free=39.6, wall=216325
2023-06-14 03:53:06 | INFO | train_inner | epoch 023:  11092 / 11284 loss=3.505, nll_loss=1.797, ppl=3.47, wps=72838.7, ups=1.22, wpb=59546.5, bsz=2208, num_updates=259100, lr=0.000196456, gnorm=0.344, loss_scale=2, train_wall=78, gb_free=39.6, wall=216407
2023-06-14 03:54:27 | INFO | train_inner | epoch 023:  11192 / 11284 loss=3.526, nll_loss=1.82, ppl=3.53, wps=72818.3, ups=1.23, wpb=59207, bsz=2233.3, num_updates=259200, lr=0.000196419, gnorm=0.333, loss_scale=2, train_wall=77, gb_free=39.7, wall=216488
2023-06-14 03:55:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-14 03:56:00 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 4.299 | nll_loss 2.617 | ppl 6.13 | bleu 20.84 | wps 3720.5 | wpb 2397.5 | bsz 71.5 | num_updates 259292 | best_loss 4.299
2023-06-14 03:56:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 259292 updates
2023-06-14 03:56:00 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint23.pt
2023-06-14 03:56:03 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint23.pt
2023-06-14 03:56:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint23.pt (epoch 23 @ 259292 updates, score 4.299) (writing took 8.725733825936913 seconds)
2023-06-14 03:56:09 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-06-14 03:56:09 | INFO | train | epoch 023 | loss 3.507 | nll_loss 1.799 | ppl 3.48 | wps 71393.5 | ups 1.2 | wpb 59500.9 | bsz 2227.6 | num_updates 259292 | lr 0.000196384 | gnorm 0.336 | loss_scale 2 | train_wall 8919 | gb_free 39.6 | wall 216590
2023-06-14 03:56:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-14 03:56:09 | INFO | fairseq.trainer | begin training epoch 24
2023-06-14 03:56:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-14 03:56:16 | INFO | train_inner | epoch 024:      8 / 11284 loss=3.507, nll_loss=1.799, ppl=3.48, wps=54193.7, ups=0.92, wpb=59118.7, bsz=2165.4, num_updates=259300, lr=0.000196381, gnorm=0.341, loss_scale=2, train_wall=78, gb_free=39.6, wall=216597
2023-06-14 03:57:43 | INFO | train_inner | epoch 024:    108 / 11284 loss=3.476, nll_loss=1.764, ppl=3.4, wps=68894.1, ups=1.16, wpb=59351.6, bsz=2196.5, num_updates=259400, lr=0.000196343, gnorm=0.333, loss_scale=2, train_wall=82, gb_free=39.6, wall=216683
2023-06-14 03:59:07 | INFO | train_inner | epoch 024:    208 / 11284 loss=3.499, nll_loss=1.79, ppl=3.46, wps=70180.1, ups=1.18, wpb=59350.9, bsz=2314.3, num_updates=259500, lr=0.000196305, gnorm=0.328, loss_scale=2, train_wall=80, gb_free=39.6, wall=216768
2023-06-14 04:00:30 | INFO | train_inner | epoch 024:    308 / 11284 loss=3.497, nll_loss=1.787, ppl=3.45, wps=71474.8, ups=1.2, wpb=59555.3, bsz=2237, num_updates=259600, lr=0.000196267, gnorm=0.329, loss_scale=2, train_wall=79, gb_free=39.6, wall=216851
2023-06-14 04:01:53 | INFO | train_inner | epoch 024:    408 / 11284 loss=3.511, nll_loss=1.804, ppl=3.49, wps=71465.4, ups=1.2, wpb=59338.9, bsz=2254.3, num_updates=259700, lr=0.000196229, gnorm=0.354, loss_scale=2, train_wall=79, gb_free=39.6, wall=216934
2023-06-14 04:03:16 | INFO | train_inner | epoch 024:    508 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=72473.1, ups=1.22, wpb=59547.6, bsz=2122.2, num_updates=259800, lr=0.000196192, gnorm=0.336, loss_scale=2, train_wall=78, gb_free=39.6, wall=217016
2023-06-14 04:04:39 | INFO | train_inner | epoch 024:    608 / 11284 loss=3.49, nll_loss=1.78, ppl=3.43, wps=71745.5, ups=1.2, wpb=59600.8, bsz=2167, num_updates=259900, lr=0.000196154, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.6, wall=217099
2023-06-14 04:06:02 | INFO | train_inner | epoch 024:    708 / 11284 loss=3.501, nll_loss=1.792, ppl=3.46, wps=71702.3, ups=1.2, wpb=59514.3, bsz=2201.1, num_updates=260000, lr=0.000196116, gnorm=0.332, loss_scale=2, train_wall=79, gb_free=39.6, wall=217182
2023-06-14 04:07:25 | INFO | train_inner | epoch 024:    808 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71690.7, ups=1.2, wpb=59633.8, bsz=2260.6, num_updates=260100, lr=0.000196078, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.6, wall=217265
2023-06-14 04:08:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 04:08:49 | INFO | train_inner | epoch 024:    909 / 11284 loss=3.496, nll_loss=1.786, ppl=3.45, wps=71040.9, ups=1.19, wpb=59600.8, bsz=2180.3, num_updates=260200, lr=0.000196041, gnorm=0.333, loss_scale=2, train_wall=80, gb_free=39.6, wall=217349
2023-06-14 04:10:12 | INFO | train_inner | epoch 024:   1009 / 11284 loss=3.497, nll_loss=1.787, ppl=3.45, wps=71758.2, ups=1.2, wpb=59677.7, bsz=2200.9, num_updates=260300, lr=0.000196003, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.5, wall=217433
2023-06-14 04:11:35 | INFO | train_inner | epoch 024:   1109 / 11284 loss=3.51, nll_loss=1.802, ppl=3.49, wps=71529.8, ups=1.21, wpb=59351.6, bsz=2169.8, num_updates=260400, lr=0.000195965, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.5, wall=217515
2023-06-14 04:12:58 | INFO | train_inner | epoch 024:   1209 / 11284 loss=3.512, nll_loss=1.804, ppl=3.49, wps=71879.9, ups=1.2, wpb=59854.8, bsz=2268.5, num_updates=260500, lr=0.000195928, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.5, wall=217599
2023-06-14 04:14:21 | INFO | train_inner | epoch 024:   1309 / 11284 loss=3.489, nll_loss=1.778, ppl=3.43, wps=71765.7, ups=1.2, wpb=59644.6, bsz=2263.9, num_updates=260600, lr=0.00019589, gnorm=0.33, loss_scale=2, train_wall=79, gb_free=39.5, wall=217682
2023-06-14 04:15:45 | INFO | train_inner | epoch 024:   1409 / 11284 loss=3.512, nll_loss=1.805, ppl=3.49, wps=71295.3, ups=1.2, wpb=59336.4, bsz=2260.3, num_updates=260700, lr=0.000195853, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.6, wall=217765
2023-06-14 04:17:07 | INFO | train_inner | epoch 024:   1509 / 11284 loss=3.518, nll_loss=1.811, ppl=3.51, wps=71975.6, ups=1.21, wpb=59675.3, bsz=2256.4, num_updates=260800, lr=0.000195815, gnorm=0.336, loss_scale=2, train_wall=79, gb_free=39.6, wall=217848
2023-06-14 04:18:31 | INFO | train_inner | epoch 024:   1609 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=71555, ups=1.2, wpb=59530.4, bsz=2250.9, num_updates=260900, lr=0.000195778, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.5, wall=217931
2023-06-14 04:19:54 | INFO | train_inner | epoch 024:   1709 / 11284 loss=3.49, nll_loss=1.78, ppl=3.43, wps=71485.7, ups=1.2, wpb=59570.2, bsz=2314.6, num_updates=261000, lr=0.00019574, gnorm=0.323, loss_scale=2, train_wall=79, gb_free=39.6, wall=218015
2023-06-14 04:21:17 | INFO | train_inner | epoch 024:   1809 / 11284 loss=3.517, nll_loss=1.81, ppl=3.51, wps=71586.4, ups=1.2, wpb=59760.5, bsz=2227.7, num_updates=261100, lr=0.000195703, gnorm=0.334, loss_scale=2, train_wall=80, gb_free=39.5, wall=218098
2023-06-14 04:22:40 | INFO | train_inner | epoch 024:   1909 / 11284 loss=3.501, nll_loss=1.792, ppl=3.46, wps=71484.4, ups=1.2, wpb=59334.1, bsz=2254.4, num_updates=261200, lr=0.000195665, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.6, wall=218181
2023-06-14 04:22:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 04:24:04 | INFO | train_inner | epoch 024:   2010 / 11284 loss=3.506, nll_loss=1.798, ppl=3.48, wps=70831.2, ups=1.19, wpb=59523, bsz=2217.1, num_updates=261300, lr=0.000195628, gnorm=0.341, loss_scale=2, train_wall=80, gb_free=39.6, wall=218265
2023-06-14 04:25:27 | INFO | train_inner | epoch 024:   2110 / 11284 loss=3.496, nll_loss=1.786, ppl=3.45, wps=71893.2, ups=1.21, wpb=59570.3, bsz=2237.4, num_updates=261400, lr=0.00019559, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.5, wall=218348
2023-06-14 04:26:50 | INFO | train_inner | epoch 024:   2210 / 11284 loss=3.514, nll_loss=1.807, ppl=3.5, wps=71679.6, ups=1.21, wpb=59470.3, bsz=2307.3, num_updates=261500, lr=0.000195553, gnorm=0.333, loss_scale=2, train_wall=79, gb_free=39.6, wall=218431
2023-06-14 04:28:14 | INFO | train_inner | epoch 024:   2310 / 11284 loss=3.492, nll_loss=1.783, ppl=3.44, wps=71580.8, ups=1.2, wpb=59551.8, bsz=2192.1, num_updates=261600, lr=0.000195515, gnorm=0.344, loss_scale=2, train_wall=80, gb_free=39.6, wall=218514
2023-06-14 04:29:37 | INFO | train_inner | epoch 024:   2410 / 11284 loss=3.504, nll_loss=1.795, ppl=3.47, wps=71545.9, ups=1.2, wpb=59619.8, bsz=2328.1, num_updates=261700, lr=0.000195478, gnorm=0.339, loss_scale=2, train_wall=79, gb_free=39.5, wall=218597
2023-06-14 04:30:59 | INFO | train_inner | epoch 024:   2510 / 11284 loss=3.502, nll_loss=1.793, ppl=3.47, wps=71788, ups=1.21, wpb=59202, bsz=2181.6, num_updates=261800, lr=0.000195441, gnorm=0.332, loss_scale=2, train_wall=79, gb_free=39.6, wall=218680
2023-06-14 04:32:22 | INFO | train_inner | epoch 024:   2610 / 11284 loss=3.519, nll_loss=1.813, ppl=3.51, wps=71882.3, ups=1.21, wpb=59381.9, bsz=2243.3, num_updates=261900, lr=0.000195403, gnorm=0.341, loss_scale=2, train_wall=78, gb_free=39.6, wall=218762
2023-06-14 04:33:45 | INFO | train_inner | epoch 024:   2710 / 11284 loss=3.509, nll_loss=1.801, ppl=3.49, wps=71727.4, ups=1.2, wpb=59525.8, bsz=2199.3, num_updates=262000, lr=0.000195366, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.5, wall=218845
2023-06-14 04:35:08 | INFO | train_inner | epoch 024:   2810 / 11284 loss=3.512, nll_loss=1.804, ppl=3.49, wps=71865.7, ups=1.21, wpb=59465.6, bsz=2225.1, num_updates=262100, lr=0.000195329, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.5, wall=218928
2023-06-14 04:36:32 | INFO | train_inner | epoch 024:   2910 / 11284 loss=3.5, nll_loss=1.791, ppl=3.46, wps=70221.8, ups=1.18, wpb=59447.4, bsz=2190.6, num_updates=262200, lr=0.000195292, gnorm=0.345, loss_scale=2, train_wall=80, gb_free=39.6, wall=219013
2023-06-14 04:37:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 04:37:57 | INFO | train_inner | epoch 024:   3011 / 11284 loss=3.494, nll_loss=1.784, ppl=3.44, wps=70439, ups=1.18, wpb=59458, bsz=2247.2, num_updates=262300, lr=0.000195254, gnorm=0.33, loss_scale=2, train_wall=80, gb_free=39.5, wall=219097
2023-06-14 04:39:19 | INFO | train_inner | epoch 024:   3111 / 11284 loss=3.494, nll_loss=1.784, ppl=3.44, wps=72278.3, ups=1.22, wpb=59292.6, bsz=2321.8, num_updates=262400, lr=0.000195217, gnorm=0.337, loss_scale=2, train_wall=78, gb_free=39.6, wall=219179
2023-06-14 04:40:41 | INFO | train_inner | epoch 024:   3211 / 11284 loss=3.491, nll_loss=1.781, ppl=3.44, wps=72183, ups=1.21, wpb=59565, bsz=2164.9, num_updates=262500, lr=0.00019518, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=38.9, wall=219262
2023-06-14 04:42:04 | INFO | train_inner | epoch 024:   3311 / 11284 loss=3.516, nll_loss=1.809, ppl=3.5, wps=71277.6, ups=1.2, wpb=59307.8, bsz=2226.1, num_updates=262600, lr=0.000195143, gnorm=0.332, loss_scale=2, train_wall=79, gb_free=39.6, wall=219345
2023-06-14 04:43:28 | INFO | train_inner | epoch 024:   3411 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=71543.7, ups=1.2, wpb=59611.5, bsz=2270.9, num_updates=262700, lr=0.000195106, gnorm=0.332, loss_scale=2, train_wall=79, gb_free=39.6, wall=219428
2023-06-14 04:44:51 | INFO | train_inner | epoch 024:   3511 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=71239.8, ups=1.2, wpb=59230.6, bsz=2293, num_updates=262800, lr=0.000195069, gnorm=0.342, loss_scale=2, train_wall=80, gb_free=39.5, wall=219512
2023-06-14 04:46:15 | INFO | train_inner | epoch 024:   3611 / 11284 loss=3.516, nll_loss=1.81, ppl=3.51, wps=70644.5, ups=1.19, wpb=59517.7, bsz=2227.9, num_updates=262900, lr=0.000195031, gnorm=0.346, loss_scale=2, train_wall=80, gb_free=39.6, wall=219596
2023-06-14 04:47:40 | INFO | train_inner | epoch 024:   3711 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=70558.2, ups=1.18, wpb=59657.1, bsz=2241.6, num_updates=263000, lr=0.000194994, gnorm=0.331, loss_scale=2, train_wall=80, gb_free=39.5, wall=219680
2023-06-14 04:49:03 | INFO | train_inner | epoch 024:   3811 / 11284 loss=3.492, nll_loss=1.782, ppl=3.44, wps=71841.7, ups=1.21, wpb=59568.8, bsz=2265.5, num_updates=263100, lr=0.000194957, gnorm=0.332, loss_scale=2, train_wall=79, gb_free=39.5, wall=219763
2023-06-14 04:50:25 | INFO | train_inner | epoch 024:   3911 / 11284 loss=3.511, nll_loss=1.804, ppl=3.49, wps=72108.3, ups=1.21, wpb=59354.1, bsz=2226.1, num_updates=263200, lr=0.00019492, gnorm=0.341, loss_scale=2, train_wall=78, gb_free=39.6, wall=219846
2023-06-14 04:51:48 | INFO | train_inner | epoch 024:   4011 / 11284 loss=3.5, nll_loss=1.791, ppl=3.46, wps=71782, ups=1.21, wpb=59316.8, bsz=2308.7, num_updates=263300, lr=0.000194883, gnorm=0.335, loss_scale=4, train_wall=79, gb_free=39.6, wall=219928
2023-06-14 04:52:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 04:53:11 | INFO | train_inner | epoch 024:   4112 / 11284 loss=3.506, nll_loss=1.798, ppl=3.48, wps=70813.8, ups=1.19, wpb=59277.6, bsz=2109.8, num_updates=263400, lr=0.000194846, gnorm=0.345, loss_scale=2, train_wall=80, gb_free=39.6, wall=220012
2023-06-14 04:54:34 | INFO | train_inner | epoch 024:   4212 / 11284 loss=3.507, nll_loss=1.799, ppl=3.48, wps=71653.5, ups=1.2, wpb=59478.7, bsz=2180.6, num_updates=263500, lr=0.000194809, gnorm=0.331, loss_scale=2, train_wall=79, gb_free=39.6, wall=220095
2023-06-14 04:55:57 | INFO | train_inner | epoch 024:   4312 / 11284 loss=3.522, nll_loss=1.816, ppl=3.52, wps=72204.9, ups=1.21, wpb=59488.2, bsz=2272.9, num_updates=263600, lr=0.000194772, gnorm=0.344, loss_scale=2, train_wall=78, gb_free=39.6, wall=220177
2023-06-14 04:57:19 | INFO | train_inner | epoch 024:   4412 / 11284 loss=3.495, nll_loss=1.785, ppl=3.45, wps=72261.2, ups=1.22, wpb=59419.8, bsz=2234.4, num_updates=263700, lr=0.000194735, gnorm=0.337, loss_scale=2, train_wall=78, gb_free=39.6, wall=220260
2023-06-14 04:58:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-06-14 04:58:42 | INFO | train_inner | epoch 024:   4513 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=70887.9, ups=1.2, wpb=59149.7, bsz=2158, num_updates=263800, lr=0.000194698, gnorm=0.344, loss_scale=1, train_wall=80, gb_free=39.6, wall=220343
2023-06-14 05:00:05 | INFO | train_inner | epoch 024:   4613 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=72486.6, ups=1.22, wpb=59548.8, bsz=2170, num_updates=263900, lr=0.000194662, gnorm=0.342, loss_scale=1, train_wall=78, gb_free=39.5, wall=220425
2023-06-14 05:01:26 | INFO | train_inner | epoch 024:   4713 / 11284 loss=3.493, nll_loss=1.783, ppl=3.44, wps=72814, ups=1.22, wpb=59441.2, bsz=2200, num_updates=264000, lr=0.000194625, gnorm=0.335, loss_scale=1, train_wall=78, gb_free=39.5, wall=220507
2023-06-14 05:02:49 | INFO | train_inner | epoch 024:   4813 / 11284 loss=3.519, nll_loss=1.813, ppl=3.51, wps=71458.4, ups=1.2, wpb=59419.3, bsz=2214.1, num_updates=264100, lr=0.000194588, gnorm=0.334, loss_scale=1, train_wall=79, gb_free=39.6, wall=220590
2023-06-14 05:04:13 | INFO | train_inner | epoch 024:   4913 / 11284 loss=3.506, nll_loss=1.798, ppl=3.48, wps=71465.5, ups=1.2, wpb=59573.6, bsz=2151.5, num_updates=264200, lr=0.000194551, gnorm=0.347, loss_scale=1, train_wall=79, gb_free=39.6, wall=220673
2023-06-14 05:05:36 | INFO | train_inner | epoch 024:   5013 / 11284 loss=3.503, nll_loss=1.794, ppl=3.47, wps=71418.4, ups=1.2, wpb=59489.4, bsz=2280.5, num_updates=264300, lr=0.000194514, gnorm=0.348, loss_scale=1, train_wall=79, gb_free=39.6, wall=220757
2023-06-14 05:06:59 | INFO | train_inner | epoch 024:   5113 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=71362.8, ups=1.2, wpb=59511.2, bsz=2093.8, num_updates=264400, lr=0.000194477, gnorm=0.336, loss_scale=1, train_wall=79, gb_free=39.5, wall=220840
2023-06-14 05:08:23 | INFO | train_inner | epoch 024:   5213 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=71306.6, ups=1.2, wpb=59494, bsz=2301.3, num_updates=264500, lr=0.000194441, gnorm=0.342, loss_scale=1, train_wall=79, gb_free=39.6, wall=220923
2023-06-14 05:09:46 | INFO | train_inner | epoch 024:   5313 / 11284 loss=3.489, nll_loss=1.779, ppl=3.43, wps=72143.7, ups=1.21, wpb=59817.1, bsz=2119.1, num_updates=264600, lr=0.000194404, gnorm=0.338, loss_scale=1, train_wall=79, gb_free=39.6, wall=221006
2023-06-14 05:11:08 | INFO | train_inner | epoch 024:   5413 / 11284 loss=3.499, nll_loss=1.79, ppl=3.46, wps=72037.1, ups=1.21, wpb=59554.9, bsz=2190.4, num_updates=264700, lr=0.000194367, gnorm=0.34, loss_scale=1, train_wall=79, gb_free=39.5, wall=221089
2023-06-14 05:12:31 | INFO | train_inner | epoch 024:   5513 / 11284 loss=3.51, nll_loss=1.803, ppl=3.49, wps=71576, ups=1.21, wpb=59385.5, bsz=2288.3, num_updates=264800, lr=0.000194331, gnorm=0.337, loss_scale=1, train_wall=79, gb_free=39.5, wall=221172
2023-06-14 05:13:54 | INFO | train_inner | epoch 024:   5613 / 11284 loss=3.51, nll_loss=1.803, ppl=3.49, wps=71791.5, ups=1.21, wpb=59536.7, bsz=2222.3, num_updates=264900, lr=0.000194294, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.6, wall=221255
2023-06-14 05:15:17 | INFO | train_inner | epoch 024:   5713 / 11284 loss=3.515, nll_loss=1.808, ppl=3.5, wps=72276.1, ups=1.22, wpb=59453.7, bsz=2267.9, num_updates=265000, lr=0.000194257, gnorm=0.34, loss_scale=2, train_wall=78, gb_free=39.6, wall=221337
2023-06-14 05:16:39 | INFO | train_inner | epoch 024:   5813 / 11284 loss=3.522, nll_loss=1.816, ppl=3.52, wps=71585.5, ups=1.21, wpb=59170.1, bsz=2220.6, num_updates=265100, lr=0.000194221, gnorm=0.339, loss_scale=2, train_wall=79, gb_free=39.6, wall=221420
2023-06-14 05:18:02 | INFO | train_inner | epoch 024:   5913 / 11284 loss=3.507, nll_loss=1.799, ppl=3.48, wps=71769.1, ups=1.21, wpb=59511.8, bsz=2259.8, num_updates=265200, lr=0.000194184, gnorm=0.33, loss_scale=2, train_wall=79, gb_free=39.6, wall=221503
2023-06-14 05:19:24 | INFO | train_inner | epoch 024:   6013 / 11284 loss=3.526, nll_loss=1.821, ppl=3.53, wps=72077.2, ups=1.22, wpb=59314.1, bsz=2231.1, num_updates=265300, lr=0.000194147, gnorm=0.336, loss_scale=2, train_wall=79, gb_free=39.6, wall=221585
2023-06-14 05:20:48 | INFO | train_inner | epoch 024:   6113 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=71610.4, ups=1.2, wpb=59495.8, bsz=2184.7, num_updates=265400, lr=0.000194111, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.6, wall=221668
2023-06-14 05:22:11 | INFO | train_inner | epoch 024:   6213 / 11284 loss=3.505, nll_loss=1.797, ppl=3.47, wps=71894.8, ups=1.2, wpb=59697.3, bsz=2233.8, num_updates=265500, lr=0.000194074, gnorm=0.328, loss_scale=2, train_wall=79, gb_free=39.6, wall=221751
2023-06-14 05:23:33 | INFO | train_inner | epoch 024:   6313 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=71799.1, ups=1.21, wpb=59369.3, bsz=2162.3, num_updates=265600, lr=0.000194038, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.5, wall=221834
2023-06-14 05:24:56 | INFO | train_inner | epoch 024:   6413 / 11284 loss=3.519, nll_loss=1.813, ppl=3.51, wps=71404.5, ups=1.2, wpb=59301.9, bsz=2190.6, num_updates=265700, lr=0.000194001, gnorm=0.338, loss_scale=2, train_wall=79, gb_free=39.5, wall=221917
2023-06-14 05:26:21 | INFO | train_inner | epoch 024:   6513 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=70412.5, ups=1.18, wpb=59651.9, bsz=2272.4, num_updates=265800, lr=0.000193965, gnorm=0.333, loss_scale=2, train_wall=80, gb_free=39.6, wall=222002
2023-06-14 05:27:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 05:27:45 | INFO | train_inner | epoch 024:   6614 / 11284 loss=3.5, nll_loss=1.791, ppl=3.46, wps=71022.7, ups=1.19, wpb=59664.6, bsz=2289.1, num_updates=265900, lr=0.000193928, gnorm=0.342, loss_scale=2, train_wall=80, gb_free=39.6, wall=222086
2023-06-14 05:29:08 | INFO | train_inner | epoch 024:   6714 / 11284 loss=3.512, nll_loss=1.805, ppl=3.49, wps=71597.5, ups=1.2, wpb=59594.8, bsz=2229.9, num_updates=266000, lr=0.000193892, gnorm=0.341, loss_scale=2, train_wall=79, gb_free=39.6, wall=222169
2023-06-14 05:30:31 | INFO | train_inner | epoch 024:   6814 / 11284 loss=3.501, nll_loss=1.793, ppl=3.46, wps=71847.8, ups=1.21, wpb=59566.5, bsz=2223.5, num_updates=266100, lr=0.000193855, gnorm=0.341, loss_scale=2, train_wall=79, gb_free=39.6, wall=222252
2023-06-14 05:31:54 | INFO | train_inner | epoch 024:   6914 / 11284 loss=3.509, nll_loss=1.801, ppl=3.49, wps=71651, ups=1.21, wpb=59460.4, bsz=2249.4, num_updates=266200, lr=0.000193819, gnorm=0.335, loss_scale=2, train_wall=79, gb_free=39.6, wall=222335
2023-06-14 05:33:20 | INFO | train_inner | epoch 024:   7014 / 11284 loss=3.5, nll_loss=1.791, ppl=3.46, wps=69188.9, ups=1.16, wpb=59534.1, bsz=2182.2, num_updates=266300, lr=0.000193782, gnorm=0.344, loss_scale=2, train_wall=82, gb_free=39.5, wall=222421
2023-06-14 05:34:44 | INFO | train_inner | epoch 024:   7114 / 11284 loss=3.492, nll_loss=1.782, ppl=3.44, wps=71261.6, ups=1.2, wpb=59531.5, bsz=2174.7, num_updates=266400, lr=0.000193746, gnorm=0.346, loss_scale=2, train_wall=80, gb_free=39.6, wall=222504
2023-06-14 05:36:07 | INFO | train_inner | epoch 024:   7214 / 11284 loss=3.498, nll_loss=1.789, ppl=3.45, wps=71218.7, ups=1.2, wpb=59479.2, bsz=2190.6, num_updates=266500, lr=0.00019371, gnorm=0.334, loss_scale=2, train_wall=80, gb_free=39.6, wall=222588
2023-06-14 05:37:30 | INFO | train_inner | epoch 024:   7314 / 11284 loss=3.508, nll_loss=1.8, ppl=3.48, wps=71810.1, ups=1.2, wpb=59685.3, bsz=2197.9, num_updates=266600, lr=0.000193673, gnorm=0.341, loss_scale=2, train_wall=79, gb_free=39.6, wall=222671
2023-06-14 05:38:53 | INFO | train_inner | epoch 024:   7414 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=71597.2, ups=1.2, wpb=59486.3, bsz=2311.1, num_updates=266700, lr=0.000193637, gnorm=0.35, loss_scale=2, train_wall=79, gb_free=39.5, wall=222754
2023-06-14 05:40:16 | INFO | train_inner | epoch 024:   7514 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=72422.4, ups=1.21, wpb=59630.2, bsz=2150.3, num_updates=266800, lr=0.000193601, gnorm=0.336, loss_scale=2, train_wall=78, gb_free=39.6, wall=222836
2023-06-14 05:41:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 05:41:38 | INFO | train_inner | epoch 024:   7615 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=72566, ups=1.21, wpb=59834.5, bsz=2139.6, num_updates=266900, lr=0.000193565, gnorm=0.345, loss_scale=2, train_wall=78, gb_free=39.5, wall=222919
2023-06-14 05:43:01 | INFO | train_inner | epoch 024:   7715 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=72249.5, ups=1.22, wpb=59446.5, bsz=2291.2, num_updates=267000, lr=0.000193528, gnorm=0.33, loss_scale=2, train_wall=78, gb_free=39.6, wall=223001
2023-06-14 05:44:24 | INFO | train_inner | epoch 024:   7815 / 11284 loss=3.503, nll_loss=1.794, ppl=3.47, wps=71727, ups=1.2, wpb=59539.6, bsz=2174.6, num_updates=267100, lr=0.000193492, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.6, wall=223084
2023-06-14 05:45:46 | INFO | train_inner | epoch 024:   7915 / 11284 loss=3.516, nll_loss=1.809, ppl=3.5, wps=72285, ups=1.21, wpb=59741.2, bsz=2244.1, num_updates=267200, lr=0.000193456, gnorm=0.339, loss_scale=2, train_wall=79, gb_free=39.6, wall=223167
2023-06-14 05:47:08 | INFO | train_inner | epoch 024:   8015 / 11284 loss=3.51, nll_loss=1.803, ppl=3.49, wps=72480.3, ups=1.22, wpb=59433.9, bsz=2270.3, num_updates=267300, lr=0.00019342, gnorm=0.344, loss_scale=2, train_wall=78, gb_free=38.7, wall=223249
2023-06-14 05:48:31 | INFO | train_inner | epoch 024:   8115 / 11284 loss=3.493, nll_loss=1.784, ppl=3.44, wps=71732.8, ups=1.2, wpb=59628.4, bsz=2183.2, num_updates=267400, lr=0.000193383, gnorm=0.327, loss_scale=2, train_wall=79, gb_free=39.6, wall=223332
2023-06-14 05:49:54 | INFO | train_inner | epoch 024:   8215 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=71448.5, ups=1.2, wpb=59332.2, bsz=2288.6, num_updates=267500, lr=0.000193347, gnorm=0.332, loss_scale=2, train_wall=79, gb_free=39.6, wall=223415
2023-06-14 05:51:17 | INFO | train_inner | epoch 024:   8315 / 11284 loss=3.501, nll_loss=1.793, ppl=3.46, wps=71507.8, ups=1.21, wpb=59211.9, bsz=2198.1, num_updates=267600, lr=0.000193311, gnorm=0.335, loss_scale=2, train_wall=79, gb_free=39.6, wall=223498
2023-06-14 05:52:41 | INFO | train_inner | epoch 024:   8415 / 11284 loss=3.522, nll_loss=1.816, ppl=3.52, wps=71361.4, ups=1.2, wpb=59461.2, bsz=2278.3, num_updates=267700, lr=0.000193275, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=39.6, wall=223581
2023-06-14 05:54:04 | INFO | train_inner | epoch 024:   8515 / 11284 loss=3.493, nll_loss=1.783, ppl=3.44, wps=71655.7, ups=1.2, wpb=59506.1, bsz=2165.4, num_updates=267800, lr=0.000193239, gnorm=0.333, loss_scale=2, train_wall=79, gb_free=39.5, wall=223664
2023-06-14 05:55:26 | INFO | train_inner | epoch 024:   8615 / 11284 loss=3.505, nll_loss=1.797, ppl=3.47, wps=72392.6, ups=1.21, wpb=59692.2, bsz=2161.5, num_updates=267900, lr=0.000193203, gnorm=0.34, loss_scale=2, train_wall=78, gb_free=39.5, wall=223747
2023-06-14 05:56:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 05:56:50 | INFO | train_inner | epoch 024:   8716 / 11284 loss=3.51, nll_loss=1.803, ppl=3.49, wps=70365.2, ups=1.19, wpb=59287.9, bsz=2327.3, num_updates=268000, lr=0.000193167, gnorm=0.343, loss_scale=2, train_wall=80, gb_free=39.5, wall=223831
2023-06-14 05:58:12 | INFO | train_inner | epoch 024:   8816 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=72576.2, ups=1.22, wpb=59547.7, bsz=2220.7, num_updates=268100, lr=0.000193131, gnorm=0.34, loss_scale=2, train_wall=78, gb_free=39.6, wall=223913
2023-06-14 05:59:35 | INFO | train_inner | epoch 024:   8916 / 11284 loss=3.499, nll_loss=1.791, ppl=3.46, wps=72294.2, ups=1.21, wpb=59806.7, bsz=2245.6, num_updates=268200, lr=0.000193095, gnorm=0.34, loss_scale=2, train_wall=78, gb_free=39.5, wall=223996
2023-06-14 06:00:58 | INFO | train_inner | epoch 024:   9016 / 11284 loss=3.515, nll_loss=1.809, ppl=3.5, wps=71801.3, ups=1.21, wpb=59498.9, bsz=2216.4, num_updates=268300, lr=0.000193059, gnorm=0.348, loss_scale=2, train_wall=79, gb_free=39.6, wall=224079
2023-06-14 06:02:21 | INFO | train_inner | epoch 024:   9116 / 11284 loss=3.499, nll_loss=1.791, ppl=3.46, wps=71731.3, ups=1.21, wpb=59500.6, bsz=2210.2, num_updates=268400, lr=0.000193023, gnorm=0.341, loss_scale=2, train_wall=79, gb_free=39.6, wall=224161
2023-06-14 06:03:43 | INFO | train_inner | epoch 024:   9216 / 11284 loss=3.511, nll_loss=1.804, ppl=3.49, wps=72466.1, ups=1.22, wpb=59554.1, bsz=2225.5, num_updates=268500, lr=0.000192987, gnorm=0.328, loss_scale=2, train_wall=78, gb_free=39.6, wall=224244
2023-06-14 06:05:05 | INFO | train_inner | epoch 024:   9316 / 11284 loss=3.501, nll_loss=1.792, ppl=3.46, wps=72736.2, ups=1.22, wpb=59587.7, bsz=2250.1, num_updates=268600, lr=0.000192951, gnorm=0.342, loss_scale=2, train_wall=78, gb_free=39.6, wall=224326
2023-06-14 06:06:27 | INFO | train_inner | epoch 024:   9416 / 11284 loss=3.511, nll_loss=1.804, ppl=3.49, wps=71859.6, ups=1.21, wpb=59193, bsz=2178.9, num_updates=268700, lr=0.000192915, gnorm=0.336, loss_scale=2, train_wall=78, gb_free=39.6, wall=224408
2023-06-14 06:07:50 | INFO | train_inner | epoch 024:   9516 / 11284 loss=3.515, nll_loss=1.808, ppl=3.5, wps=71581.7, ups=1.21, wpb=59196.5, bsz=2254.8, num_updates=268800, lr=0.000192879, gnorm=0.361, loss_scale=2, train_wall=79, gb_free=39.6, wall=224491
2023-06-14 06:09:14 | INFO | train_inner | epoch 024:   9616 / 11284 loss=3.506, nll_loss=1.798, ppl=3.48, wps=70690.6, ups=1.19, wpb=59458.8, bsz=2296.9, num_updates=268900, lr=0.000192843, gnorm=0.335, loss_scale=2, train_wall=80, gb_free=39.5, wall=224575
2023-06-14 06:10:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 06:10:41 | INFO | train_inner | epoch 024:   9717 / 11284 loss=3.514, nll_loss=1.807, ppl=3.5, wps=68454.6, ups=1.15, wpb=59547.5, bsz=2277.1, num_updates=269000, lr=0.000192807, gnorm=0.346, loss_scale=2, train_wall=83, gb_free=39.6, wall=224662
2023-06-14 06:12:06 | INFO | train_inner | epoch 024:   9817 / 11284 loss=3.51, nll_loss=1.803, ppl=3.49, wps=69533.8, ups=1.17, wpb=59288.8, bsz=2234.9, num_updates=269100, lr=0.000192772, gnorm=0.332, loss_scale=2, train_wall=81, gb_free=39.6, wall=224747
2023-06-14 06:13:32 | INFO | train_inner | epoch 024:   9917 / 11284 loss=3.493, nll_loss=1.783, ppl=3.44, wps=69284.7, ups=1.16, wpb=59616.7, bsz=2118.9, num_updates=269200, lr=0.000192736, gnorm=0.337, loss_scale=2, train_wall=82, gb_free=39.5, wall=224833
2023-06-14 06:14:58 | INFO | train_inner | epoch 024:  10017 / 11284 loss=3.513, nll_loss=1.806, ppl=3.5, wps=69964, ups=1.18, wpb=59528.9, bsz=2229.8, num_updates=269300, lr=0.0001927, gnorm=0.344, loss_scale=2, train_wall=81, gb_free=39.6, wall=224918
2023-06-14 06:16:24 | INFO | train_inner | epoch 024:  10117 / 11284 loss=3.511, nll_loss=1.804, ppl=3.49, wps=68785.7, ups=1.15, wpb=59701.5, bsz=2190.6, num_updates=269400, lr=0.000192664, gnorm=0.349, loss_scale=2, train_wall=83, gb_free=39.5, wall=225005
2023-06-14 06:17:50 | INFO | train_inner | epoch 024:  10217 / 11284 loss=3.494, nll_loss=1.784, ppl=3.44, wps=70281.7, ups=1.17, wpb=59857.2, bsz=2353.3, num_updates=269500, lr=0.000192629, gnorm=0.336, loss_scale=2, train_wall=81, gb_free=39.6, wall=225090
2023-06-14 06:19:13 | INFO | train_inner | epoch 024:  10317 / 11284 loss=3.516, nll_loss=1.81, ppl=3.51, wps=71521.7, ups=1.2, wpb=59582.9, bsz=2310.9, num_updates=269600, lr=0.000192593, gnorm=0.372, loss_scale=2, train_wall=79, gb_free=39.6, wall=225173
2023-06-14 06:20:36 | INFO | train_inner | epoch 024:  10417 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=71558.8, ups=1.2, wpb=59433, bsz=2212.1, num_updates=269700, lr=0.000192557, gnorm=0.343, loss_scale=2, train_wall=79, gb_free=39.6, wall=225256
2023-06-14 06:21:59 | INFO | train_inner | epoch 024:  10517 / 11284 loss=3.502, nll_loss=1.793, ppl=3.47, wps=71938.5, ups=1.21, wpb=59696.1, bsz=2101.1, num_updates=269800, lr=0.000192521, gnorm=0.335, loss_scale=2, train_wall=79, gb_free=39.6, wall=225339
2023-06-14 06:23:22 | INFO | train_inner | epoch 024:  10617 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=71432.5, ups=1.2, wpb=59548.2, bsz=2308.9, num_updates=269900, lr=0.000192486, gnorm=0.338, loss_scale=2, train_wall=79, gb_free=39.6, wall=225423
2023-06-14 06:24:45 | INFO | train_inner | epoch 024:  10717 / 11284 loss=3.493, nll_loss=1.784, ppl=3.44, wps=72298.1, ups=1.21, wpb=59741.8, bsz=2192.4, num_updates=270000, lr=0.00019245, gnorm=0.321, loss_scale=2, train_wall=79, gb_free=39.4, wall=225505
2023-06-14 06:25:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 06:26:08 | INFO | train_inner | epoch 024:  10818 / 11284 loss=3.524, nll_loss=1.818, ppl=3.53, wps=71526.4, ups=1.21, wpb=59308.7, bsz=2224.9, num_updates=270100, lr=0.000192414, gnorm=0.348, loss_scale=2, train_wall=79, gb_free=39.6, wall=225588
2023-06-14 06:27:31 | INFO | train_inner | epoch 024:  10918 / 11284 loss=3.51, nll_loss=1.803, ppl=3.49, wps=71655.3, ups=1.2, wpb=59568, bsz=2300.7, num_updates=270200, lr=0.000192379, gnorm=0.331, loss_scale=2, train_wall=79, gb_free=39.6, wall=225672
2023-06-14 06:28:54 | INFO | train_inner | epoch 024:  11018 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=71577.6, ups=1.2, wpb=59429.5, bsz=2281.7, num_updates=270300, lr=0.000192343, gnorm=0.336, loss_scale=2, train_wall=79, gb_free=39.6, wall=225755
2023-06-14 06:30:17 | INFO | train_inner | epoch 024:  11118 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=71777.5, ups=1.21, wpb=59536.8, bsz=2154, num_updates=270400, lr=0.000192308, gnorm=0.341, loss_scale=2, train_wall=79, gb_free=39.6, wall=225837
2023-06-14 06:31:40 | INFO | train_inner | epoch 024:  11218 / 11284 loss=3.519, nll_loss=1.813, ppl=3.51, wps=71673.4, ups=1.2, wpb=59597.7, bsz=2214.8, num_updates=270500, lr=0.000192272, gnorm=0.341, loss_scale=2, train_wall=79, gb_free=39.6, wall=225921
2023-06-14 06:32:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-14 06:32:52 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 4.307 | nll_loss 2.627 | ppl 6.18 | bleu 21.08 | wps 3736.1 | wpb 2397.5 | bsz 71.5 | num_updates 270566 | best_loss 4.299
2023-06-14 06:32:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 270566 updates
2023-06-14 06:32:52 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint24.pt
2023-06-14 06:32:55 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint24.pt
2023-06-14 06:32:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint24.pt (epoch 24 @ 270566 updates, score 4.307) (writing took 5.448726222850382 seconds)
2023-06-14 06:32:58 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-06-14 06:32:58 | INFO | train | epoch 024 | loss 3.504 | nll_loss 1.796 | ppl 3.47 | wps 71294.7 | ups 1.2 | wpb 59500.9 | bsz 2227.5 | num_updates 270566 | lr 0.000192249 | gnorm 0.339 | loss_scale 2 | train_wall 8938 | gb_free 39.6 | wall 225999
2023-06-14 06:32:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-14 06:32:58 | INFO | fairseq.trainer | begin training epoch 25
2023-06-14 06:32:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-14 06:33:28 | INFO | train_inner | epoch 025:     34 / 11284 loss=3.51, nll_loss=1.802, ppl=3.49, wps=54912.8, ups=0.93, wpb=59187.4, bsz=2382.7, num_updates=270600, lr=0.000192237, gnorm=0.334, loss_scale=2, train_wall=79, gb_free=39.4, wall=226028
2023-06-14 06:34:54 | INFO | train_inner | epoch 025:    134 / 11284 loss=3.501, nll_loss=1.792, ppl=3.46, wps=69370.5, ups=1.17, wpb=59503.3, bsz=2258.5, num_updates=270700, lr=0.000192201, gnorm=0.332, loss_scale=2, train_wall=82, gb_free=39.6, wall=226114
2023-06-14 06:36:18 | INFO | train_inner | epoch 025:    234 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=70126.7, ups=1.18, wpb=59347.1, bsz=2189.3, num_updates=270800, lr=0.000192166, gnorm=0.338, loss_scale=2, train_wall=81, gb_free=39.6, wall=226199
2023-06-14 06:37:44 | INFO | train_inner | epoch 025:    334 / 11284 loss=3.493, nll_loss=1.783, ppl=3.44, wps=69432.4, ups=1.17, wpb=59495.4, bsz=2220.2, num_updates=270900, lr=0.00019213, gnorm=0.333, loss_scale=2, train_wall=82, gb_free=39.1, wall=226285
2023-06-14 06:39:09 | INFO | train_inner | epoch 025:    434 / 11284 loss=3.513, nll_loss=1.805, ppl=3.49, wps=69528, ups=1.17, wpb=59335.2, bsz=2314.2, num_updates=271000, lr=0.000192095, gnorm=0.338, loss_scale=2, train_wall=81, gb_free=39.6, wall=226370
2023-06-14 06:40:35 | INFO | train_inner | epoch 025:    534 / 11284 loss=3.495, nll_loss=1.785, ppl=3.45, wps=69366, ups=1.17, wpb=59334.2, bsz=2201.5, num_updates=271100, lr=0.000192059, gnorm=0.337, loss_scale=4, train_wall=81, gb_free=39.6, wall=226455
2023-06-14 06:41:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 06:42:01 | INFO | train_inner | epoch 025:    635 / 11284 loss=3.497, nll_loss=1.787, ppl=3.45, wps=69597.7, ups=1.17, wpb=59624.9, bsz=2180.9, num_updates=271200, lr=0.000192024, gnorm=0.329, loss_scale=2, train_wall=82, gb_free=39.6, wall=226541
2023-06-14 06:43:26 | INFO | train_inner | epoch 025:    735 / 11284 loss=3.484, nll_loss=1.773, ppl=3.42, wps=69484.6, ups=1.17, wpb=59579.2, bsz=2205.7, num_updates=271300, lr=0.000191988, gnorm=0.33, loss_scale=2, train_wall=82, gb_free=39.6, wall=226627
2023-06-14 06:44:54 | INFO | train_inner | epoch 025:    835 / 11284 loss=3.5, nll_loss=1.791, ppl=3.46, wps=68305.6, ups=1.14, wpb=59699.5, bsz=2308.3, num_updates=271400, lr=0.000191953, gnorm=0.333, loss_scale=2, train_wall=83, gb_free=39.6, wall=226714
2023-06-14 06:46:20 | INFO | train_inner | epoch 025:    935 / 11284 loss=3.506, nll_loss=1.798, ppl=3.48, wps=69165.8, ups=1.16, wpb=59568.1, bsz=2231.8, num_updates=271500, lr=0.000191918, gnorm=0.338, loss_scale=2, train_wall=82, gb_free=39.6, wall=226800
2023-06-14 06:47:45 | INFO | train_inner | epoch 025:   1035 / 11284 loss=3.491, nll_loss=1.781, ppl=3.44, wps=69219.3, ups=1.17, wpb=59275.7, bsz=2212.2, num_updates=271600, lr=0.000191882, gnorm=0.34, loss_scale=2, train_wall=82, gb_free=39.5, wall=226886
2023-06-14 06:49:11 | INFO | train_inner | epoch 025:   1135 / 11284 loss=3.506, nll_loss=1.798, ppl=3.48, wps=69097.5, ups=1.16, wpb=59465.2, bsz=2240.8, num_updates=271700, lr=0.000191847, gnorm=0.341, loss_scale=2, train_wall=82, gb_free=39.6, wall=226972
2023-06-14 06:50:37 | INFO | train_inner | epoch 025:   1235 / 11284 loss=3.5, nll_loss=1.791, ppl=3.46, wps=69472.5, ups=1.17, wpb=59515.2, bsz=2230.4, num_updates=271800, lr=0.000191812, gnorm=0.34, loss_scale=2, train_wall=82, gb_free=39.6, wall=227058
2023-06-14 06:52:03 | INFO | train_inner | epoch 025:   1335 / 11284 loss=3.508, nll_loss=1.8, ppl=3.48, wps=69319.3, ups=1.17, wpb=59478.6, bsz=2154.2, num_updates=271900, lr=0.000191777, gnorm=0.346, loss_scale=2, train_wall=82, gb_free=39.6, wall=227144
2023-06-14 06:53:29 | INFO | train_inner | epoch 025:   1435 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=69559.6, ups=1.16, wpb=59746, bsz=2219.4, num_updates=272000, lr=0.000191741, gnorm=0.343, loss_scale=2, train_wall=82, gb_free=39.6, wall=227229
2023-06-14 06:54:55 | INFO | train_inner | epoch 025:   1535 / 11284 loss=3.491, nll_loss=1.781, ppl=3.44, wps=69304.3, ups=1.16, wpb=59582.8, bsz=2304.4, num_updates=272100, lr=0.000191706, gnorm=0.335, loss_scale=2, train_wall=82, gb_free=39.6, wall=227315
2023-06-14 06:55:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 06:56:21 | INFO | train_inner | epoch 025:   1636 / 11284 loss=3.491, nll_loss=1.781, ppl=3.44, wps=69243, ups=1.16, wpb=59700.1, bsz=2226.4, num_updates=272200, lr=0.000191671, gnorm=0.347, loss_scale=2, train_wall=82, gb_free=39.6, wall=227402
2023-06-14 06:57:45 | INFO | train_inner | epoch 025:   1736 / 11284 loss=3.494, nll_loss=1.784, ppl=3.44, wps=70688.1, ups=1.18, wpb=59657.7, bsz=2241.1, num_updates=272300, lr=0.000191636, gnorm=0.331, loss_scale=2, train_wall=81, gb_free=39.6, wall=227486
2023-06-14 06:59:09 | INFO | train_inner | epoch 025:   1836 / 11284 loss=3.506, nll_loss=1.798, ppl=3.48, wps=71286.2, ups=1.19, wpb=59670.7, bsz=2238, num_updates=272400, lr=0.0001916, gnorm=0.33, loss_scale=2, train_wall=80, gb_free=39.5, wall=227570
2023-06-14 07:00:32 | INFO | train_inner | epoch 025:   1936 / 11284 loss=3.499, nll_loss=1.79, ppl=3.46, wps=71645.8, ups=1.2, wpb=59613.5, bsz=2222.1, num_updates=272500, lr=0.000191565, gnorm=0.348, loss_scale=2, train_wall=79, gb_free=39.5, wall=227653
2023-06-14 07:01:55 | INFO | train_inner | epoch 025:   2036 / 11284 loss=3.501, nll_loss=1.792, ppl=3.46, wps=71772.2, ups=1.21, wpb=59438.7, bsz=2213.9, num_updates=272600, lr=0.00019153, gnorm=0.34, loss_scale=2, train_wall=78, gb_free=39.6, wall=227736
2023-06-14 07:03:20 | INFO | train_inner | epoch 025:   2136 / 11284 loss=3.489, nll_loss=1.778, ppl=3.43, wps=69780.7, ups=1.17, wpb=59487.4, bsz=2223.9, num_updates=272700, lr=0.000191495, gnorm=0.338, loss_scale=2, train_wall=81, gb_free=39.5, wall=227821
2023-06-14 07:04:44 | INFO | train_inner | epoch 025:   2236 / 11284 loss=3.508, nll_loss=1.8, ppl=3.48, wps=70948.5, ups=1.19, wpb=59499.2, bsz=2216.6, num_updates=272800, lr=0.00019146, gnorm=0.339, loss_scale=2, train_wall=80, gb_free=39.5, wall=227905
2023-06-14 07:06:07 | INFO | train_inner | epoch 025:   2336 / 11284 loss=3.501, nll_loss=1.792, ppl=3.46, wps=71653, ups=1.2, wpb=59470.3, bsz=2233.5, num_updates=272900, lr=0.000191425, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.6, wall=227988
2023-06-14 07:07:30 | INFO | train_inner | epoch 025:   2436 / 11284 loss=3.518, nll_loss=1.811, ppl=3.51, wps=72009.8, ups=1.21, wpb=59379.4, bsz=2232.3, num_updates=273000, lr=0.00019139, gnorm=0.341, loss_scale=2, train_wall=79, gb_free=39.6, wall=228070
2023-06-14 07:08:53 | INFO | train_inner | epoch 025:   2536 / 11284 loss=3.482, nll_loss=1.771, ppl=3.41, wps=71081.8, ups=1.19, wpb=59514.8, bsz=2235.7, num_updates=273100, lr=0.000191355, gnorm=0.341, loss_scale=2, train_wall=80, gb_free=39.5, wall=228154
2023-06-14 07:10:17 | INFO | train_inner | epoch 025:   2636 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71528, ups=1.2, wpb=59436.9, bsz=2193.4, num_updates=273200, lr=0.00019132, gnorm=0.336, loss_scale=4, train_wall=79, gb_free=39.6, wall=228237
2023-06-14 07:11:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 07:11:41 | INFO | train_inner | epoch 025:   2737 / 11284 loss=3.491, nll_loss=1.781, ppl=3.44, wps=70447.4, ups=1.19, wpb=59376.7, bsz=2192.5, num_updates=273300, lr=0.000191285, gnorm=0.339, loss_scale=2, train_wall=80, gb_free=39.6, wall=228321
2023-06-14 07:13:04 | INFO | train_inner | epoch 025:   2837 / 11284 loss=3.507, nll_loss=1.799, ppl=3.48, wps=71693.5, ups=1.2, wpb=59660.7, bsz=2250.7, num_updates=273400, lr=0.00019125, gnorm=0.339, loss_scale=2, train_wall=79, gb_free=39.6, wall=228405
2023-06-14 07:14:28 | INFO | train_inner | epoch 025:   2937 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=71603.3, ups=1.2, wpb=59770.8, bsz=2180.9, num_updates=273500, lr=0.000191215, gnorm=0.334, loss_scale=2, train_wall=80, gb_free=39.6, wall=228488
2023-06-14 07:15:51 | INFO | train_inner | epoch 025:   3037 / 11284 loss=3.507, nll_loss=1.8, ppl=3.48, wps=71524, ups=1.2, wpb=59406.7, bsz=2240, num_updates=273600, lr=0.00019118, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=228571
2023-06-14 07:17:14 | INFO | train_inner | epoch 025:   3137 / 11284 loss=3.504, nll_loss=1.795, ppl=3.47, wps=71440.8, ups=1.2, wpb=59439.6, bsz=2237, num_updates=273700, lr=0.000191145, gnorm=0.332, loss_scale=2, train_wall=79, gb_free=39.5, wall=228654
2023-06-14 07:18:36 | INFO | train_inner | epoch 025:   3237 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=71780.1, ups=1.21, wpb=59174.2, bsz=2143.3, num_updates=273800, lr=0.00019111, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.6, wall=228737
2023-06-14 07:19:58 | INFO | train_inner | epoch 025:   3337 / 11284 loss=3.513, nll_loss=1.806, ppl=3.5, wps=72741.7, ups=1.22, wpb=59716.5, bsz=2254.1, num_updates=273900, lr=0.000191075, gnorm=0.336, loss_scale=2, train_wall=78, gb_free=39.5, wall=228819
2023-06-14 07:21:22 | INFO | train_inner | epoch 025:   3437 / 11284 loss=3.516, nll_loss=1.808, ppl=3.5, wps=71269.3, ups=1.2, wpb=59573.5, bsz=2396.5, num_updates=274000, lr=0.00019104, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.6, wall=228903
2023-06-14 07:22:45 | INFO | train_inner | epoch 025:   3537 / 11284 loss=3.49, nll_loss=1.78, ppl=3.44, wps=71673, ups=1.21, wpb=59349.4, bsz=2106.6, num_updates=274100, lr=0.000191005, gnorm=0.335, loss_scale=2, train_wall=79, gb_free=39.5, wall=228985
2023-06-14 07:24:08 | INFO | train_inner | epoch 025:   3637 / 11284 loss=3.501, nll_loss=1.793, ppl=3.46, wps=71500.9, ups=1.2, wpb=59433.7, bsz=2161.4, num_updates=274200, lr=0.00019097, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.5, wall=229068
2023-06-14 07:25:31 | INFO | train_inner | epoch 025:   3737 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=71292.4, ups=1.2, wpb=59261.2, bsz=2277.8, num_updates=274300, lr=0.000190936, gnorm=0.335, loss_scale=4, train_wall=79, gb_free=39.5, wall=229152
2023-06-14 07:25:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 07:26:55 | INFO | train_inner | epoch 025:   3838 / 11284 loss=3.511, nll_loss=1.803, ppl=3.49, wps=70452.6, ups=1.19, wpb=59274.7, bsz=2190.3, num_updates=274400, lr=0.000190901, gnorm=0.354, loss_scale=2, train_wall=80, gb_free=39.6, wall=229236
2023-06-14 07:28:18 | INFO | train_inner | epoch 025:   3938 / 11284 loss=3.501, nll_loss=1.792, ppl=3.46, wps=71255.4, ups=1.2, wpb=59154.4, bsz=2243.5, num_updates=274500, lr=0.000190866, gnorm=0.334, loss_scale=2, train_wall=79, gb_free=39.6, wall=229319
2023-06-14 07:29:42 | INFO | train_inner | epoch 025:   4038 / 11284 loss=3.494, nll_loss=1.784, ppl=3.44, wps=71414.9, ups=1.2, wpb=59727.2, bsz=2186, num_updates=274600, lr=0.000190831, gnorm=0.34, loss_scale=2, train_wall=80, gb_free=39.4, wall=229402
2023-06-14 07:31:07 | INFO | train_inner | epoch 025:   4138 / 11284 loss=3.509, nll_loss=1.801, ppl=3.48, wps=70077.4, ups=1.18, wpb=59558.2, bsz=2300, num_updates=274700, lr=0.000190797, gnorm=0.341, loss_scale=2, train_wall=81, gb_free=39.6, wall=229487
2023-06-14 07:31:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-06-14 07:32:34 | INFO | train_inner | epoch 025:   4239 / 11284 loss=3.493, nll_loss=1.783, ppl=3.44, wps=68545.2, ups=1.15, wpb=59538.1, bsz=2241.9, num_updates=274800, lr=0.000190762, gnorm=0.337, loss_scale=1, train_wall=83, gb_free=39.6, wall=229574
2023-06-14 07:33:59 | INFO | train_inner | epoch 025:   4339 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=69750.6, ups=1.17, wpb=59587.4, bsz=2360, num_updates=274900, lr=0.000190727, gnorm=0.334, loss_scale=1, train_wall=81, gb_free=39.6, wall=229660
2023-06-14 07:35:26 | INFO | train_inner | epoch 025:   4439 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=68449.8, ups=1.15, wpb=59331.1, bsz=2361.3, num_updates=275000, lr=0.000190693, gnorm=0.338, loss_scale=1, train_wall=82, gb_free=39.6, wall=229746
2023-06-14 07:36:51 | INFO | train_inner | epoch 025:   4539 / 11284 loss=3.501, nll_loss=1.792, ppl=3.46, wps=69764.1, ups=1.17, wpb=59573.8, bsz=2260.1, num_updates=275100, lr=0.000190658, gnorm=0.351, loss_scale=1, train_wall=81, gb_free=39.6, wall=229832
2023-06-14 07:38:16 | INFO | train_inner | epoch 025:   4639 / 11284 loss=3.516, nll_loss=1.809, ppl=3.5, wps=69547.5, ups=1.17, wpb=59319.8, bsz=2258.8, num_updates=275200, lr=0.000190623, gnorm=0.359, loss_scale=1, train_wall=81, gb_free=39.6, wall=229917
2023-06-14 07:39:42 | INFO | train_inner | epoch 025:   4739 / 11284 loss=3.507, nll_loss=1.799, ppl=3.48, wps=70005.7, ups=1.18, wpb=59561.7, bsz=2288.1, num_updates=275300, lr=0.000190589, gnorm=0.338, loss_scale=1, train_wall=81, gb_free=39.5, wall=230002
2023-06-14 07:41:04 | INFO | train_inner | epoch 025:   4839 / 11284 loss=3.499, nll_loss=1.79, ppl=3.46, wps=71954.2, ups=1.21, wpb=59536.3, bsz=2258.4, num_updates=275400, lr=0.000190554, gnorm=0.349, loss_scale=1, train_wall=79, gb_free=39.6, wall=230085
2023-06-14 07:42:28 | INFO | train_inner | epoch 025:   4939 / 11284 loss=3.498, nll_loss=1.79, ppl=3.46, wps=71710.4, ups=1.2, wpb=59727.6, bsz=2253, num_updates=275500, lr=0.000190519, gnorm=0.328, loss_scale=1, train_wall=79, gb_free=39.6, wall=230168
2023-06-14 07:43:50 | INFO | train_inner | epoch 025:   5039 / 11284 loss=3.492, nll_loss=1.783, ppl=3.44, wps=71850.2, ups=1.21, wpb=59389.5, bsz=2301.8, num_updates=275600, lr=0.000190485, gnorm=0.338, loss_scale=1, train_wall=79, gb_free=39.6, wall=230251
2023-06-14 07:45:13 | INFO | train_inner | epoch 025:   5139 / 11284 loss=3.519, nll_loss=1.812, ppl=3.51, wps=71795.1, ups=1.21, wpb=59537.7, bsz=2295.3, num_updates=275700, lr=0.00019045, gnorm=0.341, loss_scale=1, train_wall=79, gb_free=39.6, wall=230334
2023-06-14 07:46:36 | INFO | train_inner | epoch 025:   5239 / 11284 loss=3.506, nll_loss=1.798, ppl=3.48, wps=71704.1, ups=1.21, wpb=59347.4, bsz=2190.5, num_updates=275800, lr=0.000190416, gnorm=0.338, loss_scale=2, train_wall=79, gb_free=39.6, wall=230416
2023-06-14 07:47:59 | INFO | train_inner | epoch 025:   5339 / 11284 loss=3.515, nll_loss=1.808, ppl=3.5, wps=72035.2, ups=1.21, wpb=59519.2, bsz=2205.4, num_updates=275900, lr=0.000190381, gnorm=0.349, loss_scale=2, train_wall=79, gb_free=39.6, wall=230499
2023-06-14 07:49:22 | INFO | train_inner | epoch 025:   5439 / 11284 loss=3.489, nll_loss=1.779, ppl=3.43, wps=71330.2, ups=1.2, wpb=59296.5, bsz=2281.5, num_updates=276000, lr=0.000190347, gnorm=0.343, loss_scale=2, train_wall=79, gb_free=39.5, wall=230582
2023-06-14 07:50:43 | INFO | train_inner | epoch 025:   5539 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=72857.7, ups=1.22, wpb=59490, bsz=2103.2, num_updates=276100, lr=0.000190312, gnorm=0.33, loss_scale=2, train_wall=78, gb_free=39.6, wall=230664
2023-06-14 07:52:06 | INFO | train_inner | epoch 025:   5639 / 11284 loss=3.507, nll_loss=1.799, ppl=3.48, wps=71498.9, ups=1.2, wpb=59468.7, bsz=2248.6, num_updates=276200, lr=0.000190278, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.6, wall=230747
2023-06-14 07:53:30 | INFO | train_inner | epoch 025:   5739 / 11284 loss=3.493, nll_loss=1.784, ppl=3.44, wps=71389.4, ups=1.2, wpb=59557.3, bsz=2291.6, num_updates=276300, lr=0.000190243, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.6, wall=230830
2023-06-14 07:54:53 | INFO | train_inner | epoch 025:   5839 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=71833.5, ups=1.21, wpb=59573, bsz=2217.4, num_updates=276400, lr=0.000190209, gnorm=0.327, loss_scale=2, train_wall=79, gb_free=39.6, wall=230913
2023-06-14 07:56:16 | INFO | train_inner | epoch 025:   5939 / 11284 loss=3.491, nll_loss=1.782, ppl=3.44, wps=71906.9, ups=1.21, wpb=59493.4, bsz=2169.8, num_updates=276500, lr=0.000190175, gnorm=0.343, loss_scale=2, train_wall=79, gb_free=39.7, wall=230996
2023-06-14 07:57:38 | INFO | train_inner | epoch 025:   6039 / 11284 loss=3.507, nll_loss=1.799, ppl=3.48, wps=72018.5, ups=1.21, wpb=59538.4, bsz=2185.9, num_updates=276600, lr=0.00019014, gnorm=0.332, loss_scale=2, train_wall=79, gb_free=39.6, wall=231079
2023-06-14 07:59:01 | INFO | train_inner | epoch 025:   6139 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=71431.1, ups=1.2, wpb=59423.7, bsz=2294.1, num_updates=276700, lr=0.000190106, gnorm=0.352, loss_scale=2, train_wall=79, gb_free=39.6, wall=231162
2023-06-14 08:00:25 | INFO | train_inner | epoch 025:   6239 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=71608.5, ups=1.2, wpb=59598.4, bsz=2196.6, num_updates=276800, lr=0.000190071, gnorm=0.343, loss_scale=4, train_wall=79, gb_free=39.6, wall=231245
2023-06-14 08:01:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 08:01:47 | INFO | train_inner | epoch 025:   6340 / 11284 loss=3.5, nll_loss=1.791, ppl=3.46, wps=72284.3, ups=1.21, wpb=59611, bsz=2203.4, num_updates=276900, lr=0.000190037, gnorm=0.337, loss_scale=2, train_wall=78, gb_free=39.4, wall=231328
2023-06-14 08:03:09 | INFO | train_inner | epoch 025:   6440 / 11284 loss=3.522, nll_loss=1.816, ppl=3.52, wps=72842, ups=1.22, wpb=59600.6, bsz=2226.4, num_updates=277000, lr=0.000190003, gnorm=0.347, loss_scale=2, train_wall=77, gb_free=39.6, wall=231410
2023-06-14 08:04:31 | INFO | train_inner | epoch 025:   6540 / 11284 loss=3.507, nll_loss=1.8, ppl=3.48, wps=72547.3, ups=1.22, wpb=59639, bsz=2249.4, num_updates=277100, lr=0.000189969, gnorm=0.343, loss_scale=2, train_wall=78, gb_free=39.5, wall=231492
2023-06-14 08:05:55 | INFO | train_inner | epoch 025:   6640 / 11284 loss=3.514, nll_loss=1.806, ppl=3.5, wps=70524.5, ups=1.19, wpb=59461.3, bsz=2193.7, num_updates=277200, lr=0.000189934, gnorm=0.335, loss_scale=2, train_wall=80, gb_free=39.6, wall=231576
2023-06-14 08:07:19 | INFO | train_inner | epoch 025:   6740 / 11284 loss=3.505, nll_loss=1.797, ppl=3.47, wps=71227.5, ups=1.2, wpb=59472.9, bsz=2235.6, num_updates=277300, lr=0.0001899, gnorm=0.341, loss_scale=2, train_wall=80, gb_free=39.6, wall=231660
2023-06-14 08:08:42 | INFO | train_inner | epoch 025:   6840 / 11284 loss=3.516, nll_loss=1.809, ppl=3.5, wps=71437.7, ups=1.21, wpb=59101.2, bsz=2209.8, num_updates=277400, lr=0.000189866, gnorm=0.335, loss_scale=2, train_wall=79, gb_free=39.6, wall=231742
2023-06-14 08:10:04 | INFO | train_inner | epoch 025:   6940 / 11284 loss=3.495, nll_loss=1.785, ppl=3.45, wps=72156, ups=1.21, wpb=59584, bsz=2211.1, num_updates=277500, lr=0.000189832, gnorm=0.339, loss_scale=2, train_wall=79, gb_free=39.6, wall=231825
2023-06-14 08:11:27 | INFO | train_inner | epoch 025:   7040 / 11284 loss=3.495, nll_loss=1.785, ppl=3.45, wps=71521.7, ups=1.2, wpb=59394.1, bsz=2191.7, num_updates=277600, lr=0.000189797, gnorm=0.339, loss_scale=2, train_wall=79, gb_free=39.6, wall=231908
2023-06-14 08:12:50 | INFO | train_inner | epoch 025:   7140 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71724.3, ups=1.21, wpb=59374.9, bsz=2287.2, num_updates=277700, lr=0.000189763, gnorm=0.339, loss_scale=2, train_wall=79, gb_free=39.6, wall=231991
2023-06-14 08:14:13 | INFO | train_inner | epoch 025:   7240 / 11284 loss=3.511, nll_loss=1.804, ppl=3.49, wps=71929.6, ups=1.21, wpb=59572.4, bsz=2180.7, num_updates=277800, lr=0.000189729, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.6, wall=232074
2023-06-14 08:15:36 | INFO | train_inner | epoch 025:   7340 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=71336.8, ups=1.2, wpb=59307.8, bsz=2240.5, num_updates=277900, lr=0.000189695, gnorm=0.348, loss_scale=4, train_wall=79, gb_free=39.6, wall=232157
2023-06-14 08:15:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 08:17:00 | INFO | train_inner | epoch 025:   7441 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=71109, ups=1.2, wpb=59353.3, bsz=2216.1, num_updates=278000, lr=0.000189661, gnorm=0.344, loss_scale=2, train_wall=80, gb_free=39.6, wall=232240
2023-06-14 08:18:22 | INFO | train_inner | epoch 025:   7541 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=72555.9, ups=1.22, wpb=59485.8, bsz=2165.9, num_updates=278100, lr=0.000189627, gnorm=0.347, loss_scale=2, train_wall=78, gb_free=39.6, wall=232322
2023-06-14 08:19:45 | INFO | train_inner | epoch 025:   7641 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=71665.4, ups=1.2, wpb=59474.8, bsz=2185.4, num_updates=278200, lr=0.000189593, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.5, wall=232405
2023-06-14 08:21:08 | INFO | train_inner | epoch 025:   7741 / 11284 loss=3.493, nll_loss=1.784, ppl=3.44, wps=71662.9, ups=1.2, wpb=59549.1, bsz=2224.9, num_updates=278300, lr=0.000189559, gnorm=0.339, loss_scale=2, train_wall=79, gb_free=39.5, wall=232488
2023-06-14 08:22:30 | INFO | train_inner | epoch 025:   7841 / 11284 loss=3.5, nll_loss=1.792, ppl=3.46, wps=72513.4, ups=1.22, wpb=59558.6, bsz=2160.2, num_updates=278400, lr=0.000189525, gnorm=0.337, loss_scale=2, train_wall=78, gb_free=39.6, wall=232570
2023-06-14 08:23:53 | INFO | train_inner | epoch 025:   7941 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=71357, ups=1.2, wpb=59543.8, bsz=2180.9, num_updates=278500, lr=0.00018949, gnorm=0.334, loss_scale=2, train_wall=79, gb_free=39.5, wall=232654
2023-06-14 08:25:16 | INFO | train_inner | epoch 025:   8041 / 11284 loss=3.501, nll_loss=1.793, ppl=3.46, wps=71086.6, ups=1.2, wpb=59193.5, bsz=2250.7, num_updates=278600, lr=0.000189456, gnorm=0.35, loss_scale=2, train_wall=79, gb_free=39.6, wall=232737
2023-06-14 08:26:39 | INFO | train_inner | epoch 025:   8141 / 11284 loss=3.523, nll_loss=1.817, ppl=3.52, wps=71598.4, ups=1.2, wpb=59420.3, bsz=2261.2, num_updates=278700, lr=0.000189422, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.5, wall=232820
2023-06-14 08:28:01 | INFO | train_inner | epoch 025:   8241 / 11284 loss=3.495, nll_loss=1.787, ppl=3.45, wps=73367.8, ups=1.22, wpb=60021.7, bsz=2329, num_updates=278800, lr=0.000189389, gnorm=0.333, loss_scale=2, train_wall=78, gb_free=39.6, wall=232902
2023-06-14 08:29:24 | INFO | train_inner | epoch 025:   8341 / 11284 loss=3.501, nll_loss=1.793, ppl=3.46, wps=72125, ups=1.21, wpb=59528, bsz=2268.7, num_updates=278900, lr=0.000189355, gnorm=0.346, loss_scale=2, train_wall=78, gb_free=39.5, wall=232984
2023-06-14 08:30:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 08:30:47 | INFO | train_inner | epoch 025:   8442 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=71887.7, ups=1.21, wpb=59621.4, bsz=2238.4, num_updates=279000, lr=0.000189321, gnorm=0.336, loss_scale=2, train_wall=79, gb_free=39.6, wall=233067
2023-06-14 08:32:10 | INFO | train_inner | epoch 025:   8542 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=72000.7, ups=1.21, wpb=59572, bsz=2168.5, num_updates=279100, lr=0.000189287, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.5, wall=233150
2023-06-14 08:33:31 | INFO | train_inner | epoch 025:   8642 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=73039.3, ups=1.22, wpb=59630.5, bsz=2168.2, num_updates=279200, lr=0.000189253, gnorm=0.337, loss_scale=2, train_wall=78, gb_free=39.6, wall=233232
2023-06-14 08:34:53 | INFO | train_inner | epoch 025:   8742 / 11284 loss=3.49, nll_loss=1.781, ppl=3.44, wps=72407.4, ups=1.22, wpb=59535.7, bsz=2159.7, num_updates=279300, lr=0.000189219, gnorm=0.334, loss_scale=2, train_wall=78, gb_free=39.2, wall=233314
2023-06-14 08:36:17 | INFO | train_inner | epoch 025:   8842 / 11284 loss=3.507, nll_loss=1.799, ppl=3.48, wps=71080.8, ups=1.2, wpb=59475, bsz=2196.4, num_updates=279400, lr=0.000189185, gnorm=0.337, loss_scale=2, train_wall=80, gb_free=39.5, wall=233398
2023-06-14 08:37:40 | INFO | train_inner | epoch 025:   8942 / 11284 loss=3.52, nll_loss=1.814, ppl=3.52, wps=71451.7, ups=1.2, wpb=59512.9, bsz=2177.7, num_updates=279500, lr=0.000189151, gnorm=0.35, loss_scale=2, train_wall=79, gb_free=39.6, wall=233481
2023-06-14 08:39:04 | INFO | train_inner | epoch 025:   9042 / 11284 loss=3.514, nll_loss=1.807, ppl=3.5, wps=71314.6, ups=1.2, wpb=59606.1, bsz=2292.7, num_updates=279600, lr=0.000189117, gnorm=0.336, loss_scale=2, train_wall=80, gb_free=39.5, wall=233565
2023-06-14 08:40:26 | INFO | train_inner | epoch 025:   9142 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=72555.8, ups=1.22, wpb=59698, bsz=2224.9, num_updates=279700, lr=0.000189084, gnorm=0.336, loss_scale=2, train_wall=78, gb_free=39.6, wall=233647
2023-06-14 08:41:49 | INFO | train_inner | epoch 025:   9242 / 11284 loss=3.493, nll_loss=1.784, ppl=3.44, wps=71905.3, ups=1.21, wpb=59553.7, bsz=2123.8, num_updates=279800, lr=0.00018905, gnorm=0.335, loss_scale=2, train_wall=79, gb_free=39.6, wall=233730
2023-06-14 08:43:12 | INFO | train_inner | epoch 025:   9342 / 11284 loss=3.49, nll_loss=1.781, ppl=3.44, wps=72065.6, ups=1.21, wpb=59514.6, bsz=2157, num_updates=279900, lr=0.000189016, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.5, wall=233812
2023-06-14 08:44:34 | INFO | train_inner | epoch 025:   9442 / 11284 loss=3.513, nll_loss=1.806, ppl=3.5, wps=71640.7, ups=1.21, wpb=59289.4, bsz=2217.6, num_updates=280000, lr=0.000188982, gnorm=0.339, loss_scale=4, train_wall=79, gb_free=39.6, wall=233895
2023-06-14 08:45:57 | INFO | train_inner | epoch 025:   9542 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=71755.7, ups=1.2, wpb=59580.3, bsz=2207.8, num_updates=280100, lr=0.000188948, gnorm=0.336, loss_scale=4, train_wall=79, gb_free=39.6, wall=233978
2023-06-14 08:46:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 08:47:20 | INFO | train_inner | epoch 025:   9643 / 11284 loss=3.503, nll_loss=1.794, ppl=3.47, wps=72039.4, ups=1.21, wpb=59487.5, bsz=2264.1, num_updates=280200, lr=0.000188915, gnorm=0.341, loss_scale=2, train_wall=78, gb_free=39.6, wall=234061
2023-06-14 08:48:41 | INFO | train_inner | epoch 025:   9743 / 11284 loss=3.515, nll_loss=1.808, ppl=3.5, wps=73180.2, ups=1.23, wpb=59624.6, bsz=2237.1, num_updates=280300, lr=0.000188881, gnorm=0.335, loss_scale=2, train_wall=77, gb_free=39.6, wall=234142
2023-06-14 08:50:04 | INFO | train_inner | epoch 025:   9843 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=71998.9, ups=1.21, wpb=59435.6, bsz=2200, num_updates=280400, lr=0.000188847, gnorm=0.336, loss_scale=2, train_wall=79, gb_free=39.6, wall=234225
2023-06-14 08:51:26 | INFO | train_inner | epoch 025:   9943 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=72382.8, ups=1.22, wpb=59452.2, bsz=2258.9, num_updates=280500, lr=0.000188814, gnorm=0.337, loss_scale=2, train_wall=78, gb_free=39.6, wall=234307
2023-06-14 08:52:48 | INFO | train_inner | epoch 025:  10043 / 11284 loss=3.51, nll_loss=1.802, ppl=3.49, wps=72288.2, ups=1.22, wpb=59384, bsz=2302.3, num_updates=280600, lr=0.00018878, gnorm=0.341, loss_scale=2, train_wall=78, gb_free=39.4, wall=234389
2023-06-14 08:54:12 | INFO | train_inner | epoch 025:  10143 / 11284 loss=3.483, nll_loss=1.772, ppl=3.42, wps=71669.9, ups=1.2, wpb=59662.1, bsz=2326.9, num_updates=280700, lr=0.000188746, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.6, wall=234472
2023-06-14 08:55:35 | INFO | train_inner | epoch 025:  10243 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=71718.6, ups=1.2, wpb=59578, bsz=2203.1, num_updates=280800, lr=0.000188713, gnorm=0.331, loss_scale=2, train_wall=79, gb_free=39.5, wall=234555
2023-06-14 08:56:57 | INFO | train_inner | epoch 025:  10343 / 11284 loss=3.493, nll_loss=1.784, ppl=3.44, wps=71871.6, ups=1.21, wpb=59527.5, bsz=2151.1, num_updates=280900, lr=0.000188679, gnorm=0.336, loss_scale=2, train_wall=79, gb_free=39.6, wall=234638
2023-06-14 08:58:19 | INFO | train_inner | epoch 025:  10443 / 11284 loss=3.515, nll_loss=1.808, ppl=3.5, wps=72479, ups=1.22, wpb=59337.2, bsz=2233.2, num_updates=281000, lr=0.000188646, gnorm=0.346, loss_scale=2, train_wall=78, gb_free=39.6, wall=234720
2023-06-14 08:59:42 | INFO | train_inner | epoch 025:  10543 / 11284 loss=3.513, nll_loss=1.806, ppl=3.5, wps=71898.3, ups=1.21, wpb=59529.5, bsz=2185.4, num_updates=281100, lr=0.000188612, gnorm=0.338, loss_scale=2, train_wall=79, gb_free=39.5, wall=234803
2023-06-14 09:00:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 09:01:06 | INFO | train_inner | epoch 025:  10644 / 11284 loss=3.513, nll_loss=1.806, ppl=3.5, wps=70870.1, ups=1.19, wpb=59464.1, bsz=2181.2, num_updates=281200, lr=0.000188579, gnorm=0.346, loss_scale=2, train_wall=80, gb_free=39.6, wall=234887
2023-06-14 09:02:29 | INFO | train_inner | epoch 025:  10744 / 11284 loss=3.501, nll_loss=1.792, ppl=3.46, wps=72120.1, ups=1.21, wpb=59627.6, bsz=2176.2, num_updates=281300, lr=0.000188545, gnorm=0.355, loss_scale=2, train_wall=79, gb_free=39.5, wall=234969
2023-06-14 09:03:52 | INFO | train_inner | epoch 025:  10844 / 11284 loss=3.497, nll_loss=1.789, ppl=3.45, wps=71495.8, ups=1.2, wpb=59439.5, bsz=2237, num_updates=281400, lr=0.000188512, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.6, wall=235052
2023-06-14 09:05:15 | INFO | train_inner | epoch 025:  10944 / 11284 loss=3.507, nll_loss=1.799, ppl=3.48, wps=71529.6, ups=1.2, wpb=59427.8, bsz=2216.2, num_updates=281500, lr=0.000188478, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.6, wall=235136
2023-06-14 09:06:38 | INFO | train_inner | epoch 025:  11044 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=71872.4, ups=1.2, wpb=59656, bsz=2196.1, num_updates=281600, lr=0.000188445, gnorm=0.33, loss_scale=2, train_wall=79, gb_free=39.6, wall=235219
2023-06-14 09:08:01 | INFO | train_inner | epoch 025:  11144 / 11284 loss=3.509, nll_loss=1.802, ppl=3.49, wps=71238.6, ups=1.2, wpb=59478, bsz=2275.9, num_updates=281700, lr=0.000188411, gnorm=0.344, loss_scale=2, train_wall=80, gb_free=39.6, wall=235302
2023-06-14 09:09:25 | INFO | train_inner | epoch 025:  11244 / 11284 loss=3.509, nll_loss=1.801, ppl=3.49, wps=71388.4, ups=1.2, wpb=59588.3, bsz=2191.7, num_updates=281800, lr=0.000188378, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.6, wall=235385
2023-06-14 09:09:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-14 09:10:17 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 4.298 | nll_loss 2.615 | ppl 6.13 | bleu 20.95 | wps 3618.5 | wpb 2397.5 | bsz 71.5 | num_updates 281840 | best_loss 4.298
2023-06-14 09:10:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 281840 updates
2023-06-14 09:10:17 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint25.pt
2023-06-14 09:10:19 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint25.pt
2023-06-14 09:10:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint25.pt (epoch 25 @ 281840 updates, score 4.298) (writing took 8.66810825560242 seconds)
2023-06-14 09:10:25 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-06-14 09:10:25 | INFO | train | epoch 025 | loss 3.501 | nll_loss 1.793 | ppl 3.47 | wps 71004.6 | ups 1.19 | wpb 59500.8 | bsz 2227.3 | num_updates 281840 | lr 0.000188364 | gnorm 0.34 | loss_scale 2 | train_wall 8969 | gb_free 39.5 | wall 235446
2023-06-14 09:10:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-14 09:10:26 | INFO | fairseq.trainer | begin training epoch 26
2023-06-14 09:10:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-14 09:11:17 | INFO | train_inner | epoch 026:     60 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=52715, ups=0.89, wpb=59245.8, bsz=2184.6, num_updates=281900, lr=0.000188344, gnorm=0.352, loss_scale=2, train_wall=81, gb_free=39.5, wall=235498
2023-06-14 09:12:39 | INFO | train_inner | epoch 026:    160 / 11284 loss=3.503, nll_loss=1.794, ppl=3.47, wps=72963, ups=1.23, wpb=59559.3, bsz=2180, num_updates=282000, lr=0.000188311, gnorm=0.336, loss_scale=2, train_wall=78, gb_free=39.6, wall=235579
2023-06-14 09:14:01 | INFO | train_inner | epoch 026:    260 / 11284 loss=3.486, nll_loss=1.775, ppl=3.42, wps=72574.2, ups=1.22, wpb=59368.2, bsz=2249.1, num_updates=282100, lr=0.000188278, gnorm=0.339, loss_scale=2, train_wall=78, gb_free=39.6, wall=235661
2023-06-14 09:15:23 | INFO | train_inner | epoch 026:    360 / 11284 loss=3.484, nll_loss=1.773, ppl=3.42, wps=72488.5, ups=1.22, wpb=59450.9, bsz=2158.2, num_updates=282200, lr=0.000188244, gnorm=0.341, loss_scale=4, train_wall=78, gb_free=39.6, wall=235743
2023-06-14 09:15:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 09:16:46 | INFO | train_inner | epoch 026:    461 / 11284 loss=3.501, nll_loss=1.792, ppl=3.46, wps=71305.4, ups=1.2, wpb=59554.6, bsz=2147.3, num_updates=282300, lr=0.000188211, gnorm=0.339, loss_scale=2, train_wall=80, gb_free=39.6, wall=235827
2023-06-14 09:18:09 | INFO | train_inner | epoch 026:    561 / 11284 loss=3.49, nll_loss=1.78, ppl=3.43, wps=71583.9, ups=1.2, wpb=59459.7, bsz=2337.5, num_updates=282400, lr=0.000188177, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=39.5, wall=235910
2023-06-14 09:19:32 | INFO | train_inner | epoch 026:    661 / 11284 loss=3.491, nll_loss=1.781, ppl=3.44, wps=72310, ups=1.21, wpb=59587.8, bsz=2254.8, num_updates=282500, lr=0.000188144, gnorm=0.334, loss_scale=2, train_wall=78, gb_free=39.5, wall=235992
2023-06-14 09:20:54 | INFO | train_inner | epoch 026:    761 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=72678.1, ups=1.22, wpb=59621.6, bsz=2185.7, num_updates=282600, lr=0.000188111, gnorm=0.335, loss_scale=2, train_wall=78, gb_free=39.6, wall=236074
2023-06-14 09:22:17 | INFO | train_inner | epoch 026:    861 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=71658.9, ups=1.2, wpb=59469.9, bsz=2242.8, num_updates=282700, lr=0.000188078, gnorm=0.341, loss_scale=2, train_wall=79, gb_free=39.6, wall=236157
2023-06-14 09:23:40 | INFO | train_inner | epoch 026:    961 / 11284 loss=3.502, nll_loss=1.793, ppl=3.46, wps=72040.4, ups=1.2, wpb=59842.8, bsz=2120.7, num_updates=282800, lr=0.000188044, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.6, wall=236240
2023-06-14 09:25:03 | INFO | train_inner | epoch 026:   1061 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=71381.6, ups=1.2, wpb=59495.7, bsz=2366.4, num_updates=282900, lr=0.000188011, gnorm=0.339, loss_scale=2, train_wall=79, gb_free=39.6, wall=236324
2023-06-14 09:26:26 | INFO | train_inner | epoch 026:   1161 / 11284 loss=3.48, nll_loss=1.769, ppl=3.41, wps=71502.4, ups=1.2, wpb=59522.9, bsz=2257.8, num_updates=283000, lr=0.000187978, gnorm=0.329, loss_scale=2, train_wall=79, gb_free=39.6, wall=236407
2023-06-14 09:27:50 | INFO | train_inner | epoch 026:   1261 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=71310.3, ups=1.2, wpb=59543.3, bsz=2271.2, num_updates=283100, lr=0.000187945, gnorm=0.35, loss_scale=2, train_wall=79, gb_free=39.6, wall=236491
2023-06-14 09:29:13 | INFO | train_inner | epoch 026:   1361 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=71545.6, ups=1.2, wpb=59522.1, bsz=2365.6, num_updates=283200, lr=0.000187912, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=236574
2023-06-14 09:30:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 09:30:37 | INFO | train_inner | epoch 026:   1462 / 11284 loss=3.5, nll_loss=1.791, ppl=3.46, wps=71029, ups=1.19, wpb=59606.4, bsz=2197.7, num_updates=283300, lr=0.000187878, gnorm=0.336, loss_scale=2, train_wall=80, gb_free=39.6, wall=236658
2023-06-14 09:32:00 | INFO | train_inner | epoch 026:   1562 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=71839.6, ups=1.21, wpb=59342.8, bsz=2124.9, num_updates=283400, lr=0.000187845, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.5, wall=236740
2023-06-14 09:33:23 | INFO | train_inner | epoch 026:   1662 / 11284 loss=3.501, nll_loss=1.792, ppl=3.46, wps=71699, ups=1.21, wpb=59448.2, bsz=2156.2, num_updates=283500, lr=0.000187812, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.6, wall=236823
2023-06-14 09:34:46 | INFO | train_inner | epoch 026:   1762 / 11284 loss=3.481, nll_loss=1.77, ppl=3.41, wps=71390.6, ups=1.2, wpb=59415.8, bsz=2084.2, num_updates=283600, lr=0.000187779, gnorm=0.336, loss_scale=2, train_wall=79, gb_free=39.6, wall=236906
2023-06-14 09:36:08 | INFO | train_inner | epoch 026:   1862 / 11284 loss=3.5, nll_loss=1.791, ppl=3.46, wps=72058.8, ups=1.21, wpb=59504.4, bsz=2264.1, num_updates=283700, lr=0.000187746, gnorm=0.355, loss_scale=2, train_wall=79, gb_free=39.6, wall=236989
2023-06-14 09:37:31 | INFO | train_inner | epoch 026:   1962 / 11284 loss=3.498, nll_loss=1.789, ppl=3.45, wps=71588.9, ups=1.2, wpb=59439.1, bsz=2218.8, num_updates=283800, lr=0.000187713, gnorm=0.341, loss_scale=2, train_wall=79, gb_free=39.5, wall=237072
2023-06-14 09:38:54 | INFO | train_inner | epoch 026:   2062 / 11284 loss=3.49, nll_loss=1.781, ppl=3.44, wps=71817.3, ups=1.2, wpb=59675.2, bsz=2174.7, num_updates=283900, lr=0.00018768, gnorm=0.331, loss_scale=2, train_wall=79, gb_free=39.6, wall=237155
2023-06-14 09:40:18 | INFO | train_inner | epoch 026:   2162 / 11284 loss=3.492, nll_loss=1.782, ppl=3.44, wps=71293.2, ups=1.2, wpb=59620.1, bsz=2263.7, num_updates=284000, lr=0.000187647, gnorm=0.332, loss_scale=2, train_wall=80, gb_free=39.5, wall=237239
2023-06-14 09:41:41 | INFO | train_inner | epoch 026:   2262 / 11284 loss=3.508, nll_loss=1.8, ppl=3.48, wps=71701.2, ups=1.2, wpb=59524.6, bsz=2197, num_updates=284100, lr=0.000187614, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.6, wall=237322
2023-06-14 09:43:04 | INFO | train_inner | epoch 026:   2362 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=71579.2, ups=1.2, wpb=59508.9, bsz=2232.4, num_updates=284200, lr=0.000187581, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.6, wall=237405
2023-06-14 09:44:27 | INFO | train_inner | epoch 026:   2462 / 11284 loss=3.479, nll_loss=1.768, ppl=3.4, wps=71476.2, ups=1.2, wpb=59329.2, bsz=2212.3, num_updates=284300, lr=0.000187548, gnorm=0.338, loss_scale=2, train_wall=79, gb_free=39.5, wall=237488
2023-06-14 09:44:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 09:45:52 | INFO | train_inner | epoch 026:   2563 / 11284 loss=3.511, nll_loss=1.804, ppl=3.49, wps=70651.3, ups=1.19, wpb=59521.6, bsz=2248.7, num_updates=284400, lr=0.000187515, gnorm=0.344, loss_scale=2, train_wall=80, gb_free=39.6, wall=237572
2023-06-14 09:47:15 | INFO | train_inner | epoch 026:   2663 / 11284 loss=3.493, nll_loss=1.783, ppl=3.44, wps=71602.8, ups=1.2, wpb=59423.2, bsz=2227.7, num_updates=284500, lr=0.000187482, gnorm=0.336, loss_scale=2, train_wall=79, gb_free=39.6, wall=237655
2023-06-14 09:48:38 | INFO | train_inner | epoch 026:   2763 / 11284 loss=3.492, nll_loss=1.783, ppl=3.44, wps=71691, ups=1.2, wpb=59683.5, bsz=2185.4, num_updates=284600, lr=0.000187449, gnorm=0.333, loss_scale=2, train_wall=79, gb_free=39.5, wall=237738
2023-06-14 09:50:01 | INFO | train_inner | epoch 026:   2863 / 11284 loss=3.509, nll_loss=1.802, ppl=3.49, wps=71513.3, ups=1.2, wpb=59517.7, bsz=2263.2, num_updates=284700, lr=0.000187416, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.6, wall=237822
2023-06-14 09:51:24 | INFO | train_inner | epoch 026:   2963 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=71724.9, ups=1.21, wpb=59419.9, bsz=2143.6, num_updates=284800, lr=0.000187383, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.6, wall=237904
2023-06-14 09:52:47 | INFO | train_inner | epoch 026:   3063 / 11284 loss=3.489, nll_loss=1.779, ppl=3.43, wps=71416.5, ups=1.2, wpb=59370.1, bsz=2217.9, num_updates=284900, lr=0.00018735, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.5, wall=237988
2023-06-14 09:54:10 | INFO | train_inner | epoch 026:   3163 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=71512, ups=1.2, wpb=59435.1, bsz=2243.7, num_updates=285000, lr=0.000187317, gnorm=0.323, loss_scale=2, train_wall=79, gb_free=39.5, wall=238071
2023-06-14 09:54:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-06-14 09:55:34 | INFO | train_inner | epoch 026:   3264 / 11284 loss=3.496, nll_loss=1.786, ppl=3.45, wps=70555.7, ups=1.19, wpb=59270.3, bsz=2214.7, num_updates=285100, lr=0.000187284, gnorm=0.352, loss_scale=1, train_wall=80, gb_free=39.6, wall=238155
2023-06-14 09:56:57 | INFO | train_inner | epoch 026:   3364 / 11284 loss=3.505, nll_loss=1.797, ppl=3.48, wps=71659.5, ups=1.2, wpb=59592.7, bsz=2123, num_updates=285200, lr=0.000187251, gnorm=0.345, loss_scale=1, train_wall=79, gb_free=39.6, wall=238238
2023-06-14 09:58:20 | INFO | train_inner | epoch 026:   3464 / 11284 loss=3.513, nll_loss=1.806, ppl=3.5, wps=71827.1, ups=1.2, wpb=59727.8, bsz=2234.8, num_updates=285300, lr=0.000187219, gnorm=0.341, loss_scale=1, train_wall=79, gb_free=39.6, wall=238321
2023-06-14 09:59:43 | INFO | train_inner | epoch 026:   3564 / 11284 loss=3.507, nll_loss=1.799, ppl=3.48, wps=71586.5, ups=1.21, wpb=59354.6, bsz=2164.8, num_updates=285400, lr=0.000187186, gnorm=0.343, loss_scale=1, train_wall=79, gb_free=39.6, wall=238404
2023-06-14 10:01:07 | INFO | train_inner | epoch 026:   3664 / 11284 loss=3.502, nll_loss=1.793, ppl=3.47, wps=71449.9, ups=1.2, wpb=59481.1, bsz=2209, num_updates=285500, lr=0.000187153, gnorm=0.348, loss_scale=1, train_wall=79, gb_free=39.6, wall=238487
2023-06-14 10:02:30 | INFO | train_inner | epoch 026:   3764 / 11284 loss=3.5, nll_loss=1.792, ppl=3.46, wps=71427.1, ups=1.2, wpb=59435.6, bsz=2249, num_updates=285600, lr=0.00018712, gnorm=0.331, loss_scale=1, train_wall=79, gb_free=39.6, wall=238570
2023-06-14 10:03:52 | INFO | train_inner | epoch 026:   3864 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=73014.7, ups=1.22, wpb=59830.6, bsz=2221, num_updates=285700, lr=0.000187088, gnorm=0.334, loss_scale=1, train_wall=78, gb_free=39.6, wall=238652
2023-06-14 10:05:15 | INFO | train_inner | epoch 026:   3964 / 11284 loss=3.502, nll_loss=1.793, ppl=3.47, wps=71409.2, ups=1.2, wpb=59513, bsz=2242.8, num_updates=285800, lr=0.000187055, gnorm=0.342, loss_scale=1, train_wall=79, gb_free=39.5, wall=238736
2023-06-14 10:06:38 | INFO | train_inner | epoch 026:   4064 / 11284 loss=3.49, nll_loss=1.78, ppl=3.44, wps=71148.8, ups=1.2, wpb=59308.3, bsz=2199, num_updates=285900, lr=0.000187022, gnorm=0.35, loss_scale=1, train_wall=79, gb_free=39.4, wall=238819
2023-06-14 10:08:00 | INFO | train_inner | epoch 026:   4164 / 11284 loss=3.49, nll_loss=1.78, ppl=3.43, wps=72844.3, ups=1.22, wpb=59474.5, bsz=2251.2, num_updates=286000, lr=0.000186989, gnorm=0.345, loss_scale=1, train_wall=78, gb_free=39.6, wall=238901
2023-06-14 10:09:23 | INFO | train_inner | epoch 026:   4264 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=72263.8, ups=1.21, wpb=59632, bsz=2254.4, num_updates=286100, lr=0.000186957, gnorm=0.342, loss_scale=2, train_wall=78, gb_free=39.6, wall=238983
2023-06-14 10:10:46 | INFO | train_inner | epoch 026:   4364 / 11284 loss=3.5, nll_loss=1.791, ppl=3.46, wps=71674.1, ups=1.2, wpb=59631.9, bsz=2276, num_updates=286200, lr=0.000186924, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.5, wall=239066
2023-06-14 10:12:08 | INFO | train_inner | epoch 026:   4464 / 11284 loss=3.492, nll_loss=1.783, ppl=3.44, wps=71814.9, ups=1.21, wpb=59277.5, bsz=2231.8, num_updates=286300, lr=0.000186891, gnorm=0.345, loss_scale=2, train_wall=78, gb_free=39.6, wall=239149
2023-06-14 10:13:30 | INFO | train_inner | epoch 026:   4564 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=73007.1, ups=1.23, wpb=59539, bsz=2202.5, num_updates=286400, lr=0.000186859, gnorm=0.337, loss_scale=2, train_wall=78, gb_free=39.6, wall=239230
2023-06-14 10:14:53 | INFO | train_inner | epoch 026:   4664 / 11284 loss=3.498, nll_loss=1.788, ppl=3.45, wps=71810.2, ups=1.21, wpb=59494.8, bsz=2217.4, num_updates=286500, lr=0.000186826, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=239313
2023-06-14 10:16:15 | INFO | train_inner | epoch 026:   4764 / 11284 loss=3.502, nll_loss=1.793, ppl=3.47, wps=71858.4, ups=1.21, wpb=59270.5, bsz=2186.7, num_updates=286600, lr=0.000186794, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.6, wall=239396
2023-06-14 10:17:38 | INFO | train_inner | epoch 026:   4864 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=72158.4, ups=1.21, wpb=59438.9, bsz=2200.3, num_updates=286700, lr=0.000186761, gnorm=0.355, loss_scale=2, train_wall=78, gb_free=39.6, wall=239478
2023-06-14 10:19:03 | INFO | train_inner | epoch 026:   4964 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=69740.8, ups=1.17, wpb=59534.9, bsz=2181, num_updates=286800, lr=0.000186728, gnorm=0.337, loss_scale=2, train_wall=82, gb_free=39.6, wall=239564
2023-06-14 10:20:29 | INFO | train_inner | epoch 026:   5064 / 11284 loss=3.515, nll_loss=1.808, ppl=3.5, wps=69723.6, ups=1.17, wpb=59736.8, bsz=2276.9, num_updates=286900, lr=0.000186696, gnorm=0.333, loss_scale=2, train_wall=81, gb_free=39.6, wall=239649
2023-06-14 10:21:52 | INFO | train_inner | epoch 026:   5164 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=71240.2, ups=1.2, wpb=59568.4, bsz=2222, num_updates=287000, lr=0.000186663, gnorm=0.337, loss_scale=2, train_wall=80, gb_free=39.6, wall=239733
2023-06-14 10:23:15 | INFO | train_inner | epoch 026:   5264 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=71701.1, ups=1.2, wpb=59553.4, bsz=2237.9, num_updates=287100, lr=0.000186631, gnorm=0.336, loss_scale=4, train_wall=79, gb_free=39.6, wall=239816
2023-06-14 10:24:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 10:24:38 | INFO | train_inner | epoch 026:   5365 / 11284 loss=3.492, nll_loss=1.782, ppl=3.44, wps=71711.9, ups=1.21, wpb=59437.5, bsz=2126.3, num_updates=287200, lr=0.000186598, gnorm=0.338, loss_scale=2, train_wall=79, gb_free=39.6, wall=239899
2023-06-14 10:26:02 | INFO | train_inner | epoch 026:   5465 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=71390.6, ups=1.2, wpb=59499.7, bsz=2212.6, num_updates=287300, lr=0.000186566, gnorm=0.346, loss_scale=2, train_wall=80, gb_free=39.6, wall=239982
2023-06-14 10:27:25 | INFO | train_inner | epoch 026:   5565 / 11284 loss=3.512, nll_loss=1.805, ppl=3.49, wps=71614, ups=1.2, wpb=59439, bsz=2190.1, num_updates=287400, lr=0.000186533, gnorm=0.358, loss_scale=2, train_wall=79, gb_free=39.6, wall=240065
2023-06-14 10:28:48 | INFO | train_inner | epoch 026:   5665 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=71488, ups=1.2, wpb=59698.1, bsz=2232.8, num_updates=287500, lr=0.000186501, gnorm=0.322, loss_scale=2, train_wall=80, gb_free=39.5, wall=240149
2023-06-14 10:30:11 | INFO | train_inner | epoch 026:   5765 / 11284 loss=3.506, nll_loss=1.798, ppl=3.48, wps=71281.9, ups=1.2, wpb=59408.6, bsz=2254, num_updates=287600, lr=0.000186469, gnorm=0.359, loss_scale=2, train_wall=79, gb_free=39.6, wall=240232
2023-06-14 10:31:35 | INFO | train_inner | epoch 026:   5865 / 11284 loss=3.494, nll_loss=1.784, ppl=3.44, wps=71262.6, ups=1.2, wpb=59476.7, bsz=2346.1, num_updates=287700, lr=0.000186436, gnorm=0.337, loss_scale=2, train_wall=80, gb_free=39.6, wall=240315
2023-06-14 10:32:58 | INFO | train_inner | epoch 026:   5965 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=71304.1, ups=1.2, wpb=59512.8, bsz=2244.5, num_updates=287800, lr=0.000186404, gnorm=0.344, loss_scale=2, train_wall=80, gb_free=39.6, wall=240399
2023-06-14 10:34:22 | INFO | train_inner | epoch 026:   6065 / 11284 loss=3.512, nll_loss=1.804, ppl=3.49, wps=71250, ups=1.2, wpb=59511.6, bsz=2204.8, num_updates=287900, lr=0.000186371, gnorm=0.348, loss_scale=2, train_wall=80, gb_free=39.5, wall=240482
2023-06-14 10:35:44 | INFO | train_inner | epoch 026:   6165 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=72385.6, ups=1.22, wpb=59542.8, bsz=2197.9, num_updates=288000, lr=0.000186339, gnorm=0.342, loss_scale=2, train_wall=78, gb_free=39.6, wall=240565
2023-06-14 10:37:06 | INFO | train_inner | epoch 026:   6265 / 11284 loss=3.499, nll_loss=1.79, ppl=3.46, wps=72657.3, ups=1.22, wpb=59360.4, bsz=2211.6, num_updates=288100, lr=0.000186307, gnorm=0.346, loss_scale=2, train_wall=78, gb_free=39.5, wall=240646
2023-06-14 10:38:28 | INFO | train_inner | epoch 026:   6365 / 11284 loss=3.513, nll_loss=1.806, ppl=3.5, wps=72370.7, ups=1.22, wpb=59243.1, bsz=2216.9, num_updates=288200, lr=0.000186274, gnorm=0.351, loss_scale=4, train_wall=78, gb_free=39.6, wall=240728
2023-06-14 10:39:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 10:39:51 | INFO | train_inner | epoch 026:   6466 / 11284 loss=3.49, nll_loss=1.78, ppl=3.43, wps=71598.5, ups=1.2, wpb=59633.2, bsz=2214.4, num_updates=288300, lr=0.000186242, gnorm=0.335, loss_scale=2, train_wall=79, gb_free=39.6, wall=240812
2023-06-14 10:41:14 | INFO | train_inner | epoch 026:   6566 / 11284 loss=3.487, nll_loss=1.778, ppl=3.43, wps=71790.5, ups=1.21, wpb=59418.9, bsz=2080.5, num_updates=288400, lr=0.00018621, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.5, wall=240894
2023-06-14 10:42:35 | INFO | train_inner | epoch 026:   6666 / 11284 loss=3.501, nll_loss=1.792, ppl=3.46, wps=72398.2, ups=1.22, wpb=59132.1, bsz=2262.3, num_updates=288500, lr=0.000186177, gnorm=0.341, loss_scale=2, train_wall=78, gb_free=39.6, wall=240976
2023-06-14 10:43:58 | INFO | train_inner | epoch 026:   6766 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=72574.6, ups=1.22, wpb=59617, bsz=2204.3, num_updates=288600, lr=0.000186145, gnorm=0.339, loss_scale=2, train_wall=78, gb_free=39.5, wall=241058
2023-06-14 10:45:21 | INFO | train_inner | epoch 026:   6866 / 11284 loss=3.49, nll_loss=1.781, ppl=3.44, wps=71746.7, ups=1.21, wpb=59497.4, bsz=2306.1, num_updates=288700, lr=0.000186113, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=39.6, wall=241141
2023-06-14 10:46:44 | INFO | train_inner | epoch 026:   6966 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=71504, ups=1.2, wpb=59445.3, bsz=2243.2, num_updates=288800, lr=0.000186081, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.5, wall=241224
2023-06-14 10:48:07 | INFO | train_inner | epoch 026:   7066 / 11284 loss=3.508, nll_loss=1.801, ppl=3.48, wps=71529.1, ups=1.21, wpb=59314.7, bsz=2150.8, num_updates=288900, lr=0.000186049, gnorm=0.339, loss_scale=2, train_wall=79, gb_free=39.6, wall=241307
2023-06-14 10:49:29 | INFO | train_inner | epoch 026:   7166 / 11284 loss=3.5, nll_loss=1.792, ppl=3.46, wps=71812.6, ups=1.21, wpb=59403.2, bsz=2256.8, num_updates=289000, lr=0.000186016, gnorm=0.35, loss_scale=2, train_wall=79, gb_free=39.6, wall=241390
2023-06-14 10:50:52 | INFO | train_inner | epoch 026:   7266 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=72181.3, ups=1.21, wpb=59609, bsz=2307.9, num_updates=289100, lr=0.000185984, gnorm=0.333, loss_scale=2, train_wall=79, gb_free=39.6, wall=241472
2023-06-14 10:52:16 | INFO | train_inner | epoch 026:   7366 / 11284 loss=3.501, nll_loss=1.793, ppl=3.46, wps=70870.2, ups=1.2, wpb=59298, bsz=2154.5, num_updates=289200, lr=0.000185952, gnorm=0.342, loss_scale=2, train_wall=80, gb_free=39.6, wall=241556
2023-06-14 10:53:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 10:53:39 | INFO | train_inner | epoch 026:   7467 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=71021.6, ups=1.19, wpb=59583.4, bsz=2211.6, num_updates=289300, lr=0.00018592, gnorm=0.343, loss_scale=2, train_wall=80, gb_free=39.5, wall=241640
2023-06-14 10:55:02 | INFO | train_inner | epoch 026:   7567 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=71693.4, ups=1.21, wpb=59338.3, bsz=2311.7, num_updates=289400, lr=0.000185888, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.6, wall=241723
2023-06-14 10:56:25 | INFO | train_inner | epoch 026:   7667 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=71680.7, ups=1.21, wpb=59430, bsz=2231.9, num_updates=289500, lr=0.000185856, gnorm=0.331, loss_scale=2, train_wall=79, gb_free=39.6, wall=241806
2023-06-14 10:57:48 | INFO | train_inner | epoch 026:   7767 / 11284 loss=3.492, nll_loss=1.782, ppl=3.44, wps=72056.9, ups=1.21, wpb=59753, bsz=2241.1, num_updates=289600, lr=0.000185824, gnorm=0.336, loss_scale=2, train_wall=79, gb_free=39.4, wall=241889
2023-06-14 10:59:11 | INFO | train_inner | epoch 026:   7867 / 11284 loss=3.5, nll_loss=1.792, ppl=3.46, wps=71976.9, ups=1.21, wpb=59629.6, bsz=2304.2, num_updates=289700, lr=0.000185791, gnorm=0.339, loss_scale=2, train_wall=79, gb_free=39.5, wall=241971
2023-06-14 10:59:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-06-14 11:00:35 | INFO | train_inner | epoch 026:   7968 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71038.8, ups=1.19, wpb=59518, bsz=2294.4, num_updates=289800, lr=0.000185759, gnorm=0.354, loss_scale=1, train_wall=80, gb_free=39.6, wall=242055
2023-06-14 11:01:58 | INFO | train_inner | epoch 026:   8068 / 11284 loss=3.506, nll_loss=1.798, ppl=3.48, wps=71853, ups=1.21, wpb=59559.1, bsz=2192.4, num_updates=289900, lr=0.000185727, gnorm=0.342, loss_scale=1, train_wall=79, gb_free=39.6, wall=242138
2023-06-14 11:03:20 | INFO | train_inner | epoch 026:   8168 / 11284 loss=3.491, nll_loss=1.782, ppl=3.44, wps=71795.2, ups=1.21, wpb=59445.3, bsz=2174.5, num_updates=290000, lr=0.000185695, gnorm=0.343, loss_scale=1, train_wall=79, gb_free=39.6, wall=242221
2023-06-14 11:04:44 | INFO | train_inner | epoch 026:   8268 / 11284 loss=3.505, nll_loss=1.797, ppl=3.47, wps=71506.2, ups=1.2, wpb=59649.1, bsz=2231.6, num_updates=290100, lr=0.000185663, gnorm=0.336, loss_scale=1, train_wall=79, gb_free=38.9, wall=242304
2023-06-14 11:06:07 | INFO | train_inner | epoch 026:   8368 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=71595.5, ups=1.2, wpb=59456.6, bsz=2288.6, num_updates=290200, lr=0.000185631, gnorm=0.345, loss_scale=1, train_wall=79, gb_free=39.6, wall=242387
2023-06-14 11:07:30 | INFO | train_inner | epoch 026:   8468 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=71784.4, ups=1.2, wpb=59615.2, bsz=2227.2, num_updates=290300, lr=0.000185599, gnorm=0.354, loss_scale=1, train_wall=79, gb_free=39.6, wall=242470
2023-06-14 11:08:53 | INFO | train_inner | epoch 026:   8568 / 11284 loss=3.514, nll_loss=1.808, ppl=3.5, wps=71696, ups=1.21, wpb=59229.5, bsz=2217.9, num_updates=290400, lr=0.000185567, gnorm=0.344, loss_scale=1, train_wall=79, gb_free=39.6, wall=242553
2023-06-14 11:10:17 | INFO | train_inner | epoch 026:   8668 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=70293.5, ups=1.18, wpb=59345.6, bsz=2233.3, num_updates=290500, lr=0.000185535, gnorm=0.336, loss_scale=1, train_wall=80, gb_free=39.6, wall=242638
2023-06-14 11:11:41 | INFO | train_inner | epoch 026:   8768 / 11284 loss=3.51, nll_loss=1.802, ppl=3.49, wps=70315.3, ups=1.18, wpb=59406.9, bsz=2245.8, num_updates=290600, lr=0.000185504, gnorm=0.364, loss_scale=1, train_wall=81, gb_free=39.6, wall=242722
2023-06-14 11:13:04 | INFO | train_inner | epoch 026:   8868 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=71863.5, ups=1.21, wpb=59497.8, bsz=2160.2, num_updates=290700, lr=0.000185472, gnorm=0.332, loss_scale=1, train_wall=79, gb_free=39.6, wall=242805
2023-06-14 11:14:27 | INFO | train_inner | epoch 026:   8968 / 11284 loss=3.51, nll_loss=1.803, ppl=3.49, wps=71464.8, ups=1.2, wpb=59362.7, bsz=2283.1, num_updates=290800, lr=0.00018544, gnorm=0.339, loss_scale=2, train_wall=79, gb_free=39.5, wall=242888
2023-06-14 11:15:51 | INFO | train_inner | epoch 026:   9068 / 11284 loss=3.488, nll_loss=1.779, ppl=3.43, wps=71418.6, ups=1.2, wpb=59523.5, bsz=2268.4, num_updates=290900, lr=0.000185408, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.6, wall=242971
2023-06-14 11:17:14 | INFO | train_inner | epoch 026:   9168 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=71247.1, ups=1.2, wpb=59506.3, bsz=2240.3, num_updates=291000, lr=0.000185376, gnorm=0.339, loss_scale=2, train_wall=80, gb_free=39.3, wall=243055
2023-06-14 11:18:37 | INFO | train_inner | epoch 026:   9268 / 11284 loss=3.514, nll_loss=1.808, ppl=3.5, wps=71754.3, ups=1.2, wpb=59793.8, bsz=2356.6, num_updates=291100, lr=0.000185344, gnorm=0.343, loss_scale=2, train_wall=80, gb_free=39.6, wall=243138
2023-06-14 11:20:00 | INFO | train_inner | epoch 026:   9368 / 11284 loss=3.501, nll_loss=1.793, ppl=3.46, wps=71871.9, ups=1.21, wpb=59361.4, bsz=2138.6, num_updates=291200, lr=0.000185312, gnorm=0.342, loss_scale=2, train_wall=78, gb_free=39.6, wall=243221
2023-06-14 11:21:23 | INFO | train_inner | epoch 026:   9468 / 11284 loss=3.512, nll_loss=1.805, ppl=3.49, wps=71963.2, ups=1.2, wpb=59744.8, bsz=2242.7, num_updates=291300, lr=0.000185281, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.5, wall=243304
2023-06-14 11:22:46 | INFO | train_inner | epoch 026:   9568 / 11284 loss=3.494, nll_loss=1.786, ppl=3.45, wps=71702.6, ups=1.2, wpb=59510.4, bsz=2183.1, num_updates=291400, lr=0.000185249, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.6, wall=243387
2023-06-14 11:24:09 | INFO | train_inner | epoch 026:   9668 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=71424.8, ups=1.2, wpb=59433.1, bsz=2256.3, num_updates=291500, lr=0.000185217, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.6, wall=243470
2023-06-14 11:25:33 | INFO | train_inner | epoch 026:   9768 / 11284 loss=3.513, nll_loss=1.806, ppl=3.5, wps=71324.2, ups=1.2, wpb=59371.9, bsz=2247.2, num_updates=291600, lr=0.000185185, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=243553
2023-06-14 11:26:56 | INFO | train_inner | epoch 026:   9868 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71353, ups=1.2, wpb=59425, bsz=2230.6, num_updates=291700, lr=0.000185153, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=243636
2023-06-14 11:28:19 | INFO | train_inner | epoch 026:   9968 / 11284 loss=3.5, nll_loss=1.792, ppl=3.46, wps=71926.5, ups=1.2, wpb=59743.7, bsz=2190, num_updates=291800, lr=0.000185122, gnorm=0.347, loss_scale=4, train_wall=79, gb_free=39.6, wall=243719
2023-06-14 11:28:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 11:29:43 | INFO | train_inner | epoch 026:  10069 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=70584.1, ups=1.18, wpb=59603.6, bsz=2321.8, num_updates=291900, lr=0.00018509, gnorm=0.343, loss_scale=2, train_wall=80, gb_free=39.6, wall=243804
2023-06-14 11:31:07 | INFO | train_inner | epoch 026:  10169 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=71544.2, ups=1.2, wpb=59781.6, bsz=2289.9, num_updates=292000, lr=0.000185058, gnorm=0.345, loss_scale=2, train_wall=80, gb_free=39.5, wall=243887
2023-06-14 11:32:30 | INFO | train_inner | epoch 026:  10269 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=71684.2, ups=1.2, wpb=59749.7, bsz=2214.2, num_updates=292100, lr=0.000185027, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.5, wall=243971
2023-06-14 11:33:53 | INFO | train_inner | epoch 026:  10369 / 11284 loss=3.515, nll_loss=1.808, ppl=3.5, wps=71710.8, ups=1.21, wpb=59320, bsz=2295, num_updates=292200, lr=0.000184995, gnorm=0.364, loss_scale=2, train_wall=79, gb_free=39.5, wall=244054
2023-06-14 11:35:15 | INFO | train_inner | epoch 026:  10469 / 11284 loss=3.507, nll_loss=1.799, ppl=3.48, wps=72790.9, ups=1.22, wpb=59445.2, bsz=2214.9, num_updates=292300, lr=0.000184963, gnorm=0.335, loss_scale=2, train_wall=78, gb_free=39.5, wall=244135
2023-06-14 11:36:37 | INFO | train_inner | epoch 026:  10569 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=72174.1, ups=1.21, wpb=59443.6, bsz=2245.8, num_updates=292400, lr=0.000184932, gnorm=0.353, loss_scale=2, train_wall=78, gb_free=39.6, wall=244218
2023-06-14 11:38:00 | INFO | train_inner | epoch 026:  10669 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=71421.7, ups=1.2, wpb=59426.2, bsz=2270.8, num_updates=292500, lr=0.0001849, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.6, wall=244301
2023-06-14 11:39:23 | INFO | train_inner | epoch 026:  10769 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=71851.5, ups=1.21, wpb=59522, bsz=2187.7, num_updates=292600, lr=0.000184868, gnorm=0.332, loss_scale=2, train_wall=79, gb_free=39.6, wall=244384
2023-06-14 11:40:46 | INFO | train_inner | epoch 026:  10869 / 11284 loss=3.511, nll_loss=1.804, ppl=3.49, wps=71697.6, ups=1.2, wpb=59656.6, bsz=2272.6, num_updates=292700, lr=0.000184837, gnorm=0.339, loss_scale=2, train_wall=79, gb_free=39.6, wall=244467
2023-06-14 11:42:09 | INFO | train_inner | epoch 026:  10969 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=71722.1, ups=1.21, wpb=59415.6, bsz=2204.2, num_updates=292800, lr=0.000184805, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.5, wall=244550
2023-06-14 11:43:32 | INFO | train_inner | epoch 026:  11069 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=71415.9, ups=1.2, wpb=59521.4, bsz=2305, num_updates=292900, lr=0.000184774, gnorm=0.332, loss_scale=4, train_wall=79, gb_free=39.5, wall=244633
2023-06-14 11:43:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 11:44:57 | INFO | train_inner | epoch 026:  11170 / 11284 loss=3.489, nll_loss=1.78, ppl=3.43, wps=70693.8, ups=1.19, wpb=59599.1, bsz=2251.2, num_updates=293000, lr=0.000184742, gnorm=0.339, loss_scale=2, train_wall=80, gb_free=39.6, wall=244717
2023-06-14 11:46:20 | INFO | train_inner | epoch 026:  11270 / 11284 loss=3.488, nll_loss=1.779, ppl=3.43, wps=71606.6, ups=1.2, wpb=59634.5, bsz=2211.8, num_updates=293100, lr=0.000184711, gnorm=0.359, loss_scale=2, train_wall=80, gb_free=39.1, wall=244801
2023-06-14 11:46:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-14 11:46:49 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 4.301 | nll_loss 2.619 | ppl 6.14 | bleu 20.75 | wps 3710.1 | wpb 2397.5 | bsz 71.5 | num_updates 293114 | best_loss 4.298
2023-06-14 11:46:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 293114 updates
2023-06-14 11:46:49 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint26.pt
2023-06-14 11:46:52 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint26.pt
2023-06-14 11:46:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint26.pt (epoch 26 @ 293114 updates, score 4.301) (writing took 5.525203509256244 seconds)
2023-06-14 11:46:55 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-06-14 11:46:55 | INFO | train | epoch 026 | loss 3.499 | nll_loss 1.79 | ppl 3.46 | wps 71440.4 | ups 1.2 | wpb 59499.9 | bsz 2227.6 | num_updates 293114 | lr 0.000184706 | gnorm 0.342 | loss_scale 2 | train_wall 8918 | gb_free 39.6 | wall 244836
2023-06-14 11:46:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-14 11:46:55 | INFO | fairseq.trainer | begin training epoch 27
2023-06-14 11:46:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-14 11:48:08 | INFO | train_inner | epoch 027:     86 / 11284 loss=3.499, nll_loss=1.79, ppl=3.46, wps=54696.3, ups=0.92, wpb=59139.4, bsz=2155.5, num_updates=293200, lr=0.000184679, gnorm=0.338, loss_scale=2, train_wall=80, gb_free=39.1, wall=244909
2023-06-14 11:49:34 | INFO | train_inner | epoch 027:    186 / 11284 loss=3.466, nll_loss=1.753, ppl=3.37, wps=69084, ups=1.16, wpb=59553.3, bsz=2238.4, num_updates=293300, lr=0.000184648, gnorm=0.344, loss_scale=2, train_wall=82, gb_free=39.6, wall=244995
2023-06-14 11:50:59 | INFO | train_inner | epoch 027:    286 / 11284 loss=3.482, nll_loss=1.771, ppl=3.41, wps=69879.2, ups=1.18, wpb=59359.4, bsz=2241.8, num_updates=293400, lr=0.000184616, gnorm=0.337, loss_scale=2, train_wall=81, gb_free=39.5, wall=245080
2023-06-14 11:52:22 | INFO | train_inner | epoch 027:    386 / 11284 loss=3.481, nll_loss=1.77, ppl=3.41, wps=71744.3, ups=1.2, wpb=59580.5, bsz=2214.3, num_updates=293500, lr=0.000184585, gnorm=0.35, loss_scale=2, train_wall=79, gb_free=39.6, wall=245163
2023-06-14 11:53:44 | INFO | train_inner | epoch 027:    486 / 11284 loss=3.492, nll_loss=1.783, ppl=3.44, wps=72695.6, ups=1.22, wpb=59444.2, bsz=2283.7, num_updates=293600, lr=0.000184553, gnorm=0.343, loss_scale=2, train_wall=78, gb_free=39.6, wall=245245
2023-06-14 11:55:06 | INFO | train_inner | epoch 027:    586 / 11284 loss=3.51, nll_loss=1.802, ppl=3.49, wps=72787, ups=1.23, wpb=59361.8, bsz=2246.8, num_updates=293700, lr=0.000184522, gnorm=0.342, loss_scale=2, train_wall=78, gb_free=39.6, wall=245326
2023-06-14 11:56:29 | INFO | train_inner | epoch 027:    686 / 11284 loss=3.5, nll_loss=1.792, ppl=3.46, wps=71340.7, ups=1.2, wpb=59557.8, bsz=2280.4, num_updates=293800, lr=0.000184491, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.5, wall=245410
2023-06-14 11:57:52 | INFO | train_inner | epoch 027:    786 / 11284 loss=3.491, nll_loss=1.781, ppl=3.44, wps=71696.7, ups=1.21, wpb=59458, bsz=2242.5, num_updates=293900, lr=0.000184459, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.2, wall=245493
2023-06-14 11:58:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 11:59:16 | INFO | train_inner | epoch 027:    887 / 11284 loss=3.504, nll_loss=1.795, ppl=3.47, wps=70921.2, ups=1.2, wpb=59219.3, bsz=2170, num_updates=294000, lr=0.000184428, gnorm=0.339, loss_scale=2, train_wall=80, gb_free=39.6, wall=245576
2023-06-14 12:00:39 | INFO | train_inner | epoch 027:    987 / 11284 loss=3.476, nll_loss=1.764, ppl=3.4, wps=71364.1, ups=1.2, wpb=59404.2, bsz=2186.3, num_updates=294100, lr=0.000184396, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.6, wall=245659
2023-06-14 12:02:01 | INFO | train_inner | epoch 027:   1087 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=72186.1, ups=1.22, wpb=59408.9, bsz=2231.9, num_updates=294200, lr=0.000184365, gnorm=0.343, loss_scale=2, train_wall=78, gb_free=39.6, wall=245742
2023-06-14 12:03:24 | INFO | train_inner | epoch 027:   1187 / 11284 loss=3.491, nll_loss=1.782, ppl=3.44, wps=72158.4, ups=1.21, wpb=59439.1, bsz=2272.6, num_updates=294300, lr=0.000184334, gnorm=0.349, loss_scale=2, train_wall=78, gb_free=39.6, wall=245824
2023-06-14 12:04:46 | INFO | train_inner | epoch 027:   1287 / 11284 loss=3.499, nll_loss=1.79, ppl=3.46, wps=72099.8, ups=1.21, wpb=59346.4, bsz=2344.2, num_updates=294400, lr=0.000184302, gnorm=0.356, loss_scale=2, train_wall=78, gb_free=39.6, wall=245906
2023-06-14 12:06:08 | INFO | train_inner | epoch 027:   1387 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=72050.1, ups=1.22, wpb=59297.4, bsz=2236.8, num_updates=294500, lr=0.000184271, gnorm=0.352, loss_scale=2, train_wall=78, gb_free=39.6, wall=245989
2023-06-14 12:07:31 | INFO | train_inner | epoch 027:   1487 / 11284 loss=3.51, nll_loss=1.802, ppl=3.49, wps=71920.2, ups=1.2, wpb=59838.9, bsz=2248, num_updates=294600, lr=0.00018424, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.6, wall=246072
2023-06-14 12:08:55 | INFO | train_inner | epoch 027:   1587 / 11284 loss=3.499, nll_loss=1.789, ppl=3.46, wps=71352.2, ups=1.2, wpb=59500.5, bsz=2242.8, num_updates=294700, lr=0.000184209, gnorm=0.336, loss_scale=2, train_wall=79, gb_free=38.5, wall=246155
2023-06-14 12:10:18 | INFO | train_inner | epoch 027:   1687 / 11284 loss=3.498, nll_loss=1.789, ppl=3.45, wps=71580.7, ups=1.2, wpb=59667.3, bsz=2316.9, num_updates=294800, lr=0.000184177, gnorm=0.348, loss_scale=2, train_wall=79, gb_free=39.6, wall=246239
2023-06-14 12:11:42 | INFO | train_inner | epoch 027:   1787 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=71475.2, ups=1.2, wpb=59612.6, bsz=2354.8, num_updates=294900, lr=0.000184146, gnorm=0.338, loss_scale=2, train_wall=79, gb_free=39.5, wall=246322
2023-06-14 12:12:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 12:13:04 | INFO | train_inner | epoch 027:   1888 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=72073.6, ups=1.21, wpb=59483.9, bsz=2228.1, num_updates=295000, lr=0.000184115, gnorm=0.342, loss_scale=2, train_wall=78, gb_free=39.6, wall=246405
2023-06-14 12:14:27 | INFO | train_inner | epoch 027:   1988 / 11284 loss=3.493, nll_loss=1.783, ppl=3.44, wps=71880.4, ups=1.21, wpb=59507.9, bsz=2172.5, num_updates=295100, lr=0.000184084, gnorm=0.348, loss_scale=2, train_wall=79, gb_free=39.6, wall=246487
2023-06-14 12:15:50 | INFO | train_inner | epoch 027:   2088 / 11284 loss=3.499, nll_loss=1.79, ppl=3.46, wps=71543.7, ups=1.2, wpb=59700.4, bsz=2334.8, num_updates=295200, lr=0.000184053, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.4, wall=246571
2023-06-14 12:17:13 | INFO | train_inner | epoch 027:   2188 / 11284 loss=3.492, nll_loss=1.782, ppl=3.44, wps=72004.3, ups=1.2, wpb=59757.6, bsz=2214.5, num_updates=295300, lr=0.000184021, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.6, wall=246654
2023-06-14 12:18:37 | INFO | train_inner | epoch 027:   2288 / 11284 loss=3.5, nll_loss=1.791, ppl=3.46, wps=71344.4, ups=1.2, wpb=59378.3, bsz=2261.7, num_updates=295400, lr=0.00018399, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=246737
2023-06-14 12:19:59 | INFO | train_inner | epoch 027:   2388 / 11284 loss=3.49, nll_loss=1.78, ppl=3.44, wps=71686.6, ups=1.21, wpb=59452.5, bsz=2250.7, num_updates=295500, lr=0.000183959, gnorm=0.338, loss_scale=2, train_wall=79, gb_free=39.3, wall=246820
2023-06-14 12:21:23 | INFO | train_inner | epoch 027:   2488 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=71578.7, ups=1.2, wpb=59513.1, bsz=2290, num_updates=295600, lr=0.000183928, gnorm=0.349, loss_scale=2, train_wall=79, gb_free=39.5, wall=246903
2023-06-14 12:22:46 | INFO | train_inner | epoch 027:   2588 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=71611.8, ups=1.21, wpb=59411, bsz=2254.7, num_updates=295700, lr=0.000183897, gnorm=0.343, loss_scale=2, train_wall=79, gb_free=39.5, wall=246986
2023-06-14 12:24:09 | INFO | train_inner | epoch 027:   2688 / 11284 loss=3.501, nll_loss=1.793, ppl=3.46, wps=71624, ups=1.2, wpb=59626.1, bsz=2261.5, num_updates=295800, lr=0.000183866, gnorm=0.334, loss_scale=2, train_wall=79, gb_free=39.6, wall=247069
2023-06-14 12:25:31 | INFO | train_inner | epoch 027:   2788 / 11284 loss=3.493, nll_loss=1.783, ppl=3.44, wps=71963.4, ups=1.21, wpb=59492.9, bsz=2156.8, num_updates=295900, lr=0.000183835, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.2, wall=247152
2023-06-14 12:26:54 | INFO | train_inner | epoch 027:   2888 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=72341.2, ups=1.22, wpb=59535.7, bsz=2054.6, num_updates=296000, lr=0.000183804, gnorm=0.344, loss_scale=4, train_wall=79, gb_free=39.6, wall=247234
2023-06-14 12:27:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 12:28:18 | INFO | train_inner | epoch 027:   2989 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=71072, ups=1.19, wpb=59723.4, bsz=2208, num_updates=296100, lr=0.000183773, gnorm=0.342, loss_scale=2, train_wall=80, gb_free=39.6, wall=247318
2023-06-14 12:29:41 | INFO | train_inner | epoch 027:   3089 / 11284 loss=3.486, nll_loss=1.776, ppl=3.42, wps=71603.6, ups=1.21, wpb=59381, bsz=2202.7, num_updates=296200, lr=0.000183742, gnorm=0.33, loss_scale=2, train_wall=79, gb_free=39.5, wall=247401
2023-06-14 12:31:03 | INFO | train_inner | epoch 027:   3189 / 11284 loss=3.492, nll_loss=1.783, ppl=3.44, wps=72299.6, ups=1.21, wpb=59603.4, bsz=2239.9, num_updates=296300, lr=0.000183711, gnorm=0.354, loss_scale=2, train_wall=79, gb_free=39.5, wall=247484
2023-06-14 12:32:25 | INFO | train_inner | epoch 027:   3289 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=73101, ups=1.23, wpb=59539.1, bsz=2194.3, num_updates=296400, lr=0.00018368, gnorm=0.346, loss_scale=2, train_wall=77, gb_free=39.6, wall=247565
2023-06-14 12:33:47 | INFO | train_inner | epoch 027:   3389 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=72307.2, ups=1.21, wpb=59623.5, bsz=2335.8, num_updates=296500, lr=0.000183649, gnorm=0.344, loss_scale=2, train_wall=78, gb_free=39.6, wall=247648
2023-06-14 12:35:10 | INFO | train_inner | epoch 027:   3489 / 11284 loss=3.492, nll_loss=1.783, ppl=3.44, wps=71669.7, ups=1.2, wpb=59521.3, bsz=2234.4, num_updates=296600, lr=0.000183618, gnorm=0.341, loss_scale=2, train_wall=79, gb_free=39.6, wall=247731
2023-06-14 12:36:33 | INFO | train_inner | epoch 027:   3589 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=71646.8, ups=1.2, wpb=59460, bsz=2076.9, num_updates=296700, lr=0.000183587, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.6, wall=247814
2023-06-14 12:37:55 | INFO | train_inner | epoch 027:   3689 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=72439.9, ups=1.22, wpb=59515.1, bsz=2119.4, num_updates=296800, lr=0.000183556, gnorm=0.361, loss_scale=2, train_wall=78, gb_free=39.6, wall=247896
2023-06-14 12:39:18 | INFO | train_inner | epoch 027:   3789 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=72124.8, ups=1.21, wpb=59398.9, bsz=2243.2, num_updates=296900, lr=0.000183525, gnorm=0.342, loss_scale=2, train_wall=78, gb_free=39.6, wall=247978
2023-06-14 12:40:41 | INFO | train_inner | epoch 027:   3889 / 11284 loss=3.493, nll_loss=1.783, ppl=3.44, wps=71351.3, ups=1.2, wpb=59270.3, bsz=2225.4, num_updates=297000, lr=0.000183494, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.6, wall=248061
2023-06-14 12:42:04 | INFO | train_inner | epoch 027:   3989 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=71390.2, ups=1.2, wpb=59358.3, bsz=2237.1, num_updates=297100, lr=0.000183463, gnorm=0.334, loss_scale=4, train_wall=79, gb_free=39.6, wall=248144
2023-06-14 12:42:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 12:43:27 | INFO | train_inner | epoch 027:   4090 / 11284 loss=3.507, nll_loss=1.799, ppl=3.48, wps=71410.5, ups=1.2, wpb=59373, bsz=2212.2, num_updates=297200, lr=0.000183432, gnorm=0.358, loss_scale=2, train_wall=79, gb_free=39.6, wall=248228
2023-06-14 12:44:50 | INFO | train_inner | epoch 027:   4190 / 11284 loss=3.491, nll_loss=1.781, ppl=3.44, wps=72066.2, ups=1.21, wpb=59644.3, bsz=2172.5, num_updates=297300, lr=0.000183401, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.5, wall=248310
2023-06-14 12:46:13 | INFO | train_inner | epoch 027:   4290 / 11284 loss=3.494, nll_loss=1.784, ppl=3.44, wps=71639.7, ups=1.21, wpb=59296.4, bsz=2233.7, num_updates=297400, lr=0.000183371, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.5, wall=248393
2023-06-14 12:47:36 | INFO | train_inner | epoch 027:   4390 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=71424.4, ups=1.2, wpb=59531, bsz=2311.7, num_updates=297500, lr=0.00018334, gnorm=0.341, loss_scale=2, train_wall=79, gb_free=39.5, wall=248476
2023-06-14 12:48:59 | INFO | train_inner | epoch 027:   4490 / 11284 loss=3.494, nll_loss=1.784, ppl=3.44, wps=71398.9, ups=1.2, wpb=59305.2, bsz=2278.7, num_updates=297600, lr=0.000183309, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.5, wall=248560
2023-06-14 12:50:22 | INFO | train_inner | epoch 027:   4590 / 11284 loss=3.499, nll_loss=1.79, ppl=3.46, wps=71340.9, ups=1.2, wpb=59462.9, bsz=2329.4, num_updates=297700, lr=0.000183278, gnorm=0.339, loss_scale=2, train_wall=79, gb_free=39.6, wall=248643
2023-06-14 12:51:45 | INFO | train_inner | epoch 027:   4690 / 11284 loss=3.505, nll_loss=1.797, ppl=3.47, wps=71685.2, ups=1.2, wpb=59535.9, bsz=2163.1, num_updates=297800, lr=0.000183247, gnorm=0.334, loss_scale=2, train_wall=79, gb_free=39.5, wall=248726
2023-06-14 12:53:08 | INFO | train_inner | epoch 027:   4790 / 11284 loss=3.479, nll_loss=1.768, ppl=3.41, wps=71788.4, ups=1.2, wpb=59632.2, bsz=2164.3, num_updates=297900, lr=0.000183217, gnorm=0.355, loss_scale=2, train_wall=79, gb_free=39.6, wall=248809
2023-06-14 12:54:32 | INFO | train_inner | epoch 027:   4890 / 11284 loss=3.489, nll_loss=1.779, ppl=3.43, wps=71144.6, ups=1.19, wpb=59540.7, bsz=2279.6, num_updates=298000, lr=0.000183186, gnorm=0.338, loss_scale=2, train_wall=80, gb_free=39.5, wall=248893
2023-06-14 12:55:55 | INFO | train_inner | epoch 027:   4990 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=71515.6, ups=1.2, wpb=59397.3, bsz=2213.1, num_updates=298100, lr=0.000183155, gnorm=0.33, loss_scale=2, train_wall=79, gb_free=39.5, wall=248976
2023-06-14 12:57:18 | INFO | train_inner | epoch 027:   5090 / 11284 loss=3.489, nll_loss=1.779, ppl=3.43, wps=72233.7, ups=1.21, wpb=59489.4, bsz=2256.5, num_updates=298200, lr=0.000183124, gnorm=0.344, loss_scale=4, train_wall=78, gb_free=39.6, wall=249058
2023-06-14 12:57:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 12:58:41 | INFO | train_inner | epoch 027:   5191 / 11284 loss=3.485, nll_loss=1.774, ppl=3.42, wps=71583.6, ups=1.2, wpb=59730.6, bsz=2247.4, num_updates=298300, lr=0.000183094, gnorm=0.336, loss_scale=2, train_wall=79, gb_free=39.6, wall=249142
2023-06-14 13:00:04 | INFO | train_inner | epoch 027:   5291 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=71434.5, ups=1.2, wpb=59385.4, bsz=2204.9, num_updates=298400, lr=0.000183063, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.7, wall=249225
2023-06-14 13:01:27 | INFO | train_inner | epoch 027:   5391 / 11284 loss=3.51, nll_loss=1.802, ppl=3.49, wps=71369.7, ups=1.2, wpb=59418.5, bsz=2280.2, num_updates=298500, lr=0.000183032, gnorm=0.348, loss_scale=2, train_wall=79, gb_free=39.5, wall=249308
2023-06-14 13:02:50 | INFO | train_inner | epoch 027:   5491 / 11284 loss=3.5, nll_loss=1.791, ppl=3.46, wps=71564.7, ups=1.2, wpb=59456.8, bsz=2178.9, num_updates=298600, lr=0.000183002, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.6, wall=249391
2023-06-14 13:04:13 | INFO | train_inner | epoch 027:   5591 / 11284 loss=3.491, nll_loss=1.781, ppl=3.44, wps=71552.5, ups=1.2, wpb=59409.3, bsz=2121.4, num_updates=298700, lr=0.000182971, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=39.6, wall=249474
2023-06-14 13:05:36 | INFO | train_inner | epoch 027:   5691 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=71740.1, ups=1.21, wpb=59411.3, bsz=2201.8, num_updates=298800, lr=0.00018294, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39, wall=249557
2023-06-14 13:07:00 | INFO | train_inner | epoch 027:   5791 / 11284 loss=3.505, nll_loss=1.798, ppl=3.48, wps=71042.3, ups=1.2, wpb=59300.6, bsz=2292.3, num_updates=298900, lr=0.00018291, gnorm=0.344, loss_scale=2, train_wall=80, gb_free=39.6, wall=249640
2023-06-14 13:08:23 | INFO | train_inner | epoch 027:   5891 / 11284 loss=3.506, nll_loss=1.798, ppl=3.48, wps=71400.6, ups=1.2, wpb=59596.6, bsz=2237, num_updates=299000, lr=0.000182879, gnorm=0.35, loss_scale=2, train_wall=79, gb_free=39.6, wall=249724
2023-06-14 13:09:47 | INFO | train_inner | epoch 027:   5991 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=71348.1, ups=1.2, wpb=59481.2, bsz=2207.4, num_updates=299100, lr=0.000182849, gnorm=0.343, loss_scale=2, train_wall=79, gb_free=39.5, wall=249807
2023-06-14 13:11:09 | INFO | train_inner | epoch 027:   6091 / 11284 loss=3.492, nll_loss=1.782, ppl=3.44, wps=72327.6, ups=1.21, wpb=59591, bsz=2176.2, num_updates=299200, lr=0.000182818, gnorm=0.342, loss_scale=2, train_wall=78, gb_free=39.6, wall=249890
2023-06-14 13:11:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 13:12:33 | INFO | train_inner | epoch 027:   6192 / 11284 loss=3.5, nll_loss=1.792, ppl=3.46, wps=71007.6, ups=1.19, wpb=59482.6, bsz=2225.2, num_updates=299300, lr=0.000182788, gnorm=0.354, loss_scale=2, train_wall=80, gb_free=39.6, wall=249973
2023-06-14 13:13:56 | INFO | train_inner | epoch 027:   6292 / 11284 loss=3.492, nll_loss=1.782, ppl=3.44, wps=71813, ups=1.2, wpb=59629.6, bsz=2203.6, num_updates=299400, lr=0.000182757, gnorm=0.35, loss_scale=2, train_wall=79, gb_free=39.5, wall=250056
2023-06-14 13:15:18 | INFO | train_inner | epoch 027:   6392 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=72211.6, ups=1.21, wpb=59640.3, bsz=2274.8, num_updates=299500, lr=0.000182727, gnorm=0.352, loss_scale=2, train_wall=78, gb_free=39.5, wall=250139
2023-06-14 13:16:41 | INFO | train_inner | epoch 027:   6492 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=72449.6, ups=1.22, wpb=59508.5, bsz=2300.5, num_updates=299600, lr=0.000182696, gnorm=0.342, loss_scale=2, train_wall=78, gb_free=39.5, wall=250221
2023-06-14 13:18:02 | INFO | train_inner | epoch 027:   6592 / 11284 loss=3.498, nll_loss=1.79, ppl=3.46, wps=72485.6, ups=1.22, wpb=59363.8, bsz=2184.2, num_updates=299700, lr=0.000182666, gnorm=0.332, loss_scale=2, train_wall=78, gb_free=39.6, wall=250303
2023-06-14 13:19:25 | INFO | train_inner | epoch 027:   6692 / 11284 loss=3.493, nll_loss=1.783, ppl=3.44, wps=72145.4, ups=1.21, wpb=59565.4, bsz=2172, num_updates=299800, lr=0.000182635, gnorm=0.343, loss_scale=2, train_wall=79, gb_free=39.4, wall=250386
2023-06-14 13:20:49 | INFO | train_inner | epoch 027:   6792 / 11284 loss=3.509, nll_loss=1.801, ppl=3.49, wps=71505.1, ups=1.2, wpb=59730.4, bsz=2233.3, num_updates=299900, lr=0.000182605, gnorm=0.348, loss_scale=2, train_wall=80, gb_free=39.6, wall=250469
2023-06-14 13:22:12 | INFO | train_inner | epoch 027:   6892 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=71128, ups=1.2, wpb=59298, bsz=2263, num_updates=300000, lr=0.000182574, gnorm=0.358, loss_scale=2, train_wall=79, gb_free=39.6, wall=250552
2023-06-14 13:23:35 | INFO | train_inner | epoch 027:   6992 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=71993.8, ups=1.21, wpb=59483.1, bsz=2157.5, num_updates=300100, lr=0.000182544, gnorm=0.349, loss_scale=2, train_wall=79, gb_free=39.6, wall=250635
2023-06-14 13:24:56 | INFO | train_inner | epoch 027:   7092 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=72435.5, ups=1.22, wpb=59366.3, bsz=2253.5, num_updates=300200, lr=0.000182513, gnorm=0.341, loss_scale=2, train_wall=78, gb_free=39.6, wall=250717
2023-06-14 13:25:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 13:26:20 | INFO | train_inner | epoch 027:   7193 / 11284 loss=3.505, nll_loss=1.797, ppl=3.48, wps=70855.3, ups=1.19, wpb=59362.3, bsz=2237.8, num_updates=300300, lr=0.000182483, gnorm=0.345, loss_scale=2, train_wall=80, gb_free=39.6, wall=250801
2023-06-14 13:27:44 | INFO | train_inner | epoch 027:   7293 / 11284 loss=3.499, nll_loss=1.791, ppl=3.46, wps=71553.8, ups=1.2, wpb=59612.4, bsz=2220.3, num_updates=300400, lr=0.000182453, gnorm=0.339, loss_scale=2, train_wall=79, gb_free=39.6, wall=250884
2023-06-14 13:29:07 | INFO | train_inner | epoch 027:   7393 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=71648.6, ups=1.2, wpb=59570.1, bsz=2226.8, num_updates=300500, lr=0.000182422, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.6, wall=250967
2023-06-14 13:30:29 | INFO | train_inner | epoch 027:   7493 / 11284 loss=3.49, nll_loss=1.78, ppl=3.44, wps=72625.5, ups=1.22, wpb=59454.6, bsz=2281.9, num_updates=300600, lr=0.000182392, gnorm=0.348, loss_scale=2, train_wall=78, gb_free=39.6, wall=251049
2023-06-14 13:31:51 | INFO | train_inner | epoch 027:   7593 / 11284 loss=3.505, nll_loss=1.798, ppl=3.48, wps=72422.1, ups=1.22, wpb=59552.3, bsz=2213.2, num_updates=300700, lr=0.000182362, gnorm=0.349, loss_scale=2, train_wall=78, gb_free=39.6, wall=251131
2023-06-14 13:33:13 | INFO | train_inner | epoch 027:   7693 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=72312.6, ups=1.21, wpb=59571.8, bsz=2265.1, num_updates=300800, lr=0.000182331, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.6, wall=251214
2023-06-14 13:34:36 | INFO | train_inner | epoch 027:   7793 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=71887.8, ups=1.2, wpb=59693.3, bsz=2228, num_updates=300900, lr=0.000182301, gnorm=0.335, loss_scale=2, train_wall=79, gb_free=39.6, wall=251297
2023-06-14 13:35:59 | INFO | train_inner | epoch 027:   7893 / 11284 loss=3.499, nll_loss=1.79, ppl=3.46, wps=71540.4, ups=1.2, wpb=59450.1, bsz=2194.6, num_updates=301000, lr=0.000182271, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.6, wall=251380
2023-06-14 13:37:21 | INFO | train_inner | epoch 027:   7993 / 11284 loss=3.499, nll_loss=1.79, ppl=3.46, wps=73106.3, ups=1.23, wpb=59600.5, bsz=2249.9, num_updates=301100, lr=0.00018224, gnorm=0.331, loss_scale=2, train_wall=78, gb_free=39.6, wall=251461
2023-06-14 13:38:43 | INFO | train_inner | epoch 027:   8093 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=72181.9, ups=1.21, wpb=59564.8, bsz=2305.5, num_updates=301200, lr=0.00018221, gnorm=0.345, loss_scale=2, train_wall=78, gb_free=39.6, wall=251544
2023-06-14 13:40:07 | INFO | train_inner | epoch 027:   8193 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=71519.5, ups=1.2, wpb=59442, bsz=2204.8, num_updates=301300, lr=0.00018218, gnorm=0.336, loss_scale=4, train_wall=79, gb_free=39.2, wall=251627
2023-06-14 13:41:30 | INFO | train_inner | epoch 027:   8293 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=70973.7, ups=1.19, wpb=59395.7, bsz=2251.4, num_updates=301400, lr=0.00018215, gnorm=0.339, loss_scale=4, train_wall=79, gb_free=39.5, wall=251711
2023-06-14 13:42:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 13:42:54 | INFO | train_inner | epoch 027:   8394 / 11284 loss=3.494, nll_loss=1.784, ppl=3.44, wps=71261.5, ups=1.2, wpb=59531.1, bsz=2166.2, num_updates=301500, lr=0.000182119, gnorm=0.346, loss_scale=2, train_wall=80, gb_free=39, wall=251794
2023-06-14 13:44:17 | INFO | train_inner | epoch 027:   8494 / 11284 loss=3.498, nll_loss=1.79, ppl=3.46, wps=71668.4, ups=1.2, wpb=59718.2, bsz=2231.7, num_updates=301600, lr=0.000182089, gnorm=0.332, loss_scale=2, train_wall=79, gb_free=39.6, wall=251878
2023-06-14 13:45:40 | INFO | train_inner | epoch 027:   8594 / 11284 loss=3.507, nll_loss=1.8, ppl=3.48, wps=71540, ups=1.2, wpb=59553.9, bsz=2263.6, num_updates=301700, lr=0.000182059, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=38.4, wall=251961
2023-06-14 13:47:03 | INFO | train_inner | epoch 027:   8694 / 11284 loss=3.501, nll_loss=1.793, ppl=3.46, wps=71647.5, ups=1.2, wpb=59579.2, bsz=2269.6, num_updates=301800, lr=0.000182029, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.6, wall=252044
2023-06-14 13:48:26 | INFO | train_inner | epoch 027:   8794 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=71911.1, ups=1.2, wpb=59694.1, bsz=2249.9, num_updates=301900, lr=0.000181999, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.6, wall=252127
2023-06-14 13:49:50 | INFO | train_inner | epoch 027:   8894 / 11284 loss=3.492, nll_loss=1.783, ppl=3.44, wps=71630, ups=1.2, wpb=59600, bsz=2232.8, num_updates=302000, lr=0.000181969, gnorm=0.35, loss_scale=2, train_wall=79, gb_free=39.4, wall=252210
2023-06-14 13:51:13 | INFO | train_inner | epoch 027:   8994 / 11284 loss=3.501, nll_loss=1.793, ppl=3.46, wps=71432.1, ups=1.2, wpb=59439.6, bsz=2278.1, num_updates=302100, lr=0.000181939, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.4, wall=252293
2023-06-14 13:52:35 | INFO | train_inner | epoch 027:   9094 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=72196.6, ups=1.21, wpb=59573.7, bsz=2185.5, num_updates=302200, lr=0.000181908, gnorm=0.346, loss_scale=2, train_wall=78, gb_free=38.7, wall=252376
2023-06-14 13:53:57 | INFO | train_inner | epoch 027:   9194 / 11284 loss=3.492, nll_loss=1.782, ppl=3.44, wps=72715.1, ups=1.22, wpb=59663.6, bsz=2188.4, num_updates=302300, lr=0.000181878, gnorm=0.336, loss_scale=2, train_wall=78, gb_free=39.6, wall=252458
2023-06-14 13:55:20 | INFO | train_inner | epoch 027:   9294 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=71938.9, ups=1.2, wpb=59702.5, bsz=2244.1, num_updates=302400, lr=0.000181848, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=252541
2023-06-14 13:56:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 13:56:43 | INFO | train_inner | epoch 027:   9395 / 11284 loss=3.501, nll_loss=1.793, ppl=3.46, wps=72389.4, ups=1.21, wpb=59694.8, bsz=2288.6, num_updates=302500, lr=0.000181818, gnorm=0.345, loss_scale=2, train_wall=78, gb_free=39.6, wall=252624
2023-06-14 13:58:05 | INFO | train_inner | epoch 027:   9495 / 11284 loss=3.489, nll_loss=1.779, ppl=3.43, wps=72230.4, ups=1.21, wpb=59451.5, bsz=2170.8, num_updates=302600, lr=0.000181788, gnorm=0.34, loss_scale=2, train_wall=78, gb_free=39.5, wall=252706
2023-06-14 13:59:29 | INFO | train_inner | epoch 027:   9595 / 11284 loss=3.509, nll_loss=1.801, ppl=3.49, wps=71318, ups=1.2, wpb=59513, bsz=2252.4, num_updates=302700, lr=0.000181758, gnorm=0.34, loss_scale=2, train_wall=80, gb_free=39.6, wall=252789
2023-06-14 14:00:52 | INFO | train_inner | epoch 027:   9695 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=71603.8, ups=1.2, wpb=59584.3, bsz=2232.9, num_updates=302800, lr=0.000181728, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.6, wall=252872
2023-06-14 14:02:15 | INFO | train_inner | epoch 027:   9795 / 11284 loss=3.506, nll_loss=1.798, ppl=3.48, wps=71717.4, ups=1.21, wpb=59492.9, bsz=2236.8, num_updates=302900, lr=0.000181698, gnorm=0.335, loss_scale=2, train_wall=79, gb_free=39.6, wall=252955
2023-06-14 14:03:38 | INFO | train_inner | epoch 027:   9895 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71751.2, ups=1.21, wpb=59403.2, bsz=2157.8, num_updates=303000, lr=0.000181668, gnorm=0.36, loss_scale=2, train_wall=79, gb_free=39.6, wall=253038
2023-06-14 14:05:01 | INFO | train_inner | epoch 027:   9995 / 11284 loss=3.505, nll_loss=1.797, ppl=3.47, wps=71303.9, ups=1.2, wpb=59410.2, bsz=2224, num_updates=303100, lr=0.000181638, gnorm=0.352, loss_scale=2, train_wall=79, gb_free=39.6, wall=253122
2023-06-14 14:06:24 | INFO | train_inner | epoch 027:  10095 / 11284 loss=3.501, nll_loss=1.792, ppl=3.46, wps=71433.1, ups=1.2, wpb=59438, bsz=2190.1, num_updates=303200, lr=0.000181608, gnorm=0.343, loss_scale=2, train_wall=79, gb_free=39.6, wall=253205
2023-06-14 14:07:47 | INFO | train_inner | epoch 027:  10195 / 11284 loss=3.505, nll_loss=1.798, ppl=3.48, wps=71700.5, ups=1.21, wpb=59431.8, bsz=2143.2, num_updates=303300, lr=0.000181578, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.6, wall=253288
2023-06-14 14:09:10 | INFO | train_inner | epoch 027:  10295 / 11284 loss=3.51, nll_loss=1.803, ppl=3.49, wps=71402.5, ups=1.21, wpb=59239, bsz=2172.2, num_updates=303400, lr=0.000181548, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=39.5, wall=253371
2023-06-14 14:10:33 | INFO | train_inner | epoch 027:  10395 / 11284 loss=3.51, nll_loss=1.803, ppl=3.49, wps=71851.2, ups=1.21, wpb=59592.2, bsz=2152.2, num_updates=303500, lr=0.000181518, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.6, wall=253454
2023-06-14 14:11:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 14:11:57 | INFO | train_inner | epoch 027:  10496 / 11284 loss=3.499, nll_loss=1.791, ppl=3.46, wps=70772.3, ups=1.19, wpb=59503.1, bsz=2180.7, num_updates=303600, lr=0.000181489, gnorm=0.342, loss_scale=2, train_wall=80, gb_free=39.6, wall=253538
2023-06-14 14:13:20 | INFO | train_inner | epoch 027:  10596 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=71425.9, ups=1.2, wpb=59414.4, bsz=2283.2, num_updates=303700, lr=0.000181459, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.6, wall=253621
2023-06-14 14:14:43 | INFO | train_inner | epoch 027:  10696 / 11284 loss=3.5, nll_loss=1.792, ppl=3.46, wps=71513.7, ups=1.21, wpb=59281.6, bsz=2216.1, num_updates=303800, lr=0.000181429, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.5, wall=253704
2023-06-14 14:16:06 | INFO | train_inner | epoch 027:  10796 / 11284 loss=3.481, nll_loss=1.77, ppl=3.41, wps=71716.3, ups=1.2, wpb=59630.9, bsz=2181.2, num_updates=303900, lr=0.000181399, gnorm=0.338, loss_scale=2, train_wall=79, gb_free=39.6, wall=253787
2023-06-14 14:17:30 | INFO | train_inner | epoch 027:  10896 / 11284 loss=3.498, nll_loss=1.79, ppl=3.46, wps=71532.4, ups=1.2, wpb=59553.8, bsz=2234.8, num_updates=304000, lr=0.000181369, gnorm=0.354, loss_scale=2, train_wall=79, gb_free=39.5, wall=253870
2023-06-14 14:18:52 | INFO | train_inner | epoch 027:  10996 / 11284 loss=3.494, nll_loss=1.786, ppl=3.45, wps=72203.5, ups=1.21, wpb=59607.3, bsz=2175.8, num_updates=304100, lr=0.000181339, gnorm=0.35, loss_scale=2, train_wall=78, gb_free=39.6, wall=253953
2023-06-14 14:20:15 | INFO | train_inner | epoch 027:  11096 / 11284 loss=3.518, nll_loss=1.812, ppl=3.51, wps=71641.2, ups=1.2, wpb=59474.6, bsz=2249.4, num_updates=304200, lr=0.000181309, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.6, wall=254036
2023-06-14 14:21:37 | INFO | train_inner | epoch 027:  11196 / 11284 loss=3.515, nll_loss=1.808, ppl=3.5, wps=72190.8, ups=1.21, wpb=59439.7, bsz=2204, num_updates=304300, lr=0.00018128, gnorm=0.345, loss_scale=2, train_wall=78, gb_free=39.5, wall=254118
2023-06-14 14:22:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-14 14:23:08 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 4.296 | nll_loss 2.615 | ppl 6.13 | bleu 20.76 | wps 3739.3 | wpb 2397.5 | bsz 71.5 | num_updates 304388 | best_loss 4.296
2023-06-14 14:23:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 304388 updates
2023-06-14 14:23:08 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint27.pt
2023-06-14 14:23:10 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint27.pt
2023-06-14 14:23:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint27.pt (epoch 27 @ 304388 updates, score 4.296) (writing took 7.397968828678131 seconds)
2023-06-14 14:23:16 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-06-14 14:23:16 | INFO | train | epoch 027 | loss 3.497 | nll_loss 1.788 | ppl 3.45 | wps 71510.9 | ups 1.2 | wpb 59500.9 | bsz 2227.3 | num_updates 304388 | lr 0.000181253 | gnorm 0.344 | loss_scale 2 | train_wall 8907 | gb_free 39.6 | wall 254216
2023-06-14 14:23:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-14 14:23:16 | INFO | fairseq.trainer | begin training epoch 28
2023-06-14 14:23:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-14 14:23:27 | INFO | train_inner | epoch 028:     12 / 11284 loss=3.489, nll_loss=1.779, ppl=3.43, wps=54328.8, ups=0.92, wpb=59357.5, bsz=2186, num_updates=304400, lr=0.00018125, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.6, wall=254227
2023-06-14 14:24:50 | INFO | train_inner | epoch 028:    112 / 11284 loss=3.485, nll_loss=1.774, ppl=3.42, wps=71897.6, ups=1.21, wpb=59556.8, bsz=2181, num_updates=304500, lr=0.00018122, gnorm=0.348, loss_scale=2, train_wall=79, gb_free=39.6, wall=254310
2023-06-14 14:26:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 14:26:14 | INFO | train_inner | epoch 028:    213 / 11284 loss=3.481, nll_loss=1.77, ppl=3.41, wps=70901.1, ups=1.19, wpb=59574, bsz=2218.7, num_updates=304600, lr=0.00018119, gnorm=0.347, loss_scale=2, train_wall=80, gb_free=39.6, wall=254394
2023-06-14 14:27:37 | INFO | train_inner | epoch 028:    313 / 11284 loss=3.486, nll_loss=1.775, ppl=3.42, wps=71416.8, ups=1.2, wpb=59436, bsz=2314.3, num_updates=304700, lr=0.000181161, gnorm=0.335, loss_scale=2, train_wall=79, gb_free=39.5, wall=254477
2023-06-14 14:29:00 | INFO | train_inner | epoch 028:    413 / 11284 loss=3.492, nll_loss=1.782, ppl=3.44, wps=71572.3, ups=1.21, wpb=59370.9, bsz=2240.8, num_updates=304800, lr=0.000181131, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.5, wall=254560
2023-06-14 14:30:23 | INFO | train_inner | epoch 028:    513 / 11284 loss=3.478, nll_loss=1.767, ppl=3.4, wps=71678.9, ups=1.2, wpb=59563.2, bsz=2302.2, num_updates=304900, lr=0.000181101, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.5, wall=254643
2023-06-14 14:31:46 | INFO | train_inner | epoch 028:    613 / 11284 loss=3.495, nll_loss=1.785, ppl=3.45, wps=71431.8, ups=1.2, wpb=59470.9, bsz=2212.1, num_updates=305000, lr=0.000181071, gnorm=0.348, loss_scale=2, train_wall=79, gb_free=39.6, wall=254727
2023-06-14 14:33:09 | INFO | train_inner | epoch 028:    713 / 11284 loss=3.479, nll_loss=1.768, ppl=3.41, wps=71763.7, ups=1.2, wpb=59586.7, bsz=2260.9, num_updates=305100, lr=0.000181042, gnorm=0.338, loss_scale=2, train_wall=79, gb_free=39.6, wall=254810
2023-06-14 14:34:31 | INFO | train_inner | epoch 028:    813 / 11284 loss=3.494, nll_loss=1.784, ppl=3.44, wps=72363.2, ups=1.22, wpb=59468, bsz=2242.7, num_updates=305200, lr=0.000181012, gnorm=0.353, loss_scale=2, train_wall=78, gb_free=39.6, wall=254892
2023-06-14 14:35:53 | INFO | train_inner | epoch 028:    913 / 11284 loss=3.495, nll_loss=1.785, ppl=3.45, wps=72169.8, ups=1.22, wpb=59296.2, bsz=2168.4, num_updates=305300, lr=0.000180983, gnorm=0.343, loss_scale=2, train_wall=78, gb_free=39.6, wall=254974
2023-06-14 14:37:17 | INFO | train_inner | epoch 028:   1013 / 11284 loss=3.477, nll_loss=1.765, ppl=3.4, wps=71196.6, ups=1.2, wpb=59540.3, bsz=2315.9, num_updates=305400, lr=0.000180953, gnorm=0.341, loss_scale=2, train_wall=80, gb_free=39.6, wall=255058
2023-06-14 14:38:40 | INFO | train_inner | epoch 028:   1113 / 11284 loss=3.5, nll_loss=1.791, ppl=3.46, wps=71492.1, ups=1.2, wpb=59384.4, bsz=2210.3, num_updates=305500, lr=0.000180923, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.6, wall=255141
2023-06-14 14:40:03 | INFO | train_inner | epoch 028:   1213 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=71555.7, ups=1.21, wpb=59315.8, bsz=2289.2, num_updates=305600, lr=0.000180894, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.6, wall=255224
2023-06-14 14:40:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 14:41:31 | INFO | train_inner | epoch 028:   1314 / 11284 loss=3.478, nll_loss=1.767, ppl=3.4, wps=67778.1, ups=1.14, wpb=59561.9, bsz=2240.3, num_updates=305700, lr=0.000180864, gnorm=0.348, loss_scale=2, train_wall=84, gb_free=39.6, wall=255312
2023-06-14 14:42:54 | INFO | train_inner | epoch 028:   1414 / 11284 loss=3.496, nll_loss=1.786, ppl=3.45, wps=71632.6, ups=1.21, wpb=59379.5, bsz=2293.5, num_updates=305800, lr=0.000180834, gnorm=0.359, loss_scale=2, train_wall=79, gb_free=39.5, wall=255394
2023-06-14 14:44:16 | INFO | train_inner | epoch 028:   1514 / 11284 loss=3.481, nll_loss=1.769, ppl=3.41, wps=72914.1, ups=1.22, wpb=59624.7, bsz=2163.8, num_updates=305900, lr=0.000180805, gnorm=0.336, loss_scale=2, train_wall=78, gb_free=39.5, wall=255476
2023-06-14 14:45:39 | INFO | train_inner | epoch 028:   1614 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=71832.6, ups=1.21, wpb=59575.5, bsz=2340.7, num_updates=306000, lr=0.000180775, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.5, wall=255559
2023-06-14 14:47:01 | INFO | train_inner | epoch 028:   1714 / 11284 loss=3.485, nll_loss=1.774, ppl=3.42, wps=71994.1, ups=1.21, wpb=59439, bsz=2220, num_updates=306100, lr=0.000180746, gnorm=0.349, loss_scale=2, train_wall=79, gb_free=39.6, wall=255642
2023-06-14 14:48:24 | INFO | train_inner | epoch 028:   1814 / 11284 loss=3.49, nll_loss=1.78, ppl=3.43, wps=71632.9, ups=1.2, wpb=59534.1, bsz=2291.3, num_updates=306200, lr=0.000180716, gnorm=0.328, loss_scale=2, train_wall=79, gb_free=39.6, wall=255725
2023-06-14 14:49:48 | INFO | train_inner | epoch 028:   1914 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=71249.1, ups=1.2, wpb=59345.1, bsz=2240.7, num_updates=306300, lr=0.000180687, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.6, wall=255808
2023-06-14 14:51:11 | INFO | train_inner | epoch 028:   2014 / 11284 loss=3.49, nll_loss=1.78, ppl=3.43, wps=71666.3, ups=1.2, wpb=59501, bsz=2212.1, num_updates=306400, lr=0.000180657, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.5, wall=255891
2023-06-14 14:52:33 | INFO | train_inner | epoch 028:   2114 / 11284 loss=3.49, nll_loss=1.781, ppl=3.44, wps=71930.4, ups=1.21, wpb=59614.8, bsz=2243.9, num_updates=306500, lr=0.000180628, gnorm=0.361, loss_scale=2, train_wall=79, gb_free=39.6, wall=255974
2023-06-14 14:53:56 | INFO | train_inner | epoch 028:   2214 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71606.1, ups=1.21, wpb=59400, bsz=2196.8, num_updates=306600, lr=0.000180598, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.6, wall=256057
2023-06-14 14:55:19 | INFO | train_inner | epoch 028:   2314 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=72240.7, ups=1.21, wpb=59582.8, bsz=2221.6, num_updates=306700, lr=0.000180569, gnorm=0.337, loss_scale=4, train_wall=78, gb_free=39.5, wall=256139
2023-06-14 14:56:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 14:56:43 | INFO | train_inner | epoch 028:   2415 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=71240.6, ups=1.19, wpb=59792.7, bsz=2183.3, num_updates=306800, lr=0.00018054, gnorm=0.335, loss_scale=2, train_wall=80, gb_free=39.5, wall=256223
2023-06-14 14:58:06 | INFO | train_inner | epoch 028:   2515 / 11284 loss=3.505, nll_loss=1.797, ppl=3.48, wps=71927.4, ups=1.21, wpb=59589.5, bsz=2192.6, num_updates=306900, lr=0.00018051, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.6, wall=256306
2023-06-14 14:59:28 | INFO | train_inner | epoch 028:   2615 / 11284 loss=3.508, nll_loss=1.8, ppl=3.48, wps=71719.5, ups=1.21, wpb=59418.4, bsz=2164.5, num_updates=307000, lr=0.000180481, gnorm=0.355, loss_scale=2, train_wall=79, gb_free=39.5, wall=256389
2023-06-14 15:00:51 | INFO | train_inner | epoch 028:   2715 / 11284 loss=3.481, nll_loss=1.77, ppl=3.41, wps=71534, ups=1.21, wpb=59361.2, bsz=2173.5, num_updates=307100, lr=0.000180451, gnorm=0.358, loss_scale=2, train_wall=79, gb_free=39.6, wall=256472
2023-06-14 15:02:14 | INFO | train_inner | epoch 028:   2815 / 11284 loss=3.508, nll_loss=1.8, ppl=3.48, wps=71600.8, ups=1.21, wpb=59378.2, bsz=2278.1, num_updates=307200, lr=0.000180422, gnorm=0.348, loss_scale=2, train_wall=79, gb_free=39.6, wall=256555
2023-06-14 15:03:38 | INFO | train_inner | epoch 028:   2915 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=71672, ups=1.2, wpb=59665.6, bsz=2271.3, num_updates=307300, lr=0.000180393, gnorm=0.35, loss_scale=2, train_wall=79, gb_free=39.6, wall=256638
2023-06-14 15:05:01 | INFO | train_inner | epoch 028:   3015 / 11284 loss=3.503, nll_loss=1.794, ppl=3.47, wps=71643.3, ups=1.2, wpb=59543.5, bsz=2178.2, num_updates=307400, lr=0.000180363, gnorm=0.355, loss_scale=2, train_wall=79, gb_free=39.5, wall=256721
2023-06-14 15:06:24 | INFO | train_inner | epoch 028:   3115 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=70982.6, ups=1.2, wpb=59332.5, bsz=2351.9, num_updates=307500, lr=0.000180334, gnorm=0.355, loss_scale=2, train_wall=80, gb_free=39.6, wall=256805
2023-06-14 15:07:47 | INFO | train_inner | epoch 028:   3215 / 11284 loss=3.486, nll_loss=1.776, ppl=3.42, wps=71650.6, ups=1.2, wpb=59556.8, bsz=2196.4, num_updates=307600, lr=0.000180305, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.6, wall=256888
2023-06-14 15:09:11 | INFO | train_inner | epoch 028:   3315 / 11284 loss=3.506, nll_loss=1.798, ppl=3.48, wps=71483, ups=1.2, wpb=59429.1, bsz=2169.6, num_updates=307700, lr=0.000180275, gnorm=0.336, loss_scale=2, train_wall=79, gb_free=39.6, wall=256971
2023-06-14 15:10:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 15:10:35 | INFO | train_inner | epoch 028:   3416 / 11284 loss=3.498, nll_loss=1.788, ppl=3.45, wps=70549.2, ups=1.19, wpb=59257.2, bsz=2236.8, num_updates=307800, lr=0.000180246, gnorm=0.353, loss_scale=2, train_wall=80, gb_free=39.7, wall=257055
2023-06-14 15:11:58 | INFO | train_inner | epoch 028:   3516 / 11284 loss=3.5, nll_loss=1.791, ppl=3.46, wps=71384.6, ups=1.2, wpb=59629.8, bsz=2228.3, num_updates=307900, lr=0.000180217, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=257139
2023-06-14 15:13:21 | INFO | train_inner | epoch 028:   3616 / 11284 loss=3.506, nll_loss=1.799, ppl=3.48, wps=71864.9, ups=1.2, wpb=59674.4, bsz=2304.6, num_updates=308000, lr=0.000180187, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.6, wall=257222
2023-06-14 15:14:44 | INFO | train_inner | epoch 028:   3716 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=72253.2, ups=1.21, wpb=59522.3, bsz=2288.1, num_updates=308100, lr=0.000180158, gnorm=0.34, loss_scale=2, train_wall=78, gb_free=39.5, wall=257304
2023-06-14 15:16:07 | INFO | train_inner | epoch 028:   3816 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71429.9, ups=1.2, wpb=59446.3, bsz=2287.5, num_updates=308200, lr=0.000180129, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=39.6, wall=257387
2023-06-14 15:17:30 | INFO | train_inner | epoch 028:   3916 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=71618, ups=1.2, wpb=59540.8, bsz=2234.9, num_updates=308300, lr=0.0001801, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.5, wall=257471
2023-06-14 15:18:53 | INFO | train_inner | epoch 028:   4016 / 11284 loss=3.502, nll_loss=1.793, ppl=3.47, wps=71689.3, ups=1.2, wpb=59589.8, bsz=2183.1, num_updates=308400, lr=0.000180071, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.6, wall=257554
2023-06-14 15:20:16 | INFO | train_inner | epoch 028:   4116 / 11284 loss=3.509, nll_loss=1.801, ppl=3.48, wps=71353.6, ups=1.2, wpb=59411.7, bsz=2231.1, num_updates=308500, lr=0.000180041, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.6, wall=257637
2023-06-14 15:21:39 | INFO | train_inner | epoch 028:   4216 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=71774.6, ups=1.2, wpb=59633.1, bsz=2170.2, num_updates=308600, lr=0.000180012, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=39.6, wall=257720
2023-06-14 15:23:02 | INFO | train_inner | epoch 028:   4316 / 11284 loss=3.495, nll_loss=1.785, ppl=3.45, wps=72499.6, ups=1.22, wpb=59532.7, bsz=2239.4, num_updates=308700, lr=0.000179983, gnorm=0.359, loss_scale=2, train_wall=78, gb_free=39.5, wall=257802
2023-06-14 15:24:24 | INFO | train_inner | epoch 028:   4416 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=71518.7, ups=1.21, wpb=59299, bsz=2281.2, num_updates=308800, lr=0.000179954, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.6, wall=257885
2023-06-14 15:25:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 15:25:48 | INFO | train_inner | epoch 028:   4517 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=70913.1, ups=1.19, wpb=59390.5, bsz=2176.5, num_updates=308900, lr=0.000179925, gnorm=0.346, loss_scale=2, train_wall=80, gb_free=39.6, wall=257969
2023-06-14 15:27:11 | INFO | train_inner | epoch 028:   4617 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=71915.5, ups=1.21, wpb=59499, bsz=2206.6, num_updates=309000, lr=0.000179896, gnorm=0.348, loss_scale=2, train_wall=79, gb_free=39.5, wall=258052
2023-06-14 15:28:34 | INFO | train_inner | epoch 028:   4717 / 11284 loss=3.501, nll_loss=1.793, ppl=3.47, wps=71350.8, ups=1.2, wpb=59602.9, bsz=2264.8, num_updates=309100, lr=0.000179867, gnorm=0.344, loss_scale=2, train_wall=80, gb_free=39.6, wall=258135
2023-06-14 15:29:58 | INFO | train_inner | epoch 028:   4817 / 11284 loss=3.475, nll_loss=1.764, ppl=3.4, wps=71416.6, ups=1.2, wpb=59366.3, bsz=2243.8, num_updates=309200, lr=0.000179838, gnorm=0.35, loss_scale=2, train_wall=79, gb_free=39.6, wall=258218
2023-06-14 15:31:19 | INFO | train_inner | epoch 028:   4917 / 11284 loss=3.481, nll_loss=1.77, ppl=3.41, wps=73132.8, ups=1.22, wpb=59837.2, bsz=2158.6, num_updates=309300, lr=0.000179808, gnorm=0.339, loss_scale=2, train_wall=78, gb_free=39.5, wall=258300
2023-06-14 15:32:41 | INFO | train_inner | epoch 028:   5017 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=72834.5, ups=1.22, wpb=59496.2, bsz=2267.4, num_updates=309400, lr=0.000179779, gnorm=0.348, loss_scale=2, train_wall=77, gb_free=39.6, wall=258382
2023-06-14 15:34:03 | INFO | train_inner | epoch 028:   5117 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=72362.9, ups=1.22, wpb=59526.7, bsz=2244.1, num_updates=309500, lr=0.00017975, gnorm=0.351, loss_scale=2, train_wall=78, gb_free=39.6, wall=258464
2023-06-14 15:35:26 | INFO | train_inner | epoch 028:   5217 / 11284 loss=3.489, nll_loss=1.779, ppl=3.43, wps=71336.7, ups=1.2, wpb=59299.8, bsz=2185.4, num_updates=309600, lr=0.000179721, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=258547
2023-06-14 15:36:50 | INFO | train_inner | epoch 028:   5317 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71236.1, ups=1.2, wpb=59385.2, bsz=2262.5, num_updates=309700, lr=0.000179692, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.6, wall=258630
2023-06-14 15:38:13 | INFO | train_inner | epoch 028:   5417 / 11284 loss=3.5, nll_loss=1.792, ppl=3.46, wps=71559.1, ups=1.2, wpb=59468.2, bsz=2293.2, num_updates=309800, lr=0.000179663, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.5, wall=258714
2023-06-14 15:39:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 15:39:37 | INFO | train_inner | epoch 028:   5518 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=70966.6, ups=1.19, wpb=59649, bsz=2249.7, num_updates=309900, lr=0.000179634, gnorm=0.346, loss_scale=2, train_wall=80, gb_free=39.6, wall=258798
2023-06-14 15:41:00 | INFO | train_inner | epoch 028:   5618 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=71591.1, ups=1.2, wpb=59438.7, bsz=2208.9, num_updates=310000, lr=0.000179605, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.6, wall=258881
2023-06-14 15:42:23 | INFO | train_inner | epoch 028:   5718 / 11284 loss=3.493, nll_loss=1.783, ppl=3.44, wps=71867.5, ups=1.21, wpb=59619.4, bsz=2242.5, num_updates=310100, lr=0.000179576, gnorm=0.343, loss_scale=2, train_wall=79, gb_free=39.5, wall=258964
2023-06-14 15:43:46 | INFO | train_inner | epoch 028:   5818 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=71837.8, ups=1.2, wpb=59789.6, bsz=2124.7, num_updates=310200, lr=0.000179547, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=259047
2023-06-14 15:45:09 | INFO | train_inner | epoch 028:   5918 / 11284 loss=3.502, nll_loss=1.793, ppl=3.47, wps=71698.9, ups=1.21, wpb=59459.6, bsz=2233.7, num_updates=310300, lr=0.000179518, gnorm=0.35, loss_scale=2, train_wall=79, gb_free=39.6, wall=259130
2023-06-14 15:46:32 | INFO | train_inner | epoch 028:   6018 / 11284 loss=3.493, nll_loss=1.784, ppl=3.44, wps=71890.3, ups=1.2, wpb=59788.2, bsz=2207.8, num_updates=310400, lr=0.00017949, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.6, wall=259213
2023-06-14 15:47:56 | INFO | train_inner | epoch 028:   6118 / 11284 loss=3.491, nll_loss=1.781, ppl=3.44, wps=71138.5, ups=1.2, wpb=59393.6, bsz=2375.7, num_updates=310500, lr=0.000179461, gnorm=0.349, loss_scale=2, train_wall=79, gb_free=39.6, wall=259296
2023-06-14 15:49:19 | INFO | train_inner | epoch 028:   6218 / 11284 loss=3.508, nll_loss=1.801, ppl=3.48, wps=71539.9, ups=1.2, wpb=59399.7, bsz=2247.1, num_updates=310600, lr=0.000179432, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.6, wall=259379
2023-06-14 15:50:40 | INFO | train_inner | epoch 028:   6318 / 11284 loss=3.5, nll_loss=1.792, ppl=3.46, wps=72731.6, ups=1.23, wpb=59208.9, bsz=2224.3, num_updates=310700, lr=0.000179403, gnorm=0.358, loss_scale=2, train_wall=77, gb_free=39.6, wall=259461
2023-06-14 15:52:03 | INFO | train_inner | epoch 028:   6418 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=71995.6, ups=1.21, wpb=59329.6, bsz=2194.4, num_updates=310800, lr=0.000179374, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.6, wall=259543
2023-06-14 15:53:26 | INFO | train_inner | epoch 028:   6518 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71464.8, ups=1.2, wpb=59354.8, bsz=2226.5, num_updates=310900, lr=0.000179345, gnorm=0.349, loss_scale=2, train_wall=79, gb_free=39.5, wall=259626
2023-06-14 15:53:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 15:54:50 | INFO | train_inner | epoch 028:   6619 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=71063.8, ups=1.19, wpb=59611.8, bsz=2141.4, num_updates=311000, lr=0.000179316, gnorm=0.347, loss_scale=2, train_wall=80, gb_free=39.6, wall=259710
2023-06-14 15:56:13 | INFO | train_inner | epoch 028:   6719 / 11284 loss=3.49, nll_loss=1.781, ppl=3.44, wps=71201.7, ups=1.2, wpb=59374.1, bsz=2196, num_updates=311100, lr=0.000179287, gnorm=0.343, loss_scale=2, train_wall=79, gb_free=39.6, wall=259794
2023-06-14 15:57:36 | INFO | train_inner | epoch 028:   6819 / 11284 loss=3.481, nll_loss=1.77, ppl=3.41, wps=71708.4, ups=1.2, wpb=59600.8, bsz=2237.7, num_updates=311200, lr=0.000179259, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.6, wall=259877
2023-06-14 15:58:59 | INFO | train_inner | epoch 028:   6919 / 11284 loss=3.499, nll_loss=1.79, ppl=3.46, wps=71343.4, ups=1.2, wpb=59296.6, bsz=2300.9, num_updates=311300, lr=0.00017923, gnorm=0.331, loss_scale=2, train_wall=79, gb_free=39.6, wall=259960
2023-06-14 16:00:22 | INFO | train_inner | epoch 028:   7019 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=72181, ups=1.21, wpb=59654, bsz=2217.1, num_updates=311400, lr=0.000179201, gnorm=0.352, loss_scale=2, train_wall=79, gb_free=39.4, wall=260042
2023-06-14 16:01:44 | INFO | train_inner | epoch 028:   7119 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=73014.3, ups=1.22, wpb=59814.2, bsz=2213.2, num_updates=311500, lr=0.000179172, gnorm=0.344, loss_scale=2, train_wall=78, gb_free=39.6, wall=260124
2023-06-14 16:03:06 | INFO | train_inner | epoch 028:   7219 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=72580.9, ups=1.22, wpb=59395.2, bsz=2182, num_updates=311600, lr=0.000179144, gnorm=0.358, loss_scale=2, train_wall=78, gb_free=39.6, wall=260206
2023-06-14 16:04:27 | INFO | train_inner | epoch 028:   7319 / 11284 loss=3.493, nll_loss=1.783, ppl=3.44, wps=72811.8, ups=1.22, wpb=59491.4, bsz=2209, num_updates=311700, lr=0.000179115, gnorm=0.356, loss_scale=2, train_wall=78, gb_free=39.5, wall=260288
2023-06-14 16:05:50 | INFO | train_inner | epoch 028:   7419 / 11284 loss=3.493, nll_loss=1.784, ppl=3.44, wps=71865, ups=1.2, wpb=59697.5, bsz=2174.8, num_updates=311800, lr=0.000179086, gnorm=0.338, loss_scale=2, train_wall=79, gb_free=39.6, wall=260371
2023-06-14 16:07:14 | INFO | train_inner | epoch 028:   7519 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=71543.8, ups=1.2, wpb=59511.3, bsz=2227.7, num_updates=311900, lr=0.000179057, gnorm=0.359, loss_scale=2, train_wall=79, gb_free=39.6, wall=260454
2023-06-14 16:08:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 16:08:37 | INFO | train_inner | epoch 028:   7620 / 11284 loss=3.492, nll_loss=1.782, ppl=3.44, wps=71082.7, ups=1.19, wpb=59610.2, bsz=2183.7, num_updates=312000, lr=0.000179029, gnorm=0.333, loss_scale=2, train_wall=80, gb_free=38.9, wall=260538
2023-06-14 16:10:01 | INFO | train_inner | epoch 028:   7720 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71475.9, ups=1.2, wpb=59597.8, bsz=2215, num_updates=312100, lr=0.000179, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.3, wall=260621
2023-06-14 16:11:24 | INFO | train_inner | epoch 028:   7820 / 11284 loss=3.5, nll_loss=1.792, ppl=3.46, wps=71208.9, ups=1.2, wpb=59365.3, bsz=2291.1, num_updates=312200, lr=0.000178971, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.3, wall=260705
2023-06-14 16:12:48 | INFO | train_inner | epoch 028:   7920 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=71334, ups=1.2, wpb=59418, bsz=2258.1, num_updates=312300, lr=0.000178943, gnorm=0.336, loss_scale=2, train_wall=79, gb_free=39.5, wall=260788
2023-06-14 16:14:10 | INFO | train_inner | epoch 028:   8020 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=72031.6, ups=1.21, wpb=59653.2, bsz=2234.8, num_updates=312400, lr=0.000178914, gnorm=0.327, loss_scale=2, train_wall=79, gb_free=39.6, wall=260871
2023-06-14 16:15:34 | INFO | train_inner | epoch 028:   8120 / 11284 loss=3.49, nll_loss=1.78, ppl=3.44, wps=71493.7, ups=1.2, wpb=59509, bsz=2253, num_updates=312500, lr=0.000178885, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.6, wall=260954
2023-06-14 16:16:57 | INFO | train_inner | epoch 028:   8220 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=71875.4, ups=1.2, wpb=59665, bsz=2195.1, num_updates=312600, lr=0.000178857, gnorm=0.334, loss_scale=2, train_wall=79, gb_free=39.6, wall=261037
2023-06-14 16:18:20 | INFO | train_inner | epoch 028:   8320 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=71597, ups=1.21, wpb=59402.9, bsz=2186.1, num_updates=312700, lr=0.000178828, gnorm=0.339, loss_scale=2, train_wall=79, gb_free=39.6, wall=261120
2023-06-14 16:19:42 | INFO | train_inner | epoch 028:   8420 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=72094.5, ups=1.21, wpb=59398.8, bsz=2165.9, num_updates=312800, lr=0.0001788, gnorm=0.355, loss_scale=2, train_wall=78, gb_free=39.5, wall=261203
2023-06-14 16:21:04 | INFO | train_inner | epoch 028:   8520 / 11284 loss=3.486, nll_loss=1.776, ppl=3.42, wps=72770.7, ups=1.22, wpb=59504.8, bsz=2270, num_updates=312900, lr=0.000178771, gnorm=0.358, loss_scale=2, train_wall=77, gb_free=39.6, wall=261284
2023-06-14 16:22:26 | INFO | train_inner | epoch 028:   8620 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=72371.3, ups=1.22, wpb=59538.6, bsz=2162.9, num_updates=313000, lr=0.000178743, gnorm=0.35, loss_scale=4, train_wall=78, gb_free=39.6, wall=261367
2023-06-14 16:23:49 | INFO | train_inner | epoch 028:   8720 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=71475, ups=1.2, wpb=59489.5, bsz=2265.5, num_updates=313100, lr=0.000178714, gnorm=0.336, loss_scale=4, train_wall=79, gb_free=39.6, wall=261450
2023-06-14 16:24:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 16:25:13 | INFO | train_inner | epoch 028:   8821 / 11284 loss=3.493, nll_loss=1.784, ppl=3.44, wps=70980, ups=1.19, wpb=59511.4, bsz=2230.2, num_updates=313200, lr=0.000178685, gnorm=0.344, loss_scale=2, train_wall=80, gb_free=39.6, wall=261534
2023-06-14 16:26:36 | INFO | train_inner | epoch 028:   8921 / 11284 loss=3.493, nll_loss=1.784, ppl=3.44, wps=71498.3, ups=1.2, wpb=59413, bsz=2209.4, num_updates=313300, lr=0.000178657, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.5, wall=261617
2023-06-14 16:27:59 | INFO | train_inner | epoch 028:   9021 / 11284 loss=3.504, nll_loss=1.797, ppl=3.47, wps=71594.5, ups=1.2, wpb=59574.1, bsz=2217.9, num_updates=313400, lr=0.000178628, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=261700
2023-06-14 16:29:22 | INFO | train_inner | epoch 028:   9121 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71728.6, ups=1.2, wpb=59565.9, bsz=2131.6, num_updates=313500, lr=0.0001786, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.6, wall=261783
2023-06-14 16:30:46 | INFO | train_inner | epoch 028:   9221 / 11284 loss=3.476, nll_loss=1.765, ppl=3.4, wps=71427.4, ups=1.2, wpb=59530, bsz=2250.7, num_updates=313600, lr=0.000178571, gnorm=0.333, loss_scale=2, train_wall=80, gb_free=39.6, wall=261866
2023-06-14 16:32:09 | INFO | train_inner | epoch 028:   9321 / 11284 loss=3.498, nll_loss=1.79, ppl=3.46, wps=71941.7, ups=1.21, wpb=59701.2, bsz=2169.4, num_updates=313700, lr=0.000178543, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.6, wall=261949
2023-06-14 16:33:32 | INFO | train_inner | epoch 028:   9421 / 11284 loss=3.499, nll_loss=1.79, ppl=3.46, wps=71329, ups=1.2, wpb=59367.4, bsz=2221.4, num_updates=313800, lr=0.000178515, gnorm=0.349, loss_scale=2, train_wall=79, gb_free=39.6, wall=262033
2023-06-14 16:34:55 | INFO | train_inner | epoch 028:   9521 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=71807.2, ups=1.2, wpb=59604.7, bsz=2241.5, num_updates=313900, lr=0.000178486, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.6, wall=262116
2023-06-14 16:36:18 | INFO | train_inner | epoch 028:   9621 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=71592.2, ups=1.2, wpb=59509.8, bsz=2125.1, num_updates=314000, lr=0.000178458, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.6, wall=262199
2023-06-14 16:37:41 | INFO | train_inner | epoch 028:   9721 / 11284 loss=3.474, nll_loss=1.763, ppl=3.39, wps=71674.8, ups=1.2, wpb=59582.2, bsz=2336.6, num_updates=314100, lr=0.000178429, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=39.6, wall=262282
2023-06-14 16:38:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 16:39:05 | INFO | train_inner | epoch 028:   9822 / 11284 loss=3.5, nll_loss=1.791, ppl=3.46, wps=71263.9, ups=1.2, wpb=59555.9, bsz=2185.7, num_updates=314200, lr=0.000178401, gnorm=0.344, loss_scale=2, train_wall=80, gb_free=39.6, wall=262365
2023-06-14 16:40:28 | INFO | train_inner | epoch 028:   9922 / 11284 loss=3.499, nll_loss=1.791, ppl=3.46, wps=71593.6, ups=1.2, wpb=59449.9, bsz=2255.7, num_updates=314300, lr=0.000178372, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=262448
2023-06-14 16:41:51 | INFO | train_inner | epoch 028:  10022 / 11284 loss=3.486, nll_loss=1.776, ppl=3.43, wps=71529.8, ups=1.21, wpb=59353.3, bsz=2170.5, num_updates=314400, lr=0.000178344, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.6, wall=262531
2023-06-14 16:43:14 | INFO | train_inner | epoch 028:  10122 / 11284 loss=3.499, nll_loss=1.791, ppl=3.46, wps=71234.7, ups=1.2, wpb=59452.6, bsz=2246, num_updates=314500, lr=0.000178316, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=262615
2023-06-14 16:44:37 | INFO | train_inner | epoch 028:  10222 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=71852.8, ups=1.21, wpb=59568.3, bsz=2265.4, num_updates=314600, lr=0.000178287, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=39.6, wall=262698
2023-06-14 16:45:59 | INFO | train_inner | epoch 028:  10322 / 11284 loss=3.497, nll_loss=1.789, ppl=3.46, wps=72469.6, ups=1.22, wpb=59482.2, bsz=2246.6, num_updates=314700, lr=0.000178259, gnorm=0.342, loss_scale=2, train_wall=78, gb_free=39.6, wall=262780
2023-06-14 16:47:22 | INFO | train_inner | epoch 028:  10422 / 11284 loss=3.507, nll_loss=1.799, ppl=3.48, wps=72284.1, ups=1.22, wpb=59452.2, bsz=2155.8, num_updates=314800, lr=0.000178231, gnorm=0.341, loss_scale=2, train_wall=78, gb_free=39.6, wall=262862
2023-06-14 16:48:43 | INFO | train_inner | epoch 028:  10522 / 11284 loss=3.509, nll_loss=1.802, ppl=3.49, wps=72928.2, ups=1.23, wpb=59501.6, bsz=2150.9, num_updates=314900, lr=0.000178202, gnorm=0.346, loss_scale=2, train_wall=77, gb_free=39.5, wall=262944
2023-06-14 16:50:06 | INFO | train_inner | epoch 028:  10622 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=71721.9, ups=1.2, wpb=59619.7, bsz=2290.6, num_updates=315000, lr=0.000178174, gnorm=0.331, loss_scale=2, train_wall=79, gb_free=39.6, wall=263027
2023-06-14 16:51:29 | INFO | train_inner | epoch 028:  10722 / 11284 loss=3.508, nll_loss=1.8, ppl=3.48, wps=71378.9, ups=1.2, wpb=59417.6, bsz=2188.4, num_updates=315100, lr=0.000178146, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=39.6, wall=263110
2023-06-14 16:52:53 | INFO | train_inner | epoch 028:  10822 / 11284 loss=3.514, nll_loss=1.807, ppl=3.5, wps=71591.7, ups=1.2, wpb=59564.4, bsz=2209.7, num_updates=315200, lr=0.000178118, gnorm=0.342, loss_scale=4, train_wall=79, gb_free=39.4, wall=263193
2023-06-14 16:53:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 16:54:17 | INFO | train_inner | epoch 028:  10923 / 11284 loss=3.506, nll_loss=1.798, ppl=3.48, wps=70821.4, ups=1.19, wpb=59562.7, bsz=2235.3, num_updates=315300, lr=0.000178089, gnorm=0.351, loss_scale=2, train_wall=80, gb_free=39.6, wall=263277
2023-06-14 16:55:40 | INFO | train_inner | epoch 028:  11023 / 11284 loss=3.515, nll_loss=1.809, ppl=3.5, wps=71074.5, ups=1.2, wpb=59465.6, bsz=2222.9, num_updates=315400, lr=0.000178061, gnorm=0.347, loss_scale=2, train_wall=80, gb_free=39.4, wall=263361
2023-06-14 16:57:04 | INFO | train_inner | epoch 028:  11123 / 11284 loss=3.493, nll_loss=1.784, ppl=3.44, wps=71641.2, ups=1.2, wpb=59640.3, bsz=2236.1, num_updates=315500, lr=0.000178033, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=263444
2023-06-14 16:58:28 | INFO | train_inner | epoch 028:  11223 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=70521.1, ups=1.19, wpb=59244.4, bsz=2199.2, num_updates=315600, lr=0.000178005, gnorm=0.353, loss_scale=2, train_wall=80, gb_free=39.5, wall=263528
2023-06-14 16:59:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-14 16:59:36 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 4.284 | nll_loss 2.601 | ppl 6.07 | bleu 21.18 | wps 3704.9 | wpb 2397.5 | bsz 71.5 | num_updates 315661 | best_loss 4.284
2023-06-14 16:59:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 315661 updates
2023-06-14 16:59:36 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint28.pt
2023-06-14 16:59:39 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint28.pt
2023-06-14 16:59:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint28.pt (epoch 28 @ 315661 updates, score 4.284) (writing took 8.32721471041441 seconds)
2023-06-14 16:59:45 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-06-14 16:59:45 | INFO | train | epoch 028 | loss 3.495 | nll_loss 1.786 | ppl 3.45 | wps 71439.2 | ups 1.2 | wpb 59501.1 | bsz 2227.6 | num_updates 315661 | lr 0.000177988 | gnorm 0.346 | loss_scale 2 | train_wall 8916 | gb_free 39.6 | wall 263605
2023-06-14 16:59:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-14 16:59:45 | INFO | fairseq.trainer | begin training epoch 29
2023-06-14 16:59:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-14 17:00:19 | INFO | train_inner | epoch 029:     39 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=53611.7, ups=0.9, wpb=59434.2, bsz=2230.7, num_updates=315700, lr=0.000177977, gnorm=0.349, loss_scale=2, train_wall=80, gb_free=39.6, wall=263639
2023-06-14 17:01:43 | INFO | train_inner | epoch 029:    139 / 11284 loss=3.492, nll_loss=1.783, ppl=3.44, wps=70495.4, ups=1.18, wpb=59845.1, bsz=2217.4, num_updates=315800, lr=0.000177948, gnorm=0.337, loss_scale=2, train_wall=81, gb_free=39.6, wall=263724
2023-06-14 17:03:08 | INFO | train_inner | epoch 029:    239 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=70492.1, ups=1.18, wpb=59745.1, bsz=2246.5, num_updates=315900, lr=0.00017792, gnorm=0.353, loss_scale=2, train_wall=81, gb_free=39.6, wall=263809
2023-06-14 17:04:33 | INFO | train_inner | epoch 029:    339 / 11284 loss=3.482, nll_loss=1.771, ppl=3.41, wps=70268.9, ups=1.18, wpb=59622.3, bsz=2242, num_updates=316000, lr=0.000177892, gnorm=0.349, loss_scale=2, train_wall=81, gb_free=39.6, wall=263894
2023-06-14 17:05:56 | INFO | train_inner | epoch 029:    439 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71615.8, ups=1.2, wpb=59537.8, bsz=2233.9, num_updates=316100, lr=0.000177864, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=39.5, wall=263977
2023-06-14 17:07:19 | INFO | train_inner | epoch 029:    539 / 11284 loss=3.492, nll_loss=1.782, ppl=3.44, wps=71681.9, ups=1.2, wpb=59561.7, bsz=2209.7, num_updates=316200, lr=0.000177836, gnorm=0.335, loss_scale=2, train_wall=79, gb_free=39.6, wall=264060
2023-06-14 17:08:42 | INFO | train_inner | epoch 029:    639 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=72164.8, ups=1.21, wpb=59496, bsz=2161.2, num_updates=316300, lr=0.000177808, gnorm=0.341, loss_scale=4, train_wall=79, gb_free=39.6, wall=264142
2023-06-14 17:09:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 17:10:06 | INFO | train_inner | epoch 029:    740 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=70832, ups=1.19, wpb=59363.7, bsz=2249.2, num_updates=316400, lr=0.00017778, gnorm=0.341, loss_scale=2, train_wall=79, gb_free=39.6, wall=264226
2023-06-14 17:11:28 | INFO | train_inner | epoch 029:    840 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=72566.8, ups=1.22, wpb=59637.7, bsz=2325.7, num_updates=316500, lr=0.000177751, gnorm=0.353, loss_scale=2, train_wall=78, gb_free=39.5, wall=264308
2023-06-14 17:12:51 | INFO | train_inner | epoch 029:    940 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=71661.1, ups=1.2, wpb=59749.2, bsz=2254.2, num_updates=316600, lr=0.000177723, gnorm=0.33, loss_scale=2, train_wall=79, gb_free=39.6, wall=264392
2023-06-14 17:14:14 | INFO | train_inner | epoch 029:   1040 / 11284 loss=3.49, nll_loss=1.78, ppl=3.43, wps=71526.3, ups=1.2, wpb=59456.3, bsz=2193.7, num_updates=316700, lr=0.000177695, gnorm=0.359, loss_scale=2, train_wall=79, gb_free=39.5, wall=264475
2023-06-14 17:15:37 | INFO | train_inner | epoch 029:   1140 / 11284 loss=3.5, nll_loss=1.791, ppl=3.46, wps=71718.9, ups=1.2, wpb=59616.8, bsz=2192.7, num_updates=316800, lr=0.000177667, gnorm=0.338, loss_scale=2, train_wall=79, gb_free=39.6, wall=264558
2023-06-14 17:17:01 | INFO | train_inner | epoch 029:   1240 / 11284 loss=3.487, nll_loss=1.776, ppl=3.43, wps=71519.4, ups=1.2, wpb=59516.3, bsz=2239.7, num_updates=316900, lr=0.000177639, gnorm=0.349, loss_scale=2, train_wall=79, gb_free=39.6, wall=264641
2023-06-14 17:18:23 | INFO | train_inner | epoch 029:   1340 / 11284 loss=3.486, nll_loss=1.775, ppl=3.42, wps=71735.7, ups=1.21, wpb=59227.4, bsz=2215.7, num_updates=317000, lr=0.000177611, gnorm=0.352, loss_scale=2, train_wall=79, gb_free=39.6, wall=264724
2023-06-14 17:19:46 | INFO | train_inner | epoch 029:   1440 / 11284 loss=3.498, nll_loss=1.788, ppl=3.45, wps=71754.9, ups=1.21, wpb=59392.9, bsz=2174.5, num_updates=317100, lr=0.000177583, gnorm=0.343, loss_scale=2, train_wall=79, gb_free=39.6, wall=264807
2023-06-14 17:21:09 | INFO | train_inner | epoch 029:   1540 / 11284 loss=3.491, nll_loss=1.781, ppl=3.44, wps=71429.4, ups=1.2, wpb=59517.3, bsz=2280.4, num_updates=317200, lr=0.000177555, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.5, wall=264890
2023-06-14 17:22:33 | INFO | train_inner | epoch 029:   1640 / 11284 loss=3.482, nll_loss=1.771, ppl=3.41, wps=71513.3, ups=1.2, wpb=59619.5, bsz=2275.7, num_updates=317300, lr=0.000177527, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=264973
2023-06-14 17:23:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 17:23:57 | INFO | train_inner | epoch 029:   1741 / 11284 loss=3.489, nll_loss=1.78, ppl=3.43, wps=70889.6, ups=1.19, wpb=59528.9, bsz=2267, num_updates=317400, lr=0.000177499, gnorm=0.343, loss_scale=2, train_wall=80, gb_free=39.5, wall=265057
2023-06-14 17:25:20 | INFO | train_inner | epoch 029:   1841 / 11284 loss=3.479, nll_loss=1.767, ppl=3.4, wps=71456.3, ups=1.2, wpb=59493.4, bsz=2251.3, num_updates=317500, lr=0.000177471, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=39.5, wall=265140
2023-06-14 17:26:42 | INFO | train_inner | epoch 029:   1941 / 11284 loss=3.493, nll_loss=1.783, ppl=3.44, wps=72162, ups=1.22, wpb=59265.8, bsz=2206, num_updates=317600, lr=0.000177443, gnorm=0.348, loss_scale=2, train_wall=78, gb_free=39.6, wall=265223
2023-06-14 17:28:04 | INFO | train_inner | epoch 029:   2041 / 11284 loss=3.479, nll_loss=1.768, ppl=3.41, wps=72678.4, ups=1.21, wpb=59842.7, bsz=2248.9, num_updates=317700, lr=0.000177415, gnorm=0.342, loss_scale=2, train_wall=78, gb_free=39.5, wall=265305
2023-06-14 17:29:27 | INFO | train_inner | epoch 029:   2141 / 11284 loss=3.491, nll_loss=1.781, ppl=3.44, wps=72043.4, ups=1.21, wpb=59616.6, bsz=2246.9, num_updates=317800, lr=0.000177388, gnorm=0.359, loss_scale=2, train_wall=78, gb_free=39.6, wall=265388
2023-06-14 17:30:50 | INFO | train_inner | epoch 029:   2241 / 11284 loss=3.491, nll_loss=1.782, ppl=3.44, wps=71596.6, ups=1.21, wpb=59309.2, bsz=2206.5, num_updates=317900, lr=0.00017736, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.6, wall=265471
2023-06-14 17:32:12 | INFO | train_inner | epoch 029:   2341 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=72595.6, ups=1.22, wpb=59421.1, bsz=2173, num_updates=318000, lr=0.000177332, gnorm=0.347, loss_scale=2, train_wall=78, gb_free=39.5, wall=265552
2023-06-14 17:33:34 | INFO | train_inner | epoch 029:   2441 / 11284 loss=3.484, nll_loss=1.773, ppl=3.42, wps=72333, ups=1.22, wpb=59496.5, bsz=2188.2, num_updates=318100, lr=0.000177304, gnorm=0.347, loss_scale=2, train_wall=78, gb_free=39.6, wall=265635
2023-06-14 17:34:57 | INFO | train_inner | epoch 029:   2541 / 11284 loss=3.492, nll_loss=1.782, ppl=3.44, wps=71697.1, ups=1.21, wpb=59386.9, bsz=2234.3, num_updates=318200, lr=0.000177276, gnorm=0.365, loss_scale=2, train_wall=79, gb_free=39.6, wall=265717
2023-06-14 17:36:21 | INFO | train_inner | epoch 029:   2641 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=71295, ups=1.2, wpb=59622.3, bsz=2278.6, num_updates=318300, lr=0.000177248, gnorm=0.339, loss_scale=2, train_wall=80, gb_free=39.6, wall=265801
2023-06-14 17:37:43 | INFO | train_inner | epoch 029:   2741 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=71455.9, ups=1.21, wpb=59201.9, bsz=2181.1, num_updates=318400, lr=0.00017722, gnorm=0.349, loss_scale=4, train_wall=79, gb_free=39.6, wall=265884
2023-06-14 17:39:07 | INFO | train_inner | epoch 029:   2841 / 11284 loss=3.501, nll_loss=1.793, ppl=3.46, wps=70896.9, ups=1.19, wpb=59605.2, bsz=2260.3, num_updates=318500, lr=0.000177192, gnorm=0.332, loss_scale=4, train_wall=80, gb_free=39, wall=265968
2023-06-14 17:39:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 17:40:31 | INFO | train_inner | epoch 029:   2942 / 11284 loss=3.494, nll_loss=1.784, ppl=3.44, wps=71449.4, ups=1.2, wpb=59622.8, bsz=2157.5, num_updates=318600, lr=0.000177165, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.6, wall=266051
2023-06-14 17:41:54 | INFO | train_inner | epoch 029:   3042 / 11284 loss=3.485, nll_loss=1.774, ppl=3.42, wps=71344, ups=1.2, wpb=59344, bsz=2198.9, num_updates=318700, lr=0.000177137, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.6, wall=266135
2023-06-14 17:43:17 | INFO | train_inner | epoch 029:   3142 / 11284 loss=3.482, nll_loss=1.772, ppl=3.42, wps=72082.8, ups=1.21, wpb=59576.5, bsz=2243, num_updates=318800, lr=0.000177109, gnorm=0.347, loss_scale=2, train_wall=78, gb_free=39.6, wall=266217
2023-06-14 17:44:40 | INFO | train_inner | epoch 029:   3242 / 11284 loss=3.501, nll_loss=1.792, ppl=3.46, wps=71842.5, ups=1.2, wpb=59685.2, bsz=2215.5, num_updates=318900, lr=0.000177081, gnorm=0.35, loss_scale=2, train_wall=79, gb_free=39.6, wall=266300
2023-06-14 17:46:03 | INFO | train_inner | epoch 029:   3342 / 11284 loss=3.492, nll_loss=1.783, ppl=3.44, wps=71619.6, ups=1.21, wpb=59346.3, bsz=2149, num_updates=319000, lr=0.000177054, gnorm=0.359, loss_scale=2, train_wall=79, gb_free=39.5, wall=266383
2023-06-14 17:47:26 | INFO | train_inner | epoch 029:   3442 / 11284 loss=3.486, nll_loss=1.776, ppl=3.43, wps=71651.9, ups=1.21, wpb=59406.6, bsz=2194.2, num_updates=319100, lr=0.000177026, gnorm=0.361, loss_scale=2, train_wall=79, gb_free=39.6, wall=266466
2023-06-14 17:48:49 | INFO | train_inner | epoch 029:   3542 / 11284 loss=3.506, nll_loss=1.798, ppl=3.48, wps=71397, ups=1.2, wpb=59345.8, bsz=2218.4, num_updates=319200, lr=0.000176998, gnorm=0.341, loss_scale=2, train_wall=79, gb_free=39.6, wall=266549
2023-06-14 17:50:11 | INFO | train_inner | epoch 029:   3642 / 11284 loss=3.478, nll_loss=1.766, ppl=3.4, wps=71693.3, ups=1.21, wpb=59356.3, bsz=2258.8, num_updates=319300, lr=0.00017697, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=266632
2023-06-14 17:51:34 | INFO | train_inner | epoch 029:   3742 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=71686.3, ups=1.21, wpb=59273.9, bsz=2208.4, num_updates=319400, lr=0.000176943, gnorm=0.35, loss_scale=2, train_wall=79, gb_free=39.6, wall=266715
2023-06-14 17:52:57 | INFO | train_inner | epoch 029:   3842 / 11284 loss=3.5, nll_loss=1.792, ppl=3.46, wps=71506.5, ups=1.2, wpb=59457.4, bsz=2294.7, num_updates=319500, lr=0.000176915, gnorm=0.348, loss_scale=2, train_wall=79, gb_free=39.6, wall=266798
2023-06-14 17:53:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 17:54:21 | INFO | train_inner | epoch 029:   3943 / 11284 loss=3.492, nll_loss=1.783, ppl=3.44, wps=70845.3, ups=1.19, wpb=59507.3, bsz=2233.2, num_updates=319600, lr=0.000176887, gnorm=0.352, loss_scale=2, train_wall=80, gb_free=39.6, wall=266882
2023-06-14 17:55:44 | INFO | train_inner | epoch 029:   4043 / 11284 loss=3.502, nll_loss=1.793, ppl=3.47, wps=71573.8, ups=1.2, wpb=59522.2, bsz=2242.7, num_updates=319700, lr=0.00017686, gnorm=0.348, loss_scale=2, train_wall=79, gb_free=39.6, wall=266965
2023-06-14 17:57:07 | INFO | train_inner | epoch 029:   4143 / 11284 loss=3.493, nll_loss=1.784, ppl=3.44, wps=71811.2, ups=1.21, wpb=59582.6, bsz=2175.8, num_updates=319800, lr=0.000176832, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.6, wall=267048
2023-06-14 17:58:29 | INFO | train_inner | epoch 029:   4243 / 11284 loss=3.492, nll_loss=1.783, ppl=3.44, wps=73006.9, ups=1.22, wpb=59659, bsz=2235.4, num_updates=319900, lr=0.000176804, gnorm=0.343, loss_scale=2, train_wall=78, gb_free=39.5, wall=267130
2023-06-14 17:59:52 | INFO | train_inner | epoch 029:   4343 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=71751.4, ups=1.21, wpb=59256.6, bsz=2239.4, num_updates=320000, lr=0.000176777, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=39.6, wall=267212
2023-06-14 18:01:14 | INFO | train_inner | epoch 029:   4443 / 11284 loss=3.499, nll_loss=1.79, ppl=3.46, wps=71852.2, ups=1.21, wpb=59380.6, bsz=2150.4, num_updates=320100, lr=0.000176749, gnorm=0.343, loss_scale=2, train_wall=79, gb_free=39.6, wall=267295
2023-06-14 18:02:37 | INFO | train_inner | epoch 029:   4543 / 11284 loss=3.501, nll_loss=1.792, ppl=3.46, wps=71443.1, ups=1.21, wpb=59288.3, bsz=2262.8, num_updates=320200, lr=0.000176721, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.5, wall=267378
2023-06-14 18:04:00 | INFO | train_inner | epoch 029:   4643 / 11284 loss=3.5, nll_loss=1.791, ppl=3.46, wps=71567.4, ups=1.2, wpb=59408.1, bsz=2255.5, num_updates=320300, lr=0.000176694, gnorm=0.363, loss_scale=2, train_wall=79, gb_free=39.6, wall=267461
2023-06-14 18:05:24 | INFO | train_inner | epoch 029:   4743 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=71391.2, ups=1.2, wpb=59414.4, bsz=2228.8, num_updates=320400, lr=0.000176666, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.6, wall=267544
2023-06-14 18:06:47 | INFO | train_inner | epoch 029:   4843 / 11284 loss=3.501, nll_loss=1.793, ppl=3.46, wps=71493.1, ups=1.2, wpb=59460, bsz=2269.6, num_updates=320500, lr=0.000176639, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.6, wall=267627
2023-06-14 18:08:10 | INFO | train_inner | epoch 029:   4943 / 11284 loss=3.5, nll_loss=1.791, ppl=3.46, wps=71855.5, ups=1.21, wpb=59461.1, bsz=2165.2, num_updates=320600, lr=0.000176611, gnorm=0.343, loss_scale=4, train_wall=79, gb_free=39.5, wall=267710
2023-06-14 18:08:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 18:09:33 | INFO | train_inner | epoch 029:   5044 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=71097.4, ups=1.19, wpb=59618.4, bsz=2304.9, num_updates=320700, lr=0.000176584, gnorm=0.347, loss_scale=2, train_wall=80, gb_free=39.5, wall=267794
2023-06-14 18:10:56 | INFO | train_inner | epoch 029:   5144 / 11284 loss=3.48, nll_loss=1.769, ppl=3.41, wps=72044.9, ups=1.21, wpb=59666.8, bsz=2259.9, num_updates=320800, lr=0.000176556, gnorm=0.343, loss_scale=2, train_wall=79, gb_free=39.5, wall=267877
2023-06-14 18:12:18 | INFO | train_inner | epoch 029:   5244 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=72213.3, ups=1.22, wpb=59394.5, bsz=2185.6, num_updates=320900, lr=0.000176529, gnorm=0.348, loss_scale=2, train_wall=78, gb_free=39.5, wall=267959
2023-06-14 18:13:41 | INFO | train_inner | epoch 029:   5344 / 11284 loss=3.493, nll_loss=1.784, ppl=3.44, wps=71680.4, ups=1.21, wpb=59482.9, bsz=2182.3, num_updates=321000, lr=0.000176501, gnorm=0.338, loss_scale=2, train_wall=79, gb_free=39.6, wall=268042
2023-06-14 18:15:04 | INFO | train_inner | epoch 029:   5444 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=71818.1, ups=1.21, wpb=59514.8, bsz=2190.9, num_updates=321100, lr=0.000176474, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=39.5, wall=268125
2023-06-14 18:16:28 | INFO | train_inner | epoch 029:   5544 / 11284 loss=3.482, nll_loss=1.772, ppl=3.41, wps=71721.5, ups=1.2, wpb=59681.8, bsz=2175.2, num_updates=321200, lr=0.000176446, gnorm=0.343, loss_scale=2, train_wall=79, gb_free=39.5, wall=268208
2023-06-14 18:17:50 | INFO | train_inner | epoch 029:   5644 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=71556.7, ups=1.21, wpb=59178.8, bsz=2165.8, num_updates=321300, lr=0.000176419, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=268291
2023-06-14 18:19:13 | INFO | train_inner | epoch 029:   5744 / 11284 loss=3.49, nll_loss=1.78, ppl=3.44, wps=71513.3, ups=1.2, wpb=59502, bsz=2267, num_updates=321400, lr=0.000176391, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.6, wall=268374
2023-06-14 18:20:36 | INFO | train_inner | epoch 029:   5844 / 11284 loss=3.489, nll_loss=1.779, ppl=3.43, wps=71520.6, ups=1.21, wpb=59341.7, bsz=2148.2, num_updates=321500, lr=0.000176364, gnorm=0.362, loss_scale=2, train_wall=79, gb_free=39.4, wall=268457
2023-06-14 18:21:59 | INFO | train_inner | epoch 029:   5944 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71796.1, ups=1.21, wpb=59453.1, bsz=2320.2, num_updates=321600, lr=0.000176336, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.6, wall=268540
2023-06-14 18:23:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 18:23:23 | INFO | train_inner | epoch 029:   6045 / 11284 loss=3.48, nll_loss=1.77, ppl=3.41, wps=70839.7, ups=1.19, wpb=59475.7, bsz=2188.9, num_updates=321700, lr=0.000176309, gnorm=0.349, loss_scale=2, train_wall=80, gb_free=39.6, wall=268624
2023-06-14 18:24:46 | INFO | train_inner | epoch 029:   6145 / 11284 loss=3.501, nll_loss=1.792, ppl=3.46, wps=71925.5, ups=1.21, wpb=59510.4, bsz=2250.8, num_updates=321800, lr=0.000176282, gnorm=0.348, loss_scale=2, train_wall=79, gb_free=39.6, wall=268707
2023-06-14 18:26:09 | INFO | train_inner | epoch 029:   6245 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=71898.1, ups=1.21, wpb=59587.1, bsz=2224.6, num_updates=321900, lr=0.000176254, gnorm=0.33, loss_scale=2, train_wall=79, gb_free=39.6, wall=268789
2023-06-14 18:27:32 | INFO | train_inner | epoch 029:   6345 / 11284 loss=3.499, nll_loss=1.791, ppl=3.46, wps=71446, ups=1.2, wpb=59446, bsz=2257.3, num_updates=322000, lr=0.000176227, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.6, wall=268873
2023-06-14 18:28:55 | INFO | train_inner | epoch 029:   6445 / 11284 loss=3.501, nll_loss=1.792, ppl=3.46, wps=72018.1, ups=1.21, wpb=59488.6, bsz=2165, num_updates=322100, lr=0.000176199, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=39.5, wall=268955
2023-06-14 18:30:17 | INFO | train_inner | epoch 029:   6545 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=71935.5, ups=1.21, wpb=59512.8, bsz=2153.1, num_updates=322200, lr=0.000176172, gnorm=0.338, loss_scale=2, train_wall=79, gb_free=39.6, wall=269038
2023-06-14 18:31:40 | INFO | train_inner | epoch 029:   6645 / 11284 loss=3.5, nll_loss=1.792, ppl=3.46, wps=72392.1, ups=1.21, wpb=59679.4, bsz=2326.4, num_updates=322300, lr=0.000176145, gnorm=0.337, loss_scale=2, train_wall=78, gb_free=39.6, wall=269120
2023-06-14 18:33:03 | INFO | train_inner | epoch 029:   6745 / 11284 loss=3.491, nll_loss=1.781, ppl=3.44, wps=71495.5, ups=1.2, wpb=59555.5, bsz=2252.6, num_updates=322400, lr=0.000176117, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=39.6, wall=269204
2023-06-14 18:34:26 | INFO | train_inner | epoch 029:   6845 / 11284 loss=3.489, nll_loss=1.78, ppl=3.43, wps=71527.5, ups=1.2, wpb=59587.9, bsz=2245.9, num_updates=322500, lr=0.00017609, gnorm=0.343, loss_scale=2, train_wall=79, gb_free=39.5, wall=269287
2023-06-14 18:35:49 | INFO | train_inner | epoch 029:   6945 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=71501.9, ups=1.21, wpb=59279.1, bsz=2229.5, num_updates=322600, lr=0.000176063, gnorm=0.373, loss_scale=2, train_wall=79, gb_free=39.5, wall=269370
2023-06-14 18:37:12 | INFO | train_inner | epoch 029:   7045 / 11284 loss=3.481, nll_loss=1.771, ppl=3.41, wps=71698.4, ups=1.21, wpb=59487.2, bsz=2208.3, num_updates=322700, lr=0.000176036, gnorm=0.338, loss_scale=2, train_wall=79, gb_free=39.6, wall=269453
2023-06-14 18:37:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 18:38:36 | INFO | train_inner | epoch 029:   7146 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=70994.3, ups=1.19, wpb=59454.4, bsz=2220.8, num_updates=322800, lr=0.000176008, gnorm=0.344, loss_scale=2, train_wall=80, gb_free=39.4, wall=269537
2023-06-14 18:39:59 | INFO | train_inner | epoch 029:   7246 / 11284 loss=3.489, nll_loss=1.779, ppl=3.43, wps=71666.5, ups=1.21, wpb=59295, bsz=2224.4, num_updates=322900, lr=0.000175981, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=269619
2023-06-14 18:41:22 | INFO | train_inner | epoch 029:   7346 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=71751.1, ups=1.21, wpb=59476.2, bsz=2232.4, num_updates=323000, lr=0.000175954, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.6, wall=269702
2023-06-14 18:42:45 | INFO | train_inner | epoch 029:   7446 / 11284 loss=3.497, nll_loss=1.789, ppl=3.46, wps=71259.5, ups=1.2, wpb=59515.3, bsz=2282.1, num_updates=323100, lr=0.000175927, gnorm=0.36, loss_scale=2, train_wall=79, gb_free=39.6, wall=269786
2023-06-14 18:44:09 | INFO | train_inner | epoch 029:   7546 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71311.1, ups=1.19, wpb=59815.9, bsz=2264.9, num_updates=323200, lr=0.000175899, gnorm=0.341, loss_scale=2, train_wall=80, gb_free=39.6, wall=269870
2023-06-14 18:45:34 | INFO | train_inner | epoch 029:   7646 / 11284 loss=3.489, nll_loss=1.78, ppl=3.43, wps=70527.9, ups=1.18, wpb=59830.6, bsz=2256.7, num_updates=323300, lr=0.000175872, gnorm=0.344, loss_scale=2, train_wall=81, gb_free=39.6, wall=269954
2023-06-14 18:46:56 | INFO | train_inner | epoch 029:   7746 / 11284 loss=3.501, nll_loss=1.793, ppl=3.46, wps=72772.5, ups=1.22, wpb=59530.4, bsz=2242.4, num_updates=323400, lr=0.000175845, gnorm=0.344, loss_scale=2, train_wall=78, gb_free=39.6, wall=270036
2023-06-14 18:48:18 | INFO | train_inner | epoch 029:   7846 / 11284 loss=3.489, nll_loss=1.78, ppl=3.43, wps=72804.2, ups=1.22, wpb=59669.8, bsz=2252.5, num_updates=323500, lr=0.000175818, gnorm=0.346, loss_scale=2, train_wall=78, gb_free=39.6, wall=270118
2023-06-14 18:49:41 | INFO | train_inner | epoch 029:   7946 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=71449.7, ups=1.2, wpb=59557.8, bsz=2345.2, num_updates=323600, lr=0.000175791, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.6, wall=270202
2023-06-14 18:51:04 | INFO | train_inner | epoch 029:   8046 / 11284 loss=3.493, nll_loss=1.784, ppl=3.44, wps=71706, ups=1.2, wpb=59551.2, bsz=2256, num_updates=323700, lr=0.000175763, gnorm=0.338, loss_scale=2, train_wall=79, gb_free=39.6, wall=270285
2023-06-14 18:52:27 | INFO | train_inner | epoch 029:   8146 / 11284 loss=3.498, nll_loss=1.79, ppl=3.46, wps=71668.3, ups=1.2, wpb=59622.2, bsz=2171.8, num_updates=323800, lr=0.000175736, gnorm=0.353, loss_scale=4, train_wall=79, gb_free=39.6, wall=270368
2023-06-14 18:52:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 18:53:52 | INFO | train_inner | epoch 029:   8247 / 11284 loss=3.489, nll_loss=1.78, ppl=3.43, wps=70586.9, ups=1.19, wpb=59529.1, bsz=2321.3, num_updates=323900, lr=0.000175709, gnorm=0.337, loss_scale=2, train_wall=80, gb_free=39.5, wall=270452
2023-06-14 18:55:15 | INFO | train_inner | epoch 029:   8347 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=71752, ups=1.2, wpb=59564.1, bsz=2307.1, num_updates=324000, lr=0.000175682, gnorm=0.35, loss_scale=2, train_wall=79, gb_free=39.6, wall=270535
2023-06-14 18:56:38 | INFO | train_inner | epoch 029:   8447 / 11284 loss=3.485, nll_loss=1.774, ppl=3.42, wps=71537.4, ups=1.2, wpb=59433.1, bsz=2306.7, num_updates=324100, lr=0.000175655, gnorm=0.348, loss_scale=2, train_wall=79, gb_free=39.5, wall=270618
2023-06-14 18:58:01 | INFO | train_inner | epoch 029:   8547 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=71464.3, ups=1.2, wpb=59522.7, bsz=2245.5, num_updates=324200, lr=0.000175628, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.6, wall=270702
2023-06-14 18:59:24 | INFO | train_inner | epoch 029:   8647 / 11284 loss=3.499, nll_loss=1.791, ppl=3.46, wps=71957.6, ups=1.21, wpb=59491.8, bsz=2139, num_updates=324300, lr=0.000175601, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.6, wall=270784
2023-06-14 19:00:47 | INFO | train_inner | epoch 029:   8747 / 11284 loss=3.495, nll_loss=1.787, ppl=3.45, wps=71663, ups=1.2, wpb=59479.9, bsz=2157.2, num_updates=324400, lr=0.000175574, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.6, wall=270867
2023-06-14 19:02:10 | INFO | train_inner | epoch 029:   8847 / 11284 loss=3.5, nll_loss=1.791, ppl=3.46, wps=71430.3, ups=1.2, wpb=59351.2, bsz=2225.8, num_updates=324500, lr=0.000175547, gnorm=0.376, loss_scale=2, train_wall=79, gb_free=39.6, wall=270950
2023-06-14 19:03:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-06-14 19:03:34 | INFO | train_inner | epoch 029:   8948 / 11284 loss=3.49, nll_loss=1.781, ppl=3.44, wps=70962.3, ups=1.19, wpb=59537.6, bsz=2180.7, num_updates=324600, lr=0.00017552, gnorm=0.345, loss_scale=1, train_wall=80, gb_free=39.5, wall=271034
2023-06-14 19:04:56 | INFO | train_inner | epoch 029:   9048 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=72094.8, ups=1.21, wpb=59560.1, bsz=2159.9, num_updates=324700, lr=0.000175493, gnorm=0.345, loss_scale=1, train_wall=79, gb_free=39.6, wall=271117
2023-06-14 19:06:18 | INFO | train_inner | epoch 029:   9148 / 11284 loss=3.501, nll_loss=1.793, ppl=3.47, wps=73182, ups=1.23, wpb=59693.2, bsz=2303.2, num_updates=324800, lr=0.000175466, gnorm=0.343, loss_scale=1, train_wall=77, gb_free=39.6, wall=271198
2023-06-14 19:07:40 | INFO | train_inner | epoch 029:   9248 / 11284 loss=3.506, nll_loss=1.798, ppl=3.48, wps=72665.3, ups=1.22, wpb=59331.8, bsz=2244.2, num_updates=324900, lr=0.000175439, gnorm=0.361, loss_scale=1, train_wall=78, gb_free=39.6, wall=271280
2023-06-14 19:09:03 | INFO | train_inner | epoch 029:   9348 / 11284 loss=3.491, nll_loss=1.782, ppl=3.44, wps=70977.7, ups=1.19, wpb=59537.6, bsz=2182.4, num_updates=325000, lr=0.000175412, gnorm=0.344, loss_scale=1, train_wall=80, gb_free=39.6, wall=271364
2023-06-14 19:10:28 | INFO | train_inner | epoch 029:   9448 / 11284 loss=3.495, nll_loss=1.787, ppl=3.45, wps=70131.5, ups=1.18, wpb=59522.8, bsz=2223, num_updates=325100, lr=0.000175385, gnorm=0.362, loss_scale=1, train_wall=81, gb_free=39.6, wall=271449
2023-06-14 19:11:52 | INFO | train_inner | epoch 029:   9548 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=70740.5, ups=1.19, wpb=59360.1, bsz=2247, num_updates=325200, lr=0.000175358, gnorm=0.356, loss_scale=1, train_wall=80, gb_free=39.6, wall=271533
2023-06-14 19:13:15 | INFO | train_inner | epoch 029:   9648 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=71535.2, ups=1.2, wpb=59406, bsz=2227.2, num_updates=325300, lr=0.000175331, gnorm=0.342, loss_scale=1, train_wall=79, gb_free=39.6, wall=271616
2023-06-14 19:14:39 | INFO | train_inner | epoch 029:   9748 / 11284 loss=3.504, nll_loss=1.797, ppl=3.47, wps=71519.4, ups=1.2, wpb=59624.6, bsz=2339, num_updates=325400, lr=0.000175304, gnorm=0.348, loss_scale=1, train_wall=79, gb_free=39.6, wall=271699
2023-06-14 19:16:01 | INFO | train_inner | epoch 029:   9848 / 11284 loss=3.505, nll_loss=1.797, ppl=3.48, wps=71519.9, ups=1.21, wpb=59154.3, bsz=2199.1, num_updates=325500, lr=0.000175277, gnorm=0.347, loss_scale=1, train_wall=79, gb_free=39.5, wall=271782
2023-06-14 19:17:24 | INFO | train_inner | epoch 029:   9948 / 11284 loss=3.515, nll_loss=1.808, ppl=3.5, wps=71855.8, ups=1.21, wpb=59568.1, bsz=2202.5, num_updates=325600, lr=0.00017525, gnorm=0.358, loss_scale=2, train_wall=79, gb_free=39.5, wall=271865
2023-06-14 19:18:47 | INFO | train_inner | epoch 029:  10048 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=71673.7, ups=1.2, wpb=59693.1, bsz=2278.8, num_updates=325700, lr=0.000175223, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=39.5, wall=271948
2023-06-14 19:20:10 | INFO | train_inner | epoch 029:  10148 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=71821.9, ups=1.21, wpb=59585.2, bsz=2296.2, num_updates=325800, lr=0.000175196, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=39.6, wall=272031
2023-06-14 19:21:33 | INFO | train_inner | epoch 029:  10248 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=71844, ups=1.21, wpb=59492.3, bsz=2231.3, num_updates=325900, lr=0.000175169, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.6, wall=272114
2023-06-14 19:22:56 | INFO | train_inner | epoch 029:  10348 / 11284 loss=3.489, nll_loss=1.78, ppl=3.43, wps=71464.1, ups=1.2, wpb=59470.9, bsz=2229.6, num_updates=326000, lr=0.000175142, gnorm=0.35, loss_scale=2, train_wall=79, gb_free=39.6, wall=272197
2023-06-14 19:24:19 | INFO | train_inner | epoch 029:  10448 / 11284 loss=3.486, nll_loss=1.776, ppl=3.43, wps=71861.7, ups=1.21, wpb=59567, bsz=2196.9, num_updates=326100, lr=0.000175116, gnorm=0.355, loss_scale=2, train_wall=79, gb_free=39.6, wall=272280
2023-06-14 19:25:43 | INFO | train_inner | epoch 029:  10548 / 11284 loss=3.501, nll_loss=1.793, ppl=3.47, wps=71581.1, ups=1.2, wpb=59584.3, bsz=2149.8, num_updates=326200, lr=0.000175089, gnorm=0.343, loss_scale=2, train_wall=79, gb_free=39.6, wall=272363
2023-06-14 19:27:06 | INFO | train_inner | epoch 029:  10648 / 11284 loss=3.488, nll_loss=1.779, ppl=3.43, wps=71568.9, ups=1.2, wpb=59547, bsz=2212.5, num_updates=326300, lr=0.000175062, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.6, wall=272446
2023-06-14 19:28:29 | INFO | train_inner | epoch 029:  10748 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=71669.3, ups=1.2, wpb=59484.7, bsz=2260.8, num_updates=326400, lr=0.000175035, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.6, wall=272529
2023-06-14 19:29:51 | INFO | train_inner | epoch 029:  10848 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=72178.8, ups=1.21, wpb=59651.7, bsz=2243.7, num_updates=326500, lr=0.000175008, gnorm=0.349, loss_scale=2, train_wall=78, gb_free=39.6, wall=272612
2023-06-14 19:31:13 | INFO | train_inner | epoch 029:  10948 / 11284 loss=3.518, nll_loss=1.812, ppl=3.51, wps=73103.1, ups=1.23, wpb=59468.9, bsz=2184.1, num_updates=326600, lr=0.000174981, gnorm=0.356, loss_scale=2, train_wall=77, gb_free=39.6, wall=272693
2023-06-14 19:31:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 19:32:36 | INFO | train_inner | epoch 029:  11049 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=71229.6, ups=1.2, wpb=59468.9, bsz=2207.2, num_updates=326700, lr=0.000174955, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.6, wall=272777
2023-06-14 19:33:59 | INFO | train_inner | epoch 029:  11149 / 11284 loss=3.48, nll_loss=1.77, ppl=3.41, wps=71591.5, ups=1.21, wpb=59257, bsz=2137.3, num_updates=326800, lr=0.000174928, gnorm=0.343, loss_scale=2, train_wall=79, gb_free=39.6, wall=272860
2023-06-14 19:35:20 | INFO | train_inner | epoch 029:  11249 / 11284 loss=3.504, nll_loss=1.797, ppl=3.47, wps=72977.9, ups=1.23, wpb=59398, bsz=2154.8, num_updates=326900, lr=0.000174901, gnorm=0.354, loss_scale=2, train_wall=77, gb_free=39.6, wall=272941
2023-06-14 19:35:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-14 19:36:14 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 4.29 | nll_loss 2.606 | ppl 6.09 | bleu 21.19 | wps 3665.6 | wpb 2397.5 | bsz 71.5 | num_updates 326935 | best_loss 4.284
2023-06-14 19:36:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 326935 updates
2023-06-14 19:36:15 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint29.pt
2023-06-14 19:38:36 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint29.pt
2023-06-14 19:54:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint29.pt (epoch 29 @ 326935 updates, score 4.29) (writing took 1079.2588335294276 seconds)
2023-06-14 19:54:14 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-06-14 19:54:14 | INFO | train | epoch 029 | loss 3.493 | nll_loss 1.784 | ppl 3.44 | wps 64072.3 | ups 1.08 | wpb 59500.2 | bsz 2227.5 | num_updates 326935 | lr 0.000174892 | gnorm 0.348 | loss_scale 2 | train_wall 8917 | gb_free 39.6 | wall 274075
2023-06-14 19:54:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-14 19:54:17 | INFO | fairseq.trainer | begin training epoch 30
2023-06-14 19:54:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-14 19:55:13 | INFO | train_inner | epoch 030:     65 / 11284 loss=3.486, nll_loss=1.776, ppl=3.42, wps=4981.1, ups=0.08, wpb=59418.6, bsz=2208.1, num_updates=327000, lr=0.000174874, gnorm=0.366, loss_scale=2, train_wall=80, gb_free=39.5, wall=274134
2023-06-14 19:56:37 | INFO | train_inner | epoch 030:    165 / 11284 loss=3.477, nll_loss=1.766, ppl=3.4, wps=71479.2, ups=1.2, wpb=59601.9, bsz=2276.4, num_updates=327100, lr=0.000174848, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.6, wall=274217
2023-06-14 19:58:00 | INFO | train_inner | epoch 030:    265 / 11284 loss=3.492, nll_loss=1.782, ppl=3.44, wps=71445.1, ups=1.2, wpb=59358.7, bsz=2264.7, num_updates=327200, lr=0.000174821, gnorm=0.348, loss_scale=2, train_wall=79, gb_free=39.6, wall=274300
2023-06-14 19:59:22 | INFO | train_inner | epoch 030:    365 / 11284 loss=3.499, nll_loss=1.79, ppl=3.46, wps=72163.9, ups=1.22, wpb=59309.2, bsz=2204.7, num_updates=327300, lr=0.000174794, gnorm=0.377, loss_scale=2, train_wall=78, gb_free=39.6, wall=274383
2023-06-14 20:00:45 | INFO | train_inner | epoch 030:    465 / 11284 loss=3.49, nll_loss=1.78, ppl=3.43, wps=71507.6, ups=1.2, wpb=59597, bsz=2228.2, num_updates=327400, lr=0.000174767, gnorm=0.341, loss_scale=2, train_wall=79, gb_free=39.5, wall=274466
2023-06-14 20:02:09 | INFO | train_inner | epoch 030:    565 / 11284 loss=3.475, nll_loss=1.763, ppl=3.39, wps=71101.7, ups=1.2, wpb=59186.5, bsz=2295.2, num_updates=327500, lr=0.000174741, gnorm=0.352, loss_scale=2, train_wall=79, gb_free=39.5, wall=274549
2023-06-14 20:03:32 | INFO | train_inner | epoch 030:    665 / 11284 loss=3.477, nll_loss=1.765, ppl=3.4, wps=71588.6, ups=1.21, wpb=59384, bsz=2174.1, num_updates=327600, lr=0.000174714, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.6, wall=274632
2023-06-14 20:04:54 | INFO | train_inner | epoch 030:    765 / 11284 loss=3.481, nll_loss=1.771, ppl=3.41, wps=72042.5, ups=1.21, wpb=59559.4, bsz=2241.5, num_updates=327700, lr=0.000174687, gnorm=0.354, loss_scale=4, train_wall=79, gb_free=39.6, wall=274715
2023-06-14 20:05:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 20:06:17 | INFO | train_inner | epoch 030:    866 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=71501.6, ups=1.2, wpb=59383.5, bsz=2201.7, num_updates=327800, lr=0.000174661, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.6, wall=274798
2023-06-14 20:07:40 | INFO | train_inner | epoch 030:    966 / 11284 loss=3.49, nll_loss=1.78, ppl=3.43, wps=72024.5, ups=1.21, wpb=59603.5, bsz=2209.1, num_updates=327900, lr=0.000174634, gnorm=0.341, loss_scale=2, train_wall=79, gb_free=39.6, wall=274881
2023-06-14 20:09:03 | INFO | train_inner | epoch 030:   1066 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71458.1, ups=1.2, wpb=59375.4, bsz=2289.1, num_updates=328000, lr=0.000174608, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.6, wall=274964
2023-06-14 20:10:26 | INFO | train_inner | epoch 030:   1166 / 11284 loss=3.487, nll_loss=1.776, ppl=3.43, wps=71406.1, ups=1.2, wpb=59318.3, bsz=2261.8, num_updates=328100, lr=0.000174581, gnorm=0.354, loss_scale=2, train_wall=79, gb_free=39.6, wall=275047
2023-06-14 20:11:49 | INFO | train_inner | epoch 030:   1266 / 11284 loss=3.481, nll_loss=1.77, ppl=3.41, wps=71935.5, ups=1.21, wpb=59339.9, bsz=2112.3, num_updates=328200, lr=0.000174554, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.6, wall=275129
2023-06-14 20:13:12 | INFO | train_inner | epoch 030:   1366 / 11284 loss=3.495, nll_loss=1.785, ppl=3.45, wps=71602.9, ups=1.2, wpb=59733.7, bsz=2206, num_updates=328300, lr=0.000174528, gnorm=0.339, loss_scale=2, train_wall=79, gb_free=39.6, wall=275213
2023-06-14 20:14:35 | INFO | train_inner | epoch 030:   1466 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=71673.9, ups=1.2, wpb=59728.9, bsz=2259.5, num_updates=328400, lr=0.000174501, gnorm=0.349, loss_scale=2, train_wall=79, gb_free=39.6, wall=275296
2023-06-14 20:15:58 | INFO | train_inner | epoch 030:   1566 / 11284 loss=3.481, nll_loss=1.77, ppl=3.41, wps=72337.8, ups=1.21, wpb=59547.9, bsz=2185.2, num_updates=328500, lr=0.000174475, gnorm=0.346, loss_scale=2, train_wall=78, gb_free=39.6, wall=275378
2023-06-14 20:17:19 | INFO | train_inner | epoch 030:   1666 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=73061.9, ups=1.23, wpb=59580, bsz=2227.3, num_updates=328600, lr=0.000174448, gnorm=0.352, loss_scale=2, train_wall=77, gb_free=39.6, wall=275460
2023-06-14 20:18:43 | INFO | train_inner | epoch 030:   1766 / 11284 loss=3.505, nll_loss=1.796, ppl=3.47, wps=71630.6, ups=1.2, wpb=59602, bsz=2263.4, num_updates=328700, lr=0.000174422, gnorm=0.348, loss_scale=2, train_wall=79, gb_free=39.6, wall=275543
2023-06-14 20:19:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 20:20:07 | INFO | train_inner | epoch 030:   1867 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=70603.1, ups=1.19, wpb=59397.9, bsz=2336.1, num_updates=328800, lr=0.000174395, gnorm=0.356, loss_scale=2, train_wall=80, gb_free=39.6, wall=275627
2023-06-14 20:21:30 | INFO | train_inner | epoch 030:   1967 / 11284 loss=3.475, nll_loss=1.763, ppl=3.39, wps=71679.4, ups=1.21, wpb=59478.1, bsz=2242.5, num_updates=328900, lr=0.000174369, gnorm=0.355, loss_scale=2, train_wall=79, gb_free=39.6, wall=275710
2023-06-14 20:22:53 | INFO | train_inner | epoch 030:   2067 / 11284 loss=3.476, nll_loss=1.764, ppl=3.4, wps=71744.8, ups=1.2, wpb=59766.2, bsz=2269.1, num_updates=329000, lr=0.000174342, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.6, wall=275794
2023-06-14 20:24:15 | INFO | train_inner | epoch 030:   2167 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=72410.6, ups=1.22, wpb=59529.4, bsz=2125.4, num_updates=329100, lr=0.000174316, gnorm=0.342, loss_scale=2, train_wall=78, gb_free=39.6, wall=275876
2023-06-14 20:25:38 | INFO | train_inner | epoch 030:   2267 / 11284 loss=3.49, nll_loss=1.781, ppl=3.44, wps=72339.1, ups=1.21, wpb=59623.4, bsz=2293.8, num_updates=329200, lr=0.000174289, gnorm=0.333, loss_scale=2, train_wall=78, gb_free=39.6, wall=275958
2023-06-14 20:27:00 | INFO | train_inner | epoch 030:   2367 / 11284 loss=3.494, nll_loss=1.784, ppl=3.44, wps=72069.6, ups=1.21, wpb=59587.3, bsz=2225.2, num_updates=329300, lr=0.000174263, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.5, wall=276041
2023-06-14 20:28:24 | INFO | train_inner | epoch 030:   2467 / 11284 loss=3.493, nll_loss=1.783, ppl=3.44, wps=71495.7, ups=1.2, wpb=59518.4, bsz=2212.9, num_updates=329400, lr=0.000174236, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.5, wall=276124
2023-06-14 20:29:47 | INFO | train_inner | epoch 030:   2567 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71695.4, ups=1.2, wpb=59514.6, bsz=2189.6, num_updates=329500, lr=0.00017421, gnorm=0.358, loss_scale=2, train_wall=79, gb_free=39.5, wall=276207
2023-06-14 20:31:10 | INFO | train_inner | epoch 030:   2667 / 11284 loss=3.498, nll_loss=1.79, ppl=3.46, wps=71562.4, ups=1.2, wpb=59541.4, bsz=2291.6, num_updates=329600, lr=0.000174183, gnorm=0.338, loss_scale=2, train_wall=79, gb_free=39.6, wall=276290
2023-06-14 20:32:33 | INFO | train_inner | epoch 030:   2767 / 11284 loss=3.484, nll_loss=1.773, ppl=3.42, wps=71474.2, ups=1.2, wpb=59457.2, bsz=2183.4, num_updates=329700, lr=0.000174157, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.6, wall=276374
2023-06-14 20:33:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 20:33:57 | INFO | train_inner | epoch 030:   2868 / 11284 loss=3.499, nll_loss=1.791, ppl=3.46, wps=71079.3, ups=1.19, wpb=59518.8, bsz=2273.1, num_updates=329800, lr=0.00017413, gnorm=0.358, loss_scale=2, train_wall=80, gb_free=39.6, wall=276457
2023-06-14 20:35:19 | INFO | train_inner | epoch 030:   2968 / 11284 loss=3.501, nll_loss=1.793, ppl=3.47, wps=72332.4, ups=1.22, wpb=59355.3, bsz=2304, num_updates=329900, lr=0.000174104, gnorm=0.368, loss_scale=2, train_wall=78, gb_free=39.6, wall=276539
2023-06-14 20:36:41 | INFO | train_inner | epoch 030:   3068 / 11284 loss=3.49, nll_loss=1.78, ppl=3.43, wps=72321.1, ups=1.22, wpb=59422.2, bsz=2236.5, num_updates=330000, lr=0.000174078, gnorm=0.355, loss_scale=2, train_wall=78, gb_free=39.6, wall=276621
2023-06-14 20:38:03 | INFO | train_inner | epoch 030:   3168 / 11284 loss=3.493, nll_loss=1.784, ppl=3.44, wps=72573.8, ups=1.22, wpb=59427.8, bsz=2224.1, num_updates=330100, lr=0.000174051, gnorm=0.353, loss_scale=2, train_wall=78, gb_free=39.6, wall=276703
2023-06-14 20:39:25 | INFO | train_inner | epoch 030:   3268 / 11284 loss=3.483, nll_loss=1.772, ppl=3.42, wps=71831, ups=1.21, wpb=59342, bsz=2178.8, num_updates=330200, lr=0.000174025, gnorm=0.341, loss_scale=2, train_wall=79, gb_free=39.5, wall=276786
2023-06-14 20:40:48 | INFO | train_inner | epoch 030:   3368 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=71537.3, ups=1.2, wpb=59440.9, bsz=2240.6, num_updates=330300, lr=0.000173999, gnorm=0.349, loss_scale=2, train_wall=79, gb_free=39.6, wall=276869
2023-06-14 20:42:11 | INFO | train_inner | epoch 030:   3468 / 11284 loss=3.489, nll_loss=1.779, ppl=3.43, wps=71697, ups=1.21, wpb=59472.6, bsz=2188.4, num_updates=330400, lr=0.000173972, gnorm=0.359, loss_scale=2, train_wall=79, gb_free=39.6, wall=276952
2023-06-14 20:43:35 | INFO | train_inner | epoch 030:   3568 / 11284 loss=3.49, nll_loss=1.781, ppl=3.44, wps=71378.1, ups=1.2, wpb=59427.1, bsz=2222.8, num_updates=330500, lr=0.000173946, gnorm=0.352, loss_scale=2, train_wall=79, gb_free=39.6, wall=277035
2023-06-14 20:44:58 | INFO | train_inner | epoch 030:   3668 / 11284 loss=3.482, nll_loss=1.772, ppl=3.41, wps=71565.3, ups=1.2, wpb=59569.9, bsz=2193.5, num_updates=330600, lr=0.00017392, gnorm=0.351, loss_scale=2, train_wall=80, gb_free=39.6, wall=277119
2023-06-14 20:46:21 | INFO | train_inner | epoch 030:   3768 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=71604, ups=1.2, wpb=59555.9, bsz=2287.7, num_updates=330700, lr=0.000173893, gnorm=0.358, loss_scale=2, train_wall=79, gb_free=39.6, wall=277202
2023-06-14 20:47:44 | INFO | train_inner | epoch 030:   3868 / 11284 loss=3.491, nll_loss=1.782, ppl=3.44, wps=72119.9, ups=1.21, wpb=59495, bsz=2193.4, num_updates=330800, lr=0.000173867, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.6, wall=277284
2023-06-14 20:49:06 | INFO | train_inner | epoch 030:   3968 / 11284 loss=3.495, nll_loss=1.785, ppl=3.45, wps=72039.8, ups=1.21, wpb=59673.8, bsz=2202.6, num_updates=330900, lr=0.000173841, gnorm=0.35, loss_scale=4, train_wall=79, gb_free=39.6, wall=277367
2023-06-14 20:49:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 20:50:30 | INFO | train_inner | epoch 030:   4069 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=71378.4, ups=1.2, wpb=59528.1, bsz=2180.1, num_updates=331000, lr=0.000173814, gnorm=0.339, loss_scale=2, train_wall=80, gb_free=39.5, wall=277450
2023-06-14 20:51:53 | INFO | train_inner | epoch 030:   4169 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=71621.9, ups=1.2, wpb=59626.3, bsz=2208.2, num_updates=331100, lr=0.000173788, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.5, wall=277534
2023-06-14 20:53:16 | INFO | train_inner | epoch 030:   4269 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71814.7, ups=1.21, wpb=59450.5, bsz=2222.7, num_updates=331200, lr=0.000173762, gnorm=0.355, loss_scale=2, train_wall=79, gb_free=39.6, wall=277616
2023-06-14 20:54:39 | INFO | train_inner | epoch 030:   4369 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71615.6, ups=1.21, wpb=59402.8, bsz=2185.2, num_updates=331300, lr=0.000173736, gnorm=0.361, loss_scale=2, train_wall=79, gb_free=39.6, wall=277699
2023-06-14 20:56:01 | INFO | train_inner | epoch 030:   4469 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71861.8, ups=1.21, wpb=59367, bsz=2192, num_updates=331400, lr=0.00017371, gnorm=0.339, loss_scale=2, train_wall=79, gb_free=39.6, wall=277782
2023-06-14 20:57:24 | INFO | train_inner | epoch 030:   4569 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=71738.2, ups=1.21, wpb=59438.9, bsz=2267.2, num_updates=331500, lr=0.000173683, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.5, wall=277865
2023-06-14 20:58:48 | INFO | train_inner | epoch 030:   4669 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=71372.6, ups=1.2, wpb=59536.8, bsz=2204.4, num_updates=331600, lr=0.000173657, gnorm=0.35, loss_scale=2, train_wall=79, gb_free=39.4, wall=277948
2023-06-14 21:00:10 | INFO | train_inner | epoch 030:   4769 / 11284 loss=3.486, nll_loss=1.776, ppl=3.42, wps=71797.8, ups=1.21, wpb=59438.1, bsz=2123.4, num_updates=331700, lr=0.000173631, gnorm=0.339, loss_scale=2, train_wall=79, gb_free=39.5, wall=278031
2023-06-14 21:01:34 | INFO | train_inner | epoch 030:   4869 / 11284 loss=3.495, nll_loss=1.787, ppl=3.45, wps=71340.3, ups=1.2, wpb=59390, bsz=2213.6, num_updates=331800, lr=0.000173605, gnorm=0.354, loss_scale=2, train_wall=79, gb_free=39.2, wall=278114
2023-06-14 21:02:56 | INFO | train_inner | epoch 030:   4969 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=72030.7, ups=1.21, wpb=59472.2, bsz=2302.9, num_updates=331900, lr=0.000173579, gnorm=0.353, loss_scale=2, train_wall=78, gb_free=39.5, wall=278197
2023-06-14 21:03:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 21:04:20 | INFO | train_inner | epoch 030:   5070 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=71020.3, ups=1.19, wpb=59628.2, bsz=2230.5, num_updates=332000, lr=0.000173553, gnorm=0.349, loss_scale=2, train_wall=80, gb_free=39.6, wall=278281
2023-06-14 21:05:44 | INFO | train_inner | epoch 030:   5170 / 11284 loss=3.505, nll_loss=1.797, ppl=3.47, wps=71439.5, ups=1.2, wpb=59523.3, bsz=2229.5, num_updates=332100, lr=0.000173526, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.5, wall=278364
2023-06-14 21:07:07 | INFO | train_inner | epoch 030:   5270 / 11284 loss=3.494, nll_loss=1.785, ppl=3.44, wps=71267.3, ups=1.2, wpb=59465.1, bsz=2294.6, num_updates=332200, lr=0.0001735, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.6, wall=278448
2023-06-14 21:08:30 | INFO | train_inner | epoch 030:   5370 / 11284 loss=3.489, nll_loss=1.779, ppl=3.43, wps=72030.9, ups=1.21, wpb=59611.6, bsz=2186.2, num_updates=332300, lr=0.000173474, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.5, wall=278530
2023-06-14 21:09:52 | INFO | train_inner | epoch 030:   5470 / 11284 loss=3.476, nll_loss=1.765, ppl=3.4, wps=72660.5, ups=1.22, wpb=59789.7, bsz=2200.5, num_updates=332400, lr=0.000173448, gnorm=0.341, loss_scale=2, train_wall=78, gb_free=39.6, wall=278613
2023-06-14 21:11:14 | INFO | train_inner | epoch 030:   5570 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=72548.4, ups=1.22, wpb=59630.7, bsz=2257.9, num_updates=332500, lr=0.000173422, gnorm=0.346, loss_scale=2, train_wall=78, gb_free=39.5, wall=278695
2023-06-14 21:12:37 | INFO | train_inner | epoch 030:   5670 / 11284 loss=3.481, nll_loss=1.771, ppl=3.41, wps=71592.7, ups=1.2, wpb=59481.1, bsz=2215.4, num_updates=332600, lr=0.000173396, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.6, wall=278778
2023-06-14 21:14:00 | INFO | train_inner | epoch 030:   5770 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=72377.2, ups=1.21, wpb=59725.1, bsz=2146.6, num_updates=332700, lr=0.00017337, gnorm=0.336, loss_scale=2, train_wall=79, gb_free=39.6, wall=278860
2023-06-14 21:15:23 | INFO | train_inner | epoch 030:   5870 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=72094, ups=1.21, wpb=59711.5, bsz=2272.3, num_updates=332800, lr=0.000173344, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.6, wall=278943
2023-06-14 21:16:46 | INFO | train_inner | epoch 030:   5970 / 11284 loss=3.501, nll_loss=1.793, ppl=3.47, wps=71211.8, ups=1.2, wpb=59525.3, bsz=2249, num_updates=332900, lr=0.000173318, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=39.6, wall=279027
2023-06-14 21:18:09 | INFO | train_inner | epoch 030:   6070 / 11284 loss=3.491, nll_loss=1.781, ppl=3.44, wps=71888.8, ups=1.21, wpb=59553.7, bsz=2150.5, num_updates=333000, lr=0.000173292, gnorm=0.348, loss_scale=4, train_wall=79, gb_free=38.8, wall=279110
2023-06-14 21:18:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 21:19:33 | INFO | train_inner | epoch 030:   6171 / 11284 loss=3.5, nll_loss=1.792, ppl=3.46, wps=70941.5, ups=1.19, wpb=59448.3, bsz=2244.1, num_updates=333100, lr=0.000173266, gnorm=0.355, loss_scale=2, train_wall=80, gb_free=39.6, wall=279194
2023-06-14 21:20:56 | INFO | train_inner | epoch 030:   6271 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=71472, ups=1.2, wpb=59385.1, bsz=2191.7, num_updates=333200, lr=0.00017324, gnorm=0.341, loss_scale=2, train_wall=79, gb_free=39.6, wall=279277
2023-06-14 21:22:19 | INFO | train_inner | epoch 030:   6371 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=71955.5, ups=1.21, wpb=59651.7, bsz=2198.4, num_updates=333300, lr=0.000173214, gnorm=0.343, loss_scale=2, train_wall=79, gb_free=39.6, wall=279360
2023-06-14 21:23:42 | INFO | train_inner | epoch 030:   6471 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=71960, ups=1.21, wpb=59512.8, bsz=2183.9, num_updates=333400, lr=0.000173188, gnorm=0.35, loss_scale=2, train_wall=79, gb_free=39.5, wall=279442
2023-06-14 21:25:04 | INFO | train_inner | epoch 030:   6571 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=72042.8, ups=1.21, wpb=59354.4, bsz=2328.3, num_updates=333500, lr=0.000173162, gnorm=0.349, loss_scale=2, train_wall=78, gb_free=39.6, wall=279525
2023-06-14 21:26:26 | INFO | train_inner | epoch 030:   6671 / 11284 loss=3.482, nll_loss=1.771, ppl=3.41, wps=72151.8, ups=1.21, wpb=59385, bsz=2305.5, num_updates=333600, lr=0.000173136, gnorm=0.383, loss_scale=2, train_wall=79, gb_free=39.6, wall=279607
2023-06-14 21:27:48 | INFO | train_inner | epoch 030:   6771 / 11284 loss=3.49, nll_loss=1.78, ppl=3.43, wps=72716.4, ups=1.22, wpb=59421.9, bsz=2162, num_updates=333700, lr=0.00017311, gnorm=0.357, loss_scale=2, train_wall=78, gb_free=39.5, wall=279689
2023-06-14 21:29:10 | INFO | train_inner | epoch 030:   6871 / 11284 loss=3.49, nll_loss=1.78, ppl=3.44, wps=72548.5, ups=1.22, wpb=59447.9, bsz=2195.8, num_updates=333800, lr=0.000173084, gnorm=0.349, loss_scale=2, train_wall=78, gb_free=39.6, wall=279771
2023-06-14 21:30:32 | INFO | train_inner | epoch 030:   6971 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=72868.6, ups=1.22, wpb=59498.9, bsz=2186.3, num_updates=333900, lr=0.000173058, gnorm=0.353, loss_scale=2, train_wall=78, gb_free=39.5, wall=279852
2023-06-14 21:31:55 | INFO | train_inner | epoch 030:   7071 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=71889.3, ups=1.21, wpb=59629, bsz=2244.2, num_updates=334000, lr=0.000173032, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=279935
2023-06-14 21:32:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 21:33:18 | INFO | train_inner | epoch 030:   7172 / 11284 loss=3.496, nll_loss=1.788, ppl=3.45, wps=71002.9, ups=1.19, wpb=59557.9, bsz=2238.8, num_updates=334100, lr=0.000173006, gnorm=0.339, loss_scale=2, train_wall=80, gb_free=39.6, wall=280019
2023-06-14 21:34:40 | INFO | train_inner | epoch 030:   7272 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=72730.6, ups=1.22, wpb=59647.6, bsz=2279.7, num_updates=334200, lr=0.00017298, gnorm=0.363, loss_scale=2, train_wall=78, gb_free=39.5, wall=280101
2023-06-14 21:36:03 | INFO | train_inner | epoch 030:   7372 / 11284 loss=3.497, nll_loss=1.789, ppl=3.45, wps=72238.4, ups=1.21, wpb=59514.2, bsz=2240.3, num_updates=334300, lr=0.000172954, gnorm=0.349, loss_scale=2, train_wall=78, gb_free=39.6, wall=280183
2023-06-14 21:37:25 | INFO | train_inner | epoch 030:   7472 / 11284 loss=3.489, nll_loss=1.78, ppl=3.43, wps=72289.9, ups=1.22, wpb=59284.7, bsz=2133.7, num_updates=334400, lr=0.000172929, gnorm=0.353, loss_scale=2, train_wall=78, gb_free=39.6, wall=280265
2023-06-14 21:38:47 | INFO | train_inner | epoch 030:   7572 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=72571.3, ups=1.22, wpb=59578.7, bsz=2191.1, num_updates=334500, lr=0.000172903, gnorm=0.34, loss_scale=2, train_wall=78, gb_free=39.6, wall=280348
2023-06-14 21:40:09 | INFO | train_inner | epoch 030:   7672 / 11284 loss=3.489, nll_loss=1.779, ppl=3.43, wps=72647.8, ups=1.22, wpb=59505, bsz=2277.8, num_updates=334600, lr=0.000172877, gnorm=0.346, loss_scale=2, train_wall=78, gb_free=39.6, wall=280429
2023-06-14 21:41:32 | INFO | train_inner | epoch 030:   7772 / 11284 loss=3.491, nll_loss=1.782, ppl=3.44, wps=71182.1, ups=1.2, wpb=59422.2, bsz=2242.9, num_updates=334700, lr=0.000172851, gnorm=0.358, loss_scale=2, train_wall=79, gb_free=39.6, wall=280513
2023-06-14 21:42:55 | INFO | train_inner | epoch 030:   7872 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=71694.2, ups=1.2, wpb=59561.5, bsz=2159.4, num_updates=334800, lr=0.000172825, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.5, wall=280596
2023-06-14 21:44:19 | INFO | train_inner | epoch 030:   7972 / 11284 loss=3.507, nll_loss=1.8, ppl=3.48, wps=71399.6, ups=1.2, wpb=59436, bsz=2151.4, num_updates=334900, lr=0.000172799, gnorm=0.352, loss_scale=2, train_wall=79, gb_free=39.5, wall=280679
2023-06-14 21:45:42 | INFO | train_inner | epoch 030:   8072 / 11284 loss=3.496, nll_loss=1.788, ppl=3.45, wps=71537.8, ups=1.2, wpb=59439.5, bsz=2267.3, num_updates=335000, lr=0.000172774, gnorm=0.339, loss_scale=2, train_wall=79, gb_free=39.6, wall=280762
2023-06-14 21:47:05 | INFO | train_inner | epoch 030:   8172 / 11284 loss=3.492, nll_loss=1.783, ppl=3.44, wps=71445.9, ups=1.2, wpb=59307.8, bsz=2235.9, num_updates=335100, lr=0.000172748, gnorm=0.36, loss_scale=4, train_wall=79, gb_free=39.6, wall=280845
2023-06-14 21:47:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 21:48:29 | INFO | train_inner | epoch 030:   8273 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=70622.2, ups=1.19, wpb=59226.1, bsz=2253.7, num_updates=335200, lr=0.000172722, gnorm=0.358, loss_scale=2, train_wall=80, gb_free=39.6, wall=280929
2023-06-14 21:49:52 | INFO | train_inner | epoch 030:   8373 / 11284 loss=3.48, nll_loss=1.77, ppl=3.41, wps=71760.3, ups=1.21, wpb=59547.8, bsz=2216, num_updates=335300, lr=0.000172696, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.6, wall=281012
2023-06-14 21:51:15 | INFO | train_inner | epoch 030:   8473 / 11284 loss=3.483, nll_loss=1.772, ppl=3.42, wps=71596.4, ups=1.2, wpb=59537.6, bsz=2253.8, num_updates=335400, lr=0.000172671, gnorm=0.352, loss_scale=2, train_wall=79, gb_free=39.5, wall=281095
2023-06-14 21:52:38 | INFO | train_inner | epoch 030:   8573 / 11284 loss=3.491, nll_loss=1.782, ppl=3.44, wps=71808.7, ups=1.21, wpb=59498.2, bsz=2179.1, num_updates=335500, lr=0.000172645, gnorm=0.349, loss_scale=2, train_wall=79, gb_free=39.5, wall=281178
2023-06-14 21:54:00 | INFO | train_inner | epoch 030:   8673 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=71888.6, ups=1.21, wpb=59412.9, bsz=2212.2, num_updates=335600, lr=0.000172619, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.6, wall=281261
2023-06-14 21:55:22 | INFO | train_inner | epoch 030:   8773 / 11284 loss=3.467, nll_loss=1.755, ppl=3.38, wps=73132.6, ups=1.23, wpb=59673.6, bsz=2214.9, num_updates=335700, lr=0.000172593, gnorm=0.341, loss_scale=2, train_wall=78, gb_free=39.5, wall=281342
2023-06-14 21:56:45 | INFO | train_inner | epoch 030:   8873 / 11284 loss=3.496, nll_loss=1.788, ppl=3.45, wps=71371.4, ups=1.2, wpb=59544.8, bsz=2222.2, num_updates=335800, lr=0.000172568, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.5, wall=281426
2023-06-14 21:58:08 | INFO | train_inner | epoch 030:   8973 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71686.2, ups=1.21, wpb=59349.4, bsz=2218.7, num_updates=335900, lr=0.000172542, gnorm=0.364, loss_scale=2, train_wall=79, gb_free=39.6, wall=281509
2023-06-14 21:59:31 | INFO | train_inner | epoch 030:   9073 / 11284 loss=3.482, nll_loss=1.771, ppl=3.41, wps=71919.8, ups=1.2, wpb=59738.6, bsz=2212.9, num_updates=336000, lr=0.000172516, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=39.5, wall=281592
2023-06-14 22:00:54 | INFO | train_inner | epoch 030:   9173 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=71374.8, ups=1.2, wpb=59397.3, bsz=2320.7, num_updates=336100, lr=0.000172491, gnorm=0.348, loss_scale=2, train_wall=79, gb_free=39.6, wall=281675
2023-06-14 22:02:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 22:02:18 | INFO | train_inner | epoch 030:   9274 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=71041.8, ups=1.2, wpb=59409.8, bsz=2221.4, num_updates=336200, lr=0.000172465, gnorm=0.352, loss_scale=2, train_wall=80, gb_free=39.6, wall=281759
2023-06-14 22:03:40 | INFO | train_inner | epoch 030:   9374 / 11284 loss=3.5, nll_loss=1.792, ppl=3.46, wps=72436.3, ups=1.22, wpb=59428.9, bsz=2302, num_updates=336300, lr=0.000172439, gnorm=0.365, loss_scale=2, train_wall=78, gb_free=39.6, wall=281841
2023-06-14 22:05:03 | INFO | train_inner | epoch 030:   9474 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=72054.2, ups=1.21, wpb=59563.9, bsz=2200.3, num_updates=336400, lr=0.000172414, gnorm=0.355, loss_scale=2, train_wall=79, gb_free=39.6, wall=281923
2023-06-14 22:06:26 | INFO | train_inner | epoch 030:   9574 / 11284 loss=3.505, nll_loss=1.797, ppl=3.47, wps=71631.7, ups=1.2, wpb=59787.2, bsz=2264.3, num_updates=336500, lr=0.000172388, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=282007
2023-06-14 22:07:49 | INFO | train_inner | epoch 030:   9674 / 11284 loss=3.499, nll_loss=1.791, ppl=3.46, wps=71597.1, ups=1.2, wpb=59459.5, bsz=2225.2, num_updates=336600, lr=0.000172363, gnorm=0.367, loss_scale=2, train_wall=79, gb_free=39.6, wall=282090
2023-06-14 22:09:13 | INFO | train_inner | epoch 030:   9774 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=71237.9, ups=1.2, wpb=59456.9, bsz=2245.2, num_updates=336700, lr=0.000172337, gnorm=0.366, loss_scale=2, train_wall=79, gb_free=39.6, wall=282173
2023-06-14 22:10:36 | INFO | train_inner | epoch 030:   9874 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=71146.2, ups=1.2, wpb=59405.5, bsz=2226.1, num_updates=336800, lr=0.000172311, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.6, wall=282257
2023-06-14 22:11:59 | INFO | train_inner | epoch 030:   9974 / 11284 loss=3.498, nll_loss=1.79, ppl=3.46, wps=71601, ups=1.21, wpb=59358.6, bsz=2187.5, num_updates=336900, lr=0.000172286, gnorm=0.364, loss_scale=2, train_wall=79, gb_free=38.7, wall=282340
2023-06-14 22:13:22 | INFO | train_inner | epoch 030:  10074 / 11284 loss=3.491, nll_loss=1.782, ppl=3.44, wps=71465.3, ups=1.2, wpb=59499, bsz=2284.1, num_updates=337000, lr=0.00017226, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.6, wall=282423
2023-06-14 22:14:46 | INFO | train_inner | epoch 030:  10174 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71371.6, ups=1.2, wpb=59473.5, bsz=2305.7, num_updates=337100, lr=0.000172235, gnorm=0.341, loss_scale=2, train_wall=79, gb_free=39.6, wall=282506
2023-06-14 22:16:09 | INFO | train_inner | epoch 030:  10274 / 11284 loss=3.491, nll_loss=1.781, ppl=3.44, wps=71971.7, ups=1.2, wpb=59748.5, bsz=2230, num_updates=337200, lr=0.000172209, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.6, wall=282589
2023-06-14 22:16:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 22:17:32 | INFO | train_inner | epoch 030:  10375 / 11284 loss=3.509, nll_loss=1.802, ppl=3.49, wps=71394.7, ups=1.2, wpb=59534.4, bsz=2272.7, num_updates=337300, lr=0.000172184, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=282673
2023-06-14 22:18:55 | INFO | train_inner | epoch 030:  10475 / 11284 loss=3.481, nll_loss=1.771, ppl=3.41, wps=71760.3, ups=1.2, wpb=59591.5, bsz=2152.6, num_updates=337400, lr=0.000172158, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.6, wall=282756
2023-06-14 22:20:18 | INFO | train_inner | epoch 030:  10575 / 11284 loss=3.493, nll_loss=1.784, ppl=3.44, wps=71723.4, ups=1.21, wpb=59363.4, bsz=2216.9, num_updates=337500, lr=0.000172133, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=282839
2023-06-14 22:21:41 | INFO | train_inner | epoch 030:  10675 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=71602, ups=1.2, wpb=59635.2, bsz=2203.2, num_updates=337600, lr=0.000172107, gnorm=0.349, loss_scale=2, train_wall=79, gb_free=39.6, wall=282922
2023-06-14 22:23:04 | INFO | train_inner | epoch 030:  10775 / 11284 loss=3.489, nll_loss=1.78, ppl=3.43, wps=71681.8, ups=1.2, wpb=59588.4, bsz=2205, num_updates=337700, lr=0.000172082, gnorm=0.355, loss_scale=2, train_wall=79, gb_free=39.6, wall=283005
2023-06-14 22:24:27 | INFO | train_inner | epoch 030:  10875 / 11284 loss=3.498, nll_loss=1.79, ppl=3.46, wps=72017.5, ups=1.21, wpb=59413.4, bsz=2225, num_updates=337800, lr=0.000172056, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=39.5, wall=283087
2023-06-14 22:25:49 | INFO | train_inner | epoch 030:  10975 / 11284 loss=3.492, nll_loss=1.783, ppl=3.44, wps=72819.2, ups=1.22, wpb=59619.1, bsz=2240.6, num_updates=337900, lr=0.000172031, gnorm=0.337, loss_scale=2, train_wall=78, gb_free=39.6, wall=283169
2023-06-14 22:27:11 | INFO | train_inner | epoch 030:  11075 / 11284 loss=3.491, nll_loss=1.781, ppl=3.44, wps=72466.1, ups=1.22, wpb=59336.2, bsz=2157.1, num_updates=338000, lr=0.000172005, gnorm=0.353, loss_scale=2, train_wall=78, gb_free=39.6, wall=283251
2023-06-14 22:28:33 | INFO | train_inner | epoch 030:  11175 / 11284 loss=3.48, nll_loss=1.77, ppl=3.41, wps=72304.4, ups=1.22, wpb=59482, bsz=2294.6, num_updates=338100, lr=0.00017198, gnorm=0.351, loss_scale=2, train_wall=78, gb_free=39.6, wall=283333
2023-06-14 22:29:56 | INFO | train_inner | epoch 030:  11275 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=71793.2, ups=1.21, wpb=59490, bsz=2278.1, num_updates=338200, lr=0.000171954, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.4, wall=283416
2023-06-14 22:30:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-14 22:30:22 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 4.283 | nll_loss 2.603 | ppl 6.08 | bleu 21.03 | wps 3678 | wpb 2397.5 | bsz 71.5 | num_updates 338209 | best_loss 4.283
2023-06-14 22:30:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 338209 updates
2023-06-14 22:30:23 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint30.pt
2023-06-14 22:34:03 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint30.pt
2023-06-14 22:41:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint30.pt (epoch 30 @ 338209 updates, score 4.283) (writing took 666.747198193334 seconds)
2023-06-14 22:41:30 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-06-14 22:41:30 | INFO | train | epoch 030 | loss 3.491 | nll_loss 1.781 | ppl 3.44 | wps 66845.6 | ups 1.12 | wpb 59501.2 | bsz 2227.3 | num_updates 338209 | lr 0.000171952 | gnorm 0.35 | loss_scale 2 | train_wall 8897 | gb_free 39.6 | wall 284110
2023-06-14 22:41:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-14 22:41:30 | INFO | fairseq.trainer | begin training epoch 31
2023-06-14 22:41:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-14 22:42:45 | INFO | train_inner | epoch 031:     91 / 11284 loss=3.496, nll_loss=1.786, ppl=3.45, wps=7715.3, ups=0.13, wpb=59354.3, bsz=2320.2, num_updates=338300, lr=0.000171929, gnorm=0.343, loss_scale=4, train_wall=78, gb_free=39.5, wall=284186
2023-06-14 22:43:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 22:44:08 | INFO | train_inner | epoch 031:    192 / 11284 loss=3.499, nll_loss=1.79, ppl=3.46, wps=72181.7, ups=1.21, wpb=59564.1, bsz=2252.9, num_updates=338400, lr=0.000171904, gnorm=0.346, loss_scale=2, train_wall=78, gb_free=39.7, wall=284268
2023-06-14 22:45:30 | INFO | train_inner | epoch 031:    292 / 11284 loss=3.482, nll_loss=1.771, ppl=3.41, wps=71629.2, ups=1.21, wpb=59259.6, bsz=2176.9, num_updates=338500, lr=0.000171878, gnorm=0.35, loss_scale=2, train_wall=79, gb_free=39.6, wall=284351
2023-06-14 22:46:54 | INFO | train_inner | epoch 031:    392 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=71477.4, ups=1.2, wpb=59559.7, bsz=2252.5, num_updates=338600, lr=0.000171853, gnorm=0.355, loss_scale=2, train_wall=79, gb_free=39.6, wall=284434
2023-06-14 22:48:16 | INFO | train_inner | epoch 031:    492 / 11284 loss=3.476, nll_loss=1.764, ppl=3.4, wps=72075.5, ups=1.21, wpb=59633, bsz=2211.6, num_updates=338700, lr=0.000171827, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.6, wall=284517
2023-06-14 22:49:39 | INFO | train_inner | epoch 031:    592 / 11284 loss=3.485, nll_loss=1.774, ppl=3.42, wps=71715.1, ups=1.21, wpb=59482.9, bsz=2233.2, num_updates=338800, lr=0.000171802, gnorm=0.359, loss_scale=2, train_wall=79, gb_free=39.6, wall=284600
2023-06-14 22:51:02 | INFO | train_inner | epoch 031:    692 / 11284 loss=3.491, nll_loss=1.782, ppl=3.44, wps=71748.6, ups=1.2, wpb=59561, bsz=2246.3, num_updates=338900, lr=0.000171777, gnorm=0.363, loss_scale=2, train_wall=79, gb_free=39.6, wall=284683
2023-06-14 22:52:25 | INFO | train_inner | epoch 031:    792 / 11284 loss=3.475, nll_loss=1.763, ppl=3.39, wps=71714.1, ups=1.2, wpb=59585, bsz=2226.6, num_updates=339000, lr=0.000171751, gnorm=0.341, loss_scale=2, train_wall=79, gb_free=39.6, wall=284766
2023-06-14 22:53:48 | INFO | train_inner | epoch 031:    892 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=71681.7, ups=1.21, wpb=59364.2, bsz=2177.5, num_updates=339100, lr=0.000171726, gnorm=0.363, loss_scale=2, train_wall=79, gb_free=39.6, wall=284849
2023-06-14 22:55:11 | INFO | train_inner | epoch 031:    992 / 11284 loss=3.485, nll_loss=1.774, ppl=3.42, wps=71683.2, ups=1.2, wpb=59598.2, bsz=2265.6, num_updates=339200, lr=0.000171701, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.3, wall=284932
2023-06-14 22:56:34 | INFO | train_inner | epoch 031:   1092 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=71808.5, ups=1.21, wpb=59502.2, bsz=2196.5, num_updates=339300, lr=0.000171675, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.5, wall=285015
2023-06-14 22:57:57 | INFO | train_inner | epoch 031:   1192 / 11284 loss=3.473, nll_loss=1.761, ppl=3.39, wps=71632.5, ups=1.2, wpb=59457.5, bsz=2177.5, num_updates=339400, lr=0.00017165, gnorm=0.344, loss_scale=4, train_wall=79, gb_free=39.6, wall=285098
2023-06-14 22:59:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 22:59:21 | INFO | train_inner | epoch 031:   1293 / 11284 loss=3.492, nll_loss=1.782, ppl=3.44, wps=70910.3, ups=1.19, wpb=59405.7, bsz=2145.7, num_updates=339500, lr=0.000171625, gnorm=0.355, loss_scale=2, train_wall=80, gb_free=39.6, wall=285182
2023-06-14 23:00:44 | INFO | train_inner | epoch 031:   1393 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=71777.2, ups=1.21, wpb=59527.6, bsz=2195.6, num_updates=339600, lr=0.0001716, gnorm=0.348, loss_scale=2, train_wall=79, gb_free=39.5, wall=285265
2023-06-14 23:02:07 | INFO | train_inner | epoch 031:   1493 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=71886.8, ups=1.21, wpb=59480.5, bsz=2186.6, num_updates=339700, lr=0.000171574, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.6, wall=285347
2023-06-14 23:03:29 | INFO | train_inner | epoch 031:   1593 / 11284 loss=3.482, nll_loss=1.771, ppl=3.41, wps=72002.3, ups=1.21, wpb=59529.6, bsz=2272.3, num_updates=339800, lr=0.000171549, gnorm=0.348, loss_scale=2, train_wall=79, gb_free=39.6, wall=285430
2023-06-14 23:04:52 | INFO | train_inner | epoch 031:   1693 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=71468.1, ups=1.2, wpb=59354.4, bsz=2236.9, num_updates=339900, lr=0.000171524, gnorm=0.349, loss_scale=2, train_wall=79, gb_free=39.5, wall=285513
2023-06-14 23:06:16 | INFO | train_inner | epoch 031:   1793 / 11284 loss=3.461, nll_loss=1.748, ppl=3.36, wps=71603.9, ups=1.2, wpb=59536.1, bsz=2196.1, num_updates=340000, lr=0.000171499, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=39.6, wall=285596
2023-06-14 23:07:38 | INFO | train_inner | epoch 031:   1893 / 11284 loss=3.482, nll_loss=1.771, ppl=3.41, wps=72032.9, ups=1.21, wpb=59471.6, bsz=2217.6, num_updates=340100, lr=0.000171473, gnorm=0.359, loss_scale=2, train_wall=78, gb_free=39.6, wall=285679
2023-06-14 23:09:00 | INFO | train_inner | epoch 031:   1993 / 11284 loss=3.478, nll_loss=1.767, ppl=3.4, wps=72759.8, ups=1.22, wpb=59579.7, bsz=2178.2, num_updates=340200, lr=0.000171448, gnorm=0.337, loss_scale=2, train_wall=78, gb_free=39.6, wall=285761
2023-06-14 23:10:23 | INFO | train_inner | epoch 031:   2093 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71420.9, ups=1.2, wpb=59270.7, bsz=2236.7, num_updates=340300, lr=0.000171423, gnorm=0.358, loss_scale=2, train_wall=79, gb_free=39.5, wall=285844
2023-06-14 23:11:46 | INFO | train_inner | epoch 031:   2193 / 11284 loss=3.492, nll_loss=1.782, ppl=3.44, wps=71618.8, ups=1.2, wpb=59577.1, bsz=2216.2, num_updates=340400, lr=0.000171398, gnorm=0.347, loss_scale=2, train_wall=80, gb_free=39.6, wall=285927
2023-06-14 23:13:09 | INFO | train_inner | epoch 031:   2293 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=71818.7, ups=1.21, wpb=59459.1, bsz=2190.2, num_updates=340500, lr=0.000171373, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=286010
2023-06-14 23:13:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 23:14:32 | INFO | train_inner | epoch 031:   2394 / 11284 loss=3.49, nll_loss=1.78, ppl=3.43, wps=71469.1, ups=1.2, wpb=59405.7, bsz=2144.3, num_updates=340600, lr=0.000171347, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.6, wall=286093
2023-06-14 23:15:55 | INFO | train_inner | epoch 031:   2494 / 11284 loss=3.484, nll_loss=1.773, ppl=3.42, wps=72003.9, ups=1.2, wpb=59759.4, bsz=2155.1, num_updates=340700, lr=0.000171322, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.6, wall=286176
2023-06-14 23:17:17 | INFO | train_inner | epoch 031:   2594 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=72571.5, ups=1.22, wpb=59591.2, bsz=2225.2, num_updates=340800, lr=0.000171297, gnorm=0.358, loss_scale=2, train_wall=78, gb_free=39.6, wall=286258
2023-06-14 23:18:39 | INFO | train_inner | epoch 031:   2694 / 11284 loss=3.481, nll_loss=1.77, ppl=3.41, wps=72537, ups=1.22, wpb=59519.3, bsz=2215.2, num_updates=340900, lr=0.000171272, gnorm=0.357, loss_scale=2, train_wall=78, gb_free=39.6, wall=286340
2023-06-14 23:20:02 | INFO | train_inner | epoch 031:   2794 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=72485.5, ups=1.21, wpb=59750.7, bsz=2318.1, num_updates=341000, lr=0.000171247, gnorm=0.345, loss_scale=2, train_wall=78, gb_free=39.6, wall=286422
2023-06-14 23:21:24 | INFO | train_inner | epoch 031:   2894 / 11284 loss=3.479, nll_loss=1.768, ppl=3.41, wps=72009.2, ups=1.21, wpb=59369.5, bsz=2186.5, num_updates=341100, lr=0.000171222, gnorm=0.35, loss_scale=2, train_wall=79, gb_free=39.6, wall=286505
2023-06-14 23:22:47 | INFO | train_inner | epoch 031:   2994 / 11284 loss=3.505, nll_loss=1.797, ppl=3.47, wps=71521.9, ups=1.2, wpb=59550.5, bsz=2299.3, num_updates=341200, lr=0.000171197, gnorm=0.358, loss_scale=2, train_wall=79, gb_free=39.6, wall=286588
2023-06-14 23:24:11 | INFO | train_inner | epoch 031:   3094 / 11284 loss=3.474, nll_loss=1.762, ppl=3.39, wps=71060.3, ups=1.19, wpb=59555.6, bsz=2319.3, num_updates=341300, lr=0.000171172, gnorm=0.348, loss_scale=2, train_wall=80, gb_free=39.6, wall=286672
2023-06-14 23:25:34 | INFO | train_inner | epoch 031:   3194 / 11284 loss=3.466, nll_loss=1.753, ppl=3.37, wps=71662.3, ups=1.2, wpb=59481.7, bsz=2188, num_updates=341400, lr=0.000171147, gnorm=0.337, loss_scale=2, train_wall=79, gb_free=39.6, wall=286755
2023-06-14 23:26:56 | INFO | train_inner | epoch 031:   3294 / 11284 loss=3.482, nll_loss=1.772, ppl=3.41, wps=72637.8, ups=1.22, wpb=59495.6, bsz=2249.6, num_updates=341500, lr=0.000171122, gnorm=0.362, loss_scale=2, train_wall=78, gb_free=39.6, wall=286837
2023-06-14 23:27:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 23:28:20 | INFO | train_inner | epoch 031:   3395 / 11284 loss=3.475, nll_loss=1.763, ppl=3.39, wps=71323.5, ups=1.2, wpb=59627.2, bsz=2260, num_updates=341600, lr=0.000171096, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.6, wall=286920
2023-06-14 23:29:43 | INFO | train_inner | epoch 031:   3495 / 11284 loss=3.488, nll_loss=1.779, ppl=3.43, wps=71401.8, ups=1.2, wpb=59396.3, bsz=2245.8, num_updates=341700, lr=0.000171071, gnorm=0.361, loss_scale=2, train_wall=79, gb_free=39.6, wall=287004
2023-06-14 23:31:06 | INFO | train_inner | epoch 031:   3595 / 11284 loss=3.493, nll_loss=1.784, ppl=3.44, wps=71320.3, ups=1.2, wpb=59405.8, bsz=2242.5, num_updates=341800, lr=0.000171046, gnorm=0.349, loss_scale=2, train_wall=79, gb_free=39.6, wall=287087
2023-06-14 23:32:29 | INFO | train_inner | epoch 031:   3695 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71788.4, ups=1.21, wpb=59384.3, bsz=2182.8, num_updates=341900, lr=0.000171021, gnorm=0.348, loss_scale=2, train_wall=79, gb_free=39.6, wall=287170
2023-06-14 23:33:51 | INFO | train_inner | epoch 031:   3795 / 11284 loss=3.482, nll_loss=1.771, ppl=3.41, wps=72424.2, ups=1.21, wpb=59622.6, bsz=2151.2, num_updates=342000, lr=0.000170996, gnorm=0.343, loss_scale=2, train_wall=78, gb_free=39.6, wall=287252
2023-06-14 23:35:14 | INFO | train_inner | epoch 031:   3895 / 11284 loss=3.486, nll_loss=1.776, ppl=3.42, wps=71794.1, ups=1.21, wpb=59384.8, bsz=2223.8, num_updates=342100, lr=0.000170971, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.6, wall=287335
2023-06-14 23:36:36 | INFO | train_inner | epoch 031:   3995 / 11284 loss=3.486, nll_loss=1.776, ppl=3.42, wps=72349.6, ups=1.21, wpb=59642.5, bsz=2240.8, num_updates=342200, lr=0.000170946, gnorm=0.347, loss_scale=2, train_wall=78, gb_free=39.5, wall=287417
2023-06-14 23:37:59 | INFO | train_inner | epoch 031:   4095 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=71968.9, ups=1.21, wpb=59640.5, bsz=2157.9, num_updates=342300, lr=0.000170921, gnorm=0.352, loss_scale=2, train_wall=79, gb_free=39.6, wall=287500
2023-06-14 23:39:22 | INFO | train_inner | epoch 031:   4195 / 11284 loss=3.493, nll_loss=1.784, ppl=3.44, wps=72000.6, ups=1.21, wpb=59407.9, bsz=2193.3, num_updates=342400, lr=0.000170896, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.6, wall=287582
2023-06-14 23:40:45 | INFO | train_inner | epoch 031:   4295 / 11284 loss=3.501, nll_loss=1.793, ppl=3.46, wps=71762, ups=1.2, wpb=59555.7, bsz=2180.1, num_updates=342500, lr=0.000170872, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.5, wall=287665
2023-06-14 23:42:07 | INFO | train_inner | epoch 031:   4395 / 11284 loss=3.476, nll_loss=1.765, ppl=3.4, wps=72079.8, ups=1.21, wpb=59557.9, bsz=2162.9, num_updates=342600, lr=0.000170847, gnorm=0.341, loss_scale=4, train_wall=79, gb_free=39.5, wall=287748
2023-06-14 23:42:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 23:43:31 | INFO | train_inner | epoch 031:   4496 / 11284 loss=3.49, nll_loss=1.781, ppl=3.44, wps=71149.6, ups=1.2, wpb=59532.1, bsz=2187.9, num_updates=342700, lr=0.000170822, gnorm=0.345, loss_scale=2, train_wall=80, gb_free=39.6, wall=287832
2023-06-14 23:44:53 | INFO | train_inner | epoch 031:   4596 / 11284 loss=3.492, nll_loss=1.782, ppl=3.44, wps=72874.8, ups=1.22, wpb=59505.7, bsz=2222.6, num_updates=342800, lr=0.000170797, gnorm=0.355, loss_scale=2, train_wall=78, gb_free=39.6, wall=287913
2023-06-14 23:46:15 | INFO | train_inner | epoch 031:   4696 / 11284 loss=3.482, nll_loss=1.771, ppl=3.41, wps=72883.1, ups=1.22, wpb=59654, bsz=2268.3, num_updates=342900, lr=0.000170772, gnorm=0.35, loss_scale=2, train_wall=78, gb_free=39.6, wall=287995
2023-06-14 23:47:37 | INFO | train_inner | epoch 031:   4796 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=71941.1, ups=1.21, wpb=59559.7, bsz=2165.4, num_updates=343000, lr=0.000170747, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.6, wall=288078
2023-06-14 23:49:01 | INFO | train_inner | epoch 031:   4896 / 11284 loss=3.486, nll_loss=1.777, ppl=3.43, wps=71450.5, ups=1.2, wpb=59627.4, bsz=2224.3, num_updates=343100, lr=0.000170722, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=39.6, wall=288161
2023-06-14 23:50:24 | INFO | train_inner | epoch 031:   4996 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=71828.6, ups=1.21, wpb=59475.4, bsz=2244.5, num_updates=343200, lr=0.000170697, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.6, wall=288244
2023-06-14 23:51:46 | INFO | train_inner | epoch 031:   5096 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=72272.7, ups=1.21, wpb=59600.3, bsz=2182.8, num_updates=343300, lr=0.000170672, gnorm=0.352, loss_scale=2, train_wall=78, gb_free=39.5, wall=288327
2023-06-14 23:53:09 | INFO | train_inner | epoch 031:   5196 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=71894, ups=1.21, wpb=59485.4, bsz=2207.2, num_updates=343400, lr=0.000170647, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.6, wall=288409
2023-06-14 23:54:31 | INFO | train_inner | epoch 031:   5296 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=72212.4, ups=1.21, wpb=59547.2, bsz=2291.4, num_updates=343500, lr=0.000170623, gnorm=0.344, loss_scale=2, train_wall=78, gb_free=39.6, wall=288492
2023-06-14 23:55:55 | INFO | train_inner | epoch 031:   5396 / 11284 loss=3.476, nll_loss=1.764, ppl=3.4, wps=71152.5, ups=1.2, wpb=59400.7, bsz=2342.7, num_updates=343600, lr=0.000170598, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.5, wall=288575
2023-06-14 23:56:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-14 23:57:19 | INFO | train_inner | epoch 031:   5497 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=71064.4, ups=1.19, wpb=59512.8, bsz=2196, num_updates=343700, lr=0.000170573, gnorm=0.345, loss_scale=2, train_wall=80, gb_free=39.6, wall=288659
2023-06-14 23:58:41 | INFO | train_inner | epoch 031:   5597 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=71875.2, ups=1.21, wpb=59312.7, bsz=2182.8, num_updates=343800, lr=0.000170548, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.6, wall=288742
2023-06-15 00:00:04 | INFO | train_inner | epoch 031:   5697 / 11284 loss=3.5, nll_loss=1.792, ppl=3.46, wps=72003.3, ups=1.21, wpb=59725, bsz=2201, num_updates=343900, lr=0.000170523, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.5, wall=288825
2023-06-15 00:01:27 | INFO | train_inner | epoch 031:   5797 / 11284 loss=3.478, nll_loss=1.767, ppl=3.4, wps=72267.9, ups=1.21, wpb=59718.2, bsz=2199.7, num_updates=344000, lr=0.000170499, gnorm=0.343, loss_scale=2, train_wall=79, gb_free=39.6, wall=288907
2023-06-15 00:02:49 | INFO | train_inner | epoch 031:   5897 / 11284 loss=3.506, nll_loss=1.799, ppl=3.48, wps=72132, ups=1.22, wpb=59294.3, bsz=2180.1, num_updates=344100, lr=0.000170474, gnorm=0.352, loss_scale=2, train_wall=78, gb_free=39.6, wall=288989
2023-06-15 00:04:11 | INFO | train_inner | epoch 031:   5997 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=72312.7, ups=1.21, wpb=59602.6, bsz=2272.5, num_updates=344200, lr=0.000170449, gnorm=0.35, loss_scale=2, train_wall=79, gb_free=39.6, wall=289072
2023-06-15 00:05:35 | INFO | train_inner | epoch 031:   6097 / 11284 loss=3.489, nll_loss=1.78, ppl=3.43, wps=71477.5, ups=1.2, wpb=59504.1, bsz=2329.3, num_updates=344300, lr=0.000170424, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.5, wall=289155
2023-06-15 00:06:58 | INFO | train_inner | epoch 031:   6197 / 11284 loss=3.49, nll_loss=1.78, ppl=3.44, wps=71665.1, ups=1.2, wpb=59698.3, bsz=2268.7, num_updates=344400, lr=0.0001704, gnorm=0.362, loss_scale=2, train_wall=79, gb_free=39.6, wall=289238
2023-06-15 00:08:20 | INFO | train_inner | epoch 031:   6297 / 11284 loss=3.478, nll_loss=1.767, ppl=3.4, wps=72404.9, ups=1.22, wpb=59349.4, bsz=2255.8, num_updates=344500, lr=0.000170375, gnorm=0.35, loss_scale=2, train_wall=78, gb_free=39.6, wall=289320
2023-06-15 00:09:42 | INFO | train_inner | epoch 031:   6397 / 11284 loss=3.509, nll_loss=1.801, ppl=3.48, wps=72708.7, ups=1.22, wpb=59442.4, bsz=2257, num_updates=344600, lr=0.00017035, gnorm=0.358, loss_scale=2, train_wall=78, gb_free=39.6, wall=289402
2023-06-15 00:10:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 00:11:04 | INFO | train_inner | epoch 031:   6498 / 11284 loss=3.499, nll_loss=1.791, ppl=3.46, wps=72229, ups=1.22, wpb=59441.3, bsz=2231.3, num_updates=344700, lr=0.000170325, gnorm=0.358, loss_scale=2, train_wall=78, gb_free=39.6, wall=289484
2023-06-15 00:12:26 | INFO | train_inner | epoch 031:   6598 / 11284 loss=3.492, nll_loss=1.782, ppl=3.44, wps=72646.7, ups=1.22, wpb=59389.7, bsz=2282.3, num_updates=344800, lr=0.000170301, gnorm=0.349, loss_scale=2, train_wall=78, gb_free=39.6, wall=289566
2023-06-15 00:13:48 | INFO | train_inner | epoch 031:   6698 / 11284 loss=3.488, nll_loss=1.779, ppl=3.43, wps=72035.5, ups=1.21, wpb=59554.1, bsz=2125.4, num_updates=344900, lr=0.000170276, gnorm=0.363, loss_scale=2, train_wall=79, gb_free=39.6, wall=289649
2023-06-15 00:15:12 | INFO | train_inner | epoch 031:   6798 / 11284 loss=3.49, nll_loss=1.781, ppl=3.44, wps=71391.1, ups=1.2, wpb=59492.9, bsz=2312, num_updates=345000, lr=0.000170251, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=289732
2023-06-15 00:16:35 | INFO | train_inner | epoch 031:   6898 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=71799, ups=1.21, wpb=59522, bsz=2176.4, num_updates=345100, lr=0.000170227, gnorm=0.352, loss_scale=2, train_wall=79, gb_free=39.6, wall=289815
2023-06-15 00:17:58 | INFO | train_inner | epoch 031:   6998 / 11284 loss=3.491, nll_loss=1.781, ppl=3.44, wps=71256.1, ups=1.2, wpb=59243.5, bsz=2241.4, num_updates=345200, lr=0.000170202, gnorm=0.365, loss_scale=2, train_wall=79, gb_free=39.5, wall=289898
2023-06-15 00:19:21 | INFO | train_inner | epoch 031:   7098 / 11284 loss=3.49, nll_loss=1.781, ppl=3.44, wps=71570.6, ups=1.2, wpb=59412.3, bsz=2196.5, num_updates=345300, lr=0.000170177, gnorm=0.358, loss_scale=2, train_wall=79, gb_free=39.6, wall=289981
2023-06-15 00:20:43 | INFO | train_inner | epoch 031:   7198 / 11284 loss=3.491, nll_loss=1.782, ppl=3.44, wps=72225, ups=1.21, wpb=59500.3, bsz=2231.1, num_updates=345400, lr=0.000170153, gnorm=0.351, loss_scale=2, train_wall=78, gb_free=39.5, wall=290064
2023-06-15 00:22:06 | INFO | train_inner | epoch 031:   7298 / 11284 loss=3.479, nll_loss=1.769, ppl=3.41, wps=71753.1, ups=1.21, wpb=59499.2, bsz=2344.7, num_updates=345500, lr=0.000170128, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=290147
2023-06-15 00:23:29 | INFO | train_inner | epoch 031:   7398 / 11284 loss=3.49, nll_loss=1.78, ppl=3.43, wps=71384.3, ups=1.2, wpb=59469.6, bsz=2244.8, num_updates=345600, lr=0.000170103, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=290230
2023-06-15 00:24:52 | INFO | train_inner | epoch 031:   7498 / 11284 loss=3.499, nll_loss=1.79, ppl=3.46, wps=71720.6, ups=1.21, wpb=59307.2, bsz=2263.9, num_updates=345700, lr=0.000170079, gnorm=0.375, loss_scale=2, train_wall=79, gb_free=39.6, wall=290313
2023-06-15 00:25:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 00:26:16 | INFO | train_inner | epoch 031:   7599 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=70678.7, ups=1.19, wpb=59531.8, bsz=2228, num_updates=345800, lr=0.000170054, gnorm=0.355, loss_scale=2, train_wall=80, gb_free=39.6, wall=290397
2023-06-15 00:27:39 | INFO | train_inner | epoch 031:   7699 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=72171.4, ups=1.21, wpb=59599.2, bsz=2183.9, num_updates=345900, lr=0.00017003, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.6, wall=290479
2023-06-15 00:29:01 | INFO | train_inner | epoch 031:   7799 / 11284 loss=3.496, nll_loss=1.788, ppl=3.45, wps=72815.5, ups=1.22, wpb=59510.2, bsz=2190, num_updates=346000, lr=0.000170005, gnorm=0.352, loss_scale=2, train_wall=77, gb_free=39.5, wall=290561
2023-06-15 00:30:23 | INFO | train_inner | epoch 031:   7899 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=72410, ups=1.22, wpb=59548.7, bsz=2286.8, num_updates=346100, lr=0.000169981, gnorm=0.369, loss_scale=2, train_wall=78, gb_free=39.5, wall=290643
2023-06-15 00:31:46 | INFO | train_inner | epoch 031:   7999 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=71207, ups=1.2, wpb=59356.7, bsz=2234.2, num_updates=346200, lr=0.000169956, gnorm=0.363, loss_scale=2, train_wall=79, gb_free=39.6, wall=290727
2023-06-15 00:33:09 | INFO | train_inner | epoch 031:   8099 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=71628.2, ups=1.2, wpb=59534.4, bsz=2250.3, num_updates=346300, lr=0.000169931, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.6, wall=290810
2023-06-15 00:34:32 | INFO | train_inner | epoch 031:   8199 / 11284 loss=3.506, nll_loss=1.799, ppl=3.48, wps=71910, ups=1.21, wpb=59469.1, bsz=2237.6, num_updates=346400, lr=0.000169907, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.6, wall=290893
2023-06-15 00:35:55 | INFO | train_inner | epoch 031:   8299 / 11284 loss=3.479, nll_loss=1.768, ppl=3.41, wps=72076, ups=1.21, wpb=59612.8, bsz=2239.5, num_updates=346500, lr=0.000169882, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=290975
2023-06-15 00:37:18 | INFO | train_inner | epoch 031:   8399 / 11284 loss=3.513, nll_loss=1.806, ppl=3.5, wps=71222.9, ups=1.2, wpb=59335.8, bsz=2287.7, num_updates=346600, lr=0.000169858, gnorm=0.348, loss_scale=2, train_wall=79, gb_free=39.6, wall=291059
2023-06-15 00:38:41 | INFO | train_inner | epoch 031:   8499 / 11284 loss=3.498, nll_loss=1.79, ppl=3.46, wps=71392.3, ups=1.2, wpb=59384.8, bsz=2258.3, num_updates=346700, lr=0.000169833, gnorm=0.364, loss_scale=2, train_wall=79, gb_free=39.6, wall=291142
2023-06-15 00:39:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 00:40:05 | INFO | train_inner | epoch 031:   8600 / 11284 loss=3.486, nll_loss=1.776, ppl=3.43, wps=70868, ups=1.19, wpb=59524.4, bsz=2255.4, num_updates=346800, lr=0.000169809, gnorm=0.353, loss_scale=2, train_wall=80, gb_free=39.6, wall=291226
2023-06-15 00:41:31 | INFO | train_inner | epoch 031:   8700 / 11284 loss=3.488, nll_loss=1.779, ppl=3.43, wps=69687, ups=1.17, wpb=59514.4, bsz=2111.3, num_updates=346900, lr=0.000169784, gnorm=0.345, loss_scale=2, train_wall=82, gb_free=39.6, wall=291311
2023-06-15 00:42:55 | INFO | train_inner | epoch 031:   8800 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=70362.9, ups=1.18, wpb=59545.3, bsz=2188.9, num_updates=347000, lr=0.00016976, gnorm=0.347, loss_scale=2, train_wall=81, gb_free=39.5, wall=291396
2023-06-15 00:44:21 | INFO | train_inner | epoch 031:   8900 / 11284 loss=3.491, nll_loss=1.782, ppl=3.44, wps=69539.5, ups=1.17, wpb=59473.9, bsz=2233.3, num_updates=347100, lr=0.000169736, gnorm=0.361, loss_scale=2, train_wall=81, gb_free=39.6, wall=291481
2023-06-15 00:45:46 | INFO | train_inner | epoch 031:   9000 / 11284 loss=3.501, nll_loss=1.794, ppl=3.47, wps=69415, ups=1.17, wpb=59237.3, bsz=2220.1, num_updates=347200, lr=0.000169711, gnorm=0.356, loss_scale=2, train_wall=81, gb_free=39.6, wall=291567
2023-06-15 00:47:11 | INFO | train_inner | epoch 031:   9100 / 11284 loss=3.491, nll_loss=1.782, ppl=3.44, wps=69503.3, ups=1.17, wpb=59355.4, bsz=2187.2, num_updates=347300, lr=0.000169687, gnorm=0.356, loss_scale=2, train_wall=82, gb_free=39.5, wall=291652
2023-06-15 00:48:38 | INFO | train_inner | epoch 031:   9200 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=68726.3, ups=1.16, wpb=59407, bsz=2261.6, num_updates=347400, lr=0.000169662, gnorm=0.344, loss_scale=2, train_wall=82, gb_free=39.6, wall=291739
2023-06-15 00:50:05 | INFO | train_inner | epoch 031:   9300 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=68369.6, ups=1.15, wpb=59561.9, bsz=2087.9, num_updates=347500, lr=0.000169638, gnorm=0.358, loss_scale=2, train_wall=83, gb_free=38.9, wall=291826
2023-06-15 00:51:32 | INFO | train_inner | epoch 031:   9400 / 11284 loss=3.49, nll_loss=1.781, ppl=3.44, wps=68566.8, ups=1.15, wpb=59669.8, bsz=2218.4, num_updates=347600, lr=0.000169613, gnorm=0.35, loss_scale=2, train_wall=83, gb_free=39.7, wall=291913
2023-06-15 00:52:59 | INFO | train_inner | epoch 031:   9500 / 11284 loss=3.492, nll_loss=1.783, ppl=3.44, wps=68181, ups=1.15, wpb=59055.1, bsz=2289.9, num_updates=347700, lr=0.000169589, gnorm=0.359, loss_scale=2, train_wall=83, gb_free=39.6, wall=291999
2023-06-15 00:54:26 | INFO | train_inner | epoch 031:   9600 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=68501.2, ups=1.15, wpb=59618, bsz=2290.7, num_updates=347800, lr=0.000169565, gnorm=0.353, loss_scale=4, train_wall=83, gb_free=39.6, wall=292086
2023-06-15 00:54:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 00:55:53 | INFO | train_inner | epoch 031:   9701 / 11284 loss=3.493, nll_loss=1.784, ppl=3.44, wps=67850.9, ups=1.14, wpb=59453.4, bsz=2239, num_updates=347900, lr=0.00016954, gnorm=0.366, loss_scale=2, train_wall=84, gb_free=39.6, wall=292174
2023-06-15 00:57:20 | INFO | train_inner | epoch 031:   9801 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=68657.1, ups=1.15, wpb=59641.3, bsz=2260.7, num_updates=348000, lr=0.000169516, gnorm=0.353, loss_scale=2, train_wall=83, gb_free=39.6, wall=292261
2023-06-15 00:58:47 | INFO | train_inner | epoch 031:   9901 / 11284 loss=3.481, nll_loss=1.771, ppl=3.41, wps=68467.4, ups=1.15, wpb=59563.5, bsz=2241.3, num_updates=348100, lr=0.000169492, gnorm=0.347, loss_scale=2, train_wall=83, gb_free=39.6, wall=292348
2023-06-15 01:00:14 | INFO | train_inner | epoch 031:  10001 / 11284 loss=3.515, nll_loss=1.809, ppl=3.5, wps=68364.7, ups=1.15, wpb=59585.2, bsz=2270.2, num_updates=348200, lr=0.000169467, gnorm=0.366, loss_scale=2, train_wall=83, gb_free=39.6, wall=292435
2023-06-15 01:01:41 | INFO | train_inner | epoch 031:  10101 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=68513.3, ups=1.15, wpb=59557.8, bsz=2213.6, num_updates=348300, lr=0.000169443, gnorm=0.344, loss_scale=2, train_wall=83, gb_free=39.5, wall=292522
2023-06-15 01:03:06 | INFO | train_inner | epoch 031:  10201 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=70114.5, ups=1.18, wpb=59599.2, bsz=2259.6, num_updates=348400, lr=0.000169419, gnorm=0.366, loss_scale=2, train_wall=81, gb_free=39.6, wall=292607
2023-06-15 01:04:32 | INFO | train_inner | epoch 031:  10301 / 11284 loss=3.5, nll_loss=1.792, ppl=3.46, wps=69673.1, ups=1.17, wpb=59442.8, bsz=2245.5, num_updates=348500, lr=0.000169394, gnorm=0.354, loss_scale=2, train_wall=81, gb_free=39.5, wall=292692
2023-06-15 01:05:56 | INFO | train_inner | epoch 031:  10401 / 11284 loss=3.485, nll_loss=1.776, ppl=3.42, wps=70788.8, ups=1.19, wpb=59472, bsz=2180.9, num_updates=348600, lr=0.00016937, gnorm=0.345, loss_scale=2, train_wall=80, gb_free=39.6, wall=292776
2023-06-15 01:07:22 | INFO | train_inner | epoch 031:  10501 / 11284 loss=3.5, nll_loss=1.792, ppl=3.46, wps=69416.2, ups=1.16, wpb=59628.7, bsz=2204, num_updates=348700, lr=0.000169346, gnorm=0.341, loss_scale=2, train_wall=82, gb_free=39.6, wall=292862
2023-06-15 01:08:47 | INFO | train_inner | epoch 031:  10601 / 11284 loss=3.501, nll_loss=1.792, ppl=3.46, wps=69457.7, ups=1.17, wpb=59513.3, bsz=2276.5, num_updates=348800, lr=0.000169321, gnorm=0.35, loss_scale=2, train_wall=82, gb_free=39.5, wall=292948
2023-06-15 01:09:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 01:10:13 | INFO | train_inner | epoch 031:  10702 / 11284 loss=3.492, nll_loss=1.783, ppl=3.44, wps=68929.2, ups=1.16, wpb=59458.1, bsz=2265.1, num_updates=348900, lr=0.000169297, gnorm=0.361, loss_scale=2, train_wall=82, gb_free=39.5, wall=293034
2023-06-15 01:11:39 | INFO | train_inner | epoch 031:  10802 / 11284 loss=3.48, nll_loss=1.77, ppl=3.41, wps=69960.1, ups=1.17, wpb=59744, bsz=2224.5, num_updates=349000, lr=0.000169273, gnorm=0.356, loss_scale=2, train_wall=82, gb_free=39.6, wall=293119
2023-06-15 01:13:04 | INFO | train_inner | epoch 031:  10902 / 11284 loss=3.497, nll_loss=1.789, ppl=3.46, wps=70361.5, ups=1.18, wpb=59539.8, bsz=2330.7, num_updates=349100, lr=0.000169249, gnorm=0.354, loss_scale=2, train_wall=81, gb_free=39.6, wall=293204
2023-06-15 01:14:29 | INFO | train_inner | epoch 031:  11002 / 11284 loss=3.486, nll_loss=1.777, ppl=3.43, wps=69829.7, ups=1.17, wpb=59470, bsz=2172, num_updates=349200, lr=0.000169224, gnorm=0.348, loss_scale=2, train_wall=81, gb_free=39.6, wall=293289
2023-06-15 01:15:53 | INFO | train_inner | epoch 031:  11102 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=70197.7, ups=1.18, wpb=59391.2, bsz=2192.2, num_updates=349300, lr=0.0001692, gnorm=0.363, loss_scale=2, train_wall=81, gb_free=39.6, wall=293374
2023-06-15 01:17:19 | INFO | train_inner | epoch 031:  11202 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=69437.8, ups=1.17, wpb=59394.2, bsz=2274.7, num_updates=349400, lr=0.000169176, gnorm=0.351, loss_scale=2, train_wall=82, gb_free=39.6, wall=293459
2023-06-15 01:18:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-15 01:18:48 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 4.292 | nll_loss 2.61 | ppl 6.1 | bleu 20.92 | wps 3719.3 | wpb 2397.5 | bsz 71.5 | num_updates 349482 | best_loss 4.283
2023-06-15 01:18:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 349482 updates
2023-06-15 01:18:48 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint31.pt
2023-06-15 01:18:55 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint31.pt
2023-06-15 01:19:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint31.pt (epoch 31 @ 349482 updates, score 4.292) (writing took 19.122751280665398 seconds)
2023-06-15 01:19:07 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-06-15 01:19:07 | INFO | train | epoch 031 | loss 3.489 | nll_loss 1.779 | ppl 3.43 | wps 70925.1 | ups 1.19 | wpb 59500.2 | bsz 2227.4 | num_updates 349482 | lr 0.000169156 | gnorm 0.352 | loss_scale 2 | train_wall 8968 | gb_free 39.6 | wall 293567
2023-06-15 01:19:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-15 01:19:07 | INFO | fairseq.trainer | begin training epoch 32
2023-06-15 01:19:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-15 01:19:22 | INFO | train_inner | epoch 032:     18 / 11284 loss=3.486, nll_loss=1.776, ppl=3.42, wps=48100.7, ups=0.81, wpb=59481.5, bsz=2247.2, num_updates=349500, lr=0.000169152, gnorm=0.36, loss_scale=2, train_wall=82, gb_free=39.6, wall=293583
2023-06-15 01:20:48 | INFO | train_inner | epoch 032:    118 / 11284 loss=3.482, nll_loss=1.772, ppl=3.41, wps=69899.8, ups=1.17, wpb=59609.1, bsz=2162.1, num_updates=349600, lr=0.000169128, gnorm=0.357, loss_scale=2, train_wall=81, gb_free=39.5, wall=293668
2023-06-15 01:22:14 | INFO | train_inner | epoch 032:    218 / 11284 loss=3.484, nll_loss=1.773, ppl=3.42, wps=69058.4, ups=1.16, wpb=59467.9, bsz=2197.3, num_updates=349700, lr=0.000169103, gnorm=0.359, loss_scale=2, train_wall=82, gb_free=39.6, wall=293754
2023-06-15 01:23:39 | INFO | train_inner | epoch 032:    318 / 11284 loss=3.48, nll_loss=1.769, ppl=3.41, wps=69821.4, ups=1.17, wpb=59512.8, bsz=2303.9, num_updates=349800, lr=0.000169079, gnorm=0.351, loss_scale=2, train_wall=81, gb_free=39.6, wall=293840
2023-06-15 01:25:05 | INFO | train_inner | epoch 032:    418 / 11284 loss=3.479, nll_loss=1.768, ppl=3.41, wps=69315.8, ups=1.16, wpb=59607.8, bsz=2306.1, num_updates=349900, lr=0.000169055, gnorm=0.351, loss_scale=4, train_wall=82, gb_free=39.6, wall=293926
2023-06-15 01:25:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 01:26:30 | INFO | train_inner | epoch 032:    519 / 11284 loss=3.486, nll_loss=1.776, ppl=3.42, wps=69821.9, ups=1.17, wpb=59504.9, bsz=2189.5, num_updates=350000, lr=0.000169031, gnorm=0.377, loss_scale=2, train_wall=81, gb_free=39.6, wall=294011
2023-06-15 01:27:56 | INFO | train_inner | epoch 032:    619 / 11284 loss=3.479, nll_loss=1.768, ppl=3.41, wps=69566.4, ups=1.17, wpb=59538.5, bsz=2179.4, num_updates=350100, lr=0.000169007, gnorm=0.354, loss_scale=2, train_wall=82, gb_free=39.5, wall=294097
2023-06-15 01:29:21 | INFO | train_inner | epoch 032:    719 / 11284 loss=3.486, nll_loss=1.776, ppl=3.42, wps=70124.4, ups=1.18, wpb=59592.4, bsz=2264.3, num_updates=350200, lr=0.000168983, gnorm=0.349, loss_scale=2, train_wall=81, gb_free=39.5, wall=294181
2023-06-15 01:30:46 | INFO | train_inner | epoch 032:    819 / 11284 loss=3.472, nll_loss=1.76, ppl=3.39, wps=69688.5, ups=1.17, wpb=59330.2, bsz=2283, num_updates=350300, lr=0.000168958, gnorm=0.348, loss_scale=2, train_wall=81, gb_free=39.6, wall=294267
2023-06-15 01:32:12 | INFO | train_inner | epoch 032:    919 / 11284 loss=3.482, nll_loss=1.771, ppl=3.41, wps=69567.1, ups=1.17, wpb=59493.9, bsz=2243, num_updates=350400, lr=0.000168934, gnorm=0.346, loss_scale=2, train_wall=81, gb_free=39.6, wall=294352
2023-06-15 01:33:37 | INFO | train_inner | epoch 032:   1019 / 11284 loss=3.489, nll_loss=1.779, ppl=3.43, wps=69714.7, ups=1.17, wpb=59477.2, bsz=2235.5, num_updates=350500, lr=0.00016891, gnorm=0.359, loss_scale=2, train_wall=81, gb_free=39.6, wall=294437
2023-06-15 01:35:03 | INFO | train_inner | epoch 032:   1119 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=69018.9, ups=1.16, wpb=59554.3, bsz=2241.9, num_updates=350600, lr=0.000168886, gnorm=0.353, loss_scale=2, train_wall=82, gb_free=39.6, wall=294524
2023-06-15 01:36:29 | INFO | train_inner | epoch 032:   1219 / 11284 loss=3.493, nll_loss=1.783, ppl=3.44, wps=69174.6, ups=1.16, wpb=59605.9, bsz=2269.3, num_updates=350700, lr=0.000168862, gnorm=0.348, loss_scale=2, train_wall=82, gb_free=39.5, wall=294610
2023-06-15 01:37:55 | INFO | train_inner | epoch 032:   1319 / 11284 loss=3.494, nll_loss=1.784, ppl=3.44, wps=69060.3, ups=1.16, wpb=59416.5, bsz=2321.3, num_updates=350800, lr=0.000168838, gnorm=0.351, loss_scale=2, train_wall=82, gb_free=39.6, wall=294696
2023-06-15 01:39:22 | INFO | train_inner | epoch 032:   1419 / 11284 loss=3.489, nll_loss=1.779, ppl=3.43, wps=69082.4, ups=1.16, wpb=59700.8, bsz=2300.8, num_updates=350900, lr=0.000168814, gnorm=0.375, loss_scale=2, train_wall=82, gb_free=39.6, wall=294782
2023-06-15 01:40:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 01:40:49 | INFO | train_inner | epoch 032:   1520 / 11284 loss=3.483, nll_loss=1.772, ppl=3.42, wps=68392.4, ups=1.15, wpb=59396.7, bsz=2227.8, num_updates=351000, lr=0.00016879, gnorm=0.341, loss_scale=2, train_wall=83, gb_free=39.6, wall=294869
2023-06-15 01:42:14 | INFO | train_inner | epoch 032:   1620 / 11284 loss=3.488, nll_loss=1.777, ppl=3.43, wps=69421.7, ups=1.17, wpb=59510.6, bsz=2270.4, num_updates=351100, lr=0.000168766, gnorm=0.346, loss_scale=2, train_wall=82, gb_free=39.5, wall=294955
2023-06-15 01:43:40 | INFO | train_inner | epoch 032:   1720 / 11284 loss=3.479, nll_loss=1.769, ppl=3.41, wps=69635.6, ups=1.17, wpb=59552.5, bsz=2237.9, num_updates=351200, lr=0.000168742, gnorm=0.363, loss_scale=2, train_wall=81, gb_free=39.6, wall=295040
2023-06-15 01:45:04 | INFO | train_inner | epoch 032:   1820 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=70802.2, ups=1.19, wpb=59340.3, bsz=2227.3, num_updates=351300, lr=0.000168718, gnorm=0.37, loss_scale=2, train_wall=80, gb_free=39.5, wall=295124
2023-06-15 01:46:27 | INFO | train_inner | epoch 032:   1920 / 11284 loss=3.479, nll_loss=1.767, ppl=3.4, wps=71539, ups=1.2, wpb=59463.2, bsz=2212.1, num_updates=351400, lr=0.000168694, gnorm=0.341, loss_scale=2, train_wall=79, gb_free=39.6, wall=295207
2023-06-15 01:47:50 | INFO | train_inner | epoch 032:   2020 / 11284 loss=3.474, nll_loss=1.762, ppl=3.39, wps=72028.1, ups=1.2, wpb=59807.1, bsz=2233.2, num_updates=351500, lr=0.00016867, gnorm=0.352, loss_scale=2, train_wall=79, gb_free=39.6, wall=295290
2023-06-15 01:49:13 | INFO | train_inner | epoch 032:   2120 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=71611.3, ups=1.21, wpb=59397.9, bsz=2279, num_updates=351600, lr=0.000168646, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.6, wall=295373
2023-06-15 01:50:36 | INFO | train_inner | epoch 032:   2220 / 11284 loss=3.492, nll_loss=1.783, ppl=3.44, wps=70839.4, ups=1.2, wpb=59211, bsz=2305.3, num_updates=351700, lr=0.000168622, gnorm=0.349, loss_scale=2, train_wall=79, gb_free=39.5, wall=295457
2023-06-15 01:51:59 | INFO | train_inner | epoch 032:   2320 / 11284 loss=3.482, nll_loss=1.772, ppl=3.41, wps=71850, ups=1.2, wpb=59676, bsz=2240.2, num_updates=351800, lr=0.000168598, gnorm=0.343, loss_scale=2, train_wall=79, gb_free=39.5, wall=295540
2023-06-15 01:53:23 | INFO | train_inner | epoch 032:   2420 / 11284 loss=3.483, nll_loss=1.772, ppl=3.42, wps=71287.1, ups=1.2, wpb=59452.9, bsz=2259.9, num_updates=351900, lr=0.000168574, gnorm=0.355, loss_scale=2, train_wall=79, gb_free=39.6, wall=295623
2023-06-15 01:54:46 | INFO | train_inner | epoch 032:   2520 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=71862.1, ups=1.21, wpb=59592.4, bsz=2180.2, num_updates=352000, lr=0.00016855, gnorm=0.362, loss_scale=2, train_wall=79, gb_free=39.6, wall=295706
2023-06-15 01:55:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 01:56:10 | INFO | train_inner | epoch 032:   2621 / 11284 loss=3.475, nll_loss=1.763, ppl=3.4, wps=71284.4, ups=1.19, wpb=59754.6, bsz=2231.1, num_updates=352100, lr=0.000168526, gnorm=0.354, loss_scale=2, train_wall=80, gb_free=39.6, wall=295790
2023-06-15 01:57:32 | INFO | train_inner | epoch 032:   2721 / 11284 loss=3.483, nll_loss=1.772, ppl=3.42, wps=72228.9, ups=1.21, wpb=59534.6, bsz=2255.1, num_updates=352200, lr=0.000168502, gnorm=0.352, loss_scale=2, train_wall=79, gb_free=39.5, wall=295873
2023-06-15 01:58:55 | INFO | train_inner | epoch 032:   2821 / 11284 loss=3.482, nll_loss=1.771, ppl=3.41, wps=71703, ups=1.2, wpb=59505.3, bsz=2073.9, num_updates=352300, lr=0.000168478, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.5, wall=295956
2023-06-15 02:00:17 | INFO | train_inner | epoch 032:   2921 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=72565.6, ups=1.22, wpb=59585.9, bsz=2254.4, num_updates=352400, lr=0.000168454, gnorm=0.355, loss_scale=2, train_wall=78, gb_free=39.6, wall=296038
2023-06-15 02:01:40 | INFO | train_inner | epoch 032:   3021 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=71850.6, ups=1.21, wpb=59484.1, bsz=2210.4, num_updates=352500, lr=0.00016843, gnorm=0.361, loss_scale=2, train_wall=79, gb_free=39.6, wall=296121
2023-06-15 02:03:04 | INFO | train_inner | epoch 032:   3121 / 11284 loss=3.481, nll_loss=1.77, ppl=3.41, wps=71142.3, ups=1.19, wpb=59675.2, bsz=2210.7, num_updates=352600, lr=0.000168406, gnorm=0.341, loss_scale=2, train_wall=80, gb_free=39.6, wall=296204
2023-06-15 02:04:26 | INFO | train_inner | epoch 032:   3221 / 11284 loss=3.476, nll_loss=1.764, ppl=3.4, wps=72185.9, ups=1.21, wpb=59531.2, bsz=2159.1, num_updates=352700, lr=0.000168383, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=296287
2023-06-15 02:05:49 | INFO | train_inner | epoch 032:   3321 / 11284 loss=3.492, nll_loss=1.783, ppl=3.44, wps=71505, ups=1.2, wpb=59425.5, bsz=2188.8, num_updates=352800, lr=0.000168359, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.5, wall=296370
2023-06-15 02:07:13 | INFO | train_inner | epoch 032:   3421 / 11284 loss=3.477, nll_loss=1.766, ppl=3.4, wps=71538, ups=1.2, wpb=59570.2, bsz=2218.1, num_updates=352900, lr=0.000168335, gnorm=0.35, loss_scale=2, train_wall=79, gb_free=39.6, wall=296453
2023-06-15 02:08:34 | INFO | train_inner | epoch 032:   3521 / 11284 loss=3.478, nll_loss=1.767, ppl=3.4, wps=73102.6, ups=1.23, wpb=59561.8, bsz=2252.7, num_updates=353000, lr=0.000168311, gnorm=0.344, loss_scale=2, train_wall=77, gb_free=39.5, wall=296535
2023-06-15 02:09:55 | INFO | train_inner | epoch 032:   3621 / 11284 loss=3.491, nll_loss=1.782, ppl=3.44, wps=73040.4, ups=1.23, wpb=59392.3, bsz=2182.3, num_updates=353100, lr=0.000168287, gnorm=0.352, loss_scale=4, train_wall=77, gb_free=39.6, wall=296616
2023-06-15 02:09:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 02:11:19 | INFO | train_inner | epoch 032:   3722 / 11284 loss=3.477, nll_loss=1.765, ppl=3.4, wps=71187.5, ups=1.2, wpb=59367.4, bsz=2192.9, num_updates=353200, lr=0.000168263, gnorm=0.365, loss_scale=2, train_wall=79, gb_free=39.5, wall=296699
2023-06-15 02:12:42 | INFO | train_inner | epoch 032:   3822 / 11284 loss=3.479, nll_loss=1.768, ppl=3.41, wps=71804.7, ups=1.21, wpb=59450, bsz=2217.1, num_updates=353300, lr=0.00016824, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.6, wall=296782
2023-06-15 02:14:05 | INFO | train_inner | epoch 032:   3922 / 11284 loss=3.486, nll_loss=1.776, ppl=3.43, wps=71596.7, ups=1.21, wpb=59409.8, bsz=2166.3, num_updates=353400, lr=0.000168216, gnorm=0.352, loss_scale=2, train_wall=79, gb_free=39.5, wall=296865
2023-06-15 02:15:28 | INFO | train_inner | epoch 032:   4022 / 11284 loss=3.478, nll_loss=1.767, ppl=3.4, wps=71638.8, ups=1.2, wpb=59516.9, bsz=2168.1, num_updates=353500, lr=0.000168192, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.6, wall=296948
2023-06-15 02:16:51 | INFO | train_inner | epoch 032:   4122 / 11284 loss=3.482, nll_loss=1.771, ppl=3.41, wps=71641.5, ups=1.2, wpb=59538.8, bsz=2195.6, num_updates=353600, lr=0.000168168, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.6, wall=297031
2023-06-15 02:18:14 | INFO | train_inner | epoch 032:   4222 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=71462, ups=1.2, wpb=59561.7, bsz=2223.7, num_updates=353700, lr=0.000168144, gnorm=0.35, loss_scale=2, train_wall=79, gb_free=39.6, wall=297115
2023-06-15 02:19:37 | INFO | train_inner | epoch 032:   4322 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=71866, ups=1.21, wpb=59630, bsz=2180.8, num_updates=353800, lr=0.000168121, gnorm=0.354, loss_scale=2, train_wall=79, gb_free=39.6, wall=297198
2023-06-15 02:21:00 | INFO | train_inner | epoch 032:   4422 / 11284 loss=3.483, nll_loss=1.772, ppl=3.42, wps=71979, ups=1.2, wpb=59793.4, bsz=2272.8, num_updates=353900, lr=0.000168097, gnorm=0.343, loss_scale=2, train_wall=79, gb_free=39.6, wall=297281
2023-06-15 02:22:23 | INFO | train_inner | epoch 032:   4522 / 11284 loss=3.49, nll_loss=1.78, ppl=3.43, wps=71581, ups=1.21, wpb=59319, bsz=2200.6, num_updates=354000, lr=0.000168073, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39, wall=297364
2023-06-15 02:23:46 | INFO | train_inner | epoch 032:   4622 / 11284 loss=3.509, nll_loss=1.802, ppl=3.49, wps=71475.3, ups=1.2, wpb=59419.5, bsz=2292.8, num_updates=354100, lr=0.000168049, gnorm=0.348, loss_scale=2, train_wall=79, gb_free=39.5, wall=297447
2023-06-15 02:24:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 02:25:10 | INFO | train_inner | epoch 032:   4723 / 11284 loss=3.482, nll_loss=1.772, ppl=3.41, wps=70746.1, ups=1.19, wpb=59378.5, bsz=2208.2, num_updates=354200, lr=0.000168026, gnorm=0.347, loss_scale=2, train_wall=80, gb_free=39.5, wall=297531
2023-06-15 02:26:33 | INFO | train_inner | epoch 032:   4823 / 11284 loss=3.476, nll_loss=1.765, ppl=3.4, wps=71679.1, ups=1.2, wpb=59604.4, bsz=2225.2, num_updates=354300, lr=0.000168002, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.5, wall=297614
2023-06-15 02:27:56 | INFO | train_inner | epoch 032:   4923 / 11284 loss=3.49, nll_loss=1.781, ppl=3.44, wps=72441, ups=1.22, wpb=59612.3, bsz=2133, num_updates=354400, lr=0.000167978, gnorm=0.356, loss_scale=2, train_wall=78, gb_free=39.6, wall=297696
2023-06-15 02:29:19 | INFO | train_inner | epoch 032:   5023 / 11284 loss=3.479, nll_loss=1.769, ppl=3.41, wps=71583.9, ups=1.2, wpb=59518.3, bsz=2289.5, num_updates=354500, lr=0.000167955, gnorm=0.352, loss_scale=2, train_wall=79, gb_free=39.6, wall=297779
2023-06-15 02:30:41 | INFO | train_inner | epoch 032:   5123 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=72325.3, ups=1.21, wpb=59716.2, bsz=2269.4, num_updates=354600, lr=0.000167931, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.6, wall=297862
2023-06-15 02:32:03 | INFO | train_inner | epoch 032:   5223 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=72997.1, ups=1.23, wpb=59530.5, bsz=2221.6, num_updates=354700, lr=0.000167907, gnorm=0.367, loss_scale=2, train_wall=78, gb_free=39.6, wall=297943
2023-06-15 02:33:25 | INFO | train_inner | epoch 032:   5323 / 11284 loss=3.491, nll_loss=1.782, ppl=3.44, wps=72973.9, ups=1.22, wpb=59611.8, bsz=2222.1, num_updates=354800, lr=0.000167884, gnorm=0.368, loss_scale=2, train_wall=78, gb_free=39.6, wall=298025
2023-06-15 02:34:48 | INFO | train_inner | epoch 032:   5423 / 11284 loss=3.48, nll_loss=1.77, ppl=3.41, wps=71594, ups=1.2, wpb=59520.9, bsz=2186.1, num_updates=354900, lr=0.00016786, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.5, wall=298108
2023-06-15 02:36:10 | INFO | train_inner | epoch 032:   5523 / 11284 loss=3.489, nll_loss=1.78, ppl=3.43, wps=72129, ups=1.21, wpb=59416.9, bsz=2162.4, num_updates=355000, lr=0.000167836, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.6, wall=298191
2023-06-15 02:37:33 | INFO | train_inner | epoch 032:   5623 / 11284 loss=3.483, nll_loss=1.772, ppl=3.42, wps=71996.3, ups=1.21, wpb=59459.3, bsz=2376.1, num_updates=355100, lr=0.000167813, gnorm=0.35, loss_scale=2, train_wall=78, gb_free=39.6, wall=298273
2023-06-15 02:38:56 | INFO | train_inner | epoch 032:   5723 / 11284 loss=3.5, nll_loss=1.791, ppl=3.46, wps=71951.7, ups=1.21, wpb=59645.8, bsz=2201.2, num_updates=355200, lr=0.000167789, gnorm=0.361, loss_scale=4, train_wall=79, gb_free=39.6, wall=298356
2023-06-15 02:39:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 02:40:20 | INFO | train_inner | epoch 032:   5824 / 11284 loss=3.474, nll_loss=1.763, ppl=3.39, wps=70717.7, ups=1.19, wpb=59579, bsz=2253, num_updates=355300, lr=0.000167765, gnorm=0.345, loss_scale=2, train_wall=80, gb_free=39.6, wall=298440
2023-06-15 02:41:43 | INFO | train_inner | epoch 032:   5924 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=71215.5, ups=1.2, wpb=59392.6, bsz=2281.8, num_updates=355400, lr=0.000167742, gnorm=0.361, loss_scale=2, train_wall=79, gb_free=39.6, wall=298524
2023-06-15 02:43:06 | INFO | train_inner | epoch 032:   6024 / 11284 loss=3.486, nll_loss=1.776, ppl=3.42, wps=71119.1, ups=1.2, wpb=59231.2, bsz=2265.5, num_updates=355500, lr=0.000167718, gnorm=0.352, loss_scale=2, train_wall=79, gb_free=39.6, wall=298607
2023-06-15 02:44:29 | INFO | train_inner | epoch 032:   6124 / 11284 loss=3.489, nll_loss=1.78, ppl=3.43, wps=71906.9, ups=1.21, wpb=59605.3, bsz=2243.5, num_updates=355600, lr=0.000167695, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.5, wall=298690
2023-06-15 02:45:53 | INFO | train_inner | epoch 032:   6224 / 11284 loss=3.492, nll_loss=1.782, ppl=3.44, wps=71686.2, ups=1.2, wpb=59689.5, bsz=2283.1, num_updates=355700, lr=0.000167671, gnorm=0.354, loss_scale=2, train_wall=79, gb_free=39.6, wall=298773
2023-06-15 02:47:16 | INFO | train_inner | epoch 032:   6324 / 11284 loss=3.487, nll_loss=1.778, ppl=3.43, wps=71428.8, ups=1.2, wpb=59370.8, bsz=2199.2, num_updates=355800, lr=0.000167647, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=298856
2023-06-15 02:48:39 | INFO | train_inner | epoch 032:   6424 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=71902.3, ups=1.21, wpb=59518.6, bsz=2295.6, num_updates=355900, lr=0.000167624, gnorm=0.354, loss_scale=2, train_wall=79, gb_free=39.5, wall=298939
2023-06-15 02:50:02 | INFO | train_inner | epoch 032:   6524 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=71419.2, ups=1.2, wpb=59363, bsz=2271.8, num_updates=356000, lr=0.0001676, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.2, wall=299022
2023-06-15 02:51:24 | INFO | train_inner | epoch 032:   6624 / 11284 loss=3.491, nll_loss=1.782, ppl=3.44, wps=72209.7, ups=1.21, wpb=59533.5, bsz=2167.8, num_updates=356100, lr=0.000167577, gnorm=0.342, loss_scale=2, train_wall=78, gb_free=39.6, wall=299105
2023-06-15 02:52:47 | INFO | train_inner | epoch 032:   6724 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=71949, ups=1.21, wpb=59557.1, bsz=2157.2, num_updates=356200, lr=0.000167553, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.5, wall=299187
2023-06-15 02:53:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 02:54:10 | INFO | train_inner | epoch 032:   6825 / 11284 loss=3.48, nll_loss=1.769, ppl=3.41, wps=71316.6, ups=1.2, wpb=59497.8, bsz=2144.4, num_updates=356300, lr=0.00016753, gnorm=0.353, loss_scale=2, train_wall=80, gb_free=39.6, wall=299271
2023-06-15 02:55:34 | INFO | train_inner | epoch 032:   6925 / 11284 loss=3.49, nll_loss=1.781, ppl=3.44, wps=71171.9, ups=1.2, wpb=59410.9, bsz=2184.8, num_updates=356400, lr=0.000167506, gnorm=0.368, loss_scale=2, train_wall=80, gb_free=39, wall=299354
2023-06-15 02:57:00 | INFO | train_inner | epoch 032:   7025 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=68732.1, ups=1.16, wpb=59449, bsz=2262.5, num_updates=356500, lr=0.000167483, gnorm=0.366, loss_scale=2, train_wall=82, gb_free=39.6, wall=299441
2023-06-15 02:58:26 | INFO | train_inner | epoch 032:   7125 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=69651.5, ups=1.17, wpb=59481, bsz=2321.4, num_updates=356600, lr=0.000167459, gnorm=0.358, loss_scale=2, train_wall=81, gb_free=39.6, wall=299526
2023-06-15 02:59:52 | INFO | train_inner | epoch 032:   7225 / 11284 loss=3.491, nll_loss=1.782, ppl=3.44, wps=69294.8, ups=1.16, wpb=59653.8, bsz=2252.5, num_updates=356700, lr=0.000167436, gnorm=0.349, loss_scale=2, train_wall=82, gb_free=39.6, wall=299612
2023-06-15 03:01:18 | INFO | train_inner | epoch 032:   7325 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=68867.5, ups=1.16, wpb=59466.2, bsz=2191.8, num_updates=356800, lr=0.000167412, gnorm=0.352, loss_scale=2, train_wall=82, gb_free=39.6, wall=299699
2023-06-15 03:02:45 | INFO | train_inner | epoch 032:   7425 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=67972.3, ups=1.15, wpb=59345.1, bsz=2177.4, num_updates=356900, lr=0.000167389, gnorm=0.343, loss_scale=2, train_wall=83, gb_free=39.5, wall=299786
2023-06-15 03:04:12 | INFO | train_inner | epoch 032:   7525 / 11284 loss=3.486, nll_loss=1.777, ppl=3.43, wps=69031.5, ups=1.16, wpb=59584.6, bsz=2176.9, num_updates=357000, lr=0.000167365, gnorm=0.344, loss_scale=2, train_wall=82, gb_free=39.5, wall=299872
2023-06-15 03:05:38 | INFO | train_inner | epoch 032:   7625 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=68905, ups=1.16, wpb=59508.6, bsz=2198.7, num_updates=357100, lr=0.000167342, gnorm=0.365, loss_scale=2, train_wall=82, gb_free=39.5, wall=299959
2023-06-15 03:07:03 | INFO | train_inner | epoch 032:   7725 / 11284 loss=3.479, nll_loss=1.769, ppl=3.41, wps=70240, ups=1.18, wpb=59609.2, bsz=2114.5, num_updates=357200, lr=0.000167319, gnorm=0.353, loss_scale=2, train_wall=81, gb_free=39.6, wall=300044
2023-06-15 03:08:29 | INFO | train_inner | epoch 032:   7825 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=69365.8, ups=1.17, wpb=59314.7, bsz=2254, num_updates=357300, lr=0.000167295, gnorm=0.349, loss_scale=2, train_wall=82, gb_free=39.3, wall=300129
2023-06-15 03:09:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 03:09:55 | INFO | train_inner | epoch 032:   7926 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=68544.3, ups=1.15, wpb=59367.6, bsz=2254.6, num_updates=357400, lr=0.000167272, gnorm=0.368, loss_scale=2, train_wall=83, gb_free=39.6, wall=300216
2023-06-15 03:11:21 | INFO | train_inner | epoch 032:   8026 / 11284 loss=3.492, nll_loss=1.783, ppl=3.44, wps=69315.4, ups=1.17, wpb=59220.2, bsz=2230.5, num_updates=357500, lr=0.000167248, gnorm=0.366, loss_scale=2, train_wall=82, gb_free=39.6, wall=300301
2023-06-15 03:12:46 | INFO | train_inner | epoch 032:   8126 / 11284 loss=3.476, nll_loss=1.764, ppl=3.4, wps=69400.3, ups=1.17, wpb=59471.3, bsz=2327.3, num_updates=357600, lr=0.000167225, gnorm=0.359, loss_scale=2, train_wall=82, gb_free=39.6, wall=300387
2023-06-15 03:14:12 | INFO | train_inner | epoch 032:   8226 / 11284 loss=3.492, nll_loss=1.783, ppl=3.44, wps=69738, ups=1.17, wpb=59520.7, bsz=2256.1, num_updates=357700, lr=0.000167202, gnorm=0.355, loss_scale=2, train_wall=81, gb_free=39.6, wall=300472
2023-06-15 03:15:36 | INFO | train_inner | epoch 032:   8326 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=70167.9, ups=1.18, wpb=59570.9, bsz=2138.4, num_updates=357800, lr=0.000167178, gnorm=0.344, loss_scale=2, train_wall=81, gb_free=39.6, wall=300557
2023-06-15 03:17:02 | INFO | train_inner | epoch 032:   8426 / 11284 loss=3.49, nll_loss=1.781, ppl=3.44, wps=69757, ups=1.17, wpb=59472.7, bsz=2250.1, num_updates=357900, lr=0.000167155, gnorm=0.354, loss_scale=2, train_wall=81, gb_free=39.6, wall=300642
2023-06-15 03:18:27 | INFO | train_inner | epoch 032:   8526 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=69557, ups=1.17, wpb=59393.8, bsz=2284.5, num_updates=358000, lr=0.000167132, gnorm=0.344, loss_scale=2, train_wall=81, gb_free=39.6, wall=300728
2023-06-15 03:19:51 | INFO | train_inner | epoch 032:   8626 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=70718.1, ups=1.19, wpb=59574.8, bsz=2280.2, num_updates=358100, lr=0.000167108, gnorm=0.359, loss_scale=2, train_wall=80, gb_free=39.5, wall=300812
2023-06-15 03:21:14 | INFO | train_inner | epoch 032:   8726 / 11284 loss=3.491, nll_loss=1.782, ppl=3.44, wps=72019.9, ups=1.21, wpb=59643.5, bsz=2195.6, num_updates=358200, lr=0.000167085, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.5, wall=300895
2023-06-15 03:22:37 | INFO | train_inner | epoch 032:   8826 / 11284 loss=3.481, nll_loss=1.771, ppl=3.41, wps=71592.4, ups=1.2, wpb=59566.4, bsz=2191.3, num_updates=358300, lr=0.000167062, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.6, wall=300978
2023-06-15 03:23:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 03:24:01 | INFO | train_inner | epoch 032:   8927 / 11284 loss=3.482, nll_loss=1.771, ppl=3.41, wps=70897.6, ups=1.19, wpb=59423, bsz=2223.8, num_updates=358400, lr=0.000167038, gnorm=0.348, loss_scale=2, train_wall=80, gb_free=39.5, wall=301062
2023-06-15 03:25:24 | INFO | train_inner | epoch 032:   9027 / 11284 loss=3.493, nll_loss=1.784, ppl=3.44, wps=71940.9, ups=1.21, wpb=59537.9, bsz=2279.9, num_updates=358500, lr=0.000167015, gnorm=0.358, loss_scale=2, train_wall=79, gb_free=39.5, wall=301145
2023-06-15 03:26:47 | INFO | train_inner | epoch 032:   9127 / 11284 loss=3.489, nll_loss=1.78, ppl=3.43, wps=71820.8, ups=1.21, wpb=59481.8, bsz=2207.1, num_updates=358600, lr=0.000166992, gnorm=0.349, loss_scale=2, train_wall=79, gb_free=39.1, wall=301227
2023-06-15 03:28:10 | INFO | train_inner | epoch 032:   9227 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=71357.4, ups=1.2, wpb=59508, bsz=2194.5, num_updates=358700, lr=0.000166968, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.6, wall=301311
2023-06-15 03:29:33 | INFO | train_inner | epoch 032:   9327 / 11284 loss=3.486, nll_loss=1.776, ppl=3.42, wps=71619.1, ups=1.21, wpb=59249.7, bsz=2236.2, num_updates=358800, lr=0.000166945, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.6, wall=301394
2023-06-15 03:30:56 | INFO | train_inner | epoch 032:   9427 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=71292.1, ups=1.2, wpb=59502.9, bsz=2271.2, num_updates=358900, lr=0.000166922, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.6, wall=301477
2023-06-15 03:32:19 | INFO | train_inner | epoch 032:   9527 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=71649.9, ups=1.21, wpb=59378.5, bsz=2276.4, num_updates=359000, lr=0.000166899, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=38.7, wall=301560
2023-06-15 03:33:44 | INFO | train_inner | epoch 032:   9627 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=70599.3, ups=1.19, wpb=59576.2, bsz=2160.6, num_updates=359100, lr=0.000166875, gnorm=0.345, loss_scale=2, train_wall=80, gb_free=39.6, wall=301644
2023-06-15 03:35:09 | INFO | train_inner | epoch 032:   9727 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=69678.5, ups=1.17, wpb=59440.2, bsz=2248.5, num_updates=359200, lr=0.000166852, gnorm=0.362, loss_scale=2, train_wall=81, gb_free=39.5, wall=301730
2023-06-15 03:36:33 | INFO | train_inner | epoch 032:   9827 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=70346.4, ups=1.19, wpb=59287.4, bsz=2225.4, num_updates=359300, lr=0.000166829, gnorm=0.358, loss_scale=2, train_wall=80, gb_free=39.4, wall=301814
2023-06-15 03:37:56 | INFO | train_inner | epoch 032:   9927 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=71672.2, ups=1.21, wpb=59379, bsz=2181.7, num_updates=359400, lr=0.000166806, gnorm=0.344, loss_scale=4, train_wall=79, gb_free=39.6, wall=301897
2023-06-15 03:37:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 03:39:20 | INFO | train_inner | epoch 032:  10028 / 11284 loss=3.491, nll_loss=1.782, ppl=3.44, wps=70700.1, ups=1.19, wpb=59259.5, bsz=2188, num_updates=359500, lr=0.000166783, gnorm=0.359, loss_scale=2, train_wall=80, gb_free=39.5, wall=301980
2023-06-15 03:40:43 | INFO | train_inner | epoch 032:  10128 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=71528.2, ups=1.21, wpb=59205.6, bsz=2184.7, num_updates=359600, lr=0.000166759, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.6, wall=302063
2023-06-15 03:42:05 | INFO | train_inner | epoch 032:  10228 / 11284 loss=3.497, nll_loss=1.789, ppl=3.46, wps=71716.6, ups=1.21, wpb=59353.5, bsz=2172.8, num_updates=359700, lr=0.000166736, gnorm=0.354, loss_scale=2, train_wall=79, gb_free=39.6, wall=302146
2023-06-15 03:43:27 | INFO | train_inner | epoch 032:  10328 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=72687, ups=1.22, wpb=59582.7, bsz=2289.8, num_updates=359800, lr=0.000166713, gnorm=0.365, loss_scale=2, train_wall=78, gb_free=39.6, wall=302228
2023-06-15 03:44:50 | INFO | train_inner | epoch 032:  10428 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=72446.6, ups=1.21, wpb=59650.2, bsz=2311, num_updates=359900, lr=0.00016669, gnorm=0.349, loss_scale=2, train_wall=78, gb_free=39.5, wall=302310
2023-06-15 03:46:13 | INFO | train_inner | epoch 032:  10528 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71902.6, ups=1.2, wpb=59712.6, bsz=2271.8, num_updates=360000, lr=0.000166667, gnorm=0.341, loss_scale=2, train_wall=79, gb_free=39.6, wall=302393
2023-06-15 03:47:35 | INFO | train_inner | epoch 032:  10628 / 11284 loss=3.497, nll_loss=1.789, ppl=3.45, wps=72295.4, ups=1.22, wpb=59382.9, bsz=2204.4, num_updates=360100, lr=0.000166644, gnorm=0.354, loss_scale=2, train_wall=78, gb_free=39.6, wall=302476
2023-06-15 03:48:58 | INFO | train_inner | epoch 032:  10728 / 11284 loss=3.495, nll_loss=1.787, ppl=3.45, wps=71936.5, ups=1.21, wpb=59688.2, bsz=2185.3, num_updates=360200, lr=0.00016662, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.6, wall=302559
2023-06-15 03:50:21 | INFO | train_inner | epoch 032:  10828 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=71769, ups=1.2, wpb=59573.1, bsz=2232.9, num_updates=360300, lr=0.000166597, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.5, wall=302642
2023-06-15 03:51:44 | INFO | train_inner | epoch 032:  10928 / 11284 loss=3.471, nll_loss=1.759, ppl=3.39, wps=72024.2, ups=1.21, wpb=59535.7, bsz=2241.1, num_updates=360400, lr=0.000166574, gnorm=0.343, loss_scale=2, train_wall=79, gb_free=39.5, wall=302724
2023-06-15 03:52:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 03:53:06 | INFO | train_inner | epoch 032:  11029 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=71968.8, ups=1.21, wpb=59268.1, bsz=2202.2, num_updates=360500, lr=0.000166551, gnorm=0.357, loss_scale=2, train_wall=78, gb_free=39.3, wall=302807
2023-06-15 03:54:28 | INFO | train_inner | epoch 032:  11129 / 11284 loss=3.496, nll_loss=1.788, ppl=3.45, wps=73343.2, ups=1.23, wpb=59823.9, bsz=2227.1, num_updates=360600, lr=0.000166528, gnorm=0.357, loss_scale=2, train_wall=78, gb_free=39.6, wall=302888
2023-06-15 03:55:49 | INFO | train_inner | epoch 032:  11229 / 11284 loss=3.501, nll_loss=1.793, ppl=3.47, wps=72822, ups=1.22, wpb=59584.9, bsz=2226.6, num_updates=360700, lr=0.000166505, gnorm=0.364, loss_scale=2, train_wall=78, gb_free=39.6, wall=302970
2023-06-15 03:56:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-15 03:56:52 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 4.293 | nll_loss 2.611 | ppl 6.11 | bleu 20.61 | wps 3743.4 | wpb 2397.5 | bsz 71.5 | num_updates 360755 | best_loss 4.283
2023-06-15 03:56:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 360755 updates
2023-06-15 03:56:52 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint32.pt
2023-06-15 03:56:55 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint32.pt
2023-06-15 03:57:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint32.pt (epoch 32 @ 360755 updates, score 4.293) (writing took 8.584985051304102 seconds)
2023-06-15 03:57:01 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-06-15 03:57:01 | INFO | train | epoch 032 | loss 3.487 | nll_loss 1.777 | ppl 3.43 | wps 70799.2 | ups 1.19 | wpb 59499.8 | bsz 2227.5 | num_updates 360755 | lr 0.000166492 | gnorm 0.353 | loss_scale 2 | train_wall 9000 | gb_free 39.6 | wall 303041
2023-06-15 03:57:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-15 03:57:01 | INFO | fairseq.trainer | begin training epoch 33
2023-06-15 03:57:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-15 03:57:38 | INFO | train_inner | epoch 033:     45 / 11284 loss=3.473, nll_loss=1.762, ppl=3.39, wps=54514.5, ups=0.92, wpb=59229.9, bsz=2172, num_updates=360800, lr=0.000166482, gnorm=0.349, loss_scale=2, train_wall=77, gb_free=39.6, wall=303079
2023-06-15 03:58:59 | INFO | train_inner | epoch 033:    145 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=73072.4, ups=1.23, wpb=59397.6, bsz=2226.6, num_updates=360900, lr=0.000166459, gnorm=0.357, loss_scale=2, train_wall=77, gb_free=39.6, wall=303160
2023-06-15 04:00:22 | INFO | train_inner | epoch 033:    245 / 11284 loss=3.485, nll_loss=1.774, ppl=3.42, wps=71925.9, ups=1.21, wpb=59470.8, bsz=2236.8, num_updates=361000, lr=0.000166436, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=39.5, wall=303243
2023-06-15 04:01:45 | INFO | train_inner | epoch 033:    345 / 11284 loss=3.483, nll_loss=1.772, ppl=3.42, wps=71693.7, ups=1.2, wpb=59552.5, bsz=2179.2, num_updates=361100, lr=0.000166413, gnorm=0.355, loss_scale=2, train_wall=79, gb_free=39.6, wall=303326
2023-06-15 04:03:08 | INFO | train_inner | epoch 033:    445 / 11284 loss=3.472, nll_loss=1.76, ppl=3.39, wps=71456.8, ups=1.21, wpb=59282.3, bsz=2232.1, num_updates=361200, lr=0.00016639, gnorm=0.362, loss_scale=2, train_wall=79, gb_free=39.5, wall=303409
2023-06-15 04:04:31 | INFO | train_inner | epoch 033:    545 / 11284 loss=3.498, nll_loss=1.79, ppl=3.46, wps=72151.4, ups=1.21, wpb=59559.9, bsz=2233.1, num_updates=361300, lr=0.000166367, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.5, wall=303491
2023-06-15 04:05:53 | INFO | train_inner | epoch 033:    645 / 11284 loss=3.479, nll_loss=1.768, ppl=3.41, wps=72029.8, ups=1.21, wpb=59661.7, bsz=2230.7, num_updates=361400, lr=0.000166344, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.6, wall=303574
2023-06-15 04:07:16 | INFO | train_inner | epoch 033:    745 / 11284 loss=3.477, nll_loss=1.766, ppl=3.4, wps=71674.5, ups=1.21, wpb=59433.6, bsz=2290.8, num_updates=361500, lr=0.000166321, gnorm=0.366, loss_scale=4, train_wall=79, gb_free=39.6, wall=303657
2023-06-15 04:07:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 04:08:43 | INFO | train_inner | epoch 033:    846 / 11284 loss=3.482, nll_loss=1.771, ppl=3.41, wps=69004.5, ups=1.16, wpb=59682.2, bsz=2343.5, num_updates=361600, lr=0.000166298, gnorm=0.345, loss_scale=2, train_wall=83, gb_free=39.6, wall=303743
2023-06-15 04:10:07 | INFO | train_inner | epoch 033:    946 / 11284 loss=3.481, nll_loss=1.771, ppl=3.41, wps=70405.6, ups=1.18, wpb=59554.2, bsz=2268.6, num_updates=361700, lr=0.000166275, gnorm=0.362, loss_scale=2, train_wall=80, gb_free=39.6, wall=303828
2023-06-15 04:11:31 | INFO | train_inner | epoch 033:   1046 / 11284 loss=3.48, nll_loss=1.769, ppl=3.41, wps=71387.3, ups=1.2, wpb=59355.3, bsz=2339.5, num_updates=361800, lr=0.000166252, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.6, wall=303911
2023-06-15 04:12:54 | INFO | train_inner | epoch 033:   1146 / 11284 loss=3.477, nll_loss=1.766, ppl=3.4, wps=71535.3, ups=1.2, wpb=59557.1, bsz=2235.1, num_updates=361900, lr=0.000166229, gnorm=0.354, loss_scale=2, train_wall=79, gb_free=39.6, wall=303994
2023-06-15 04:14:16 | INFO | train_inner | epoch 033:   1246 / 11284 loss=3.481, nll_loss=1.77, ppl=3.41, wps=71852.6, ups=1.21, wpb=59413.6, bsz=2190.9, num_updates=362000, lr=0.000166206, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.6, wall=304077
2023-06-15 04:15:40 | INFO | train_inner | epoch 033:   1346 / 11284 loss=3.477, nll_loss=1.766, ppl=3.4, wps=71299.7, ups=1.2, wpb=59409.4, bsz=2235.2, num_updates=362100, lr=0.000166183, gnorm=0.355, loss_scale=2, train_wall=79, gb_free=39.6, wall=304160
2023-06-15 04:17:03 | INFO | train_inner | epoch 033:   1446 / 11284 loss=3.463, nll_loss=1.75, ppl=3.36, wps=71819, ups=1.21, wpb=59592.5, bsz=2203.3, num_updates=362200, lr=0.00016616, gnorm=0.349, loss_scale=2, train_wall=79, gb_free=39.6, wall=304243
2023-06-15 04:18:26 | INFO | train_inner | epoch 033:   1546 / 11284 loss=3.468, nll_loss=1.756, ppl=3.38, wps=71571.7, ups=1.21, wpb=59349.5, bsz=2161.5, num_updates=362300, lr=0.000166137, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.6, wall=304326
2023-06-15 04:19:49 | INFO | train_inner | epoch 033:   1646 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=71294.2, ups=1.2, wpb=59411.8, bsz=2218, num_updates=362400, lr=0.000166114, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.6, wall=304410
2023-06-15 04:21:12 | INFO | train_inner | epoch 033:   1746 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71344.8, ups=1.2, wpb=59373.5, bsz=2254.8, num_updates=362500, lr=0.000166091, gnorm=0.349, loss_scale=2, train_wall=79, gb_free=39.5, wall=304493
2023-06-15 04:22:35 | INFO | train_inner | epoch 033:   1846 / 11284 loss=3.482, nll_loss=1.771, ppl=3.41, wps=71771.8, ups=1.21, wpb=59456.3, bsz=2235.8, num_updates=362600, lr=0.000166068, gnorm=0.35, loss_scale=4, train_wall=79, gb_free=39.6, wall=304576
2023-06-15 04:23:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 04:23:59 | INFO | train_inner | epoch 033:   1947 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=71175.6, ups=1.2, wpb=59518.4, bsz=2181, num_updates=362700, lr=0.000166045, gnorm=0.348, loss_scale=2, train_wall=80, gb_free=39.6, wall=304659
2023-06-15 04:25:21 | INFO | train_inner | epoch 033:   2047 / 11284 loss=3.476, nll_loss=1.765, ppl=3.4, wps=72573.9, ups=1.22, wpb=59642.6, bsz=2310.4, num_updates=362800, lr=0.000166022, gnorm=0.352, loss_scale=2, train_wall=78, gb_free=39.6, wall=304741
2023-06-15 04:26:44 | INFO | train_inner | epoch 033:   2147 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=71515.8, ups=1.2, wpb=59584.7, bsz=2339.5, num_updates=362900, lr=0.000165999, gnorm=0.362, loss_scale=2, train_wall=79, gb_free=39.6, wall=304825
2023-06-15 04:28:08 | INFO | train_inner | epoch 033:   2247 / 11284 loss=3.469, nll_loss=1.757, ppl=3.38, wps=70902.1, ups=1.19, wpb=59692, bsz=2214.1, num_updates=363000, lr=0.000165977, gnorm=0.348, loss_scale=2, train_wall=80, gb_free=39.5, wall=304909
2023-06-15 04:29:33 | INFO | train_inner | epoch 033:   2347 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=70109.1, ups=1.18, wpb=59639.5, bsz=2231.6, num_updates=363100, lr=0.000165954, gnorm=0.345, loss_scale=2, train_wall=81, gb_free=39.6, wall=304994
2023-06-15 04:30:57 | INFO | train_inner | epoch 033:   2447 / 11284 loss=3.484, nll_loss=1.773, ppl=3.42, wps=71706.2, ups=1.2, wpb=59550.1, bsz=2309, num_updates=363200, lr=0.000165931, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.6, wall=305077
2023-06-15 04:32:19 | INFO | train_inner | epoch 033:   2547 / 11284 loss=3.47, nll_loss=1.758, ppl=3.38, wps=71833.6, ups=1.21, wpb=59338.1, bsz=2181.6, num_updates=363300, lr=0.000165908, gnorm=0.355, loss_scale=2, train_wall=78, gb_free=39.5, wall=305160
2023-06-15 04:33:42 | INFO | train_inner | epoch 033:   2647 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=72232.5, ups=1.21, wpb=59571.2, bsz=2236.8, num_updates=363400, lr=0.000165885, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.6, wall=305242
2023-06-15 04:35:04 | INFO | train_inner | epoch 033:   2747 / 11284 loss=3.483, nll_loss=1.772, ppl=3.42, wps=71939.6, ups=1.21, wpb=59568.5, bsz=2143.1, num_updates=363500, lr=0.000165862, gnorm=0.361, loss_scale=2, train_wall=79, gb_free=39.4, wall=305325
2023-06-15 04:36:27 | INFO | train_inner | epoch 033:   2847 / 11284 loss=3.48, nll_loss=1.77, ppl=3.41, wps=71797.1, ups=1.21, wpb=59420.4, bsz=2328.8, num_updates=363600, lr=0.00016584, gnorm=0.366, loss_scale=2, train_wall=79, gb_free=39.6, wall=305408
2023-06-15 04:37:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 04:37:51 | INFO | train_inner | epoch 033:   2948 / 11284 loss=3.49, nll_loss=1.78, ppl=3.43, wps=70923.8, ups=1.2, wpb=59265.8, bsz=2228.2, num_updates=363700, lr=0.000165817, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.6, wall=305491
2023-06-15 04:39:13 | INFO | train_inner | epoch 033:   3048 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=71927.7, ups=1.21, wpb=59523.7, bsz=2166.6, num_updates=363800, lr=0.000165794, gnorm=0.371, loss_scale=2, train_wall=79, gb_free=39.6, wall=305574
2023-06-15 04:40:36 | INFO | train_inner | epoch 033:   3148 / 11284 loss=3.486, nll_loss=1.776, ppl=3.43, wps=71378.8, ups=1.2, wpb=59236.1, bsz=2171.7, num_updates=363900, lr=0.000165771, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.6, wall=305657
2023-06-15 04:41:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-06-15 04:42:00 | INFO | train_inner | epoch 033:   3249 / 11284 loss=3.478, nll_loss=1.767, ppl=3.4, wps=70921.2, ups=1.19, wpb=59437.6, bsz=2146.3, num_updates=364000, lr=0.000165748, gnorm=0.358, loss_scale=1, train_wall=80, gb_free=39.6, wall=305741
2023-06-15 04:43:22 | INFO | train_inner | epoch 033:   3349 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=72610.9, ups=1.22, wpb=59458.4, bsz=2121.4, num_updates=364100, lr=0.000165726, gnorm=0.354, loss_scale=1, train_wall=78, gb_free=39.5, wall=305823
2023-06-15 04:44:44 | INFO | train_inner | epoch 033:   3449 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=72554.6, ups=1.22, wpb=59299.7, bsz=2264.5, num_updates=364200, lr=0.000165703, gnorm=0.364, loss_scale=1, train_wall=78, gb_free=39.5, wall=305904
2023-06-15 04:46:06 | INFO | train_inner | epoch 033:   3549 / 11284 loss=3.481, nll_loss=1.771, ppl=3.41, wps=72782.9, ups=1.22, wpb=59599.9, bsz=2280.7, num_updates=364300, lr=0.00016568, gnorm=0.357, loss_scale=1, train_wall=78, gb_free=39.4, wall=305986
2023-06-15 04:47:28 | INFO | train_inner | epoch 033:   3649 / 11284 loss=3.469, nll_loss=1.757, ppl=3.38, wps=72445.2, ups=1.22, wpb=59480.4, bsz=2303.1, num_updates=364400, lr=0.000165657, gnorm=0.344, loss_scale=1, train_wall=78, gb_free=39.5, wall=306068
2023-06-15 04:48:50 | INFO | train_inner | epoch 033:   3749 / 11284 loss=3.491, nll_loss=1.781, ppl=3.44, wps=72697.9, ups=1.22, wpb=59486.9, bsz=2204.7, num_updates=364500, lr=0.000165635, gnorm=0.37, loss_scale=1, train_wall=78, gb_free=39.5, wall=306150
2023-06-15 04:50:13 | INFO | train_inner | epoch 033:   3849 / 11284 loss=3.492, nll_loss=1.783, ppl=3.44, wps=71613.2, ups=1.21, wpb=59391.4, bsz=2273.9, num_updates=364600, lr=0.000165612, gnorm=0.356, loss_scale=1, train_wall=79, gb_free=39.6, wall=306233
2023-06-15 04:51:36 | INFO | train_inner | epoch 033:   3949 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=71637, ups=1.2, wpb=59480.6, bsz=2186, num_updates=364700, lr=0.000165589, gnorm=0.352, loss_scale=1, train_wall=79, gb_free=39.5, wall=306316
2023-06-15 04:52:59 | INFO | train_inner | epoch 033:   4049 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=72025, ups=1.21, wpb=59683.7, bsz=2258.5, num_updates=364800, lr=0.000165567, gnorm=0.345, loss_scale=1, train_wall=79, gb_free=39.6, wall=306399
2023-06-15 04:54:22 | INFO | train_inner | epoch 033:   4149 / 11284 loss=3.501, nll_loss=1.793, ppl=3.47, wps=71613.8, ups=1.21, wpb=59388, bsz=2222.2, num_updates=364900, lr=0.000165544, gnorm=0.364, loss_scale=1, train_wall=79, gb_free=39.6, wall=306482
2023-06-15 04:55:45 | INFO | train_inner | epoch 033:   4249 / 11284 loss=3.476, nll_loss=1.765, ppl=3.4, wps=71595.7, ups=1.2, wpb=59522.4, bsz=2251.6, num_updates=365000, lr=0.000165521, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.6, wall=306565
2023-06-15 04:57:08 | INFO | train_inner | epoch 033:   4349 / 11284 loss=3.48, nll_loss=1.769, ppl=3.41, wps=71393, ups=1.2, wpb=59336.8, bsz=2256.1, num_updates=365100, lr=0.000165499, gnorm=0.362, loss_scale=2, train_wall=79, gb_free=39.6, wall=306648
2023-06-15 04:58:31 | INFO | train_inner | epoch 033:   4449 / 11284 loss=3.476, nll_loss=1.766, ppl=3.4, wps=71480.1, ups=1.2, wpb=59413.9, bsz=2181.4, num_updates=365200, lr=0.000165476, gnorm=0.359, loss_scale=2, train_wall=79, gb_free=39.6, wall=306731
2023-06-15 04:59:53 | INFO | train_inner | epoch 033:   4549 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=72437.3, ups=1.22, wpb=59499.5, bsz=2327.1, num_updates=365300, lr=0.000165453, gnorm=0.353, loss_scale=2, train_wall=78, gb_free=39.6, wall=306814
2023-06-15 05:01:15 | INFO | train_inner | epoch 033:   4649 / 11284 loss=3.463, nll_loss=1.75, ppl=3.36, wps=72421.1, ups=1.22, wpb=59585.4, bsz=2254.5, num_updates=365400, lr=0.000165431, gnorm=0.358, loss_scale=2, train_wall=78, gb_free=39.6, wall=306896
2023-06-15 05:02:38 | INFO | train_inner | epoch 033:   4749 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=71819.8, ups=1.2, wpb=59684.6, bsz=2213.8, num_updates=365500, lr=0.000165408, gnorm=0.35, loss_scale=2, train_wall=79, gb_free=39.6, wall=306979
2023-06-15 05:04:02 | INFO | train_inner | epoch 033:   4849 / 11284 loss=3.473, nll_loss=1.761, ppl=3.39, wps=71569.3, ups=1.2, wpb=59742.8, bsz=2235.1, num_updates=365600, lr=0.000165385, gnorm=0.351, loss_scale=2, train_wall=80, gb_free=39.5, wall=307062
2023-06-15 05:05:25 | INFO | train_inner | epoch 033:   4949 / 11284 loss=3.489, nll_loss=1.78, ppl=3.43, wps=71308.1, ups=1.2, wpb=59406.5, bsz=2173.4, num_updates=365700, lr=0.000165363, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.6, wall=307146
2023-06-15 05:06:48 | INFO | train_inner | epoch 033:   5049 / 11284 loss=3.497, nll_loss=1.789, ppl=3.46, wps=71811.1, ups=1.21, wpb=59535.9, bsz=2214.7, num_updates=365800, lr=0.00016534, gnorm=0.358, loss_scale=2, train_wall=79, gb_free=39.5, wall=307229
2023-06-15 05:08:11 | INFO | train_inner | epoch 033:   5149 / 11284 loss=3.467, nll_loss=1.755, ppl=3.38, wps=71544.2, ups=1.2, wpb=59528.3, bsz=2126.9, num_updates=365900, lr=0.000165317, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.5, wall=307312
2023-06-15 05:09:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 05:09:35 | INFO | train_inner | epoch 033:   5250 / 11284 loss=3.489, nll_loss=1.779, ppl=3.43, wps=70951, ups=1.19, wpb=59539.6, bsz=2180.1, num_updates=366000, lr=0.000165295, gnorm=0.344, loss_scale=2, train_wall=80, gb_free=39.5, wall=307396
2023-06-15 05:10:59 | INFO | train_inner | epoch 033:   5350 / 11284 loss=3.473, nll_loss=1.762, ppl=3.39, wps=71605.4, ups=1.2, wpb=59668.8, bsz=2203.8, num_updates=366100, lr=0.000165272, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.6, wall=307479
2023-06-15 05:12:22 | INFO | train_inner | epoch 033:   5450 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=71491.1, ups=1.2, wpb=59406.1, bsz=2254.7, num_updates=366200, lr=0.00016525, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.6, wall=307562
2023-06-15 05:13:45 | INFO | train_inner | epoch 033:   5550 / 11284 loss=3.486, nll_loss=1.777, ppl=3.43, wps=71672.1, ups=1.2, wpb=59621.8, bsz=2245.6, num_updates=366300, lr=0.000165227, gnorm=0.355, loss_scale=2, train_wall=79, gb_free=39.6, wall=307645
2023-06-15 05:15:07 | INFO | train_inner | epoch 033:   5650 / 11284 loss=3.486, nll_loss=1.776, ppl=3.43, wps=72704.8, ups=1.22, wpb=59473.4, bsz=2227.8, num_updates=366400, lr=0.000165205, gnorm=0.351, loss_scale=2, train_wall=78, gb_free=39.6, wall=307727
2023-06-15 05:16:29 | INFO | train_inner | epoch 033:   5750 / 11284 loss=3.489, nll_loss=1.78, ppl=3.43, wps=72714.3, ups=1.22, wpb=59564.3, bsz=2224.8, num_updates=366500, lr=0.000165182, gnorm=0.355, loss_scale=2, train_wall=78, gb_free=38.7, wall=307809
2023-06-15 05:17:51 | INFO | train_inner | epoch 033:   5850 / 11284 loss=3.5, nll_loss=1.792, ppl=3.46, wps=72059.7, ups=1.21, wpb=59443.5, bsz=2186.8, num_updates=366600, lr=0.00016516, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.5, wall=307892
2023-06-15 05:19:13 | INFO | train_inner | epoch 033:   5950 / 11284 loss=3.485, nll_loss=1.776, ppl=3.42, wps=72862.5, ups=1.22, wpb=59682.4, bsz=2234.4, num_updates=366700, lr=0.000165137, gnorm=0.348, loss_scale=2, train_wall=78, gb_free=39.5, wall=307974
2023-06-15 05:20:36 | INFO | train_inner | epoch 033:   6050 / 11284 loss=3.478, nll_loss=1.767, ppl=3.4, wps=71420.8, ups=1.2, wpb=59524.6, bsz=2304.5, num_updates=366800, lr=0.000165115, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.6, wall=308057
2023-06-15 05:22:00 | INFO | train_inner | epoch 033:   6150 / 11284 loss=3.468, nll_loss=1.756, ppl=3.38, wps=71409.3, ups=1.2, wpb=59607.7, bsz=2241.3, num_updates=366900, lr=0.000165092, gnorm=0.364, loss_scale=2, train_wall=80, gb_free=39.6, wall=308140
2023-06-15 05:23:23 | INFO | train_inner | epoch 033:   6250 / 11284 loss=3.481, nll_loss=1.771, ppl=3.41, wps=71755.4, ups=1.21, wpb=59507.5, bsz=2219.9, num_updates=367000, lr=0.00016507, gnorm=0.362, loss_scale=2, train_wall=79, gb_free=39.6, wall=308223
2023-06-15 05:23:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 05:24:47 | INFO | train_inner | epoch 033:   6351 / 11284 loss=3.479, nll_loss=1.768, ppl=3.41, wps=71077.9, ups=1.19, wpb=59688.4, bsz=2252.7, num_updates=367100, lr=0.000165047, gnorm=0.35, loss_scale=2, train_wall=80, gb_free=39.6, wall=308307
2023-06-15 05:26:10 | INFO | train_inner | epoch 033:   6451 / 11284 loss=3.492, nll_loss=1.782, ppl=3.44, wps=71593.9, ups=1.2, wpb=59700.6, bsz=2260.2, num_updates=367200, lr=0.000165025, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.6, wall=308391
2023-06-15 05:27:33 | INFO | train_inner | epoch 033:   6551 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=71675.6, ups=1.21, wpb=59384, bsz=2217.4, num_updates=367300, lr=0.000165002, gnorm=0.348, loss_scale=2, train_wall=79, gb_free=39.6, wall=308474
2023-06-15 05:28:56 | INFO | train_inner | epoch 033:   6651 / 11284 loss=3.478, nll_loss=1.768, ppl=3.4, wps=71684.1, ups=1.2, wpb=59612.4, bsz=2220.2, num_updates=367400, lr=0.00016498, gnorm=0.354, loss_scale=2, train_wall=79, gb_free=39.5, wall=308557
2023-06-15 05:30:19 | INFO | train_inner | epoch 033:   6751 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=71764.8, ups=1.21, wpb=59453.9, bsz=2261, num_updates=367500, lr=0.000164957, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.6, wall=308640
2023-06-15 05:31:40 | INFO | train_inner | epoch 033:   6851 / 11284 loss=3.499, nll_loss=1.791, ppl=3.46, wps=73124.8, ups=1.23, wpb=59589.7, bsz=2196, num_updates=367600, lr=0.000164935, gnorm=0.369, loss_scale=2, train_wall=77, gb_free=39.5, wall=308721
2023-06-15 05:33:03 | INFO | train_inner | epoch 033:   6951 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=72175.9, ups=1.21, wpb=59500.8, bsz=2199.4, num_updates=367700, lr=0.000164912, gnorm=0.352, loss_scale=2, train_wall=78, gb_free=39.5, wall=308803
2023-06-15 05:34:25 | INFO | train_inner | epoch 033:   7051 / 11284 loss=3.486, nll_loss=1.776, ppl=3.42, wps=72186.5, ups=1.21, wpb=59464.2, bsz=2197.6, num_updates=367800, lr=0.00016489, gnorm=0.365, loss_scale=2, train_wall=78, gb_free=39.3, wall=308886
2023-06-15 05:35:47 | INFO | train_inner | epoch 033:   7151 / 11284 loss=3.503, nll_loss=1.795, ppl=3.47, wps=72708.4, ups=1.22, wpb=59383.9, bsz=2224.4, num_updates=367900, lr=0.000164868, gnorm=0.35, loss_scale=2, train_wall=78, gb_free=39.6, wall=308968
2023-06-15 05:37:10 | INFO | train_inner | epoch 033:   7251 / 11284 loss=3.486, nll_loss=1.777, ppl=3.43, wps=71501.4, ups=1.2, wpb=59412.8, bsz=2163.9, num_updates=368000, lr=0.000164845, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.6, wall=309051
2023-06-15 05:38:33 | INFO | train_inner | epoch 033:   7351 / 11284 loss=3.489, nll_loss=1.779, ppl=3.43, wps=71952.7, ups=1.21, wpb=59566.4, bsz=2196.2, num_updates=368100, lr=0.000164823, gnorm=0.343, loss_scale=4, train_wall=79, gb_free=39.5, wall=309133
2023-06-15 05:38:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 05:39:56 | INFO | train_inner | epoch 033:   7452 / 11284 loss=3.472, nll_loss=1.76, ppl=3.39, wps=71590.2, ups=1.2, wpb=59538.7, bsz=2235.2, num_updates=368200, lr=0.0001648, gnorm=0.352, loss_scale=2, train_wall=79, gb_free=39.6, wall=309217
2023-06-15 05:41:19 | INFO | train_inner | epoch 033:   7552 / 11284 loss=3.493, nll_loss=1.785, ppl=3.45, wps=71859.4, ups=1.2, wpb=59843.9, bsz=2280.1, num_updates=368300, lr=0.000164778, gnorm=0.348, loss_scale=2, train_wall=79, gb_free=39.6, wall=309300
2023-06-15 05:42:41 | INFO | train_inner | epoch 033:   7652 / 11284 loss=3.504, nll_loss=1.796, ppl=3.47, wps=72734.7, ups=1.22, wpb=59449.7, bsz=2194.5, num_updates=368400, lr=0.000164756, gnorm=0.362, loss_scale=2, train_wall=78, gb_free=39.5, wall=309382
2023-06-15 05:44:04 | INFO | train_inner | epoch 033:   7752 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=71858.6, ups=1.21, wpb=59533.3, bsz=2251.2, num_updates=368500, lr=0.000164733, gnorm=0.34, loss_scale=2, train_wall=79, gb_free=39.6, wall=309464
2023-06-15 05:45:27 | INFO | train_inner | epoch 033:   7852 / 11284 loss=3.492, nll_loss=1.783, ppl=3.44, wps=71973.1, ups=1.21, wpb=59579.6, bsz=2165.9, num_updates=368600, lr=0.000164711, gnorm=0.365, loss_scale=2, train_wall=79, gb_free=39.6, wall=309547
2023-06-15 05:46:48 | INFO | train_inner | epoch 033:   7952 / 11284 loss=3.496, nll_loss=1.788, ppl=3.45, wps=72971, ups=1.22, wpb=59633.2, bsz=2154.7, num_updates=368700, lr=0.000164689, gnorm=0.35, loss_scale=2, train_wall=78, gb_free=39.6, wall=309629
2023-06-15 05:48:11 | INFO | train_inner | epoch 033:   8052 / 11284 loss=3.477, nll_loss=1.767, ppl=3.4, wps=72465.9, ups=1.21, wpb=59687.9, bsz=2237.3, num_updates=368800, lr=0.000164666, gnorm=0.347, loss_scale=2, train_wall=78, gb_free=39.6, wall=309711
2023-06-15 05:49:34 | INFO | train_inner | epoch 033:   8152 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=71223.2, ups=1.2, wpb=59357.2, bsz=2182.5, num_updates=368900, lr=0.000164644, gnorm=0.362, loss_scale=2, train_wall=79, gb_free=39.6, wall=309795
2023-06-15 05:50:57 | INFO | train_inner | epoch 033:   8252 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=71792.6, ups=1.21, wpb=59410.3, bsz=2322, num_updates=369000, lr=0.000164622, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=39.6, wall=309877
2023-06-15 05:52:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-06-15 05:52:20 | INFO | train_inner | epoch 033:   8353 / 11284 loss=3.491, nll_loss=1.781, ppl=3.44, wps=71279.4, ups=1.2, wpb=59564.6, bsz=2222.7, num_updates=369100, lr=0.000164599, gnorm=0.356, loss_scale=1, train_wall=80, gb_free=39.6, wall=309961
2023-06-15 05:53:44 | INFO | train_inner | epoch 033:   8453 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=71614.1, ups=1.2, wpb=59558.6, bsz=2169.3, num_updates=369200, lr=0.000164577, gnorm=0.357, loss_scale=1, train_wall=79, gb_free=39.6, wall=310044
2023-06-15 05:55:07 | INFO | train_inner | epoch 033:   8553 / 11284 loss=3.499, nll_loss=1.791, ppl=3.46, wps=71463, ups=1.2, wpb=59417.6, bsz=2157.8, num_updates=369300, lr=0.000164555, gnorm=0.353, loss_scale=1, train_wall=79, gb_free=39.6, wall=310127
2023-06-15 05:56:30 | INFO | train_inner | epoch 033:   8653 / 11284 loss=3.479, nll_loss=1.768, ppl=3.41, wps=71295.6, ups=1.2, wpb=59248.4, bsz=2194.3, num_updates=369400, lr=0.000164532, gnorm=0.366, loss_scale=1, train_wall=79, gb_free=39.5, wall=310210
2023-06-15 05:57:53 | INFO | train_inner | epoch 033:   8753 / 11284 loss=3.5, nll_loss=1.791, ppl=3.46, wps=71367.8, ups=1.21, wpb=59038.3, bsz=2185, num_updates=369500, lr=0.00016451, gnorm=0.359, loss_scale=1, train_wall=79, gb_free=39.5, wall=310293
2023-06-15 05:59:15 | INFO | train_inner | epoch 033:   8853 / 11284 loss=3.486, nll_loss=1.777, ppl=3.43, wps=72301.6, ups=1.22, wpb=59447.1, bsz=2249.9, num_updates=369600, lr=0.000164488, gnorm=0.351, loss_scale=1, train_wall=78, gb_free=39.6, wall=310375
2023-06-15 06:00:38 | INFO | train_inner | epoch 033:   8953 / 11284 loss=3.49, nll_loss=1.781, ppl=3.44, wps=71870, ups=1.2, wpb=59839.9, bsz=2268.2, num_updates=369700, lr=0.000164466, gnorm=0.349, loss_scale=1, train_wall=79, gb_free=39.6, wall=310459
2023-06-15 06:02:01 | INFO | train_inner | epoch 033:   9053 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71847.3, ups=1.21, wpb=59607.4, bsz=2305.1, num_updates=369800, lr=0.000164443, gnorm=0.353, loss_scale=1, train_wall=79, gb_free=39.6, wall=310542
2023-06-15 06:03:24 | INFO | train_inner | epoch 033:   9153 / 11284 loss=3.478, nll_loss=1.767, ppl=3.4, wps=71910.4, ups=1.2, wpb=59701.6, bsz=2346.5, num_updates=369900, lr=0.000164421, gnorm=0.365, loss_scale=1, train_wall=79, gb_free=39.6, wall=310625
2023-06-15 06:04:46 | INFO | train_inner | epoch 033:   9253 / 11284 loss=3.502, nll_loss=1.795, ppl=3.47, wps=72482.7, ups=1.22, wpb=59477.3, bsz=2163.6, num_updates=370000, lr=0.000164399, gnorm=0.362, loss_scale=1, train_wall=78, gb_free=39.5, wall=310707
2023-06-15 06:06:09 | INFO | train_inner | epoch 033:   9353 / 11284 loss=3.494, nll_loss=1.786, ppl=3.45, wps=71388.4, ups=1.2, wpb=59498.9, bsz=2236.5, num_updates=370100, lr=0.000164377, gnorm=0.36, loss_scale=1, train_wall=79, gb_free=39.6, wall=310790
2023-06-15 06:07:33 | INFO | train_inner | epoch 033:   9453 / 11284 loss=3.493, nll_loss=1.784, ppl=3.44, wps=71171, ups=1.2, wpb=59457.3, bsz=2297.2, num_updates=370200, lr=0.000164355, gnorm=0.343, loss_scale=2, train_wall=79, gb_free=39.5, wall=310874
2023-06-15 06:08:56 | INFO | train_inner | epoch 033:   9553 / 11284 loss=3.479, nll_loss=1.769, ppl=3.41, wps=71819.7, ups=1.21, wpb=59595.2, bsz=2199.9, num_updates=370300, lr=0.000164332, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.6, wall=310957
2023-06-15 06:10:19 | INFO | train_inner | epoch 033:   9653 / 11284 loss=3.489, nll_loss=1.78, ppl=3.43, wps=71618.5, ups=1.2, wpb=59524.9, bsz=2218.6, num_updates=370400, lr=0.00016431, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.5, wall=311040
2023-06-15 06:11:41 | INFO | train_inner | epoch 033:   9753 / 11284 loss=3.492, nll_loss=1.784, ppl=3.44, wps=72013, ups=1.21, wpb=59371.8, bsz=2205, num_updates=370500, lr=0.000164288, gnorm=0.347, loss_scale=2, train_wall=78, gb_free=39.6, wall=311122
2023-06-15 06:13:04 | INFO | train_inner | epoch 033:   9853 / 11284 loss=3.482, nll_loss=1.773, ppl=3.42, wps=72446.2, ups=1.22, wpb=59548.8, bsz=2321.1, num_updates=370600, lr=0.000164266, gnorm=0.349, loss_scale=2, train_wall=78, gb_free=39.6, wall=311204
2023-06-15 06:14:25 | INFO | train_inner | epoch 033:   9953 / 11284 loss=3.488, nll_loss=1.779, ppl=3.43, wps=72588.8, ups=1.23, wpb=59175, bsz=2157.5, num_updates=370700, lr=0.000164244, gnorm=0.37, loss_scale=2, train_wall=78, gb_free=39.6, wall=311286
2023-06-15 06:15:48 | INFO | train_inner | epoch 033:  10053 / 11284 loss=3.49, nll_loss=1.781, ppl=3.44, wps=71988.3, ups=1.21, wpb=59475, bsz=2292.8, num_updates=370800, lr=0.000164222, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.6, wall=311368
2023-06-15 06:17:11 | INFO | train_inner | epoch 033:  10153 / 11284 loss=3.493, nll_loss=1.785, ppl=3.45, wps=71771.3, ups=1.21, wpb=59461.3, bsz=2155.2, num_updates=370900, lr=0.000164199, gnorm=0.352, loss_scale=2, train_wall=79, gb_free=39.6, wall=311451
2023-06-15 06:18:34 | INFO | train_inner | epoch 033:  10253 / 11284 loss=3.48, nll_loss=1.77, ppl=3.41, wps=71629.1, ups=1.2, wpb=59860.1, bsz=2214.1, num_updates=371000, lr=0.000164177, gnorm=0.355, loss_scale=2, train_wall=80, gb_free=39.4, wall=311535
2023-06-15 06:19:57 | INFO | train_inner | epoch 033:  10353 / 11284 loss=3.488, nll_loss=1.779, ppl=3.43, wps=71434.9, ups=1.2, wpb=59445.3, bsz=2245.7, num_updates=371100, lr=0.000164155, gnorm=0.355, loss_scale=2, train_wall=79, gb_free=39.6, wall=311618
2023-06-15 06:20:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 06:21:21 | INFO | train_inner | epoch 033:  10454 / 11284 loss=3.481, nll_loss=1.771, ppl=3.41, wps=71241.3, ups=1.2, wpb=59579.1, bsz=2277.8, num_updates=371200, lr=0.000164133, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.6, wall=311702
2023-06-15 06:22:45 | INFO | train_inner | epoch 033:  10554 / 11284 loss=3.488, nll_loss=1.779, ppl=3.43, wps=71360, ups=1.2, wpb=59573.2, bsz=2280, num_updates=371300, lr=0.000164111, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.5, wall=311785
2023-06-15 06:24:07 | INFO | train_inner | epoch 033:  10654 / 11284 loss=3.5, nll_loss=1.792, ppl=3.46, wps=71679.9, ups=1.21, wpb=59232.1, bsz=2169.2, num_updates=371400, lr=0.000164089, gnorm=0.365, loss_scale=2, train_wall=79, gb_free=39.5, wall=311868
2023-06-15 06:25:30 | INFO | train_inner | epoch 033:  10754 / 11284 loss=3.481, nll_loss=1.771, ppl=3.41, wps=71723.8, ups=1.21, wpb=59511.8, bsz=2156.4, num_updates=371500, lr=0.000164067, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.5, wall=311951
2023-06-15 06:26:53 | INFO | train_inner | epoch 033:  10854 / 11284 loss=3.501, nll_loss=1.793, ppl=3.46, wps=71444.7, ups=1.2, wpb=59403.6, bsz=2184.6, num_updates=371600, lr=0.000164045, gnorm=0.36, loss_scale=2, train_wall=79, gb_free=39.6, wall=312034
2023-06-15 06:28:16 | INFO | train_inner | epoch 033:  10954 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=71333, ups=1.2, wpb=59281.6, bsz=2196.7, num_updates=371700, lr=0.000164023, gnorm=0.352, loss_scale=2, train_wall=79, gb_free=39.5, wall=312117
2023-06-15 06:29:40 | INFO | train_inner | epoch 033:  11054 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=71679.1, ups=1.2, wpb=59660.3, bsz=2300.3, num_updates=371800, lr=0.000164001, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=39.6, wall=312200
2023-06-15 06:31:03 | INFO | train_inner | epoch 033:  11154 / 11284 loss=3.478, nll_loss=1.767, ppl=3.4, wps=71455, ups=1.2, wpb=59513.1, bsz=2174.1, num_updates=371900, lr=0.000163979, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.6, wall=312284
2023-06-15 06:32:26 | INFO | train_inner | epoch 033:  11254 / 11284 loss=3.485, nll_loss=1.776, ppl=3.42, wps=71743.7, ups=1.21, wpb=59448.9, bsz=2135.7, num_updates=372000, lr=0.000163956, gnorm=0.343, loss_scale=2, train_wall=79, gb_free=39.4, wall=312366
2023-06-15 06:32:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-15 06:33:28 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 4.278 | nll_loss 2.599 | ppl 6.06 | bleu 21.07 | wps 3665.2 | wpb 2397.5 | bsz 71.5 | num_updates 372030 | best_loss 4.278
2023-06-15 06:33:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 372030 updates
2023-06-15 06:33:29 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint33.pt
2023-06-15 06:40:01 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint33.pt
2023-06-15 06:42:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint33.pt (epoch 33 @ 372030 updates, score 4.278) (writing took 570.2917537558824 seconds)
2023-06-15 06:42:59 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-06-15 06:42:59 | INFO | train | epoch 033 | loss 3.486 | nll_loss 1.776 | ppl 3.42 | wps 67368.2 | ups 1.13 | wpb 59501.4 | bsz 2227.4 | num_updates 372030 | lr 0.00016395 | gnorm 0.354 | loss_scale 2 | train_wall 8900 | gb_free 39.6 | wall 313000
2023-06-15 06:42:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-15 06:42:59 | INFO | fairseq.trainer | begin training epoch 34
2023-06-15 06:42:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-15 06:43:58 | INFO | train_inner | epoch 034:     70 / 11284 loss=3.479, nll_loss=1.768, ppl=3.41, wps=8565.7, ups=0.14, wpb=59254.7, bsz=2226.8, num_updates=372100, lr=0.000163934, gnorm=0.357, loss_scale=2, train_wall=78, gb_free=39.6, wall=313058
2023-06-15 06:45:21 | INFO | train_inner | epoch 034:    170 / 11284 loss=3.472, nll_loss=1.761, ppl=3.39, wps=71633, ups=1.2, wpb=59712.5, bsz=2340, num_updates=372200, lr=0.000163912, gnorm=0.35, loss_scale=4, train_wall=79, gb_free=39.5, wall=313142
2023-06-15 06:45:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 06:46:45 | INFO | train_inner | epoch 034:    271 / 11284 loss=3.486, nll_loss=1.775, ppl=3.42, wps=71039.3, ups=1.19, wpb=59552.2, bsz=2196.9, num_updates=372300, lr=0.00016389, gnorm=0.352, loss_scale=2, train_wall=80, gb_free=39.5, wall=313225
2023-06-15 06:48:08 | INFO | train_inner | epoch 034:    371 / 11284 loss=3.473, nll_loss=1.761, ppl=3.39, wps=71763.4, ups=1.21, wpb=59436.7, bsz=2214.7, num_updates=372400, lr=0.000163868, gnorm=0.366, loss_scale=2, train_wall=79, gb_free=39.6, wall=313308
2023-06-15 06:49:30 | INFO | train_inner | epoch 034:    471 / 11284 loss=3.476, nll_loss=1.764, ppl=3.4, wps=72071, ups=1.21, wpb=59484, bsz=2209.2, num_updates=372500, lr=0.000163846, gnorm=0.348, loss_scale=2, train_wall=78, gb_free=39.6, wall=313391
2023-06-15 06:50:53 | INFO | train_inner | epoch 034:    571 / 11284 loss=3.48, nll_loss=1.769, ppl=3.41, wps=71542.2, ups=1.2, wpb=59491.1, bsz=2236.7, num_updates=372600, lr=0.000163824, gnorm=0.354, loss_scale=2, train_wall=79, gb_free=39.6, wall=313474
2023-06-15 06:52:16 | INFO | train_inner | epoch 034:    671 / 11284 loss=3.477, nll_loss=1.766, ppl=3.4, wps=71665.2, ups=1.2, wpb=59478.4, bsz=2175.1, num_updates=372700, lr=0.000163802, gnorm=0.358, loss_scale=2, train_wall=79, gb_free=39.5, wall=313557
2023-06-15 06:53:39 | INFO | train_inner | epoch 034:    771 / 11284 loss=3.47, nll_loss=1.758, ppl=3.38, wps=71645.1, ups=1.2, wpb=59497.6, bsz=2229.9, num_updates=372800, lr=0.00016378, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.5, wall=313640
2023-06-15 06:55:03 | INFO | train_inner | epoch 034:    871 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=71075.7, ups=1.19, wpb=59482.1, bsz=2223.9, num_updates=372900, lr=0.000163758, gnorm=0.378, loss_scale=2, train_wall=80, gb_free=39.6, wall=313724
2023-06-15 06:56:26 | INFO | train_inner | epoch 034:    971 / 11284 loss=3.485, nll_loss=1.774, ppl=3.42, wps=71497.4, ups=1.2, wpb=59495.1, bsz=2272.7, num_updates=373000, lr=0.000163737, gnorm=0.354, loss_scale=2, train_wall=79, gb_free=39.6, wall=313807
2023-06-15 06:57:49 | INFO | train_inner | epoch 034:   1071 / 11284 loss=3.468, nll_loss=1.756, ppl=3.38, wps=71406, ups=1.2, wpb=59416.2, bsz=2188.4, num_updates=373100, lr=0.000163715, gnorm=0.354, loss_scale=2, train_wall=79, gb_free=39.5, wall=313890
2023-06-15 06:59:13 | INFO | train_inner | epoch 034:   1171 / 11284 loss=3.461, nll_loss=1.748, ppl=3.36, wps=71309.8, ups=1.2, wpb=59630.1, bsz=2290.2, num_updates=373200, lr=0.000163693, gnorm=0.351, loss_scale=2, train_wall=80, gb_free=39.6, wall=313974
2023-06-15 07:00:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 07:00:37 | INFO | train_inner | epoch 034:   1272 / 11284 loss=3.485, nll_loss=1.774, ppl=3.42, wps=70833.8, ups=1.19, wpb=59526.7, bsz=2240.2, num_updates=373300, lr=0.000163671, gnorm=0.355, loss_scale=2, train_wall=80, gb_free=39.6, wall=314058
2023-06-15 07:02:00 | INFO | train_inner | epoch 034:   1372 / 11284 loss=3.486, nll_loss=1.776, ppl=3.42, wps=71659.9, ups=1.2, wpb=59606, bsz=2256, num_updates=373400, lr=0.000163649, gnorm=0.365, loss_scale=2, train_wall=79, gb_free=39.5, wall=314141
2023-06-15 07:03:24 | INFO | train_inner | epoch 034:   1472 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=71309.6, ups=1.2, wpb=59446.4, bsz=2290.1, num_updates=373500, lr=0.000163627, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.5, wall=314224
2023-06-15 07:04:47 | INFO | train_inner | epoch 034:   1572 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=71219.9, ups=1.2, wpb=59244.4, bsz=2223, num_updates=373600, lr=0.000163605, gnorm=0.355, loss_scale=2, train_wall=79, gb_free=39.6, wall=314307
2023-06-15 07:06:10 | INFO | train_inner | epoch 034:   1672 / 11284 loss=3.48, nll_loss=1.769, ppl=3.41, wps=71856.7, ups=1.21, wpb=59593.9, bsz=2194.2, num_updates=373700, lr=0.000163583, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.6, wall=314390
2023-06-15 07:07:32 | INFO | train_inner | epoch 034:   1772 / 11284 loss=3.48, nll_loss=1.769, ppl=3.41, wps=72306.6, ups=1.21, wpb=59646.7, bsz=2159.6, num_updates=373800, lr=0.000163561, gnorm=0.35, loss_scale=2, train_wall=78, gb_free=39.6, wall=314473
2023-06-15 07:08:55 | INFO | train_inner | epoch 034:   1872 / 11284 loss=3.479, nll_loss=1.768, ppl=3.41, wps=72104.5, ups=1.2, wpb=59859.5, bsz=2194.3, num_updates=373900, lr=0.000163539, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=39.6, wall=314556
2023-06-15 07:10:19 | INFO | train_inner | epoch 034:   1972 / 11284 loss=3.498, nll_loss=1.79, ppl=3.46, wps=71235, ups=1.2, wpb=59313.6, bsz=2202.4, num_updates=374000, lr=0.000163517, gnorm=0.37, loss_scale=2, train_wall=79, gb_free=39.6, wall=314639
2023-06-15 07:11:42 | INFO | train_inner | epoch 034:   2072 / 11284 loss=3.477, nll_loss=1.765, ppl=3.4, wps=71423.3, ups=1.2, wpb=59362.5, bsz=2217.4, num_updates=374100, lr=0.000163496, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.6, wall=314722
2023-06-15 07:13:05 | INFO | train_inner | epoch 034:   2172 / 11284 loss=3.476, nll_loss=1.765, ppl=3.4, wps=71759, ups=1.2, wpb=59670.3, bsz=2192.1, num_updates=374200, lr=0.000163474, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.6, wall=314805
2023-06-15 07:14:28 | INFO | train_inner | epoch 034:   2272 / 11284 loss=3.473, nll_loss=1.761, ppl=3.39, wps=71527, ups=1.2, wpb=59486.3, bsz=2221.3, num_updates=374300, lr=0.000163452, gnorm=0.357, loss_scale=4, train_wall=79, gb_free=39.6, wall=314889
2023-06-15 07:15:51 | INFO | train_inner | epoch 034:   2372 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=71869.2, ups=1.21, wpb=59629.4, bsz=2226.2, num_updates=374400, lr=0.00016343, gnorm=0.35, loss_scale=4, train_wall=79, gb_free=39.6, wall=314972
2023-06-15 07:16:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 07:17:15 | INFO | train_inner | epoch 034:   2473 / 11284 loss=3.482, nll_loss=1.772, ppl=3.41, wps=70954.3, ups=1.19, wpb=59396.7, bsz=2147.3, num_updates=374500, lr=0.000163408, gnorm=0.354, loss_scale=2, train_wall=80, gb_free=39.5, wall=315055
2023-06-15 07:18:38 | INFO | train_inner | epoch 034:   2573 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=71618.7, ups=1.2, wpb=59519.3, bsz=2266.4, num_updates=374600, lr=0.000163386, gnorm=0.361, loss_scale=2, train_wall=79, gb_free=39.5, wall=315138
2023-06-15 07:20:01 | INFO | train_inner | epoch 034:   2673 / 11284 loss=3.476, nll_loss=1.765, ppl=3.4, wps=71155.8, ups=1.2, wpb=59531, bsz=2256.3, num_updates=374700, lr=0.000163365, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.6, wall=315222
2023-06-15 07:21:25 | INFO | train_inner | epoch 034:   2773 / 11284 loss=3.474, nll_loss=1.763, ppl=3.39, wps=71411.3, ups=1.2, wpb=59703.3, bsz=2247.7, num_updates=374800, lr=0.000163343, gnorm=0.349, loss_scale=2, train_wall=79, gb_free=39.6, wall=315306
2023-06-15 07:22:48 | INFO | train_inner | epoch 034:   2873 / 11284 loss=3.491, nll_loss=1.782, ppl=3.44, wps=71741.9, ups=1.21, wpb=59440.2, bsz=2232.7, num_updates=374900, lr=0.000163321, gnorm=0.366, loss_scale=2, train_wall=79, gb_free=39.6, wall=315389
2023-06-15 07:24:11 | INFO | train_inner | epoch 034:   2973 / 11284 loss=3.475, nll_loss=1.764, ppl=3.4, wps=71428.9, ups=1.2, wpb=59344.9, bsz=2162.3, num_updates=375000, lr=0.000163299, gnorm=0.363, loss_scale=2, train_wall=79, gb_free=39.4, wall=315472
2023-06-15 07:25:34 | INFO | train_inner | epoch 034:   3073 / 11284 loss=3.491, nll_loss=1.782, ppl=3.44, wps=71892.7, ups=1.21, wpb=59602.5, bsz=2237.2, num_updates=375100, lr=0.000163278, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.5, wall=315554
2023-06-15 07:26:57 | INFO | train_inner | epoch 034:   3173 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=71788, ups=1.21, wpb=59368.5, bsz=2179.3, num_updates=375200, lr=0.000163256, gnorm=0.359, loss_scale=2, train_wall=79, gb_free=39.6, wall=315637
2023-06-15 07:28:19 | INFO | train_inner | epoch 034:   3273 / 11284 loss=3.481, nll_loss=1.771, ppl=3.41, wps=72024.9, ups=1.21, wpb=59346.7, bsz=2260.4, num_updates=375300, lr=0.000163234, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.5, wall=315720
2023-06-15 07:29:42 | INFO | train_inner | epoch 034:   3373 / 11284 loss=3.49, nll_loss=1.78, ppl=3.43, wps=71724.8, ups=1.21, wpb=59278.2, bsz=2236.2, num_updates=375400, lr=0.000163212, gnorm=0.35, loss_scale=2, train_wall=78, gb_free=39.6, wall=315802
2023-06-15 07:30:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 07:31:06 | INFO | train_inner | epoch 034:   3474 / 11284 loss=3.477, nll_loss=1.766, ppl=3.4, wps=70972.6, ups=1.19, wpb=59687.5, bsz=2233.2, num_updates=375500, lr=0.000163191, gnorm=0.349, loss_scale=2, train_wall=80, gb_free=39.6, wall=315886
2023-06-15 07:32:29 | INFO | train_inner | epoch 034:   3574 / 11284 loss=3.489, nll_loss=1.779, ppl=3.43, wps=71403.2, ups=1.2, wpb=59486.4, bsz=2197.6, num_updates=375600, lr=0.000163169, gnorm=0.358, loss_scale=2, train_wall=79, gb_free=39.6, wall=315970
2023-06-15 07:33:52 | INFO | train_inner | epoch 034:   3674 / 11284 loss=3.472, nll_loss=1.76, ppl=3.39, wps=71339.8, ups=1.2, wpb=59441.8, bsz=2324.5, num_updates=375700, lr=0.000163147, gnorm=0.368, loss_scale=2, train_wall=79, gb_free=39.6, wall=316053
2023-06-15 07:35:16 | INFO | train_inner | epoch 034:   3774 / 11284 loss=3.479, nll_loss=1.768, ppl=3.41, wps=71587.6, ups=1.2, wpb=59501.6, bsz=2221, num_updates=375800, lr=0.000163125, gnorm=0.367, loss_scale=2, train_wall=79, gb_free=39.5, wall=316136
2023-06-15 07:36:39 | INFO | train_inner | epoch 034:   3874 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=71898.5, ups=1.2, wpb=59680.3, bsz=2239.7, num_updates=375900, lr=0.000163104, gnorm=0.349, loss_scale=2, train_wall=79, gb_free=39.6, wall=316219
2023-06-15 07:38:02 | INFO | train_inner | epoch 034:   3974 / 11284 loss=3.49, nll_loss=1.781, ppl=3.44, wps=71264.6, ups=1.2, wpb=59467.6, bsz=2201.6, num_updates=376000, lr=0.000163082, gnorm=0.35, loss_scale=2, train_wall=80, gb_free=39.5, wall=316303
2023-06-15 07:39:25 | INFO | train_inner | epoch 034:   4074 / 11284 loss=3.47, nll_loss=1.758, ppl=3.38, wps=71153.1, ups=1.2, wpb=59345, bsz=2255.2, num_updates=376100, lr=0.00016306, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.5, wall=316386
2023-06-15 07:40:48 | INFO | train_inner | epoch 034:   4174 / 11284 loss=3.476, nll_loss=1.765, ppl=3.4, wps=71566.6, ups=1.2, wpb=59486.3, bsz=2165.4, num_updates=376200, lr=0.000163039, gnorm=0.362, loss_scale=2, train_wall=79, gb_free=39.6, wall=316469
2023-06-15 07:42:12 | INFO | train_inner | epoch 034:   4274 / 11284 loss=3.483, nll_loss=1.772, ppl=3.42, wps=71455.1, ups=1.2, wpb=59461.5, bsz=2207.6, num_updates=376300, lr=0.000163017, gnorm=0.359, loss_scale=2, train_wall=79, gb_free=39.5, wall=316552
2023-06-15 07:43:35 | INFO | train_inner | epoch 034:   4374 / 11284 loss=3.483, nll_loss=1.772, ppl=3.42, wps=71545, ups=1.2, wpb=59595.8, bsz=2244.1, num_updates=376400, lr=0.000162995, gnorm=0.35, loss_scale=2, train_wall=79, gb_free=39.5, wall=316636
2023-06-15 07:44:58 | INFO | train_inner | epoch 034:   4474 / 11284 loss=3.474, nll_loss=1.763, ppl=3.39, wps=71810.9, ups=1.2, wpb=59843, bsz=2201.4, num_updates=376500, lr=0.000162974, gnorm=0.353, loss_scale=4, train_wall=79, gb_free=39.5, wall=316719
2023-06-15 07:45:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 07:46:22 | INFO | train_inner | epoch 034:   4575 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71285.5, ups=1.2, wpb=59356.8, bsz=2096.1, num_updates=376600, lr=0.000162952, gnorm=0.369, loss_scale=2, train_wall=79, gb_free=39.6, wall=316802
2023-06-15 07:47:45 | INFO | train_inner | epoch 034:   4675 / 11284 loss=3.496, nll_loss=1.788, ppl=3.45, wps=71446.4, ups=1.2, wpb=59400.7, bsz=2259.8, num_updates=376700, lr=0.00016293, gnorm=0.35, loss_scale=2, train_wall=79, gb_free=39.5, wall=316885
2023-06-15 07:49:07 | INFO | train_inner | epoch 034:   4775 / 11284 loss=3.489, nll_loss=1.779, ppl=3.43, wps=72395.8, ups=1.22, wpb=59517.9, bsz=2233.2, num_updates=376800, lr=0.000162909, gnorm=0.353, loss_scale=2, train_wall=78, gb_free=39.6, wall=316968
2023-06-15 07:50:29 | INFO | train_inner | epoch 034:   4875 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=72421.6, ups=1.22, wpb=59325, bsz=2239.3, num_updates=376900, lr=0.000162887, gnorm=0.372, loss_scale=2, train_wall=78, gb_free=39.2, wall=317049
2023-06-15 07:51:51 | INFO | train_inner | epoch 034:   4975 / 11284 loss=3.491, nll_loss=1.781, ppl=3.44, wps=72814.9, ups=1.22, wpb=59517.3, bsz=2308.2, num_updates=377000, lr=0.000162866, gnorm=0.358, loss_scale=2, train_wall=78, gb_free=39.5, wall=317131
2023-06-15 07:53:13 | INFO | train_inner | epoch 034:   5075 / 11284 loss=3.486, nll_loss=1.776, ppl=3.43, wps=72235.2, ups=1.21, wpb=59495.4, bsz=2252.2, num_updates=377100, lr=0.000162844, gnorm=0.354, loss_scale=2, train_wall=79, gb_free=39.6, wall=317214
2023-06-15 07:54:36 | INFO | train_inner | epoch 034:   5175 / 11284 loss=3.471, nll_loss=1.76, ppl=3.39, wps=71435.1, ups=1.2, wpb=59560.9, bsz=2233, num_updates=377200, lr=0.000162822, gnorm=0.342, loss_scale=2, train_wall=79, gb_free=39.6, wall=317297
2023-06-15 07:55:59 | INFO | train_inner | epoch 034:   5275 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=72264.8, ups=1.21, wpb=59811.2, bsz=2257, num_updates=377300, lr=0.000162801, gnorm=0.345, loss_scale=2, train_wall=79, gb_free=38.8, wall=317380
2023-06-15 07:57:22 | INFO | train_inner | epoch 034:   5375 / 11284 loss=3.486, nll_loss=1.776, ppl=3.42, wps=71715.9, ups=1.2, wpb=59560.5, bsz=2267.4, num_updates=377400, lr=0.000162779, gnorm=0.344, loss_scale=2, train_wall=79, gb_free=39.5, wall=317463
2023-06-15 07:58:45 | INFO | train_inner | epoch 034:   5475 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=72111.9, ups=1.21, wpb=59415.7, bsz=2239.1, num_updates=377500, lr=0.000162758, gnorm=0.353, loss_scale=2, train_wall=78, gb_free=39.6, wall=317545
2023-06-15 07:59:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 08:00:07 | INFO | train_inner | epoch 034:   5576 / 11284 loss=3.491, nll_loss=1.782, ppl=3.44, wps=72060.1, ups=1.21, wpb=59440.1, bsz=2235.3, num_updates=377600, lr=0.000162736, gnorm=0.373, loss_scale=2, train_wall=78, gb_free=39.6, wall=317628
2023-06-15 08:01:30 | INFO | train_inner | epoch 034:   5676 / 11284 loss=3.477, nll_loss=1.766, ppl=3.4, wps=71726, ups=1.2, wpb=59561.4, bsz=2253.4, num_updates=377700, lr=0.000162715, gnorm=0.355, loss_scale=2, train_wall=79, gb_free=39.6, wall=317711
2023-06-15 08:02:53 | INFO | train_inner | epoch 034:   5776 / 11284 loss=3.479, nll_loss=1.769, ppl=3.41, wps=71451.1, ups=1.2, wpb=59418.2, bsz=2264.4, num_updates=377800, lr=0.000162693, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.6, wall=317794
2023-06-15 08:04:16 | INFO | train_inner | epoch 034:   5876 / 11284 loss=3.496, nll_loss=1.788, ppl=3.45, wps=71814.1, ups=1.21, wpb=59372.4, bsz=2238, num_updates=377900, lr=0.000162672, gnorm=0.358, loss_scale=2, train_wall=79, gb_free=39.6, wall=317877
2023-06-15 08:05:38 | INFO | train_inner | epoch 034:   5976 / 11284 loss=3.476, nll_loss=1.764, ppl=3.4, wps=72348.7, ups=1.21, wpb=59614, bsz=2284.7, num_updates=378000, lr=0.00016265, gnorm=0.357, loss_scale=2, train_wall=78, gb_free=39.6, wall=317959
2023-06-15 08:07:02 | INFO | train_inner | epoch 034:   6076 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=71209.8, ups=1.2, wpb=59371.9, bsz=2146.9, num_updates=378100, lr=0.000162629, gnorm=0.355, loss_scale=2, train_wall=79, gb_free=39.5, wall=318042
2023-06-15 08:08:25 | INFO | train_inner | epoch 034:   6176 / 11284 loss=3.475, nll_loss=1.764, ppl=3.4, wps=71480.8, ups=1.2, wpb=59671.2, bsz=2253.8, num_updates=378200, lr=0.000162607, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=39.6, wall=318126
2023-06-15 08:09:47 | INFO | train_inner | epoch 034:   6276 / 11284 loss=3.478, nll_loss=1.767, ppl=3.4, wps=72653.7, ups=1.22, wpb=59569.8, bsz=2211.4, num_updates=378300, lr=0.000162586, gnorm=0.348, loss_scale=2, train_wall=78, gb_free=39.5, wall=318208
2023-06-15 08:11:10 | INFO | train_inner | epoch 034:   6376 / 11284 loss=3.486, nll_loss=1.777, ppl=3.43, wps=72177.1, ups=1.21, wpb=59447.9, bsz=2252.5, num_updates=378400, lr=0.000162564, gnorm=0.358, loss_scale=2, train_wall=78, gb_free=39.6, wall=318290
2023-06-15 08:12:32 | INFO | train_inner | epoch 034:   6476 / 11284 loss=3.48, nll_loss=1.77, ppl=3.41, wps=71878.4, ups=1.21, wpb=59390.3, bsz=2246.8, num_updates=378500, lr=0.000162543, gnorm=0.372, loss_scale=2, train_wall=79, gb_free=39.5, wall=318373
2023-06-15 08:13:54 | INFO | train_inner | epoch 034:   6576 / 11284 loss=3.473, nll_loss=1.762, ppl=3.39, wps=72264.2, ups=1.22, wpb=59361.6, bsz=2204.8, num_updates=378600, lr=0.000162521, gnorm=0.366, loss_scale=2, train_wall=78, gb_free=39.6, wall=318455
2023-06-15 08:14:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 08:15:17 | INFO | train_inner | epoch 034:   6677 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=71782.6, ups=1.21, wpb=59505, bsz=2251.2, num_updates=378700, lr=0.0001625, gnorm=0.355, loss_scale=2, train_wall=79, gb_free=39.6, wall=318538
2023-06-15 08:16:40 | INFO | train_inner | epoch 034:   6777 / 11284 loss=3.479, nll_loss=1.768, ppl=3.41, wps=71377.3, ups=1.2, wpb=59345.4, bsz=2212.9, num_updates=378800, lr=0.000162478, gnorm=0.37, loss_scale=2, train_wall=79, gb_free=39.6, wall=318621
2023-06-15 08:18:04 | INFO | train_inner | epoch 034:   6877 / 11284 loss=3.488, nll_loss=1.779, ppl=3.43, wps=71392, ups=1.2, wpb=59503.8, bsz=2246.1, num_updates=378900, lr=0.000162457, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.6, wall=318704
2023-06-15 08:19:27 | INFO | train_inner | epoch 034:   6977 / 11284 loss=3.503, nll_loss=1.796, ppl=3.47, wps=71570.9, ups=1.2, wpb=59422.3, bsz=2145.1, num_updates=379000, lr=0.000162435, gnorm=0.365, loss_scale=2, train_wall=79, gb_free=39.6, wall=318787
2023-06-15 08:20:50 | INFO | train_inner | epoch 034:   7077 / 11284 loss=3.488, nll_loss=1.779, ppl=3.43, wps=71309.1, ups=1.2, wpb=59441.2, bsz=2308.5, num_updates=379100, lr=0.000162414, gnorm=0.358, loss_scale=2, train_wall=79, gb_free=39.6, wall=318871
2023-06-15 08:22:13 | INFO | train_inner | epoch 034:   7177 / 11284 loss=3.487, nll_loss=1.778, ppl=3.43, wps=71986, ups=1.21, wpb=59568.4, bsz=2185.9, num_updates=379200, lr=0.000162392, gnorm=0.354, loss_scale=2, train_wall=79, gb_free=39.5, wall=318953
2023-06-15 08:23:36 | INFO | train_inner | epoch 034:   7277 / 11284 loss=3.486, nll_loss=1.777, ppl=3.43, wps=71578.4, ups=1.2, wpb=59582.3, bsz=2297.2, num_updates=379300, lr=0.000162371, gnorm=0.35, loss_scale=2, train_wall=79, gb_free=39.6, wall=319037
2023-06-15 08:24:59 | INFO | train_inner | epoch 034:   7377 / 11284 loss=3.485, nll_loss=1.776, ppl=3.42, wps=71474.4, ups=1.2, wpb=59563.4, bsz=2239.3, num_updates=379400, lr=0.00016235, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.6, wall=319120
2023-06-15 08:26:22 | INFO | train_inner | epoch 034:   7477 / 11284 loss=3.493, nll_loss=1.785, ppl=3.44, wps=72226.4, ups=1.22, wpb=59395.8, bsz=2206.2, num_updates=379500, lr=0.000162328, gnorm=0.366, loss_scale=2, train_wall=78, gb_free=39.6, wall=319202
2023-06-15 08:27:45 | INFO | train_inner | epoch 034:   7577 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=71341.9, ups=1.2, wpb=59260.1, bsz=2251, num_updates=379600, lr=0.000162307, gnorm=0.363, loss_scale=2, train_wall=79, gb_free=39.6, wall=319285
2023-06-15 08:29:08 | INFO | train_inner | epoch 034:   7677 / 11284 loss=3.488, nll_loss=1.779, ppl=3.43, wps=71705.3, ups=1.21, wpb=59343.2, bsz=2319.7, num_updates=379700, lr=0.000162285, gnorm=0.359, loss_scale=4, train_wall=79, gb_free=39.6, wall=319368
2023-06-15 08:29:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 08:30:31 | INFO | train_inner | epoch 034:   7778 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71075.9, ups=1.19, wpb=59584, bsz=2164.1, num_updates=379800, lr=0.000162264, gnorm=0.348, loss_scale=2, train_wall=80, gb_free=39.5, wall=319452
2023-06-15 08:31:54 | INFO | train_inner | epoch 034:   7878 / 11284 loss=3.475, nll_loss=1.764, ppl=3.4, wps=72106.8, ups=1.21, wpb=59556.2, bsz=2291.8, num_updates=379900, lr=0.000162243, gnorm=0.359, loss_scale=2, train_wall=79, gb_free=39.6, wall=319535
2023-06-15 08:33:17 | INFO | train_inner | epoch 034:   7978 / 11284 loss=3.488, nll_loss=1.779, ppl=3.43, wps=71380, ups=1.2, wpb=59443.9, bsz=2258.9, num_updates=380000, lr=0.000162221, gnorm=0.349, loss_scale=2, train_wall=79, gb_free=39.6, wall=319618
2023-06-15 08:34:43 | INFO | train_inner | epoch 034:   8078 / 11284 loss=3.492, nll_loss=1.783, ppl=3.44, wps=69399.2, ups=1.17, wpb=59563.1, bsz=2274.7, num_updates=380100, lr=0.0001622, gnorm=0.365, loss_scale=2, train_wall=82, gb_free=39.6, wall=319704
2023-06-15 08:36:06 | INFO | train_inner | epoch 034:   8178 / 11284 loss=3.489, nll_loss=1.779, ppl=3.43, wps=71502.5, ups=1.2, wpb=59462.6, bsz=2200.8, num_updates=380200, lr=0.000162179, gnorm=0.364, loss_scale=2, train_wall=79, gb_free=39.6, wall=319787
2023-06-15 08:37:29 | INFO | train_inner | epoch 034:   8278 / 11284 loss=3.493, nll_loss=1.784, ppl=3.44, wps=71732.2, ups=1.2, wpb=59652.2, bsz=2199.8, num_updates=380300, lr=0.000162157, gnorm=0.36, loss_scale=2, train_wall=79, gb_free=39.6, wall=319870
2023-06-15 08:38:52 | INFO | train_inner | epoch 034:   8378 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=71940.1, ups=1.21, wpb=59383.5, bsz=2153, num_updates=380400, lr=0.000162136, gnorm=0.37, loss_scale=2, train_wall=79, gb_free=39.6, wall=319953
2023-06-15 08:40:15 | INFO | train_inner | epoch 034:   8478 / 11284 loss=3.486, nll_loss=1.776, ppl=3.43, wps=71804, ups=1.21, wpb=59393.7, bsz=2210.5, num_updates=380500, lr=0.000162115, gnorm=0.349, loss_scale=2, train_wall=79, gb_free=39.3, wall=320035
2023-06-15 08:41:37 | INFO | train_inner | epoch 034:   8578 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=71875.4, ups=1.21, wpb=59547.4, bsz=2152.6, num_updates=380600, lr=0.000162094, gnorm=0.36, loss_scale=2, train_wall=79, gb_free=39.6, wall=320118
2023-06-15 08:43:00 | INFO | train_inner | epoch 034:   8678 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=71782.5, ups=1.21, wpb=59404.8, bsz=2134.3, num_updates=380700, lr=0.000162072, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.6, wall=320201
2023-06-15 08:43:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 08:44:24 | INFO | train_inner | epoch 034:   8779 / 11284 loss=3.486, nll_loss=1.776, ppl=3.42, wps=70914.6, ups=1.19, wpb=59531, bsz=2269.3, num_updates=380800, lr=0.000162051, gnorm=0.364, loss_scale=2, train_wall=80, gb_free=39.5, wall=320285
2023-06-15 08:45:48 | INFO | train_inner | epoch 034:   8879 / 11284 loss=3.496, nll_loss=1.788, ppl=3.45, wps=71417.3, ups=1.2, wpb=59567.6, bsz=2290.5, num_updates=380900, lr=0.00016203, gnorm=0.355, loss_scale=2, train_wall=79, gb_free=39.6, wall=320368
2023-06-15 08:47:11 | INFO | train_inner | epoch 034:   8979 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=71563, ups=1.2, wpb=59565.8, bsz=2321.7, num_updates=381000, lr=0.000162008, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=39.6, wall=320451
2023-06-15 08:48:34 | INFO | train_inner | epoch 034:   9079 / 11284 loss=3.492, nll_loss=1.783, ppl=3.44, wps=71896.6, ups=1.21, wpb=59602.5, bsz=2250.5, num_updates=381100, lr=0.000161987, gnorm=0.364, loss_scale=2, train_wall=79, gb_free=39.6, wall=320534
2023-06-15 08:49:57 | INFO | train_inner | epoch 034:   9179 / 11284 loss=3.475, nll_loss=1.764, ppl=3.4, wps=71291.8, ups=1.2, wpb=59483.5, bsz=2282.7, num_updates=381200, lr=0.000161966, gnorm=0.359, loss_scale=2, train_wall=79, gb_free=39.6, wall=320618
2023-06-15 08:51:21 | INFO | train_inner | epoch 034:   9279 / 11284 loss=3.474, nll_loss=1.763, ppl=3.39, wps=71427.8, ups=1.2, wpb=59583.4, bsz=2269.5, num_updates=381300, lr=0.000161945, gnorm=0.37, loss_scale=2, train_wall=80, gb_free=39.6, wall=320701
2023-06-15 08:52:43 | INFO | train_inner | epoch 034:   9379 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=72171.7, ups=1.21, wpb=59620.6, bsz=2199.7, num_updates=381400, lr=0.000161923, gnorm=0.348, loss_scale=2, train_wall=79, gb_free=39.6, wall=320784
2023-06-15 08:54:05 | INFO | train_inner | epoch 034:   9479 / 11284 loss=3.486, nll_loss=1.777, ppl=3.43, wps=72612.1, ups=1.22, wpb=59583.2, bsz=2221.5, num_updates=381500, lr=0.000161902, gnorm=0.356, loss_scale=2, train_wall=78, gb_free=39.6, wall=320866
2023-06-15 08:55:27 | INFO | train_inner | epoch 034:   9579 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=72720.1, ups=1.22, wpb=59365.9, bsz=2191.3, num_updates=381600, lr=0.000161881, gnorm=0.355, loss_scale=2, train_wall=77, gb_free=39.6, wall=320947
2023-06-15 08:56:49 | INFO | train_inner | epoch 034:   9679 / 11284 loss=3.487, nll_loss=1.778, ppl=3.43, wps=72409.8, ups=1.21, wpb=59681, bsz=2193.8, num_updates=381700, lr=0.00016186, gnorm=0.357, loss_scale=2, train_wall=78, gb_free=39.6, wall=321030
2023-06-15 08:57:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 08:58:13 | INFO | train_inner | epoch 034:   9780 / 11284 loss=3.496, nll_loss=1.788, ppl=3.45, wps=71039.1, ups=1.19, wpb=59591.9, bsz=2137, num_updates=381800, lr=0.000161839, gnorm=0.364, loss_scale=2, train_wall=80, gb_free=39.6, wall=321114
2023-06-15 08:59:36 | INFO | train_inner | epoch 034:   9880 / 11284 loss=3.479, nll_loss=1.769, ppl=3.41, wps=71727.5, ups=1.2, wpb=59550.4, bsz=2258.3, num_updates=381900, lr=0.000161817, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.6, wall=321197
2023-06-15 09:01:00 | INFO | train_inner | epoch 034:   9980 / 11284 loss=3.505, nll_loss=1.797, ppl=3.48, wps=71209.6, ups=1.2, wpb=59297.7, bsz=2220.9, num_updates=382000, lr=0.000161796, gnorm=0.369, loss_scale=2, train_wall=79, gb_free=39.6, wall=321280
2023-06-15 09:02:23 | INFO | train_inner | epoch 034:  10080 / 11284 loss=3.49, nll_loss=1.781, ppl=3.44, wps=71515.9, ups=1.2, wpb=59584.2, bsz=2189.1, num_updates=382100, lr=0.000161775, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.5, wall=321363
2023-06-15 09:03:45 | INFO | train_inner | epoch 034:  10180 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=72079.2, ups=1.21, wpb=59437.4, bsz=2215.5, num_updates=382200, lr=0.000161754, gnorm=0.363, loss_scale=2, train_wall=78, gb_free=39.6, wall=321446
2023-06-15 09:05:07 | INFO | train_inner | epoch 034:  10280 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=72624.1, ups=1.22, wpb=59493.8, bsz=2251, num_updates=382300, lr=0.000161733, gnorm=0.358, loss_scale=2, train_wall=78, gb_free=39.5, wall=321528
2023-06-15 09:06:30 | INFO | train_inner | epoch 034:  10380 / 11284 loss=3.482, nll_loss=1.772, ppl=3.42, wps=71797.6, ups=1.2, wpb=59652.5, bsz=2154, num_updates=382400, lr=0.000161712, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.4, wall=321611
2023-06-15 09:07:54 | INFO | train_inner | epoch 034:  10480 / 11284 loss=3.497, nll_loss=1.789, ppl=3.46, wps=71476.3, ups=1.2, wpb=59535.6, bsz=2208.3, num_updates=382500, lr=0.00016169, gnorm=0.359, loss_scale=2, train_wall=80, gb_free=38.5, wall=321694
2023-06-15 09:09:17 | INFO | train_inner | epoch 034:  10580 / 11284 loss=3.49, nll_loss=1.781, ppl=3.44, wps=71829.6, ups=1.21, wpb=59547.6, bsz=2113, num_updates=382600, lr=0.000161669, gnorm=0.352, loss_scale=2, train_wall=79, gb_free=39.5, wall=321777
2023-06-15 09:10:38 | INFO | train_inner | epoch 034:  10680 / 11284 loss=3.472, nll_loss=1.761, ppl=3.39, wps=72562.5, ups=1.22, wpb=59318.5, bsz=2172, num_updates=382700, lr=0.000161648, gnorm=0.374, loss_scale=2, train_wall=78, gb_free=39.5, wall=321859
2023-06-15 09:12:01 | INFO | train_inner | epoch 034:  10780 / 11284 loss=3.475, nll_loss=1.764, ppl=3.4, wps=71783.3, ups=1.21, wpb=59278, bsz=2233.4, num_updates=382800, lr=0.000161627, gnorm=0.371, loss_scale=2, train_wall=79, gb_free=39.6, wall=321941
2023-06-15 09:12:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 09:13:25 | INFO | train_inner | epoch 034:  10881 / 11284 loss=3.483, nll_loss=1.774, ppl=3.42, wps=71021.1, ups=1.19, wpb=59669.1, bsz=2264.1, num_updates=382900, lr=0.000161606, gnorm=0.35, loss_scale=2, train_wall=80, gb_free=39.5, wall=322025
2023-06-15 09:14:49 | INFO | train_inner | epoch 034:  10981 / 11284 loss=3.474, nll_loss=1.763, ppl=3.39, wps=71107.8, ups=1.19, wpb=59688.9, bsz=2294.7, num_updates=383000, lr=0.000161585, gnorm=0.36, loss_scale=2, train_wall=80, gb_free=39.6, wall=322109
2023-06-15 09:16:12 | INFO | train_inner | epoch 034:  11081 / 11284 loss=3.489, nll_loss=1.78, ppl=3.43, wps=71422.3, ups=1.2, wpb=59419.4, bsz=2221.5, num_updates=383100, lr=0.000161564, gnorm=0.362, loss_scale=2, train_wall=79, gb_free=39.6, wall=322193
2023-06-15 09:17:35 | INFO | train_inner | epoch 034:  11181 / 11284 loss=3.48, nll_loss=1.769, ppl=3.41, wps=71779.9, ups=1.21, wpb=59440.8, bsz=2128, num_updates=383200, lr=0.000161543, gnorm=0.352, loss_scale=2, train_wall=79, gb_free=39.5, wall=322275
2023-06-15 09:18:58 | INFO | train_inner | epoch 034:  11281 / 11284 loss=3.482, nll_loss=1.773, ppl=3.42, wps=71910.9, ups=1.21, wpb=59565.1, bsz=2298.9, num_updates=383300, lr=0.000161522, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.6, wall=322358
2023-06-15 09:19:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-15 09:19:52 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 4.292 | nll_loss 2.61 | ppl 6.1 | bleu 20.79 | wps 3806.5 | wpb 2397.5 | bsz 71.5 | num_updates 383303 | best_loss 4.278
2023-06-15 09:19:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 383303 updates
2023-06-15 09:19:55 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint34.pt
2023-06-15 09:20:40 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint34.pt
2023-06-15 09:21:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint34.pt (epoch 34 @ 383303 updates, score 4.292) (writing took 65.84017028193921 seconds)
2023-06-15 09:21:01 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-06-15 09:21:01 | INFO | train | epoch 034 | loss 3.484 | nll_loss 1.774 | ppl 3.42 | wps 70740 | ups 1.19 | wpb 59501 | bsz 2227.4 | num_updates 383303 | lr 0.000161521 | gnorm 0.357 | loss_scale 2 | train_wall 8913 | gb_free 39.6 | wall 322482
2023-06-15 09:21:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-15 09:21:02 | INFO | fairseq.trainer | begin training epoch 35
2023-06-15 09:21:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-15 09:22:22 | INFO | train_inner | epoch 035:     97 / 11284 loss=3.464, nll_loss=1.752, ppl=3.37, wps=28996.6, ups=0.49, wpb=59239.6, bsz=2168.1, num_updates=383400, lr=0.000161501, gnorm=0.366, loss_scale=2, train_wall=78, gb_free=39.6, wall=322563
2023-06-15 09:23:45 | INFO | train_inner | epoch 035:    197 / 11284 loss=3.459, nll_loss=1.746, ppl=3.35, wps=71436.6, ups=1.2, wpb=59520.8, bsz=2131.3, num_updates=383500, lr=0.000161479, gnorm=0.364, loss_scale=2, train_wall=80, gb_free=39.5, wall=322646
2023-06-15 09:25:08 | INFO | train_inner | epoch 035:    297 / 11284 loss=3.472, nll_loss=1.76, ppl=3.39, wps=71598.1, ups=1.2, wpb=59424.9, bsz=2226.6, num_updates=383600, lr=0.000161458, gnorm=0.358, loss_scale=2, train_wall=79, gb_free=39.6, wall=322729
2023-06-15 09:26:31 | INFO | train_inner | epoch 035:    397 / 11284 loss=3.491, nll_loss=1.781, ppl=3.44, wps=71575.2, ups=1.2, wpb=59423.6, bsz=2186.8, num_updates=383700, lr=0.000161437, gnorm=0.359, loss_scale=2, train_wall=79, gb_free=39.5, wall=322812
2023-06-15 09:27:54 | INFO | train_inner | epoch 035:    497 / 11284 loss=3.481, nll_loss=1.771, ppl=3.41, wps=71455.5, ups=1.2, wpb=59317.8, bsz=2240.5, num_updates=383800, lr=0.000161416, gnorm=0.354, loss_scale=2, train_wall=79, gb_free=39.6, wall=322895
2023-06-15 09:28:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 09:29:18 | INFO | train_inner | epoch 035:    598 / 11284 loss=3.461, nll_loss=1.748, ppl=3.36, wps=70937.6, ups=1.19, wpb=59545, bsz=2190.1, num_updates=383900, lr=0.000161395, gnorm=0.355, loss_scale=2, train_wall=80, gb_free=39.6, wall=322979
2023-06-15 09:30:42 | INFO | train_inner | epoch 035:    698 / 11284 loss=3.481, nll_loss=1.77, ppl=3.41, wps=70954.2, ups=1.2, wpb=59298.6, bsz=2253.2, num_updates=384000, lr=0.000161374, gnorm=0.367, loss_scale=2, train_wall=80, gb_free=39.6, wall=323062
2023-06-15 09:32:05 | INFO | train_inner | epoch 035:    798 / 11284 loss=3.473, nll_loss=1.762, ppl=3.39, wps=71206.1, ups=1.2, wpb=59255.7, bsz=2161.6, num_updates=384100, lr=0.000161353, gnorm=0.35, loss_scale=2, train_wall=79, gb_free=39.5, wall=323146
2023-06-15 09:33:28 | INFO | train_inner | epoch 035:    898 / 11284 loss=3.475, nll_loss=1.764, ppl=3.4, wps=71920.4, ups=1.21, wpb=59683.9, bsz=2239.7, num_updates=384200, lr=0.000161332, gnorm=0.364, loss_scale=2, train_wall=79, gb_free=39.5, wall=323229
2023-06-15 09:34:51 | INFO | train_inner | epoch 035:    998 / 11284 loss=3.482, nll_loss=1.771, ppl=3.41, wps=71667.9, ups=1.2, wpb=59680, bsz=2225.8, num_updates=384300, lr=0.000161311, gnorm=0.358, loss_scale=2, train_wall=79, gb_free=39.6, wall=323312
2023-06-15 09:36:15 | INFO | train_inner | epoch 035:   1098 / 11284 loss=3.48, nll_loss=1.769, ppl=3.41, wps=71542.7, ups=1.2, wpb=59588, bsz=2226.9, num_updates=384400, lr=0.00016129, gnorm=0.358, loss_scale=2, train_wall=79, gb_free=39.5, wall=323395
2023-06-15 09:37:38 | INFO | train_inner | epoch 035:   1198 / 11284 loss=3.48, nll_loss=1.769, ppl=3.41, wps=71556.9, ups=1.2, wpb=59541.2, bsz=2256.3, num_updates=384500, lr=0.000161269, gnorm=0.367, loss_scale=2, train_wall=79, gb_free=39.5, wall=323478
2023-06-15 09:39:01 | INFO | train_inner | epoch 035:   1298 / 11284 loss=3.468, nll_loss=1.756, ppl=3.38, wps=71267.3, ups=1.2, wpb=59399.1, bsz=2280.4, num_updates=384600, lr=0.000161248, gnorm=0.354, loss_scale=2, train_wall=79, gb_free=39.6, wall=323562
2023-06-15 09:40:23 | INFO | train_inner | epoch 035:   1398 / 11284 loss=3.468, nll_loss=1.756, ppl=3.38, wps=72396.1, ups=1.22, wpb=59510.8, bsz=2184.9, num_updates=384700, lr=0.000161227, gnorm=0.365, loss_scale=2, train_wall=78, gb_free=39.2, wall=323644
2023-06-15 09:41:47 | INFO | train_inner | epoch 035:   1498 / 11284 loss=3.471, nll_loss=1.76, ppl=3.39, wps=71354.8, ups=1.2, wpb=59540.6, bsz=2261.5, num_updates=384800, lr=0.000161206, gnorm=0.355, loss_scale=2, train_wall=79, gb_free=39.6, wall=323727
2023-06-15 09:42:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 09:43:11 | INFO | train_inner | epoch 035:   1599 / 11284 loss=3.474, nll_loss=1.763, ppl=3.39, wps=70777.4, ups=1.19, wpb=59550.1, bsz=2228.1, num_updates=384900, lr=0.000161186, gnorm=0.361, loss_scale=2, train_wall=80, gb_free=39.6, wall=323812
2023-06-15 09:44:35 | INFO | train_inner | epoch 035:   1699 / 11284 loss=3.475, nll_loss=1.764, ppl=3.4, wps=71305.4, ups=1.2, wpb=59644.4, bsz=2243.3, num_updates=385000, lr=0.000161165, gnorm=0.357, loss_scale=2, train_wall=80, gb_free=39.5, wall=323895
2023-06-15 09:45:59 | INFO | train_inner | epoch 035:   1799 / 11284 loss=3.468, nll_loss=1.756, ppl=3.38, wps=70161.1, ups=1.18, wpb=59455, bsz=2265.1, num_updates=385100, lr=0.000161144, gnorm=0.361, loss_scale=2, train_wall=81, gb_free=39.6, wall=323980
2023-06-15 09:47:24 | INFO | train_inner | epoch 035:   1899 / 11284 loss=3.48, nll_loss=1.77, ppl=3.41, wps=70047.6, ups=1.18, wpb=59452.8, bsz=2210.9, num_updates=385200, lr=0.000161123, gnorm=0.365, loss_scale=2, train_wall=81, gb_free=39.6, wall=324065
2023-06-15 09:48:49 | INFO | train_inner | epoch 035:   1999 / 11284 loss=3.479, nll_loss=1.768, ppl=3.41, wps=69628.8, ups=1.17, wpb=59304, bsz=2159.5, num_updates=385300, lr=0.000161102, gnorm=0.363, loss_scale=2, train_wall=81, gb_free=39.6, wall=324150
2023-06-15 09:50:16 | INFO | train_inner | epoch 035:   2099 / 11284 loss=3.475, nll_loss=1.764, ppl=3.4, wps=69102.3, ups=1.16, wpb=59531.9, bsz=2302.7, num_updates=385400, lr=0.000161081, gnorm=0.357, loss_scale=2, train_wall=82, gb_free=39.6, wall=324236
2023-06-15 09:51:41 | INFO | train_inner | epoch 035:   2199 / 11284 loss=3.481, nll_loss=1.771, ppl=3.41, wps=69962.9, ups=1.17, wpb=59705.4, bsz=2190.6, num_updates=385500, lr=0.00016106, gnorm=0.356, loss_scale=2, train_wall=81, gb_free=39.6, wall=324321
2023-06-15 09:53:06 | INFO | train_inner | epoch 035:   2299 / 11284 loss=3.476, nll_loss=1.765, ppl=3.4, wps=69471.2, ups=1.17, wpb=59418.4, bsz=2214.4, num_updates=385600, lr=0.000161039, gnorm=0.36, loss_scale=2, train_wall=82, gb_free=39.6, wall=324407
2023-06-15 09:54:31 | INFO | train_inner | epoch 035:   2399 / 11284 loss=3.471, nll_loss=1.759, ppl=3.39, wps=70158.1, ups=1.18, wpb=59630.4, bsz=2257.7, num_updates=385700, lr=0.000161018, gnorm=0.351, loss_scale=2, train_wall=81, gb_free=39.6, wall=324492
2023-06-15 09:55:56 | INFO | train_inner | epoch 035:   2499 / 11284 loss=3.474, nll_loss=1.762, ppl=3.39, wps=69965.9, ups=1.18, wpb=59498.9, bsz=2227.3, num_updates=385800, lr=0.000160997, gnorm=0.355, loss_scale=2, train_wall=81, gb_free=39.6, wall=324577
2023-06-15 09:57:22 | INFO | train_inner | epoch 035:   2599 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=69502.8, ups=1.17, wpb=59459.2, bsz=2274.2, num_updates=385900, lr=0.000160977, gnorm=0.361, loss_scale=2, train_wall=82, gb_free=39.6, wall=324663
2023-06-15 09:57:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 09:58:48 | INFO | train_inner | epoch 035:   2700 / 11284 loss=3.475, nll_loss=1.764, ppl=3.4, wps=69007.4, ups=1.16, wpb=59658.6, bsz=2242.5, num_updates=386000, lr=0.000160956, gnorm=0.366, loss_scale=2, train_wall=83, gb_free=39.6, wall=324749
2023-06-15 10:00:14 | INFO | train_inner | epoch 035:   2800 / 11284 loss=3.472, nll_loss=1.761, ppl=3.39, wps=69726.3, ups=1.18, wpb=59339.2, bsz=2300.9, num_updates=386100, lr=0.000160935, gnorm=0.379, loss_scale=2, train_wall=81, gb_free=39.6, wall=324834
2023-06-15 10:01:35 | INFO | train_inner | epoch 035:   2900 / 11284 loss=3.469, nll_loss=1.757, ppl=3.38, wps=73171.4, ups=1.22, wpb=59745.5, bsz=2235.9, num_updates=386200, lr=0.000160914, gnorm=0.351, loss_scale=2, train_wall=78, gb_free=39.5, wall=324916
2023-06-15 10:02:57 | INFO | train_inner | epoch 035:   3000 / 11284 loss=3.475, nll_loss=1.763, ppl=3.4, wps=72614.4, ups=1.22, wpb=59525.4, bsz=2243.1, num_updates=386300, lr=0.000160893, gnorm=0.348, loss_scale=2, train_wall=78, gb_free=39.6, wall=324998
2023-06-15 10:04:19 | INFO | train_inner | epoch 035:   3100 / 11284 loss=3.471, nll_loss=1.759, ppl=3.38, wps=73180.8, ups=1.22, wpb=59741.5, bsz=2214.4, num_updates=386400, lr=0.000160872, gnorm=0.357, loss_scale=2, train_wall=77, gb_free=39.6, wall=325079
2023-06-15 10:05:41 | INFO | train_inner | epoch 035:   3200 / 11284 loss=3.486, nll_loss=1.776, ppl=3.43, wps=72024.9, ups=1.21, wpb=59549, bsz=2192.6, num_updates=386500, lr=0.000160852, gnorm=0.362, loss_scale=2, train_wall=79, gb_free=39.4, wall=325162
2023-06-15 10:07:05 | INFO | train_inner | epoch 035:   3300 / 11284 loss=3.492, nll_loss=1.783, ppl=3.44, wps=71405.5, ups=1.2, wpb=59625.8, bsz=2273.9, num_updates=386600, lr=0.000160831, gnorm=0.37, loss_scale=2, train_wall=79, gb_free=39.6, wall=325246
2023-06-15 10:08:28 | INFO | train_inner | epoch 035:   3400 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=71780.4, ups=1.21, wpb=59446.8, bsz=2240.2, num_updates=386700, lr=0.00016081, gnorm=0.358, loss_scale=2, train_wall=79, gb_free=39.6, wall=325328
2023-06-15 10:09:51 | INFO | train_inner | epoch 035:   3500 / 11284 loss=3.479, nll_loss=1.768, ppl=3.41, wps=72016.9, ups=1.21, wpb=59601.1, bsz=2181.2, num_updates=386800, lr=0.000160789, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.5, wall=325411
2023-06-15 10:11:13 | INFO | train_inner | epoch 035:   3600 / 11284 loss=3.481, nll_loss=1.771, ppl=3.41, wps=71445.5, ups=1.21, wpb=59200.6, bsz=2256.7, num_updates=386900, lr=0.000160768, gnorm=0.374, loss_scale=2, train_wall=79, gb_free=39.6, wall=325494
2023-06-15 10:11:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 10:12:37 | INFO | train_inner | epoch 035:   3701 / 11284 loss=3.47, nll_loss=1.758, ppl=3.38, wps=71369.9, ups=1.2, wpb=59497, bsz=2198, num_updates=387000, lr=0.000160748, gnorm=0.35, loss_scale=2, train_wall=79, gb_free=39.6, wall=325577
2023-06-15 10:14:00 | INFO | train_inner | epoch 035:   3801 / 11284 loss=3.477, nll_loss=1.766, ppl=3.4, wps=71862.9, ups=1.2, wpb=59663.3, bsz=2233.5, num_updates=387100, lr=0.000160727, gnorm=0.355, loss_scale=2, train_wall=79, gb_free=39.6, wall=325660
2023-06-15 10:15:22 | INFO | train_inner | epoch 035:   3901 / 11284 loss=3.488, nll_loss=1.779, ppl=3.43, wps=72132.5, ups=1.21, wpb=59573.4, bsz=2172.9, num_updates=387200, lr=0.000160706, gnorm=0.376, loss_scale=2, train_wall=79, gb_free=39.5, wall=325743
2023-06-15 10:16:45 | INFO | train_inner | epoch 035:   4001 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=71696.8, ups=1.21, wpb=59421.8, bsz=2242.1, num_updates=387300, lr=0.000160685, gnorm=0.364, loss_scale=2, train_wall=79, gb_free=39.5, wall=325826
2023-06-15 10:18:09 | INFO | train_inner | epoch 035:   4101 / 11284 loss=3.468, nll_loss=1.756, ppl=3.38, wps=71483.6, ups=1.2, wpb=59546, bsz=2226.2, num_updates=387400, lr=0.000160665, gnorm=0.358, loss_scale=2, train_wall=79, gb_free=39.5, wall=325909
2023-06-15 10:19:32 | INFO | train_inner | epoch 035:   4201 / 11284 loss=3.477, nll_loss=1.766, ppl=3.4, wps=71414.5, ups=1.2, wpb=59580.1, bsz=2238.7, num_updates=387500, lr=0.000160644, gnorm=0.348, loss_scale=2, train_wall=80, gb_free=39.6, wall=325993
2023-06-15 10:20:55 | INFO | train_inner | epoch 035:   4301 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=71285.7, ups=1.2, wpb=59242.6, bsz=2200.2, num_updates=387600, lr=0.000160623, gnorm=0.362, loss_scale=2, train_wall=79, gb_free=39.5, wall=326076
2023-06-15 10:22:19 | INFO | train_inner | epoch 035:   4401 / 11284 loss=3.498, nll_loss=1.789, ppl=3.46, wps=71276, ups=1.2, wpb=59440.9, bsz=2296.3, num_updates=387700, lr=0.000160602, gnorm=0.358, loss_scale=2, train_wall=79, gb_free=39.6, wall=326159
2023-06-15 10:23:43 | INFO | train_inner | epoch 035:   4501 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=70900, ups=1.19, wpb=59675.2, bsz=2181.8, num_updates=387800, lr=0.000160582, gnorm=0.356, loss_scale=2, train_wall=80, gb_free=39.6, wall=326243
2023-06-15 10:25:06 | INFO | train_inner | epoch 035:   4601 / 11284 loss=3.482, nll_loss=1.771, ppl=3.41, wps=71693.1, ups=1.21, wpb=59376.5, bsz=2153.1, num_updates=387900, lr=0.000160561, gnorm=0.37, loss_scale=2, train_wall=79, gb_free=39.6, wall=326326
2023-06-15 10:26:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 10:26:29 | INFO | train_inner | epoch 035:   4702 / 11284 loss=3.476, nll_loss=1.766, ppl=3.4, wps=71011.2, ups=1.19, wpb=59502.2, bsz=2226.3, num_updates=388000, lr=0.00016054, gnorm=0.352, loss_scale=2, train_wall=80, gb_free=39.6, wall=326410
2023-06-15 10:27:52 | INFO | train_inner | epoch 035:   4802 / 11284 loss=3.474, nll_loss=1.762, ppl=3.39, wps=71700.3, ups=1.2, wpb=59636.8, bsz=2327.5, num_updates=388100, lr=0.00016052, gnorm=0.367, loss_scale=2, train_wall=79, gb_free=39.5, wall=326493
2023-06-15 10:29:16 | INFO | train_inner | epoch 035:   4902 / 11284 loss=3.481, nll_loss=1.771, ppl=3.41, wps=71417.4, ups=1.19, wpb=59813.7, bsz=2339.7, num_updates=388200, lr=0.000160499, gnorm=0.361, loss_scale=2, train_wall=80, gb_free=39.6, wall=326577
2023-06-15 10:30:38 | INFO | train_inner | epoch 035:   5002 / 11284 loss=3.489, nll_loss=1.78, ppl=3.43, wps=72714.6, ups=1.22, wpb=59439.7, bsz=2263.3, num_updates=388300, lr=0.000160478, gnorm=0.354, loss_scale=2, train_wall=78, gb_free=39.6, wall=326659
2023-06-15 10:32:01 | INFO | train_inner | epoch 035:   5102 / 11284 loss=3.5, nll_loss=1.792, ppl=3.46, wps=71863.6, ups=1.21, wpb=59425.2, bsz=2315.1, num_updates=388400, lr=0.000160458, gnorm=0.366, loss_scale=2, train_wall=78, gb_free=39.6, wall=326741
2023-06-15 10:33:24 | INFO | train_inner | epoch 035:   5202 / 11284 loss=3.499, nll_loss=1.79, ppl=3.46, wps=71440.5, ups=1.2, wpb=59462.5, bsz=2214.8, num_updates=388500, lr=0.000160437, gnorm=0.37, loss_scale=2, train_wall=79, gb_free=39.6, wall=326824
2023-06-15 10:34:47 | INFO | train_inner | epoch 035:   5302 / 11284 loss=3.479, nll_loss=1.769, ppl=3.41, wps=71551.6, ups=1.2, wpb=59547.5, bsz=2221.5, num_updates=388600, lr=0.000160416, gnorm=0.355, loss_scale=2, train_wall=79, gb_free=39.6, wall=326908
2023-06-15 10:36:10 | INFO | train_inner | epoch 035:   5402 / 11284 loss=3.478, nll_loss=1.767, ppl=3.4, wps=72078.5, ups=1.21, wpb=59452.4, bsz=2269.4, num_updates=388700, lr=0.000160396, gnorm=0.349, loss_scale=2, train_wall=79, gb_free=39.6, wall=326990
2023-06-15 10:37:32 | INFO | train_inner | epoch 035:   5502 / 11284 loss=3.476, nll_loss=1.766, ppl=3.4, wps=72540.1, ups=1.21, wpb=59705.8, bsz=2360.5, num_updates=388800, lr=0.000160375, gnorm=0.364, loss_scale=2, train_wall=78, gb_free=39.5, wall=327073
2023-06-15 10:38:55 | INFO | train_inner | epoch 035:   5602 / 11284 loss=3.495, nll_loss=1.786, ppl=3.45, wps=71625.7, ups=1.21, wpb=59306, bsz=2277.2, num_updates=388900, lr=0.000160354, gnorm=0.36, loss_scale=2, train_wall=79, gb_free=39.6, wall=327155
2023-06-15 10:40:18 | INFO | train_inner | epoch 035:   5702 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=71403.2, ups=1.2, wpb=59535.1, bsz=2256.2, num_updates=389000, lr=0.000160334, gnorm=0.354, loss_scale=2, train_wall=80, gb_free=39.6, wall=327239
2023-06-15 10:40:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 10:41:42 | INFO | train_inner | epoch 035:   5803 / 11284 loss=3.491, nll_loss=1.782, ppl=3.44, wps=70892.7, ups=1.19, wpb=59709.2, bsz=2270.6, num_updates=389100, lr=0.000160313, gnorm=0.363, loss_scale=2, train_wall=80, gb_free=39.6, wall=327323
2023-06-15 10:43:05 | INFO | train_inner | epoch 035:   5903 / 11284 loss=3.487, nll_loss=1.778, ppl=3.43, wps=72042.2, ups=1.21, wpb=59421.7, bsz=2263.6, num_updates=389200, lr=0.000160293, gnorm=0.381, loss_scale=2, train_wall=78, gb_free=39.5, wall=327405
2023-06-15 10:44:27 | INFO | train_inner | epoch 035:   6003 / 11284 loss=3.491, nll_loss=1.782, ppl=3.44, wps=72117.5, ups=1.22, wpb=59298.4, bsz=2193.8, num_updates=389300, lr=0.000160272, gnorm=0.36, loss_scale=2, train_wall=78, gb_free=39.6, wall=327488
2023-06-15 10:45:51 | INFO | train_inner | epoch 035:   6103 / 11284 loss=3.48, nll_loss=1.769, ppl=3.41, wps=71065.7, ups=1.2, wpb=59309.4, bsz=2205.6, num_updates=389400, lr=0.000160251, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.6, wall=327571
2023-06-15 10:47:14 | INFO | train_inner | epoch 035:   6203 / 11284 loss=3.481, nll_loss=1.771, ppl=3.41, wps=71249.7, ups=1.2, wpb=59538.3, bsz=2361, num_updates=389500, lr=0.000160231, gnorm=0.361, loss_scale=2, train_wall=79, gb_free=39.6, wall=327655
2023-06-15 10:48:37 | INFO | train_inner | epoch 035:   6303 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=71384.5, ups=1.2, wpb=59423.1, bsz=2319.5, num_updates=389600, lr=0.00016021, gnorm=0.362, loss_scale=2, train_wall=79, gb_free=39.6, wall=327738
2023-06-15 10:50:00 | INFO | train_inner | epoch 035:   6403 / 11284 loss=3.489, nll_loss=1.78, ppl=3.43, wps=71790, ups=1.21, wpb=59551.7, bsz=2251.7, num_updates=389700, lr=0.00016019, gnorm=0.352, loss_scale=2, train_wall=79, gb_free=39.6, wall=327821
2023-06-15 10:51:23 | INFO | train_inner | epoch 035:   6503 / 11284 loss=3.5, nll_loss=1.791, ppl=3.46, wps=71636, ups=1.2, wpb=59483, bsz=2255.8, num_updates=389800, lr=0.000160169, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.6, wall=327904
2023-06-15 10:52:45 | INFO | train_inner | epoch 035:   6603 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=72275.4, ups=1.22, wpb=59379.9, bsz=2206.4, num_updates=389900, lr=0.000160149, gnorm=0.357, loss_scale=2, train_wall=78, gb_free=39.6, wall=327986
2023-06-15 10:54:08 | INFO | train_inner | epoch 035:   6703 / 11284 loss=3.478, nll_loss=1.767, ppl=3.4, wps=71878, ups=1.21, wpb=59506.7, bsz=2191.1, num_updates=390000, lr=0.000160128, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.6, wall=328069
2023-06-15 10:54:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 10:55:34 | INFO | train_inner | epoch 035:   6804 / 11284 loss=3.492, nll_loss=1.783, ppl=3.44, wps=69960, ups=1.17, wpb=59693.7, bsz=2286.8, num_updates=390100, lr=0.000160108, gnorm=0.356, loss_scale=2, train_wall=81, gb_free=39.6, wall=328154
2023-06-15 10:56:58 | INFO | train_inner | epoch 035:   6904 / 11284 loss=3.475, nll_loss=1.764, ppl=3.4, wps=70057.2, ups=1.18, wpb=59376.4, bsz=2206.4, num_updates=390200, lr=0.000160087, gnorm=0.358, loss_scale=2, train_wall=81, gb_free=39.6, wall=328239
2023-06-15 10:58:23 | INFO | train_inner | epoch 035:   7004 / 11284 loss=3.493, nll_loss=1.784, ppl=3.44, wps=70064.9, ups=1.18, wpb=59412.5, bsz=2197.6, num_updates=390300, lr=0.000160067, gnorm=0.37, loss_scale=2, train_wall=81, gb_free=39.6, wall=328324
2023-06-15 10:59:47 | INFO | train_inner | epoch 035:   7104 / 11284 loss=3.456, nll_loss=1.742, ppl=3.35, wps=71055.8, ups=1.2, wpb=59401.5, bsz=2218.1, num_updates=390400, lr=0.000160046, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.6, wall=328407
2023-06-15 11:01:10 | INFO | train_inner | epoch 035:   7204 / 11284 loss=3.478, nll_loss=1.768, ppl=3.41, wps=71467.8, ups=1.2, wpb=59477.3, bsz=2203.3, num_updates=390500, lr=0.000160026, gnorm=0.361, loss_scale=2, train_wall=79, gb_free=39.6, wall=328491
2023-06-15 11:02:33 | INFO | train_inner | epoch 035:   7304 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=71676.1, ups=1.2, wpb=59525.2, bsz=2260.2, num_updates=390600, lr=0.000160005, gnorm=0.355, loss_scale=2, train_wall=79, gb_free=39.5, wall=328574
2023-06-15 11:03:55 | INFO | train_inner | epoch 035:   7404 / 11284 loss=3.493, nll_loss=1.785, ppl=3.45, wps=72592.8, ups=1.22, wpb=59415.2, bsz=2175.3, num_updates=390700, lr=0.000159985, gnorm=0.358, loss_scale=2, train_wall=78, gb_free=39.6, wall=328655
2023-06-15 11:05:17 | INFO | train_inner | epoch 035:   7504 / 11284 loss=3.472, nll_loss=1.761, ppl=3.39, wps=72771.6, ups=1.22, wpb=59611.1, bsz=2169.7, num_updates=390800, lr=0.000159964, gnorm=0.366, loss_scale=2, train_wall=78, gb_free=39.5, wall=328737
2023-06-15 11:06:40 | INFO | train_inner | epoch 035:   7604 / 11284 loss=3.476, nll_loss=1.765, ppl=3.4, wps=71702.1, ups=1.21, wpb=59425.3, bsz=2102.6, num_updates=390900, lr=0.000159944, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.6, wall=328820
2023-06-15 11:08:02 | INFO | train_inner | epoch 035:   7704 / 11284 loss=3.48, nll_loss=1.769, ppl=3.41, wps=72416.9, ups=1.22, wpb=59441.6, bsz=2284.2, num_updates=391000, lr=0.000159923, gnorm=0.354, loss_scale=2, train_wall=78, gb_free=39.6, wall=328902
2023-06-15 11:09:24 | INFO | train_inner | epoch 035:   7804 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=72618.7, ups=1.22, wpb=59526, bsz=2161.2, num_updates=391100, lr=0.000159903, gnorm=0.359, loss_scale=4, train_wall=78, gb_free=39.6, wall=328984
2023-06-15 11:09:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 11:10:47 | INFO | train_inner | epoch 035:   7905 / 11284 loss=3.478, nll_loss=1.767, ppl=3.4, wps=70902.2, ups=1.19, wpb=59384.6, bsz=2099.1, num_updates=391200, lr=0.000159882, gnorm=0.361, loss_scale=2, train_wall=80, gb_free=39, wall=329068
2023-06-15 11:12:11 | INFO | train_inner | epoch 035:   8005 / 11284 loss=3.475, nll_loss=1.764, ppl=3.4, wps=71463.5, ups=1.2, wpb=59603.8, bsz=2288.5, num_updates=391300, lr=0.000159862, gnorm=0.362, loss_scale=2, train_wall=79, gb_free=39.6, wall=329151
2023-06-15 11:13:34 | INFO | train_inner | epoch 035:   8105 / 11284 loss=3.499, nll_loss=1.791, ppl=3.46, wps=71678.1, ups=1.2, wpb=59582.2, bsz=2200.8, num_updates=391400, lr=0.000159842, gnorm=0.365, loss_scale=2, train_wall=79, gb_free=39.6, wall=329235
2023-06-15 11:14:57 | INFO | train_inner | epoch 035:   8205 / 11284 loss=3.502, nll_loss=1.794, ppl=3.47, wps=71672.3, ups=1.21, wpb=59368.7, bsz=2253.5, num_updates=391500, lr=0.000159821, gnorm=0.354, loss_scale=2, train_wall=79, gb_free=39.6, wall=329317
2023-06-15 11:16:21 | INFO | train_inner | epoch 035:   8305 / 11284 loss=3.501, nll_loss=1.793, ppl=3.47, wps=71170.5, ups=1.19, wpb=59598.7, bsz=2293.1, num_updates=391600, lr=0.000159801, gnorm=0.358, loss_scale=2, train_wall=80, gb_free=39.4, wall=329401
2023-06-15 11:17:46 | INFO | train_inner | epoch 035:   8405 / 11284 loss=3.479, nll_loss=1.769, ppl=3.41, wps=69652.9, ups=1.17, wpb=59544.1, bsz=2257.9, num_updates=391700, lr=0.00015978, gnorm=0.353, loss_scale=2, train_wall=82, gb_free=39.1, wall=329487
2023-06-15 11:19:09 | INFO | train_inner | epoch 035:   8505 / 11284 loss=3.489, nll_loss=1.779, ppl=3.43, wps=71909.6, ups=1.21, wpb=59659.6, bsz=2138.7, num_updates=391800, lr=0.00015976, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.6, wall=329570
2023-06-15 11:20:32 | INFO | train_inner | epoch 035:   8605 / 11284 loss=3.497, nll_loss=1.789, ppl=3.46, wps=71493.3, ups=1.2, wpb=59487.3, bsz=2243.1, num_updates=391900, lr=0.00015974, gnorm=0.349, loss_scale=2, train_wall=79, gb_free=39.5, wall=329653
2023-06-15 11:21:55 | INFO | train_inner | epoch 035:   8705 / 11284 loss=3.471, nll_loss=1.76, ppl=3.39, wps=71709, ups=1.2, wpb=59528.9, bsz=2201.8, num_updates=392000, lr=0.000159719, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.6, wall=329736
2023-06-15 11:23:18 | INFO | train_inner | epoch 035:   8805 / 11284 loss=3.486, nll_loss=1.776, ppl=3.42, wps=72319.7, ups=1.21, wpb=59673.5, bsz=2179.8, num_updates=392100, lr=0.000159699, gnorm=0.356, loss_scale=2, train_wall=78, gb_free=39.1, wall=329818
2023-06-15 11:24:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 11:24:42 | INFO | train_inner | epoch 035:   8906 / 11284 loss=3.491, nll_loss=1.781, ppl=3.44, wps=70525.7, ups=1.19, wpb=59296.2, bsz=2173.9, num_updates=392200, lr=0.000159678, gnorm=0.361, loss_scale=2, train_wall=80, gb_free=39.6, wall=329902
2023-06-15 11:26:05 | INFO | train_inner | epoch 035:   9006 / 11284 loss=3.493, nll_loss=1.784, ppl=3.44, wps=71410.1, ups=1.2, wpb=59494.2, bsz=2200.5, num_updates=392300, lr=0.000159658, gnorm=0.35, loss_scale=2, train_wall=79, gb_free=39.6, wall=329986
2023-06-15 11:27:28 | INFO | train_inner | epoch 035:   9106 / 11284 loss=3.477, nll_loss=1.767, ppl=3.4, wps=71310.2, ups=1.2, wpb=59372.3, bsz=2167.8, num_updates=392400, lr=0.000159638, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.6, wall=330069
2023-06-15 11:28:51 | INFO | train_inner | epoch 035:   9206 / 11284 loss=3.496, nll_loss=1.788, ppl=3.45, wps=71759.8, ups=1.21, wpb=59539.6, bsz=2196.8, num_updates=392500, lr=0.000159617, gnorm=0.354, loss_scale=2, train_wall=79, gb_free=39.6, wall=330152
2023-06-15 11:30:14 | INFO | train_inner | epoch 035:   9306 / 11284 loss=3.488, nll_loss=1.779, ppl=3.43, wps=72217, ups=1.21, wpb=59661.8, bsz=2219.8, num_updates=392600, lr=0.000159597, gnorm=0.346, loss_scale=2, train_wall=79, gb_free=39.6, wall=330235
2023-06-15 11:31:37 | INFO | train_inner | epoch 035:   9406 / 11284 loss=3.469, nll_loss=1.758, ppl=3.38, wps=71951.8, ups=1.21, wpb=59686.3, bsz=2144.9, num_updates=392700, lr=0.000159577, gnorm=0.359, loss_scale=2, train_wall=79, gb_free=39.5, wall=330318
2023-06-15 11:33:00 | INFO | train_inner | epoch 035:   9506 / 11284 loss=3.498, nll_loss=1.79, ppl=3.46, wps=71593.3, ups=1.2, wpb=59628.5, bsz=2292.4, num_updates=392800, lr=0.000159556, gnorm=0.376, loss_scale=2, train_wall=79, gb_free=39.5, wall=330401
2023-06-15 11:34:24 | INFO | train_inner | epoch 035:   9606 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=71353, ups=1.2, wpb=59501.7, bsz=2203.8, num_updates=392900, lr=0.000159536, gnorm=0.365, loss_scale=2, train_wall=79, gb_free=39.6, wall=330484
2023-06-15 11:35:47 | INFO | train_inner | epoch 035:   9706 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=71747.4, ups=1.2, wpb=59559.7, bsz=2203.8, num_updates=393000, lr=0.000159516, gnorm=0.37, loss_scale=2, train_wall=79, gb_free=39.6, wall=330567
2023-06-15 11:37:09 | INFO | train_inner | epoch 035:   9806 / 11284 loss=3.494, nll_loss=1.786, ppl=3.45, wps=72073.1, ups=1.21, wpb=59498.5, bsz=2259.4, num_updates=393100, lr=0.000159496, gnorm=0.364, loss_scale=2, train_wall=78, gb_free=39.5, wall=330650
2023-06-15 11:38:35 | INFO | train_inner | epoch 035:   9906 / 11284 loss=3.481, nll_loss=1.771, ppl=3.41, wps=69409.9, ups=1.17, wpb=59460.9, bsz=2280.7, num_updates=393200, lr=0.000159475, gnorm=0.359, loss_scale=4, train_wall=82, gb_free=39.6, wall=330735
2023-06-15 11:38:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 11:40:01 | INFO | train_inner | epoch 035:  10007 / 11284 loss=3.475, nll_loss=1.764, ppl=3.4, wps=69398.8, ups=1.17, wpb=59528.8, bsz=2192.1, num_updates=393300, lr=0.000159455, gnorm=0.369, loss_scale=2, train_wall=82, gb_free=39.6, wall=330821
2023-06-15 11:41:22 | INFO | train_inner | epoch 035:  10107 / 11284 loss=3.491, nll_loss=1.781, ppl=3.44, wps=73200.7, ups=1.23, wpb=59524.4, bsz=2186.4, num_updates=393400, lr=0.000159435, gnorm=0.355, loss_scale=2, train_wall=77, gb_free=39.6, wall=330903
2023-06-15 11:42:44 | INFO | train_inner | epoch 035:  10207 / 11284 loss=3.486, nll_loss=1.777, ppl=3.43, wps=72840.9, ups=1.22, wpb=59563.4, bsz=2323.4, num_updates=393500, lr=0.000159414, gnorm=0.359, loss_scale=2, train_wall=78, gb_free=39.6, wall=330984
2023-06-15 11:44:06 | INFO | train_inner | epoch 035:  10307 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=71831.7, ups=1.21, wpb=59433.8, bsz=2185.6, num_updates=393600, lr=0.000159394, gnorm=0.363, loss_scale=2, train_wall=79, gb_free=39.6, wall=331067
2023-06-15 11:45:29 | INFO | train_inner | epoch 035:  10407 / 11284 loss=3.481, nll_loss=1.771, ppl=3.41, wps=71861.1, ups=1.21, wpb=59554.5, bsz=2138.8, num_updates=393700, lr=0.000159374, gnorm=0.349, loss_scale=2, train_wall=79, gb_free=39.5, wall=331150
2023-06-15 11:46:53 | INFO | train_inner | epoch 035:  10507 / 11284 loss=3.482, nll_loss=1.772, ppl=3.41, wps=71395.8, ups=1.2, wpb=59432.8, bsz=2258.3, num_updates=393800, lr=0.000159354, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.6, wall=331233
2023-06-15 11:48:16 | INFO | train_inner | epoch 035:  10607 / 11284 loss=3.491, nll_loss=1.782, ppl=3.44, wps=71578.3, ups=1.2, wpb=59465.5, bsz=2213.3, num_updates=393900, lr=0.000159333, gnorm=0.372, loss_scale=2, train_wall=79, gb_free=39.6, wall=331316
2023-06-15 11:49:39 | INFO | train_inner | epoch 035:  10707 / 11284 loss=3.491, nll_loss=1.782, ppl=3.44, wps=71514.4, ups=1.2, wpb=59575.9, bsz=2239.3, num_updates=394000, lr=0.000159313, gnorm=0.36, loss_scale=2, train_wall=79, gb_free=39.5, wall=331400
2023-06-15 11:51:02 | INFO | train_inner | epoch 035:  10807 / 11284 loss=3.49, nll_loss=1.781, ppl=3.44, wps=71624.6, ups=1.2, wpb=59538.1, bsz=2237.7, num_updates=394100, lr=0.000159293, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.6, wall=331483
2023-06-15 11:52:25 | INFO | train_inner | epoch 035:  10907 / 11284 loss=3.498, nll_loss=1.79, ppl=3.46, wps=71722.5, ups=1.21, wpb=59403.7, bsz=2245.6, num_updates=394200, lr=0.000159273, gnorm=0.355, loss_scale=2, train_wall=79, gb_free=39.6, wall=331566
2023-06-15 11:53:48 | INFO | train_inner | epoch 035:  11007 / 11284 loss=3.493, nll_loss=1.784, ppl=3.44, wps=71461.7, ups=1.2, wpb=59341.9, bsz=2143, num_updates=394300, lr=0.000159253, gnorm=0.365, loss_scale=4, train_wall=79, gb_free=39.5, wall=331649
2023-06-15 11:53:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 11:55:12 | INFO | train_inner | epoch 035:  11108 / 11284 loss=3.49, nll_loss=1.78, ppl=3.44, wps=70757.7, ups=1.19, wpb=59306.5, bsz=2217.8, num_updates=394400, lr=0.000159232, gnorm=0.362, loss_scale=2, train_wall=80, gb_free=39.5, wall=331732
2023-06-15 11:56:35 | INFO | train_inner | epoch 035:  11208 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=71365.3, ups=1.2, wpb=59404.9, bsz=2179.8, num_updates=394500, lr=0.000159212, gnorm=0.352, loss_scale=2, train_wall=79, gb_free=39.6, wall=331816
2023-06-15 11:57:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-15 11:57:57 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 4.271 | nll_loss 2.591 | ppl 6.02 | bleu 21.52 | wps 3543 | wpb 2397.5 | bsz 71.5 | num_updates 394576 | best_loss 4.271
2023-06-15 11:57:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 394576 updates
2023-06-15 11:57:57 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint35.pt
2023-06-15 11:58:00 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint35.pt
2023-06-15 11:58:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint35.pt (epoch 35 @ 394576 updates, score 4.271) (writing took 7.49400644376874 seconds)
2023-06-15 11:58:05 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-06-15 11:58:05 | INFO | train | epoch 035 | loss 3.482 | nll_loss 1.772 | ppl 3.42 | wps 71172 | ups 1.2 | wpb 59499.5 | bsz 2227 | num_updates 394576 | lr 0.000159197 | gnorm 0.359 | loss_scale 2 | train_wall 8948 | gb_free 39.6 | wall 331906
2023-06-15 11:58:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-15 11:58:06 | INFO | fairseq.trainer | begin training epoch 36
2023-06-15 11:58:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-15 11:58:26 | INFO | train_inner | epoch 036:     24 / 11284 loss=3.479, nll_loss=1.769, ppl=3.41, wps=53263.3, ups=0.9, wpb=59046.5, bsz=2179.2, num_updates=394600, lr=0.000159192, gnorm=0.358, loss_scale=2, train_wall=79, gb_free=39.5, wall=331926
2023-06-15 11:59:49 | INFO | train_inner | epoch 036:    124 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=71935.9, ups=1.21, wpb=59560.4, bsz=2206, num_updates=394700, lr=0.000159172, gnorm=0.382, loss_scale=2, train_wall=79, gb_free=39.6, wall=332009
2023-06-15 12:01:11 | INFO | train_inner | epoch 036:    224 / 11284 loss=3.475, nll_loss=1.763, ppl=3.39, wps=72609.5, ups=1.22, wpb=59637.3, bsz=2273, num_updates=394800, lr=0.000159152, gnorm=0.354, loss_scale=2, train_wall=78, gb_free=39.6, wall=332091
2023-06-15 12:02:34 | INFO | train_inner | epoch 036:    324 / 11284 loss=3.472, nll_loss=1.761, ppl=3.39, wps=71683.8, ups=1.21, wpb=59471.1, bsz=2191.5, num_updates=394900, lr=0.000159132, gnorm=0.37, loss_scale=2, train_wall=79, gb_free=39.5, wall=332174
2023-06-15 12:03:56 | INFO | train_inner | epoch 036:    424 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=72147.8, ups=1.21, wpb=59419.8, bsz=2216.9, num_updates=395000, lr=0.000159111, gnorm=0.357, loss_scale=2, train_wall=78, gb_free=39.6, wall=332257
2023-06-15 12:05:20 | INFO | train_inner | epoch 036:    524 / 11284 loss=3.471, nll_loss=1.759, ppl=3.39, wps=71379.6, ups=1.2, wpb=59592, bsz=2216.6, num_updates=395100, lr=0.000159091, gnorm=0.36, loss_scale=2, train_wall=79, gb_free=39.5, wall=332340
2023-06-15 12:06:43 | INFO | train_inner | epoch 036:    624 / 11284 loss=3.477, nll_loss=1.766, ppl=3.4, wps=71402.6, ups=1.2, wpb=59684.6, bsz=2209.3, num_updates=395200, lr=0.000159071, gnorm=0.356, loss_scale=2, train_wall=80, gb_free=39.6, wall=332424
2023-06-15 12:08:06 | INFO | train_inner | epoch 036:    724 / 11284 loss=3.466, nll_loss=1.753, ppl=3.37, wps=72042.9, ups=1.21, wpb=59616.4, bsz=2249.5, num_updates=395300, lr=0.000159051, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.6, wall=332507
2023-06-15 12:09:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 12:09:28 | INFO | train_inner | epoch 036:    825 / 11284 loss=3.477, nll_loss=1.766, ppl=3.4, wps=72214, ups=1.21, wpb=59541.7, bsz=2193.4, num_updates=395400, lr=0.000159031, gnorm=0.366, loss_scale=2, train_wall=78, gb_free=39.5, wall=332589
2023-06-15 12:10:51 | INFO | train_inner | epoch 036:    925 / 11284 loss=3.476, nll_loss=1.764, ppl=3.4, wps=72614.7, ups=1.22, wpb=59682.8, bsz=2294.6, num_updates=395500, lr=0.000159011, gnorm=0.358, loss_scale=2, train_wall=78, gb_free=39.6, wall=332671
2023-06-15 12:12:14 | INFO | train_inner | epoch 036:   1025 / 11284 loss=3.472, nll_loss=1.76, ppl=3.39, wps=71487.5, ups=1.2, wpb=59461.8, bsz=2143.2, num_updates=395600, lr=0.000158991, gnorm=0.361, loss_scale=2, train_wall=79, gb_free=39.6, wall=332754
2023-06-15 12:13:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-06-15 12:13:37 | INFO | train_inner | epoch 036:   1126 / 11284 loss=3.473, nll_loss=1.762, ppl=3.39, wps=71646, ups=1.2, wpb=59584.1, bsz=2133.3, num_updates=395700, lr=0.000158971, gnorm=0.352, loss_scale=1, train_wall=80, gb_free=39.6, wall=332838
2023-06-15 12:14:59 | INFO | train_inner | epoch 036:   1226 / 11284 loss=3.472, nll_loss=1.761, ppl=3.39, wps=72399.2, ups=1.22, wpb=59524.4, bsz=2310.4, num_updates=395800, lr=0.000158951, gnorm=0.362, loss_scale=1, train_wall=78, gb_free=39.5, wall=332920
2023-06-15 12:16:22 | INFO | train_inner | epoch 036:   1326 / 11284 loss=3.474, nll_loss=1.763, ppl=3.39, wps=72015.9, ups=1.21, wpb=59512.7, bsz=2269.8, num_updates=395900, lr=0.00015893, gnorm=0.364, loss_scale=1, train_wall=79, gb_free=39.5, wall=333002
2023-06-15 12:17:45 | INFO | train_inner | epoch 036:   1426 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=71618.8, ups=1.21, wpb=59328, bsz=2172.4, num_updates=396000, lr=0.00015891, gnorm=0.368, loss_scale=1, train_wall=79, gb_free=39.6, wall=333085
2023-06-15 12:19:08 | INFO | train_inner | epoch 036:   1526 / 11284 loss=3.473, nll_loss=1.762, ppl=3.39, wps=70853.7, ups=1.2, wpb=59205.3, bsz=2243.4, num_updates=396100, lr=0.00015889, gnorm=0.36, loss_scale=1, train_wall=79, gb_free=39.6, wall=333169
2023-06-15 12:20:30 | INFO | train_inner | epoch 036:   1626 / 11284 loss=3.486, nll_loss=1.776, ppl=3.42, wps=72455.6, ups=1.22, wpb=59356, bsz=2295.8, num_updates=396200, lr=0.00015887, gnorm=0.355, loss_scale=1, train_wall=78, gb_free=39.5, wall=333251
2023-06-15 12:21:52 | INFO | train_inner | epoch 036:   1726 / 11284 loss=3.469, nll_loss=1.757, ppl=3.38, wps=72677.7, ups=1.22, wpb=59665.4, bsz=2238, num_updates=396300, lr=0.00015885, gnorm=0.35, loss_scale=1, train_wall=78, gb_free=39.6, wall=333333
2023-06-15 12:23:15 | INFO | train_inner | epoch 036:   1826 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=72300, ups=1.21, wpb=59653.2, bsz=2212.7, num_updates=396400, lr=0.00015883, gnorm=0.358, loss_scale=1, train_wall=79, gb_free=39.5, wall=333415
2023-06-15 12:24:38 | INFO | train_inner | epoch 036:   1926 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=71530.6, ups=1.2, wpb=59652, bsz=2272.7, num_updates=396500, lr=0.00015881, gnorm=0.366, loss_scale=1, train_wall=79, gb_free=39.6, wall=333499
2023-06-15 12:26:01 | INFO | train_inner | epoch 036:   2026 / 11284 loss=3.475, nll_loss=1.764, ppl=3.4, wps=71685.1, ups=1.2, wpb=59592.2, bsz=2301.8, num_updates=396600, lr=0.00015879, gnorm=0.364, loss_scale=1, train_wall=79, gb_free=39.6, wall=333582
2023-06-15 12:27:24 | INFO | train_inner | epoch 036:   2126 / 11284 loss=3.475, nll_loss=1.763, ppl=3.4, wps=71577.3, ups=1.2, wpb=59440.3, bsz=2173.7, num_updates=396700, lr=0.00015877, gnorm=0.357, loss_scale=1, train_wall=79, gb_free=39.6, wall=333665
2023-06-15 12:28:48 | INFO | train_inner | epoch 036:   2226 / 11284 loss=3.481, nll_loss=1.771, ppl=3.41, wps=71485.6, ups=1.2, wpb=59479.3, bsz=2303.5, num_updates=396800, lr=0.00015875, gnorm=0.365, loss_scale=2, train_wall=79, gb_free=39.5, wall=333748
2023-06-15 12:30:11 | INFO | train_inner | epoch 036:   2326 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=71501, ups=1.2, wpb=59445.3, bsz=2245.9, num_updates=396900, lr=0.00015873, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.6, wall=333831
2023-06-15 12:31:34 | INFO | train_inner | epoch 036:   2426 / 11284 loss=3.47, nll_loss=1.758, ppl=3.38, wps=71523.2, ups=1.2, wpb=59595.4, bsz=2212.5, num_updates=397000, lr=0.00015871, gnorm=0.362, loss_scale=2, train_wall=79, gb_free=39.6, wall=333915
2023-06-15 12:32:57 | INFO | train_inner | epoch 036:   2526 / 11284 loss=3.473, nll_loss=1.762, ppl=3.39, wps=71551.9, ups=1.2, wpb=59495.8, bsz=2272.2, num_updates=397100, lr=0.00015869, gnorm=0.359, loss_scale=2, train_wall=79, gb_free=39.6, wall=333998
2023-06-15 12:34:20 | INFO | train_inner | epoch 036:   2626 / 11284 loss=3.47, nll_loss=1.759, ppl=3.38, wps=71675.7, ups=1.21, wpb=59259.1, bsz=2246, num_updates=397200, lr=0.00015867, gnorm=0.358, loss_scale=2, train_wall=79, gb_free=39.4, wall=334080
2023-06-15 12:35:43 | INFO | train_inner | epoch 036:   2726 / 11284 loss=3.472, nll_loss=1.76, ppl=3.39, wps=71311.7, ups=1.2, wpb=59400.2, bsz=2200.7, num_updates=397300, lr=0.00015865, gnorm=0.361, loss_scale=2, train_wall=79, gb_free=39.6, wall=334164
2023-06-15 12:37:06 | INFO | train_inner | epoch 036:   2826 / 11284 loss=3.483, nll_loss=1.772, ppl=3.42, wps=71853.8, ups=1.21, wpb=59479.7, bsz=2171, num_updates=397400, lr=0.00015863, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.6, wall=334247
2023-06-15 12:38:29 | INFO | train_inner | epoch 036:   2926 / 11284 loss=3.492, nll_loss=1.783, ppl=3.44, wps=71459.1, ups=1.2, wpb=59445.3, bsz=2195.6, num_updates=397500, lr=0.00015861, gnorm=0.354, loss_scale=2, train_wall=79, gb_free=39.6, wall=334330
2023-06-15 12:39:52 | INFO | train_inner | epoch 036:   3026 / 11284 loss=3.478, nll_loss=1.768, ppl=3.41, wps=72141.5, ups=1.21, wpb=59530.6, bsz=2250, num_updates=397600, lr=0.00015859, gnorm=0.363, loss_scale=2, train_wall=78, gb_free=39.5, wall=334412
2023-06-15 12:41:14 | INFO | train_inner | epoch 036:   3126 / 11284 loss=3.486, nll_loss=1.776, ppl=3.43, wps=72603.4, ups=1.22, wpb=59484.8, bsz=2277.9, num_updates=397700, lr=0.00015857, gnorm=0.362, loss_scale=2, train_wall=78, gb_free=39.5, wall=334494
2023-06-15 12:42:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 12:42:38 | INFO | train_inner | epoch 036:   3227 / 11284 loss=3.471, nll_loss=1.76, ppl=3.39, wps=70810.8, ups=1.19, wpb=59622.1, bsz=2203.2, num_updates=397800, lr=0.00015855, gnorm=0.36, loss_scale=2, train_wall=80, gb_free=39.5, wall=334578
2023-06-15 12:44:00 | INFO | train_inner | epoch 036:   3327 / 11284 loss=3.467, nll_loss=1.755, ppl=3.38, wps=72205.9, ups=1.21, wpb=59439.1, bsz=2198.8, num_updates=397900, lr=0.000158531, gnorm=0.357, loss_scale=2, train_wall=78, gb_free=39.6, wall=334661
2023-06-15 12:45:23 | INFO | train_inner | epoch 036:   3427 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=71420.8, ups=1.2, wpb=59430.1, bsz=2275.4, num_updates=398000, lr=0.000158511, gnorm=0.36, loss_scale=2, train_wall=79, gb_free=39.6, wall=334744
2023-06-15 12:46:47 | INFO | train_inner | epoch 036:   3527 / 11284 loss=3.478, nll_loss=1.767, ppl=3.4, wps=71791.5, ups=1.2, wpb=59779.4, bsz=2213.8, num_updates=398100, lr=0.000158491, gnorm=0.363, loss_scale=2, train_wall=79, gb_free=39.6, wall=334827
2023-06-15 12:48:09 | INFO | train_inner | epoch 036:   3627 / 11284 loss=3.479, nll_loss=1.768, ppl=3.41, wps=71611.4, ups=1.21, wpb=59320.1, bsz=2209.2, num_updates=398200, lr=0.000158471, gnorm=0.375, loss_scale=2, train_wall=79, gb_free=39.5, wall=334910
2023-06-15 12:49:33 | INFO | train_inner | epoch 036:   3727 / 11284 loss=3.486, nll_loss=1.776, ppl=3.42, wps=71497.7, ups=1.2, wpb=59560.9, bsz=2242.3, num_updates=398300, lr=0.000158451, gnorm=0.36, loss_scale=2, train_wall=79, gb_free=39.6, wall=334993
2023-06-15 12:50:56 | INFO | train_inner | epoch 036:   3827 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=71369.4, ups=1.2, wpb=59580.9, bsz=2291.5, num_updates=398400, lr=0.000158431, gnorm=0.35, loss_scale=2, train_wall=80, gb_free=39.6, wall=335077
2023-06-15 12:52:19 | INFO | train_inner | epoch 036:   3927 / 11284 loss=3.479, nll_loss=1.768, ppl=3.41, wps=71726.3, ups=1.2, wpb=59524.4, bsz=2247.3, num_updates=398500, lr=0.000158411, gnorm=0.367, loss_scale=2, train_wall=79, gb_free=39.5, wall=335160
2023-06-15 12:53:41 | INFO | train_inner | epoch 036:   4027 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=72347.1, ups=1.21, wpb=59546.1, bsz=2287.9, num_updates=398600, lr=0.000158391, gnorm=0.368, loss_scale=2, train_wall=78, gb_free=39.5, wall=335242
2023-06-15 12:55:04 | INFO | train_inner | epoch 036:   4127 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=72109.3, ups=1.22, wpb=59327.3, bsz=2314.5, num_updates=398700, lr=0.000158371, gnorm=0.376, loss_scale=2, train_wall=78, gb_free=39.6, wall=335324
2023-06-15 12:56:27 | INFO | train_inner | epoch 036:   4227 / 11284 loss=3.48, nll_loss=1.77, ppl=3.41, wps=71260.1, ups=1.2, wpb=59225, bsz=2325.2, num_updates=398800, lr=0.000158352, gnorm=0.361, loss_scale=4, train_wall=79, gb_free=39.6, wall=335407
2023-06-15 12:56:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 12:57:50 | INFO | train_inner | epoch 036:   4328 / 11284 loss=3.489, nll_loss=1.779, ppl=3.43, wps=71287.2, ups=1.2, wpb=59383.8, bsz=2255.2, num_updates=398900, lr=0.000158332, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.3, wall=335491
2023-06-15 12:59:13 | INFO | train_inner | epoch 036:   4428 / 11284 loss=3.474, nll_loss=1.762, ppl=3.39, wps=72172.7, ups=1.21, wpb=59596.3, bsz=2194, num_updates=399000, lr=0.000158312, gnorm=0.354, loss_scale=2, train_wall=79, gb_free=39.6, wall=335573
2023-06-15 13:00:35 | INFO | train_inner | epoch 036:   4528 / 11284 loss=3.486, nll_loss=1.776, ppl=3.43, wps=72052.5, ups=1.21, wpb=59520.5, bsz=2243.9, num_updates=399100, lr=0.000158292, gnorm=0.37, loss_scale=2, train_wall=78, gb_free=39.4, wall=335656
2023-06-15 13:01:59 | INFO | train_inner | epoch 036:   4628 / 11284 loss=3.471, nll_loss=1.759, ppl=3.39, wps=71404.3, ups=1.2, wpb=59525.1, bsz=2202.5, num_updates=399200, lr=0.000158272, gnorm=0.364, loss_scale=2, train_wall=79, gb_free=39.5, wall=335739
2023-06-15 13:03:22 | INFO | train_inner | epoch 036:   4728 / 11284 loss=3.471, nll_loss=1.76, ppl=3.39, wps=71729.8, ups=1.21, wpb=59452.2, bsz=2153.1, num_updates=399300, lr=0.000158252, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.6, wall=335822
2023-06-15 13:04:45 | INFO | train_inner | epoch 036:   4828 / 11284 loss=3.47, nll_loss=1.759, ppl=3.38, wps=71560.4, ups=1.2, wpb=59512.3, bsz=2230.4, num_updates=399400, lr=0.000158233, gnorm=0.354, loss_scale=2, train_wall=79, gb_free=39.6, wall=335905
2023-06-15 13:06:08 | INFO | train_inner | epoch 036:   4928 / 11284 loss=3.48, nll_loss=1.769, ppl=3.41, wps=71726.8, ups=1.2, wpb=59581.2, bsz=2239.7, num_updates=399500, lr=0.000158213, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.6, wall=335988
2023-06-15 13:07:31 | INFO | train_inner | epoch 036:   5028 / 11284 loss=3.482, nll_loss=1.772, ppl=3.41, wps=71589.9, ups=1.2, wpb=59553, bsz=2211.2, num_updates=399600, lr=0.000158193, gnorm=0.374, loss_scale=2, train_wall=79, gb_free=39.6, wall=336072
2023-06-15 13:08:54 | INFO | train_inner | epoch 036:   5128 / 11284 loss=3.479, nll_loss=1.768, ppl=3.41, wps=71978.1, ups=1.21, wpb=59419.8, bsz=2095.8, num_updates=399700, lr=0.000158173, gnorm=0.355, loss_scale=2, train_wall=79, gb_free=39.5, wall=336154
2023-06-15 13:10:16 | INFO | train_inner | epoch 036:   5228 / 11284 loss=3.482, nll_loss=1.772, ppl=3.41, wps=71739.7, ups=1.21, wpb=59430.3, bsz=2237.2, num_updates=399800, lr=0.000158153, gnorm=0.364, loss_scale=2, train_wall=79, gb_free=39.4, wall=336237
2023-06-15 13:11:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 13:11:39 | INFO | train_inner | epoch 036:   5329 / 11284 loss=3.486, nll_loss=1.776, ppl=3.42, wps=72370.9, ups=1.21, wpb=59630.3, bsz=2228.4, num_updates=399900, lr=0.000158134, gnorm=0.363, loss_scale=2, train_wall=78, gb_free=39.6, wall=336319
2023-06-15 13:13:01 | INFO | train_inner | epoch 036:   5429 / 11284 loss=3.479, nll_loss=1.768, ppl=3.41, wps=72870, ups=1.22, wpb=59666.4, bsz=2148, num_updates=400000, lr=0.000158114, gnorm=0.351, loss_scale=2, train_wall=78, gb_free=39.5, wall=336401
2023-06-15 13:14:24 | INFO | train_inner | epoch 036:   5529 / 11284 loss=3.475, nll_loss=1.764, ppl=3.4, wps=71388.1, ups=1.2, wpb=59472.7, bsz=2227, num_updates=400100, lr=0.000158094, gnorm=0.367, loss_scale=2, train_wall=79, gb_free=39.6, wall=336485
2023-06-15 13:15:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-06-15 13:15:48 | INFO | train_inner | epoch 036:   5630 / 11284 loss=3.481, nll_loss=1.771, ppl=3.41, wps=71152.1, ups=1.19, wpb=59735.9, bsz=2193.9, num_updates=400200, lr=0.000158074, gnorm=0.353, loss_scale=1, train_wall=80, gb_free=39.5, wall=336569
2023-06-15 13:17:11 | INFO | train_inner | epoch 036:   5730 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=71854.8, ups=1.2, wpb=59671.3, bsz=2230.9, num_updates=400300, lr=0.000158055, gnorm=0.369, loss_scale=1, train_wall=79, gb_free=39.5, wall=336652
2023-06-15 13:18:34 | INFO | train_inner | epoch 036:   5830 / 11284 loss=3.489, nll_loss=1.779, ppl=3.43, wps=72154.3, ups=1.21, wpb=59574.5, bsz=2174.4, num_updates=400400, lr=0.000158035, gnorm=0.362, loss_scale=1, train_wall=79, gb_free=39.6, wall=336734
2023-06-15 13:19:56 | INFO | train_inner | epoch 036:   5930 / 11284 loss=3.481, nll_loss=1.771, ppl=3.41, wps=72477, ups=1.22, wpb=59433.2, bsz=2195.6, num_updates=400500, lr=0.000158015, gnorm=0.357, loss_scale=1, train_wall=78, gb_free=38.7, wall=336816
2023-06-15 13:21:17 | INFO | train_inner | epoch 036:   6030 / 11284 loss=3.476, nll_loss=1.765, ppl=3.4, wps=72882.6, ups=1.23, wpb=59446.5, bsz=2191.2, num_updates=400600, lr=0.000157995, gnorm=0.358, loss_scale=1, train_wall=77, gb_free=39.6, wall=336898
2023-06-15 13:22:40 | INFO | train_inner | epoch 036:   6130 / 11284 loss=3.473, nll_loss=1.762, ppl=3.39, wps=72144.1, ups=1.21, wpb=59434.2, bsz=2153.5, num_updates=400700, lr=0.000157976, gnorm=0.355, loss_scale=1, train_wall=78, gb_free=39.6, wall=336980
2023-06-15 13:24:02 | INFO | train_inner | epoch 036:   6230 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=72073.3, ups=1.21, wpb=59483.7, bsz=2260.3, num_updates=400800, lr=0.000157956, gnorm=0.374, loss_scale=1, train_wall=79, gb_free=39.6, wall=337063
2023-06-15 13:25:24 | INFO | train_inner | epoch 036:   6330 / 11284 loss=3.479, nll_loss=1.769, ppl=3.41, wps=72504.7, ups=1.22, wpb=59376.7, bsz=2175.3, num_updates=400900, lr=0.000157936, gnorm=0.355, loss_scale=1, train_wall=78, gb_free=39.6, wall=337145
2023-06-15 13:26:46 | INFO | train_inner | epoch 036:   6430 / 11284 loss=3.478, nll_loss=1.767, ppl=3.4, wps=72213.4, ups=1.22, wpb=59392.5, bsz=2183.8, num_updates=401000, lr=0.000157917, gnorm=0.371, loss_scale=1, train_wall=78, gb_free=38.2, wall=337227
2023-06-15 13:28:08 | INFO | train_inner | epoch 036:   6530 / 11284 loss=3.49, nll_loss=1.781, ppl=3.44, wps=72669.7, ups=1.22, wpb=59401.4, bsz=2218.4, num_updates=401100, lr=0.000157897, gnorm=0.366, loss_scale=1, train_wall=78, gb_free=39.5, wall=337309
2023-06-15 13:29:30 | INFO | train_inner | epoch 036:   6630 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=72293.7, ups=1.22, wpb=59410.7, bsz=2311.7, num_updates=401200, lr=0.000157877, gnorm=0.361, loss_scale=2, train_wall=78, gb_free=39.6, wall=337391
2023-06-15 13:30:52 | INFO | train_inner | epoch 036:   6730 / 11284 loss=3.472, nll_loss=1.761, ppl=3.39, wps=72907.9, ups=1.23, wpb=59453.7, bsz=2168.2, num_updates=401300, lr=0.000157858, gnorm=0.364, loss_scale=2, train_wall=77, gb_free=39.6, wall=337472
2023-06-15 13:32:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-06-15 13:32:15 | INFO | train_inner | epoch 036:   6831 / 11284 loss=3.489, nll_loss=1.78, ppl=3.43, wps=71195.5, ups=1.2, wpb=59459.7, bsz=2196.8, num_updates=401400, lr=0.000157838, gnorm=0.366, loss_scale=1, train_wall=79, gb_free=39.5, wall=337556
2023-06-15 13:33:38 | INFO | train_inner | epoch 036:   6931 / 11284 loss=3.476, nll_loss=1.765, ppl=3.4, wps=71857.7, ups=1.21, wpb=59553.4, bsz=2195.8, num_updates=401500, lr=0.000157818, gnorm=0.367, loss_scale=1, train_wall=79, gb_free=39.5, wall=337639
2023-06-15 13:35:01 | INFO | train_inner | epoch 036:   7031 / 11284 loss=3.481, nll_loss=1.771, ppl=3.41, wps=71697.6, ups=1.2, wpb=59546.1, bsz=2255.1, num_updates=401600, lr=0.000157799, gnorm=0.364, loss_scale=1, train_wall=79, gb_free=39.6, wall=337722
2023-06-15 13:36:24 | INFO | train_inner | epoch 036:   7131 / 11284 loss=3.496, nll_loss=1.788, ppl=3.45, wps=71457.1, ups=1.2, wpb=59443.2, bsz=2267.7, num_updates=401700, lr=0.000157779, gnorm=0.359, loss_scale=1, train_wall=79, gb_free=39.6, wall=337805
2023-06-15 13:37:48 | INFO | train_inner | epoch 036:   7231 / 11284 loss=3.475, nll_loss=1.764, ppl=3.4, wps=70778.7, ups=1.19, wpb=59543.9, bsz=2283.9, num_updates=401800, lr=0.000157759, gnorm=0.349, loss_scale=1, train_wall=80, gb_free=39.5, wall=337889
2023-06-15 13:39:13 | INFO | train_inner | epoch 036:   7331 / 11284 loss=3.49, nll_loss=1.78, ppl=3.44, wps=70444.6, ups=1.19, wpb=59383.3, bsz=2185.2, num_updates=401900, lr=0.00015774, gnorm=0.362, loss_scale=1, train_wall=80, gb_free=39.6, wall=337973
2023-06-15 13:40:37 | INFO | train_inner | epoch 036:   7431 / 11284 loss=3.478, nll_loss=1.768, ppl=3.4, wps=70994.4, ups=1.19, wpb=59536.4, bsz=2194.6, num_updates=402000, lr=0.00015772, gnorm=0.352, loss_scale=1, train_wall=80, gb_free=39.5, wall=338057
2023-06-15 13:42:00 | INFO | train_inner | epoch 036:   7531 / 11284 loss=3.471, nll_loss=1.76, ppl=3.39, wps=71345.4, ups=1.2, wpb=59654.5, bsz=2247.7, num_updates=402100, lr=0.0001577, gnorm=0.352, loss_scale=1, train_wall=80, gb_free=39.6, wall=338141
2023-06-15 13:43:23 | INFO | train_inner | epoch 036:   7631 / 11284 loss=3.476, nll_loss=1.766, ppl=3.4, wps=72107.1, ups=1.21, wpb=59596.7, bsz=2266, num_updates=402200, lr=0.000157681, gnorm=0.354, loss_scale=1, train_wall=79, gb_free=39.6, wall=338223
2023-06-15 13:44:45 | INFO | train_inner | epoch 036:   7731 / 11284 loss=3.486, nll_loss=1.776, ppl=3.43, wps=72554.4, ups=1.22, wpb=59479.4, bsz=2193.3, num_updates=402300, lr=0.000157661, gnorm=0.364, loss_scale=1, train_wall=78, gb_free=39.6, wall=338305
2023-06-15 13:46:08 | INFO | train_inner | epoch 036:   7831 / 11284 loss=3.501, nll_loss=1.793, ppl=3.46, wps=71676, ups=1.21, wpb=59473.8, bsz=2255.5, num_updates=402400, lr=0.000157642, gnorm=0.363, loss_scale=1, train_wall=79, gb_free=39.6, wall=338388
2023-06-15 13:47:31 | INFO | train_inner | epoch 036:   7931 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=71020.1, ups=1.2, wpb=59371.6, bsz=2181.8, num_updates=402500, lr=0.000157622, gnorm=0.358, loss_scale=2, train_wall=80, gb_free=39.5, wall=338472
2023-06-15 13:48:54 | INFO | train_inner | epoch 036:   8031 / 11284 loss=3.473, nll_loss=1.762, ppl=3.39, wps=71753.3, ups=1.21, wpb=59402.4, bsz=2176.8, num_updates=402600, lr=0.000157603, gnorm=0.351, loss_scale=2, train_wall=79, gb_free=39.6, wall=338555
2023-06-15 13:50:19 | INFO | train_inner | epoch 036:   8131 / 11284 loss=3.493, nll_loss=1.784, ppl=3.44, wps=70842.9, ups=1.19, wpb=59727.2, bsz=2277, num_updates=402700, lr=0.000157583, gnorm=0.358, loss_scale=2, train_wall=80, gb_free=39.5, wall=338639
2023-06-15 13:51:44 | INFO | train_inner | epoch 036:   8231 / 11284 loss=3.481, nll_loss=1.771, ppl=3.41, wps=69127.2, ups=1.16, wpb=59387.5, bsz=2195.8, num_updates=402800, lr=0.000157563, gnorm=0.372, loss_scale=2, train_wall=82, gb_free=39.5, wall=338725
2023-06-15 13:53:06 | INFO | train_inner | epoch 036:   8331 / 11284 loss=3.49, nll_loss=1.781, ppl=3.44, wps=72829.7, ups=1.22, wpb=59696.4, bsz=2170.8, num_updates=402900, lr=0.000157544, gnorm=0.373, loss_scale=2, train_wall=78, gb_free=39.6, wall=338807
2023-06-15 13:54:28 | INFO | train_inner | epoch 036:   8431 / 11284 loss=3.497, nll_loss=1.788, ppl=3.45, wps=73082.1, ups=1.23, wpb=59594.2, bsz=2240.8, num_updates=403000, lr=0.000157524, gnorm=0.356, loss_scale=2, train_wall=78, gb_free=39.6, wall=338889
2023-06-15 13:55:50 | INFO | train_inner | epoch 036:   8531 / 11284 loss=3.493, nll_loss=1.785, ppl=3.45, wps=72163.1, ups=1.22, wpb=59311.5, bsz=2176.9, num_updates=403100, lr=0.000157505, gnorm=0.366, loss_scale=2, train_wall=78, gb_free=39.6, wall=338971
2023-06-15 13:57:13 | INFO | train_inner | epoch 036:   8631 / 11284 loss=3.488, nll_loss=1.779, ppl=3.43, wps=71937, ups=1.21, wpb=59250.8, bsz=2173.7, num_updates=403200, lr=0.000157485, gnorm=0.365, loss_scale=2, train_wall=79, gb_free=39.6, wall=339053
2023-06-15 13:58:35 | INFO | train_inner | epoch 036:   8731 / 11284 loss=3.476, nll_loss=1.766, ppl=3.4, wps=72009.3, ups=1.21, wpb=59537, bsz=2186.8, num_updates=403300, lr=0.000157466, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.6, wall=339136
2023-06-15 13:59:58 | INFO | train_inner | epoch 036:   8831 / 11284 loss=3.481, nll_loss=1.771, ppl=3.41, wps=71598.1, ups=1.2, wpb=59574.9, bsz=2238.6, num_updates=403400, lr=0.000157446, gnorm=0.361, loss_scale=2, train_wall=79, gb_free=39.6, wall=339219
2023-06-15 14:00:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 14:01:23 | INFO | train_inner | epoch 036:   8932 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=70804.6, ups=1.18, wpb=59764.3, bsz=2264.8, num_updates=403500, lr=0.000157427, gnorm=0.357, loss_scale=2, train_wall=80, gb_free=39.5, wall=339303
2023-06-15 14:02:45 | INFO | train_inner | epoch 036:   9032 / 11284 loss=3.498, nll_loss=1.79, ppl=3.46, wps=72101.6, ups=1.21, wpb=59377, bsz=2299, num_updates=403600, lr=0.000157407, gnorm=0.366, loss_scale=2, train_wall=78, gb_free=39.6, wall=339386
2023-06-15 14:04:07 | INFO | train_inner | epoch 036:   9132 / 11284 loss=3.49, nll_loss=1.78, ppl=3.44, wps=72664.5, ups=1.22, wpb=59585.7, bsz=2313.3, num_updates=403700, lr=0.000157388, gnorm=0.351, loss_scale=2, train_wall=78, gb_free=39.6, wall=339468
2023-06-15 14:05:33 | INFO | train_inner | epoch 036:   9232 / 11284 loss=3.479, nll_loss=1.769, ppl=3.41, wps=69749.8, ups=1.17, wpb=59565.9, bsz=2283.4, num_updates=403800, lr=0.000157368, gnorm=0.355, loss_scale=2, train_wall=81, gb_free=39.6, wall=339553
2023-06-15 14:06:59 | INFO | train_inner | epoch 036:   9332 / 11284 loss=3.481, nll_loss=1.771, ppl=3.41, wps=69206.9, ups=1.16, wpb=59484.9, bsz=2231, num_updates=403900, lr=0.000157349, gnorm=0.365, loss_scale=2, train_wall=82, gb_free=39.6, wall=339639
2023-06-15 14:08:21 | INFO | train_inner | epoch 036:   9432 / 11284 loss=3.469, nll_loss=1.757, ppl=3.38, wps=72761.5, ups=1.22, wpb=59729.3, bsz=2294.1, num_updates=404000, lr=0.000157329, gnorm=0.366, loss_scale=2, train_wall=78, gb_free=39.6, wall=339721
2023-06-15 14:09:44 | INFO | train_inner | epoch 036:   9532 / 11284 loss=3.477, nll_loss=1.767, ppl=3.4, wps=71177, ups=1.19, wpb=59665.1, bsz=2298.3, num_updates=404100, lr=0.00015731, gnorm=0.36, loss_scale=2, train_wall=80, gb_free=39.5, wall=339805
2023-06-15 14:11:09 | INFO | train_inner | epoch 036:   9632 / 11284 loss=3.505, nll_loss=1.797, ppl=3.48, wps=70136.3, ups=1.18, wpb=59323.2, bsz=2209.4, num_updates=404200, lr=0.00015729, gnorm=0.373, loss_scale=2, train_wall=81, gb_free=39.6, wall=339890
2023-06-15 14:12:34 | INFO | train_inner | epoch 036:   9732 / 11284 loss=3.48, nll_loss=1.77, ppl=3.41, wps=69905.7, ups=1.18, wpb=59399.8, bsz=2252.3, num_updates=404300, lr=0.000157271, gnorm=0.362, loss_scale=2, train_wall=81, gb_free=39.5, wall=339975
2023-06-15 14:13:58 | INFO | train_inner | epoch 036:   9832 / 11284 loss=3.482, nll_loss=1.772, ppl=3.42, wps=70510.9, ups=1.18, wpb=59518.6, bsz=2316.1, num_updates=404400, lr=0.000157251, gnorm=0.361, loss_scale=2, train_wall=80, gb_free=39.6, wall=340059
2023-06-15 14:15:23 | INFO | train_inner | epoch 036:   9932 / 11284 loss=3.487, nll_loss=1.778, ppl=3.43, wps=70510.1, ups=1.19, wpb=59309.3, bsz=2219.8, num_updates=404500, lr=0.000157232, gnorm=0.361, loss_scale=4, train_wall=80, gb_free=39.6, wall=340143
2023-06-15 14:15:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 14:16:47 | INFO | train_inner | epoch 036:  10033 / 11284 loss=3.483, nll_loss=1.774, ppl=3.42, wps=70856.2, ups=1.19, wpb=59741.7, bsz=2223.8, num_updates=404600, lr=0.000157212, gnorm=0.364, loss_scale=2, train_wall=80, gb_free=39.6, wall=340227
2023-06-15 14:18:10 | INFO | train_inner | epoch 036:  10133 / 11284 loss=3.477, nll_loss=1.766, ppl=3.4, wps=71310.7, ups=1.2, wpb=59257, bsz=2121.2, num_updates=404700, lr=0.000157193, gnorm=0.359, loss_scale=2, train_wall=79, gb_free=39.5, wall=340311
2023-06-15 14:19:33 | INFO | train_inner | epoch 036:  10233 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=71063.7, ups=1.2, wpb=59347.2, bsz=2265.9, num_updates=404800, lr=0.000157174, gnorm=0.361, loss_scale=2, train_wall=79, gb_free=39.6, wall=340394
2023-06-15 14:20:57 | INFO | train_inner | epoch 036:  10333 / 11284 loss=3.485, nll_loss=1.776, ppl=3.42, wps=71037, ups=1.19, wpb=59637.4, bsz=2215.7, num_updates=404900, lr=0.000157154, gnorm=0.361, loss_scale=2, train_wall=80, gb_free=39.6, wall=340478
2023-06-15 14:22:22 | INFO | train_inner | epoch 036:  10433 / 11284 loss=3.489, nll_loss=1.78, ppl=3.43, wps=70471.3, ups=1.19, wpb=59395.4, bsz=2282.2, num_updates=405000, lr=0.000157135, gnorm=0.365, loss_scale=2, train_wall=80, gb_free=39.6, wall=340562
2023-06-15 14:23:44 | INFO | train_inner | epoch 036:  10533 / 11284 loss=3.475, nll_loss=1.764, ppl=3.4, wps=71854.5, ups=1.21, wpb=59478.3, bsz=2235.8, num_updates=405100, lr=0.000157115, gnorm=0.354, loss_scale=2, train_wall=79, gb_free=39.6, wall=340645
2023-06-15 14:25:07 | INFO | train_inner | epoch 036:  10633 / 11284 loss=3.486, nll_loss=1.776, ppl=3.43, wps=71853.1, ups=1.21, wpb=59456.7, bsz=2234.2, num_updates=405200, lr=0.000157096, gnorm=0.361, loss_scale=2, train_wall=78, gb_free=39.6, wall=340728
2023-06-15 14:26:30 | INFO | train_inner | epoch 036:  10733 / 11284 loss=3.47, nll_loss=1.759, ppl=3.38, wps=71405.2, ups=1.2, wpb=59425.9, bsz=2228.7, num_updates=405300, lr=0.000157077, gnorm=0.362, loss_scale=2, train_wall=79, gb_free=39.6, wall=340811
2023-06-15 14:27:54 | INFO | train_inner | epoch 036:  10833 / 11284 loss=3.479, nll_loss=1.769, ppl=3.41, wps=71551, ups=1.2, wpb=59423.9, bsz=2255, num_updates=405400, lr=0.000157057, gnorm=0.355, loss_scale=2, train_wall=79, gb_free=39.5, wall=340894
2023-06-15 14:29:16 | INFO | train_inner | epoch 036:  10933 / 11284 loss=3.48, nll_loss=1.77, ppl=3.41, wps=72010.1, ups=1.21, wpb=59671.5, bsz=2178.9, num_updates=405500, lr=0.000157038, gnorm=0.363, loss_scale=2, train_wall=79, gb_free=39.6, wall=340977
2023-06-15 14:30:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 14:30:40 | INFO | train_inner | epoch 036:  11034 / 11284 loss=3.471, nll_loss=1.76, ppl=3.39, wps=71058.5, ups=1.19, wpb=59492, bsz=2144.4, num_updates=405600, lr=0.000157019, gnorm=0.352, loss_scale=2, train_wall=80, gb_free=39.6, wall=341061
2023-06-15 14:32:04 | INFO | train_inner | epoch 036:  11134 / 11284 loss=3.485, nll_loss=1.776, ppl=3.42, wps=71104, ups=1.19, wpb=59574.9, bsz=2252.5, num_updates=405700, lr=0.000156999, gnorm=0.357, loss_scale=2, train_wall=80, gb_free=39.6, wall=341144
2023-06-15 14:33:27 | INFO | train_inner | epoch 036:  11234 / 11284 loss=3.471, nll_loss=1.76, ppl=3.39, wps=71478.5, ups=1.2, wpb=59477.7, bsz=2188.9, num_updates=405800, lr=0.00015698, gnorm=0.362, loss_scale=2, train_wall=79, gb_free=39.6, wall=341228
2023-06-15 14:34:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-15 14:34:27 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 4.285 | nll_loss 2.605 | ppl 6.09 | bleu 21.29 | wps 3760.1 | wpb 2397.5 | bsz 71.5 | num_updates 405850 | best_loss 4.271
2023-06-15 14:34:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 405850 updates
2023-06-15 14:34:27 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint36.pt
2023-06-15 14:34:31 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint36.pt
2023-06-15 14:34:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint36.pt (epoch 36 @ 405850 updates, score 4.285) (writing took 10.57164802774787 seconds)
2023-06-15 14:34:37 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-06-15 14:34:37 | INFO | train | epoch 036 | loss 3.481 | nll_loss 1.771 | ppl 3.41 | wps 71420.9 | ups 1.2 | wpb 59499.9 | bsz 2227.4 | num_updates 405850 | lr 0.00015697 | gnorm 0.361 | loss_scale 2 | train_wall 8912 | gb_free 39.5 | wall 341298
2023-06-15 14:34:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-15 14:34:38 | INFO | fairseq.trainer | begin training epoch 37
2023-06-15 14:34:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-15 14:35:20 | INFO | train_inner | epoch 037:     50 / 11284 loss=3.467, nll_loss=1.756, ppl=3.38, wps=52482.1, ups=0.88, wpb=59302.6, bsz=2180.4, num_updates=405900, lr=0.000156961, gnorm=0.354, loss_scale=2, train_wall=79, gb_free=39.6, wall=341341
2023-06-15 14:36:43 | INFO | train_inner | epoch 037:    150 / 11284 loss=3.477, nll_loss=1.766, ppl=3.4, wps=72036.6, ups=1.21, wpb=59368.6, bsz=2243.3, num_updates=406000, lr=0.000156941, gnorm=0.368, loss_scale=2, train_wall=78, gb_free=39.6, wall=341423
2023-06-15 14:38:05 | INFO | train_inner | epoch 037:    250 / 11284 loss=3.468, nll_loss=1.755, ppl=3.38, wps=71832.6, ups=1.21, wpb=59551.8, bsz=2286.9, num_updates=406100, lr=0.000156922, gnorm=0.359, loss_scale=2, train_wall=79, gb_free=39.5, wall=341506
2023-06-15 14:39:29 | INFO | train_inner | epoch 037:    350 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=71215.8, ups=1.2, wpb=59516.8, bsz=2307.3, num_updates=406200, lr=0.000156903, gnorm=0.352, loss_scale=2, train_wall=79, gb_free=39.6, wall=341590
2023-06-15 14:40:52 | INFO | train_inner | epoch 037:    450 / 11284 loss=3.468, nll_loss=1.756, ppl=3.38, wps=71883.2, ups=1.21, wpb=59446.4, bsz=2165.1, num_updates=406300, lr=0.000156883, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.6, wall=341672
2023-06-15 14:42:15 | INFO | train_inner | epoch 037:    550 / 11284 loss=3.474, nll_loss=1.762, ppl=3.39, wps=71635.3, ups=1.2, wpb=59497.5, bsz=2234.9, num_updates=406400, lr=0.000156864, gnorm=0.369, loss_scale=2, train_wall=79, gb_free=39.6, wall=341755
2023-06-15 14:43:37 | INFO | train_inner | epoch 037:    650 / 11284 loss=3.461, nll_loss=1.748, ppl=3.36, wps=72544.1, ups=1.22, wpb=59487.9, bsz=2200.3, num_updates=406500, lr=0.000156845, gnorm=0.36, loss_scale=2, train_wall=78, gb_free=39.5, wall=341837
2023-06-15 14:45:00 | INFO | train_inner | epoch 037:    750 / 11284 loss=3.469, nll_loss=1.757, ppl=3.38, wps=71882.9, ups=1.2, wpb=59783.9, bsz=2205.9, num_updates=406600, lr=0.000156825, gnorm=0.352, loss_scale=4, train_wall=79, gb_free=39.5, wall=341921
2023-06-15 14:46:23 | INFO | train_inner | epoch 037:    850 / 11284 loss=3.492, nll_loss=1.783, ppl=3.44, wps=71389.1, ups=1.2, wpb=59643.7, bsz=2255.5, num_updates=406700, lr=0.000156806, gnorm=0.351, loss_scale=4, train_wall=79, gb_free=39.6, wall=342004
2023-06-15 14:47:47 | INFO | train_inner | epoch 037:    950 / 11284 loss=3.474, nll_loss=1.763, ppl=3.39, wps=71203.3, ups=1.2, wpb=59300.2, bsz=2134.1, num_updates=406800, lr=0.000156787, gnorm=0.353, loss_scale=4, train_wall=79, gb_free=39.6, wall=342087
2023-06-15 14:47:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 14:49:11 | INFO | train_inner | epoch 037:   1051 / 11284 loss=3.48, nll_loss=1.769, ppl=3.41, wps=70917.3, ups=1.19, wpb=59439.4, bsz=2166.7, num_updates=406900, lr=0.000156768, gnorm=0.38, loss_scale=2, train_wall=80, gb_free=39.6, wall=342171
2023-06-15 14:50:34 | INFO | train_inner | epoch 037:   1151 / 11284 loss=3.478, nll_loss=1.767, ppl=3.4, wps=71424.5, ups=1.2, wpb=59727.6, bsz=2223.9, num_updates=407000, lr=0.000156748, gnorm=0.362, loss_scale=2, train_wall=80, gb_free=39.6, wall=342255
2023-06-15 14:51:57 | INFO | train_inner | epoch 037:   1251 / 11284 loss=3.475, nll_loss=1.764, ppl=3.4, wps=71345.1, ups=1.2, wpb=59225.4, bsz=2231.6, num_updates=407100, lr=0.000156729, gnorm=0.359, loss_scale=2, train_wall=79, gb_free=39.6, wall=342338
2023-06-15 14:53:20 | INFO | train_inner | epoch 037:   1351 / 11284 loss=3.478, nll_loss=1.767, ppl=3.4, wps=71933.5, ups=1.21, wpb=59624.4, bsz=2272.4, num_updates=407200, lr=0.00015671, gnorm=0.38, loss_scale=2, train_wall=79, gb_free=39.6, wall=342421
2023-06-15 14:54:43 | INFO | train_inner | epoch 037:   1451 / 11284 loss=3.472, nll_loss=1.761, ppl=3.39, wps=71785.9, ups=1.21, wpb=59450.4, bsz=2238.9, num_updates=407300, lr=0.000156691, gnorm=0.368, loss_scale=2, train_wall=79, gb_free=39.6, wall=342503
2023-06-15 14:55:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-06-15 14:56:06 | INFO | train_inner | epoch 037:   1552 / 11284 loss=3.481, nll_loss=1.771, ppl=3.41, wps=71489.1, ups=1.2, wpb=59641.8, bsz=2287.3, num_updates=407400, lr=0.000156671, gnorm=0.37, loss_scale=1, train_wall=79, gb_free=39.6, wall=342587
2023-06-15 14:57:30 | INFO | train_inner | epoch 037:   1652 / 11284 loss=3.478, nll_loss=1.767, ppl=3.4, wps=71082.4, ups=1.2, wpb=59172.4, bsz=2222, num_updates=407500, lr=0.000156652, gnorm=0.358, loss_scale=1, train_wall=79, gb_free=39.5, wall=342670
2023-06-15 14:58:53 | INFO | train_inner | epoch 037:   1752 / 11284 loss=3.478, nll_loss=1.768, ppl=3.41, wps=71077.1, ups=1.2, wpb=59245.9, bsz=2185, num_updates=407600, lr=0.000156633, gnorm=0.368, loss_scale=1, train_wall=79, gb_free=39.6, wall=342754
2023-06-15 15:00:16 | INFO | train_inner | epoch 037:   1852 / 11284 loss=3.474, nll_loss=1.763, ppl=3.39, wps=71558.3, ups=1.2, wpb=59633.2, bsz=2290.3, num_updates=407700, lr=0.000156614, gnorm=0.354, loss_scale=1, train_wall=79, gb_free=39.6, wall=342837
2023-06-15 15:01:40 | INFO | train_inner | epoch 037:   1952 / 11284 loss=3.489, nll_loss=1.779, ppl=3.43, wps=71074.7, ups=1.19, wpb=59547.8, bsz=2327.3, num_updates=407800, lr=0.000156594, gnorm=0.376, loss_scale=1, train_wall=79, gb_free=39.5, wall=342921
2023-06-15 15:03:03 | INFO | train_inner | epoch 037:   2052 / 11284 loss=3.472, nll_loss=1.76, ppl=3.39, wps=71920.6, ups=1.21, wpb=59457.5, bsz=2166.3, num_updates=407900, lr=0.000156575, gnorm=0.357, loss_scale=1, train_wall=79, gb_free=39.6, wall=343003
2023-06-15 15:04:24 | INFO | train_inner | epoch 037:   2152 / 11284 loss=3.49, nll_loss=1.781, ppl=3.44, wps=73071.7, ups=1.23, wpb=59532, bsz=2138.8, num_updates=408000, lr=0.000156556, gnorm=0.367, loss_scale=1, train_wall=78, gb_free=39.6, wall=343085
2023-06-15 15:05:47 | INFO | train_inner | epoch 037:   2252 / 11284 loss=3.469, nll_loss=1.757, ppl=3.38, wps=71688.6, ups=1.21, wpb=59337.2, bsz=2198, num_updates=408100, lr=0.000156537, gnorm=0.371, loss_scale=1, train_wall=79, gb_free=39.6, wall=343168
2023-06-15 15:07:10 | INFO | train_inner | epoch 037:   2352 / 11284 loss=3.489, nll_loss=1.779, ppl=3.43, wps=71624.3, ups=1.2, wpb=59550.6, bsz=2232.5, num_updates=408200, lr=0.000156518, gnorm=0.365, loss_scale=1, train_wall=79, gb_free=39.5, wall=343251
2023-06-15 15:08:33 | INFO | train_inner | epoch 037:   2452 / 11284 loss=3.476, nll_loss=1.765, ppl=3.4, wps=71573.7, ups=1.2, wpb=59457.1, bsz=2172.9, num_updates=408300, lr=0.000156499, gnorm=0.36, loss_scale=1, train_wall=79, gb_free=39.6, wall=343334
2023-06-15 15:09:57 | INFO | train_inner | epoch 037:   2552 / 11284 loss=3.494, nll_loss=1.785, ppl=3.45, wps=71471, ups=1.2, wpb=59534.7, bsz=2235.6, num_updates=408400, lr=0.000156479, gnorm=0.36, loss_scale=1, train_wall=79, gb_free=39.6, wall=343417
2023-06-15 15:11:20 | INFO | train_inner | epoch 037:   2652 / 11284 loss=3.465, nll_loss=1.753, ppl=3.37, wps=71490.7, ups=1.2, wpb=59483.6, bsz=2352.1, num_updates=408500, lr=0.00015646, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.6, wall=343500
2023-06-15 15:12:43 | INFO | train_inner | epoch 037:   2752 / 11284 loss=3.47, nll_loss=1.758, ppl=3.38, wps=71531.1, ups=1.2, wpb=59529.1, bsz=2236.1, num_updates=408600, lr=0.000156441, gnorm=0.365, loss_scale=2, train_wall=79, gb_free=38.6, wall=343584
2023-06-15 15:14:07 | INFO | train_inner | epoch 037:   2852 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=71250, ups=1.2, wpb=59581.2, bsz=2285.7, num_updates=408700, lr=0.000156422, gnorm=0.356, loss_scale=2, train_wall=80, gb_free=39.6, wall=343667
2023-06-15 15:15:30 | INFO | train_inner | epoch 037:   2952 / 11284 loss=3.478, nll_loss=1.767, ppl=3.4, wps=71166.7, ups=1.19, wpb=59611.9, bsz=2312.4, num_updates=408800, lr=0.000156403, gnorm=0.364, loss_scale=2, train_wall=79, gb_free=39.5, wall=343751
2023-06-15 15:16:53 | INFO | train_inner | epoch 037:   3052 / 11284 loss=3.473, nll_loss=1.762, ppl=3.39, wps=71853.9, ups=1.21, wpb=59528.9, bsz=2146.5, num_updates=408900, lr=0.000156384, gnorm=0.362, loss_scale=2, train_wall=79, gb_free=39.5, wall=343834
2023-06-15 15:18:16 | INFO | train_inner | epoch 037:   3152 / 11284 loss=3.485, nll_loss=1.776, ppl=3.42, wps=71383.4, ups=1.2, wpb=59308.9, bsz=2212.1, num_updates=409000, lr=0.000156365, gnorm=0.359, loss_scale=2, train_wall=79, gb_free=39.4, wall=343917
2023-06-15 15:19:40 | INFO | train_inner | epoch 037:   3252 / 11284 loss=3.476, nll_loss=1.765, ppl=3.4, wps=71442.6, ups=1.2, wpb=59477.8, bsz=2196, num_updates=409100, lr=0.000156345, gnorm=0.372, loss_scale=2, train_wall=79, gb_free=39.5, wall=344000
2023-06-15 15:21:03 | INFO | train_inner | epoch 037:   3352 / 11284 loss=3.483, nll_loss=1.772, ppl=3.42, wps=71507.6, ups=1.2, wpb=59698.4, bsz=2206.3, num_updates=409200, lr=0.000156326, gnorm=0.355, loss_scale=2, train_wall=80, gb_free=39.6, wall=344084
2023-06-15 15:22:28 | INFO | train_inner | epoch 037:   3452 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=70429.2, ups=1.18, wpb=59716.6, bsz=2312.8, num_updates=409300, lr=0.000156307, gnorm=0.353, loss_scale=2, train_wall=81, gb_free=39.6, wall=344168
2023-06-15 15:23:51 | INFO | train_inner | epoch 037:   3552 / 11284 loss=3.476, nll_loss=1.765, ppl=3.4, wps=71093, ups=1.2, wpb=59490.7, bsz=2228.6, num_updates=409400, lr=0.000156288, gnorm=0.358, loss_scale=2, train_wall=80, gb_free=39.6, wall=344252
2023-06-15 15:24:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 15:25:16 | INFO | train_inner | epoch 037:   3653 / 11284 loss=3.47, nll_loss=1.758, ppl=3.38, wps=70849.2, ups=1.19, wpb=59587.1, bsz=2293.1, num_updates=409500, lr=0.000156269, gnorm=0.363, loss_scale=2, train_wall=80, gb_free=39.6, wall=344336
2023-06-15 15:26:39 | INFO | train_inner | epoch 037:   3753 / 11284 loss=3.47, nll_loss=1.758, ppl=3.38, wps=71546.4, ups=1.2, wpb=59618.8, bsz=2174.1, num_updates=409600, lr=0.00015625, gnorm=0.361, loss_scale=2, train_wall=79, gb_free=39.7, wall=344419
2023-06-15 15:28:02 | INFO | train_inner | epoch 037:   3853 / 11284 loss=3.48, nll_loss=1.769, ppl=3.41, wps=70981.1, ups=1.2, wpb=59152.7, bsz=2073.6, num_updates=409700, lr=0.000156231, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.6, wall=344503
2023-06-15 15:29:29 | INFO | train_inner | epoch 037:   3953 / 11284 loss=3.477, nll_loss=1.767, ppl=3.4, wps=68829.6, ups=1.16, wpb=59437.5, bsz=2213.2, num_updates=409800, lr=0.000156212, gnorm=0.353, loss_scale=2, train_wall=82, gb_free=39.5, wall=344589
2023-06-15 15:30:54 | INFO | train_inner | epoch 037:   4053 / 11284 loss=3.489, nll_loss=1.78, ppl=3.43, wps=69477, ups=1.17, wpb=59510.4, bsz=2223.7, num_updates=409900, lr=0.000156193, gnorm=0.373, loss_scale=2, train_wall=82, gb_free=39.6, wall=344675
2023-06-15 15:32:17 | INFO | train_inner | epoch 037:   4153 / 11284 loss=3.47, nll_loss=1.758, ppl=3.38, wps=71905.3, ups=1.21, wpb=59525.3, bsz=2118.3, num_updates=410000, lr=0.000156174, gnorm=0.361, loss_scale=2, train_wall=79, gb_free=39.5, wall=344758
2023-06-15 15:33:40 | INFO | train_inner | epoch 037:   4253 / 11284 loss=3.477, nll_loss=1.766, ppl=3.4, wps=71745.5, ups=1.21, wpb=59269.2, bsz=2056.7, num_updates=410100, lr=0.000156155, gnorm=0.358, loss_scale=2, train_wall=79, gb_free=39.6, wall=344840
2023-06-15 15:35:02 | INFO | train_inner | epoch 037:   4353 / 11284 loss=3.47, nll_loss=1.759, ppl=3.38, wps=71568.5, ups=1.21, wpb=59278, bsz=2265.5, num_updates=410200, lr=0.000156136, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.6, wall=344923
2023-06-15 15:36:26 | INFO | train_inner | epoch 037:   4453 / 11284 loss=3.476, nll_loss=1.766, ppl=3.4, wps=71793.6, ups=1.2, wpb=59671.8, bsz=2272.3, num_updates=410300, lr=0.000156117, gnorm=0.369, loss_scale=2, train_wall=79, gb_free=39.6, wall=345006
2023-06-15 15:37:48 | INFO | train_inner | epoch 037:   4553 / 11284 loss=3.492, nll_loss=1.783, ppl=3.44, wps=71824.1, ups=1.21, wpb=59464.3, bsz=2209.4, num_updates=410400, lr=0.000156098, gnorm=0.377, loss_scale=2, train_wall=79, gb_free=39.6, wall=345089
2023-06-15 15:38:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 15:39:12 | INFO | train_inner | epoch 037:   4654 / 11284 loss=3.471, nll_loss=1.76, ppl=3.39, wps=71009.4, ups=1.19, wpb=59604.6, bsz=2175.2, num_updates=410500, lr=0.000156079, gnorm=0.366, loss_scale=2, train_wall=80, gb_free=39.6, wall=345173
2023-06-15 15:40:36 | INFO | train_inner | epoch 037:   4754 / 11284 loss=3.487, nll_loss=1.778, ppl=3.43, wps=71419.3, ups=1.2, wpb=59551.4, bsz=2231.3, num_updates=410600, lr=0.00015606, gnorm=0.365, loss_scale=2, train_wall=79, gb_free=39.4, wall=345256
2023-06-15 15:41:59 | INFO | train_inner | epoch 037:   4854 / 11284 loss=3.471, nll_loss=1.76, ppl=3.39, wps=71532, ups=1.2, wpb=59579.2, bsz=2279.2, num_updates=410700, lr=0.000156041, gnorm=0.361, loss_scale=2, train_wall=79, gb_free=39.6, wall=345340
2023-06-15 15:43:24 | INFO | train_inner | epoch 037:   4954 / 11284 loss=3.473, nll_loss=1.762, ppl=3.39, wps=70091.3, ups=1.18, wpb=59429.6, bsz=2244.6, num_updates=410800, lr=0.000156022, gnorm=0.36, loss_scale=2, train_wall=81, gb_free=39.6, wall=345424
2023-06-15 15:44:49 | INFO | train_inner | epoch 037:   5054 / 11284 loss=3.482, nll_loss=1.772, ppl=3.41, wps=69998.1, ups=1.18, wpb=59304.4, bsz=2240.6, num_updates=410900, lr=0.000156003, gnorm=0.375, loss_scale=2, train_wall=81, gb_free=39.5, wall=345509
2023-06-15 15:46:12 | INFO | train_inner | epoch 037:   5154 / 11284 loss=3.479, nll_loss=1.768, ppl=3.41, wps=70854.6, ups=1.19, wpb=59493.4, bsz=2239.7, num_updates=411000, lr=0.000155984, gnorm=0.365, loss_scale=2, train_wall=80, gb_free=39.6, wall=345593
2023-06-15 15:47:35 | INFO | train_inner | epoch 037:   5254 / 11284 loss=3.48, nll_loss=1.77, ppl=3.41, wps=72090.4, ups=1.21, wpb=59677.6, bsz=2297.8, num_updates=411100, lr=0.000155965, gnorm=0.349, loss_scale=2, train_wall=78, gb_free=39.6, wall=345676
2023-06-15 15:48:57 | INFO | train_inner | epoch 037:   5354 / 11284 loss=3.482, nll_loss=1.772, ppl=3.41, wps=72729.2, ups=1.22, wpb=59640.9, bsz=2300, num_updates=411200, lr=0.000155946, gnorm=0.364, loss_scale=2, train_wall=78, gb_free=39.6, wall=345758
2023-06-15 15:50:19 | INFO | train_inner | epoch 037:   5454 / 11284 loss=3.461, nll_loss=1.748, ppl=3.36, wps=72970.7, ups=1.23, wpb=59442.2, bsz=2132.9, num_updates=411300, lr=0.000155927, gnorm=0.365, loss_scale=2, train_wall=77, gb_free=39.6, wall=345839
2023-06-15 15:51:42 | INFO | train_inner | epoch 037:   5554 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=71350.6, ups=1.2, wpb=59363.2, bsz=2167, num_updates=411400, lr=0.000155908, gnorm=0.367, loss_scale=2, train_wall=79, gb_free=39.5, wall=345923
2023-06-15 15:53:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 15:53:06 | INFO | train_inner | epoch 037:   5655 / 11284 loss=3.486, nll_loss=1.777, ppl=3.43, wps=71035.7, ups=1.2, wpb=59422.9, bsz=2180.2, num_updates=411500, lr=0.000155889, gnorm=0.357, loss_scale=2, train_wall=80, gb_free=39.5, wall=346006
2023-06-15 15:54:29 | INFO | train_inner | epoch 037:   5755 / 11284 loss=3.473, nll_loss=1.762, ppl=3.39, wps=71403, ups=1.2, wpb=59508.4, bsz=2248.6, num_updates=411600, lr=0.00015587, gnorm=0.367, loss_scale=2, train_wall=79, gb_free=39.6, wall=346090
2023-06-15 15:55:53 | INFO | train_inner | epoch 037:   5855 / 11284 loss=3.494, nll_loss=1.786, ppl=3.45, wps=71211.7, ups=1.2, wpb=59546.8, bsz=2247.2, num_updates=411700, lr=0.000155851, gnorm=0.359, loss_scale=2, train_wall=80, gb_free=39.5, wall=346173
2023-06-15 15:57:18 | INFO | train_inner | epoch 037:   5955 / 11284 loss=3.496, nll_loss=1.788, ppl=3.45, wps=69882.2, ups=1.17, wpb=59497.4, bsz=2310, num_updates=411800, lr=0.000155832, gnorm=0.359, loss_scale=2, train_wall=81, gb_free=39.6, wall=346258
2023-06-15 15:58:44 | INFO | train_inner | epoch 037:   6055 / 11284 loss=3.478, nll_loss=1.767, ppl=3.4, wps=68649.6, ups=1.16, wpb=59378.2, bsz=2153.5, num_updates=411900, lr=0.000155813, gnorm=0.359, loss_scale=2, train_wall=83, gb_free=39.6, wall=346345
2023-06-15 16:00:08 | INFO | train_inner | epoch 037:   6155 / 11284 loss=3.477, nll_loss=1.767, ppl=3.4, wps=70920.7, ups=1.19, wpb=59391, bsz=2256.9, num_updates=412000, lr=0.000155794, gnorm=0.352, loss_scale=2, train_wall=80, gb_free=39.6, wall=346429
2023-06-15 16:01:30 | INFO | train_inner | epoch 037:   6255 / 11284 loss=3.486, nll_loss=1.776, ppl=3.43, wps=72429.1, ups=1.22, wpb=59594.7, bsz=2213.3, num_updates=412100, lr=0.000155775, gnorm=0.354, loss_scale=2, train_wall=78, gb_free=39.6, wall=346511
2023-06-15 16:02:53 | INFO | train_inner | epoch 037:   6355 / 11284 loss=3.479, nll_loss=1.769, ppl=3.41, wps=71854.2, ups=1.2, wpb=59729.6, bsz=2317.8, num_updates=412200, lr=0.000155756, gnorm=0.347, loss_scale=2, train_wall=79, gb_free=39.6, wall=346594
2023-06-15 16:04:17 | INFO | train_inner | epoch 037:   6455 / 11284 loss=3.479, nll_loss=1.769, ppl=3.41, wps=71293.5, ups=1.2, wpb=59474.6, bsz=2247, num_updates=412300, lr=0.000155738, gnorm=0.382, loss_scale=2, train_wall=79, gb_free=39.6, wall=346677
2023-06-15 16:05:40 | INFO | train_inner | epoch 037:   6555 / 11284 loss=3.475, nll_loss=1.764, ppl=3.4, wps=71881.9, ups=1.21, wpb=59648.8, bsz=2194.7, num_updates=412400, lr=0.000155719, gnorm=0.367, loss_scale=2, train_wall=79, gb_free=39.6, wall=346760
2023-06-15 16:07:02 | INFO | train_inner | epoch 037:   6655 / 11284 loss=3.47, nll_loss=1.758, ppl=3.38, wps=72242.6, ups=1.21, wpb=59556, bsz=2200.5, num_updates=412500, lr=0.0001557, gnorm=0.357, loss_scale=2, train_wall=78, gb_free=39.5, wall=346843
2023-06-15 16:08:25 | INFO | train_inner | epoch 037:   6755 / 11284 loss=3.482, nll_loss=1.772, ppl=3.42, wps=71760.5, ups=1.21, wpb=59426.3, bsz=2140.8, num_updates=412600, lr=0.000155681, gnorm=0.368, loss_scale=4, train_wall=79, gb_free=39.6, wall=346926
2023-06-15 16:08:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 16:09:48 | INFO | train_inner | epoch 037:   6856 / 11284 loss=3.488, nll_loss=1.779, ppl=3.43, wps=71386.2, ups=1.2, wpb=59396.4, bsz=2297.5, num_updates=412700, lr=0.000155662, gnorm=0.358, loss_scale=2, train_wall=79, gb_free=39.6, wall=347009
2023-06-15 16:11:10 | INFO | train_inner | epoch 037:   6956 / 11284 loss=3.479, nll_loss=1.769, ppl=3.41, wps=72659.1, ups=1.22, wpb=59578.3, bsz=2215.6, num_updates=412800, lr=0.000155643, gnorm=0.354, loss_scale=2, train_wall=78, gb_free=39.2, wall=347091
2023-06-15 16:12:34 | INFO | train_inner | epoch 037:   7056 / 11284 loss=3.479, nll_loss=1.769, ppl=3.41, wps=71623.1, ups=1.2, wpb=59698.2, bsz=2218.2, num_updates=412900, lr=0.000155624, gnorm=0.361, loss_scale=2, train_wall=79, gb_free=39.6, wall=347174
2023-06-15 16:13:57 | INFO | train_inner | epoch 037:   7156 / 11284 loss=3.489, nll_loss=1.779, ppl=3.43, wps=71566.6, ups=1.2, wpb=59393, bsz=2152.4, num_updates=413000, lr=0.000155606, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.6, wall=347257
2023-06-15 16:15:20 | INFO | train_inner | epoch 037:   7256 / 11284 loss=3.479, nll_loss=1.768, ppl=3.41, wps=71417.5, ups=1.2, wpb=59331.1, bsz=2242.9, num_updates=413100, lr=0.000155587, gnorm=0.362, loss_scale=2, train_wall=79, gb_free=39.6, wall=347340
2023-06-15 16:16:43 | INFO | train_inner | epoch 037:   7356 / 11284 loss=3.475, nll_loss=1.764, ppl=3.4, wps=71337.5, ups=1.2, wpb=59531, bsz=2310.6, num_updates=413200, lr=0.000155568, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.6, wall=347424
2023-06-15 16:18:06 | INFO | train_inner | epoch 037:   7456 / 11284 loss=3.489, nll_loss=1.78, ppl=3.43, wps=71879.1, ups=1.21, wpb=59404.2, bsz=2225.5, num_updates=413300, lr=0.000155549, gnorm=0.362, loss_scale=2, train_wall=79, gb_free=39.6, wall=347506
2023-06-15 16:19:28 | INFO | train_inner | epoch 037:   7556 / 11284 loss=3.477, nll_loss=1.766, ppl=3.4, wps=72500.6, ups=1.22, wpb=59579.2, bsz=2306.5, num_updates=413400, lr=0.00015553, gnorm=0.366, loss_scale=2, train_wall=78, gb_free=39.6, wall=347588
2023-06-15 16:20:50 | INFO | train_inner | epoch 037:   7656 / 11284 loss=3.476, nll_loss=1.766, ppl=3.4, wps=72275.2, ups=1.21, wpb=59663.4, bsz=2307, num_updates=413500, lr=0.000155511, gnorm=0.373, loss_scale=2, train_wall=78, gb_free=39.6, wall=347671
2023-06-15 16:22:12 | INFO | train_inner | epoch 037:   7756 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=72446.9, ups=1.22, wpb=59432, bsz=2231.8, num_updates=413600, lr=0.000155493, gnorm=0.365, loss_scale=2, train_wall=78, gb_free=39.6, wall=347753
2023-06-15 16:23:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 16:23:35 | INFO | train_inner | epoch 037:   7857 / 11284 loss=3.465, nll_loss=1.753, ppl=3.37, wps=71975.4, ups=1.21, wpb=59619.2, bsz=2257.8, num_updates=413700, lr=0.000155474, gnorm=0.354, loss_scale=2, train_wall=79, gb_free=39.5, wall=347836
2023-06-15 16:24:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-06-15 16:24:58 | INFO | train_inner | epoch 037:   7958 / 11284 loss=3.48, nll_loss=1.769, ppl=3.41, wps=71963.3, ups=1.21, wpb=59537.7, bsz=2235, num_updates=413800, lr=0.000155455, gnorm=0.353, loss_scale=1, train_wall=79, gb_free=39.6, wall=347919
2023-06-15 16:26:20 | INFO | train_inner | epoch 037:   8058 / 11284 loss=3.49, nll_loss=1.781, ppl=3.44, wps=72190.5, ups=1.21, wpb=59448.2, bsz=2215, num_updates=413900, lr=0.000155436, gnorm=0.381, loss_scale=1, train_wall=78, gb_free=39.6, wall=348001
2023-06-15 16:27:44 | INFO | train_inner | epoch 037:   8158 / 11284 loss=3.476, nll_loss=1.765, ppl=3.4, wps=71504.1, ups=1.2, wpb=59483.3, bsz=2177.5, num_updates=414000, lr=0.000155417, gnorm=0.37, loss_scale=1, train_wall=79, gb_free=39.5, wall=348084
2023-06-15 16:29:07 | INFO | train_inner | epoch 037:   8258 / 11284 loss=3.48, nll_loss=1.77, ppl=3.41, wps=71968, ups=1.21, wpb=59671.4, bsz=2178.8, num_updates=414100, lr=0.000155399, gnorm=0.376, loss_scale=1, train_wall=79, gb_free=39.5, wall=348167
2023-06-15 16:30:29 | INFO | train_inner | epoch 037:   8358 / 11284 loss=3.485, nll_loss=1.776, ppl=3.42, wps=72299.4, ups=1.22, wpb=59392.8, bsz=2277.1, num_updates=414200, lr=0.00015538, gnorm=0.355, loss_scale=1, train_wall=78, gb_free=39.6, wall=348249
2023-06-15 16:31:51 | INFO | train_inner | epoch 037:   8458 / 11284 loss=3.476, nll_loss=1.766, ppl=3.4, wps=71775.2, ups=1.21, wpb=59222.5, bsz=2188.1, num_updates=414300, lr=0.000155361, gnorm=0.383, loss_scale=1, train_wall=78, gb_free=39.5, wall=348332
2023-06-15 16:33:14 | INFO | train_inner | epoch 037:   8558 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=71618.1, ups=1.2, wpb=59563, bsz=2207.1, num_updates=414400, lr=0.000155342, gnorm=0.36, loss_scale=1, train_wall=79, gb_free=39.6, wall=348415
2023-06-15 16:34:37 | INFO | train_inner | epoch 037:   8658 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=71890, ups=1.2, wpb=59661.8, bsz=2182.7, num_updates=414500, lr=0.000155324, gnorm=0.346, loss_scale=1, train_wall=79, gb_free=39.4, wall=348498
2023-06-15 16:34:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-06-15 16:36:01 | INFO | train_inner | epoch 037:   8759 / 11284 loss=3.492, nll_loss=1.783, ppl=3.44, wps=71293.2, ups=1.2, wpb=59593.6, bsz=2231.1, num_updates=414600, lr=0.000155305, gnorm=0.362, loss_scale=0.5, train_wall=80, gb_free=38.7, wall=348582
2023-06-15 16:37:25 | INFO | train_inner | epoch 037:   8859 / 11284 loss=3.493, nll_loss=1.784, ppl=3.44, wps=71435.7, ups=1.2, wpb=59702.3, bsz=2288.3, num_updates=414700, lr=0.000155286, gnorm=0.359, loss_scale=0.5, train_wall=79, gb_free=39.6, wall=348665
2023-06-15 16:38:47 | INFO | train_inner | epoch 037:   8959 / 11284 loss=3.488, nll_loss=1.779, ppl=3.43, wps=71902.6, ups=1.21, wpb=59319.6, bsz=2236.8, num_updates=414800, lr=0.000155268, gnorm=0.364, loss_scale=0.5, train_wall=78, gb_free=39.6, wall=348748
2023-06-15 16:40:10 | INFO | train_inner | epoch 037:   9059 / 11284 loss=3.487, nll_loss=1.778, ppl=3.43, wps=72104.9, ups=1.21, wpb=59653, bsz=2227.2, num_updates=414900, lr=0.000155249, gnorm=0.352, loss_scale=0.5, train_wall=79, gb_free=39.6, wall=348830
2023-06-15 16:41:32 | INFO | train_inner | epoch 037:   9159 / 11284 loss=3.482, nll_loss=1.772, ppl=3.41, wps=72005, ups=1.21, wpb=59399.6, bsz=2266.8, num_updates=415000, lr=0.00015523, gnorm=0.36, loss_scale=0.5, train_wall=79, gb_free=39.5, wall=348913
2023-06-15 16:42:54 | INFO | train_inner | epoch 037:   9259 / 11284 loss=3.488, nll_loss=1.779, ppl=3.43, wps=72603.1, ups=1.22, wpb=59503.4, bsz=2318.5, num_updates=415100, lr=0.000155211, gnorm=0.367, loss_scale=0.5, train_wall=78, gb_free=39, wall=348995
2023-06-15 16:44:16 | INFO | train_inner | epoch 037:   9359 / 11284 loss=3.468, nll_loss=1.756, ppl=3.38, wps=72790, ups=1.22, wpb=59526.7, bsz=2222.5, num_updates=415200, lr=0.000155193, gnorm=0.36, loss_scale=0.5, train_wall=78, gb_free=39.6, wall=349077
2023-06-15 16:45:38 | INFO | train_inner | epoch 037:   9459 / 11284 loss=3.465, nll_loss=1.753, ppl=3.37, wps=72523.2, ups=1.22, wpb=59485.2, bsz=2267.7, num_updates=415300, lr=0.000155174, gnorm=0.365, loss_scale=0.5, train_wall=78, gb_free=39.6, wall=349159
2023-06-15 16:47:00 | INFO | train_inner | epoch 037:   9559 / 11284 loss=3.477, nll_loss=1.767, ppl=3.4, wps=72498.2, ups=1.22, wpb=59620.4, bsz=2259.2, num_updates=415400, lr=0.000155155, gnorm=0.359, loss_scale=0.5, train_wall=78, gb_free=39.6, wall=349241
2023-06-15 16:48:22 | INFO | train_inner | epoch 037:   9659 / 11284 loss=3.48, nll_loss=1.77, ppl=3.41, wps=72409.4, ups=1.22, wpb=59540.3, bsz=2198.5, num_updates=415500, lr=0.000155137, gnorm=0.361, loss_scale=0.5, train_wall=78, gb_free=39.6, wall=349323
2023-06-15 16:49:45 | INFO | train_inner | epoch 037:   9759 / 11284 loss=3.469, nll_loss=1.758, ppl=3.38, wps=71966.7, ups=1.21, wpb=59572.1, bsz=2212.1, num_updates=415600, lr=0.000155118, gnorm=0.362, loss_scale=1, train_wall=79, gb_free=39.6, wall=349406
2023-06-15 16:51:08 | INFO | train_inner | epoch 037:   9859 / 11284 loss=3.483, nll_loss=1.774, ppl=3.42, wps=71245.8, ups=1.2, wpb=59265.8, bsz=2146.8, num_updates=415700, lr=0.000155099, gnorm=0.366, loss_scale=1, train_wall=79, gb_free=39.6, wall=349489
2023-06-15 16:52:32 | INFO | train_inner | epoch 037:   9959 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=71511.9, ups=1.2, wpb=59530.9, bsz=2278.1, num_updates=415800, lr=0.000155081, gnorm=0.363, loss_scale=1, train_wall=79, gb_free=39.5, wall=349572
2023-06-15 16:53:55 | INFO | train_inner | epoch 037:  10059 / 11284 loss=3.479, nll_loss=1.768, ppl=3.41, wps=71311.9, ups=1.2, wpb=59375.8, bsz=2301.7, num_updates=415900, lr=0.000155062, gnorm=0.364, loss_scale=1, train_wall=79, gb_free=39.6, wall=349656
2023-06-15 16:55:18 | INFO | train_inner | epoch 037:  10159 / 11284 loss=3.497, nll_loss=1.789, ppl=3.46, wps=71303.7, ups=1.2, wpb=59479.5, bsz=2186.2, num_updates=416000, lr=0.000155043, gnorm=0.361, loss_scale=1, train_wall=79, gb_free=39.6, wall=349739
2023-06-15 16:56:41 | INFO | train_inner | epoch 037:  10259 / 11284 loss=3.49, nll_loss=1.782, ppl=3.44, wps=71650.6, ups=1.2, wpb=59515.9, bsz=2164.3, num_updates=416100, lr=0.000155025, gnorm=0.378, loss_scale=1, train_wall=79, gb_free=39.6, wall=349822
2023-06-15 16:58:04 | INFO | train_inner | epoch 037:  10359 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=71622.3, ups=1.21, wpb=59409.7, bsz=2219.3, num_updates=416200, lr=0.000155006, gnorm=0.376, loss_scale=1, train_wall=79, gb_free=39.6, wall=349905
2023-06-15 16:59:27 | INFO | train_inner | epoch 037:  10459 / 11284 loss=3.474, nll_loss=1.763, ppl=3.39, wps=71738.6, ups=1.2, wpb=59587.7, bsz=2256.2, num_updates=416300, lr=0.000154988, gnorm=0.353, loss_scale=1, train_wall=79, gb_free=39.6, wall=349988
2023-06-15 17:00:49 | INFO | train_inner | epoch 037:  10559 / 11284 loss=3.488, nll_loss=1.779, ppl=3.43, wps=72934.4, ups=1.23, wpb=59489.2, bsz=2223.8, num_updates=416400, lr=0.000154969, gnorm=0.365, loss_scale=1, train_wall=77, gb_free=39.6, wall=350070
2023-06-15 17:02:11 | INFO | train_inner | epoch 037:  10659 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=72753.8, ups=1.22, wpb=59638.3, bsz=2208.8, num_updates=416500, lr=0.00015495, gnorm=0.355, loss_scale=1, train_wall=78, gb_free=39.6, wall=350152
2023-06-15 17:03:34 | INFO | train_inner | epoch 037:  10759 / 11284 loss=3.472, nll_loss=1.762, ppl=3.39, wps=72192.8, ups=1.21, wpb=59700.4, bsz=2286.2, num_updates=416600, lr=0.000154932, gnorm=0.353, loss_scale=2, train_wall=79, gb_free=39.6, wall=350234
2023-06-15 17:04:56 | INFO | train_inner | epoch 037:  10859 / 11284 loss=3.473, nll_loss=1.762, ppl=3.39, wps=72047.2, ups=1.21, wpb=59496.7, bsz=2127.4, num_updates=416700, lr=0.000154913, gnorm=0.365, loss_scale=2, train_wall=79, gb_free=39.6, wall=350317
2023-06-15 17:06:19 | INFO | train_inner | epoch 037:  10959 / 11284 loss=3.482, nll_loss=1.772, ppl=3.42, wps=71990.7, ups=1.21, wpb=59570.6, bsz=2186.6, num_updates=416800, lr=0.000154895, gnorm=0.364, loss_scale=2, train_wall=79, gb_free=39.6, wall=350400
2023-06-15 17:07:42 | INFO | train_inner | epoch 037:  11059 / 11284 loss=3.495, nll_loss=1.787, ppl=3.45, wps=71748.2, ups=1.21, wpb=59509.2, bsz=2200.2, num_updates=416900, lr=0.000154876, gnorm=0.364, loss_scale=2, train_wall=79, gb_free=39.6, wall=350483
2023-06-15 17:09:05 | INFO | train_inner | epoch 037:  11159 / 11284 loss=3.491, nll_loss=1.782, ppl=3.44, wps=71892.1, ups=1.21, wpb=59379.9, bsz=2308.3, num_updates=417000, lr=0.000154857, gnorm=0.376, loss_scale=2, train_wall=78, gb_free=39.6, wall=350565
2023-06-15 17:10:28 | INFO | train_inner | epoch 037:  11259 / 11284 loss=3.476, nll_loss=1.766, ppl=3.4, wps=71736.4, ups=1.2, wpb=59568.1, bsz=2302, num_updates=417100, lr=0.000154839, gnorm=0.361, loss_scale=2, train_wall=79, gb_free=39.5, wall=350648
2023-06-15 17:10:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-15 17:11:06 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 4.28 | nll_loss 2.598 | ppl 6.06 | bleu 21.18 | wps 3708.6 | wpb 2397.5 | bsz 71.5 | num_updates 417125 | best_loss 4.271
2023-06-15 17:11:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 417125 updates
2023-06-15 17:11:06 | INFO | fairseq.trainer | Saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint37.pt
2023-06-15 17:11:09 | INFO | fairseq.trainer | Finished saving checkpoint to /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint37.pt
2023-06-15 17:11:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /project/jonmay_231/linghaoj/reproduce/data/wmt17/ckpt/xfmr-wmt17/checkpoint37.pt (epoch 37 @ 417125 updates, score 4.28) (writing took 5.726412267424166 seconds)
2023-06-15 17:11:12 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-06-15 17:11:12 | INFO | train | epoch 037 | loss 3.479 | nll_loss 1.769 | ppl 3.41 | wps 71411.1 | ups 1.2 | wpb 59501.1 | bsz 2227.5 | num_updates 417125 | lr 0.000154834 | gnorm 0.362 | loss_scale 2 | train_wall 8915 | gb_free 39.6 | wall 350693
2023-06-15 17:11:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11284
2023-06-15 17:11:12 | INFO | fairseq.trainer | begin training epoch 38
2023-06-15 17:11:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-15 17:12:17 | INFO | train_inner | epoch 038:     75 / 11284 loss=3.479, nll_loss=1.768, ppl=3.41, wps=54237.4, ups=0.92, wpb=59103.7, bsz=2078.3, num_updates=417200, lr=0.00015482, gnorm=0.377, loss_scale=2, train_wall=81, gb_free=39.6, wall=350757
2023-06-15 17:13:42 | INFO | train_inner | epoch 038:    175 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=70032.2, ups=1.17, wpb=59794.6, bsz=2218.2, num_updates=417300, lr=0.000154802, gnorm=0.366, loss_scale=2, train_wall=82, gb_free=39.5, wall=350843
2023-06-15 17:15:08 | INFO | train_inner | epoch 038:    275 / 11284 loss=3.468, nll_loss=1.756, ppl=3.38, wps=69702.5, ups=1.17, wpb=59700.8, bsz=2273, num_updates=417400, lr=0.000154783, gnorm=0.375, loss_scale=2, train_wall=82, gb_free=39.6, wall=350928
2023-06-15 17:16:32 | INFO | train_inner | epoch 038:    375 / 11284 loss=3.486, nll_loss=1.776, ppl=3.43, wps=70298.2, ups=1.18, wpb=59600.6, bsz=2157.7, num_updates=417500, lr=0.000154765, gnorm=0.364, loss_scale=2, train_wall=81, gb_free=39.6, wall=351013
2023-06-15 17:17:59 | INFO | train_inner | epoch 038:    475 / 11284 loss=3.475, nll_loss=1.763, ppl=3.4, wps=68134, ups=1.15, wpb=59311.2, bsz=2224.6, num_updates=417600, lr=0.000154746, gnorm=0.361, loss_scale=4, train_wall=83, gb_free=39.5, wall=351100
2023-06-15 17:18:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 17:19:27 | INFO | train_inner | epoch 038:    576 / 11284 loss=3.469, nll_loss=1.758, ppl=3.38, wps=67665.3, ups=1.14, wpb=59564.2, bsz=2214.5, num_updates=417700, lr=0.000154728, gnorm=0.354, loss_scale=2, train_wall=84, gb_free=39.4, wall=351188
2023-06-15 17:20:54 | INFO | train_inner | epoch 038:    676 / 11284 loss=3.459, nll_loss=1.746, ppl=3.35, wps=68475.1, ups=1.15, wpb=59517.9, bsz=2217.2, num_updates=417800, lr=0.000154709, gnorm=0.38, loss_scale=2, train_wall=83, gb_free=39.6, wall=351275
2023-06-15 17:22:22 | INFO | train_inner | epoch 038:    776 / 11284 loss=3.493, nll_loss=1.784, ppl=3.44, wps=67925.1, ups=1.14, wpb=59421.7, bsz=2290.5, num_updates=417900, lr=0.000154691, gnorm=0.362, loss_scale=2, train_wall=83, gb_free=39.6, wall=351362
2023-06-15 17:23:48 | INFO | train_inner | epoch 038:    876 / 11284 loss=3.469, nll_loss=1.757, ppl=3.38, wps=68605.3, ups=1.16, wpb=59207, bsz=2221.4, num_updates=418000, lr=0.000154672, gnorm=0.356, loss_scale=2, train_wall=82, gb_free=39.6, wall=351449
2023-06-15 17:25:14 | INFO | train_inner | epoch 038:    976 / 11284 loss=3.479, nll_loss=1.769, ppl=3.41, wps=69645.4, ups=1.17, wpb=59565.7, bsz=2248, num_updates=418100, lr=0.000154654, gnorm=0.368, loss_scale=2, train_wall=82, gb_free=39.6, wall=351534
2023-06-15 17:26:39 | INFO | train_inner | epoch 038:   1076 / 11284 loss=3.473, nll_loss=1.762, ppl=3.39, wps=69724.1, ups=1.17, wpb=59632.5, bsz=2256.4, num_updates=418200, lr=0.000154635, gnorm=0.36, loss_scale=2, train_wall=82, gb_free=39.6, wall=351620
2023-06-15 17:28:05 | INFO | train_inner | epoch 038:   1176 / 11284 loss=3.491, nll_loss=1.782, ppl=3.44, wps=69196.6, ups=1.16, wpb=59566.8, bsz=2173.3, num_updates=418300, lr=0.000154617, gnorm=0.362, loss_scale=2, train_wall=82, gb_free=39.5, wall=351706
2023-06-15 17:29:31 | INFO | train_inner | epoch 038:   1276 / 11284 loss=3.46, nll_loss=1.747, ppl=3.36, wps=69604, ups=1.17, wpb=59571, bsz=2166.2, num_updates=418400, lr=0.000154598, gnorm=0.371, loss_scale=2, train_wall=82, gb_free=39.6, wall=351791
2023-06-15 17:30:57 | INFO | train_inner | epoch 038:   1376 / 11284 loss=3.475, nll_loss=1.764, ppl=3.4, wps=69061.1, ups=1.17, wpb=59191, bsz=2230.2, num_updates=418500, lr=0.00015458, gnorm=0.372, loss_scale=2, train_wall=82, gb_free=39.6, wall=351877
2023-06-15 17:32:21 | INFO | train_inner | epoch 038:   1476 / 11284 loss=3.47, nll_loss=1.758, ppl=3.38, wps=70240.3, ups=1.18, wpb=59516.2, bsz=2289.9, num_updates=418600, lr=0.000154561, gnorm=0.362, loss_scale=2, train_wall=81, gb_free=39.6, wall=351962
2023-06-15 17:33:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 17:33:44 | INFO | train_inner | epoch 038:   1577 / 11284 loss=3.461, nll_loss=1.748, ppl=3.36, wps=71835.6, ups=1.2, wpb=59650.1, bsz=2234.8, num_updates=418700, lr=0.000154543, gnorm=0.357, loss_scale=2, train_wall=79, gb_free=39.6, wall=352045
2023-06-15 17:35:06 | INFO | train_inner | epoch 038:   1677 / 11284 loss=3.465, nll_loss=1.753, ppl=3.37, wps=72917.5, ups=1.22, wpb=59601.4, bsz=2223.6, num_updates=418800, lr=0.000154524, gnorm=0.36, loss_scale=2, train_wall=78, gb_free=39.5, wall=352127
2023-06-15 17:36:28 | INFO | train_inner | epoch 038:   1777 / 11284 loss=3.469, nll_loss=1.757, ppl=3.38, wps=72109.4, ups=1.21, wpb=59397.1, bsz=2225.8, num_updates=418900, lr=0.000154506, gnorm=0.361, loss_scale=2, train_wall=78, gb_free=39.5, wall=352209
2023-06-15 17:37:52 | INFO | train_inner | epoch 038:   1877 / 11284 loss=3.485, nll_loss=1.775, ppl=3.42, wps=71505, ups=1.2, wpb=59650.3, bsz=2330.7, num_updates=419000, lr=0.000154487, gnorm=0.372, loss_scale=2, train_wall=79, gb_free=39.5, wall=352292
2023-06-15 17:39:15 | INFO | train_inner | epoch 038:   1977 / 11284 loss=3.468, nll_loss=1.756, ppl=3.38, wps=72087.1, ups=1.21, wpb=59579.2, bsz=2324.7, num_updates=419100, lr=0.000154469, gnorm=0.359, loss_scale=2, train_wall=78, gb_free=39.6, wall=352375
2023-06-15 17:40:38 | INFO | train_inner | epoch 038:   2077 / 11284 loss=3.465, nll_loss=1.753, ppl=3.37, wps=71367.5, ups=1.2, wpb=59475.2, bsz=2251.3, num_updates=419200, lr=0.000154451, gnorm=0.384, loss_scale=2, train_wall=79, gb_free=39.6, wall=352458
2023-06-15 17:42:01 | INFO | train_inner | epoch 038:   2177 / 11284 loss=3.482, nll_loss=1.771, ppl=3.41, wps=71663.8, ups=1.21, wpb=59460.6, bsz=2243, num_updates=419300, lr=0.000154432, gnorm=0.375, loss_scale=2, train_wall=79, gb_free=39.6, wall=352541
2023-06-15 17:43:24 | INFO | train_inner | epoch 038:   2277 / 11284 loss=3.463, nll_loss=1.75, ppl=3.36, wps=71709.5, ups=1.21, wpb=59500.1, bsz=2201.5, num_updates=419400, lr=0.000154414, gnorm=0.359, loss_scale=2, train_wall=79, gb_free=39.6, wall=352624
2023-06-15 17:44:46 | INFO | train_inner | epoch 038:   2377 / 11284 loss=3.47, nll_loss=1.758, ppl=3.38, wps=72319.1, ups=1.21, wpb=59586.2, bsz=2179.1, num_updates=419500, lr=0.000154395, gnorm=0.361, loss_scale=2, train_wall=78, gb_free=39.5, wall=352707
2023-06-15 17:46:09 | INFO | train_inner | epoch 038:   2477 / 11284 loss=3.473, nll_loss=1.761, ppl=3.39, wps=71789.5, ups=1.2, wpb=59638.4, bsz=2290.6, num_updates=419600, lr=0.000154377, gnorm=0.356, loss_scale=2, train_wall=79, gb_free=39.6, wall=352790
2023-06-15 17:47:33 | INFO | train_inner | epoch 038:   2577 / 11284 loss=3.474, nll_loss=1.762, ppl=3.39, wps=71105.1, ups=1.2, wpb=59305.5, bsz=2335.9, num_updates=419700, lr=0.000154358, gnorm=0.367, loss_scale=2, train_wall=79, gb_free=39.5, wall=352873
2023-06-15 17:48:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 17:48:56 | INFO | train_inner | epoch 038:   2678 / 11284 loss=3.487, nll_loss=1.777, ppl=3.43, wps=71275.9, ups=1.2, wpb=59458, bsz=2216.5, num_updates=419800, lr=0.00015434, gnorm=0.365, loss_scale=2, train_wall=79, gb_free=38.8, wall=352957
2023-06-15 17:50:19 | INFO | train_inner | epoch 038:   2778 / 11284 loss=3.496, nll_loss=1.787, ppl=3.45, wps=71628.7, ups=1.2, wpb=59548.1, bsz=2274.1, num_updates=419900, lr=0.000154322, gnorm=0.366, loss_scale=2, train_wall=79, gb_free=39.5, wall=353040
2023-06-15 17:51:42 | INFO | train_inner | epoch 038:   2878 / 11284 loss=3.475, nll_loss=1.764, ppl=3.4, wps=71565.5, ups=1.21, wpb=59353.7, bsz=2214.3, num_updates=420000, lr=0.000154303, gnorm=0.358, loss_scale=2, train_wall=79, gb_free=39.6, wall=353123
2023-06-15 17:53:06 | INFO | train_inner | epoch 038:   2978 / 11284 loss=3.467, nll_loss=1.756, ppl=3.38, wps=71266.4, ups=1.19, wpb=59754.2, bsz=2321.2, num_updates=420100, lr=0.000154285, gnorm=0.351, loss_scale=2, train_wall=80, gb_free=39.6, wall=353207
2023-06-15 17:54:28 | INFO | train_inner | epoch 038:   3078 / 11284 loss=3.475, nll_loss=1.764, ppl=3.4, wps=72215.5, ups=1.22, wpb=59385.5, bsz=2172.8, num_updates=420200, lr=0.000154267, gnorm=0.361, loss_scale=2, train_wall=78, gb_free=39.5, wall=353289
2023-06-15 17:55:52 | INFO | train_inner | epoch 038:   3178 / 11284 loss=3.476, nll_loss=1.765, ppl=3.4, wps=71398, ups=1.2, wpb=59460.9, bsz=2233.9, num_updates=420300, lr=0.000154248, gnorm=0.371, loss_scale=2, train_wall=79, gb_free=39.6, wall=353372
2023-06-15 17:57:15 | INFO | train_inner | epoch 038:   3278 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=71614.5, ups=1.2, wpb=59593.6, bsz=2244.1, num_updates=420400, lr=0.00015423, gnorm=0.362, loss_scale=2, train_wall=79, gb_free=39.6, wall=353455
2023-06-15 17:58:40 | INFO | train_inner | epoch 038:   3378 / 11284 loss=3.479, nll_loss=1.768, ppl=3.41, wps=70171.3, ups=1.18, wpb=59594.2, bsz=2204.3, num_updates=420500, lr=0.000154212, gnorm=0.357, loss_scale=2, train_wall=81, gb_free=39.6, wall=353540
2023-06-15 18:00:06 | INFO | train_inner | epoch 038:   3478 / 11284 loss=3.47, nll_loss=1.758, ppl=3.38, wps=69273.9, ups=1.16, wpb=59565.7, bsz=2219.3, num_updates=420600, lr=0.000154193, gnorm=0.367, loss_scale=2, train_wall=82, gb_free=39.6, wall=353626
2023-06-15 18:01:30 | INFO | train_inner | epoch 038:   3578 / 11284 loss=3.48, nll_loss=1.77, ppl=3.41, wps=70058.6, ups=1.18, wpb=59330.2, bsz=2216, num_updates=420700, lr=0.000154175, gnorm=0.37, loss_scale=2, train_wall=81, gb_free=39.6, wall=353711
2023-06-15 18:02:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 18:02:56 | INFO | train_inner | epoch 038:   3679 / 11284 loss=3.483, nll_loss=1.772, ppl=3.42, wps=69321.3, ups=1.16, wpb=59520.9, bsz=2197.3, num_updates=420800, lr=0.000154157, gnorm=0.371, loss_scale=2, train_wall=82, gb_free=39.5, wall=353797
2023-06-15 18:04:23 | INFO | train_inner | epoch 038:   3779 / 11284 loss=3.477, nll_loss=1.766, ppl=3.4, wps=68730.5, ups=1.16, wpb=59365.8, bsz=2253.5, num_updates=420900, lr=0.000154138, gnorm=0.364, loss_scale=2, train_wall=82, gb_free=39.5, wall=353883
2023-06-15 18:05:48 | INFO | train_inner | epoch 038:   3879 / 11284 loss=3.487, nll_loss=1.778, ppl=3.43, wps=69373.3, ups=1.17, wpb=59494.8, bsz=2327.8, num_updates=421000, lr=0.00015412, gnorm=0.364, loss_scale=2, train_wall=82, gb_free=39.6, wall=353969
2023-06-15 18:07:14 | INFO | train_inner | epoch 038:   3979 / 11284 loss=3.481, nll_loss=1.77, ppl=3.41, wps=69943.1, ups=1.17, wpb=59549.8, bsz=2149.9, num_updates=421100, lr=0.000154102, gnorm=0.361, loss_scale=2, train_wall=81, gb_free=38.2, wall=354054
2023-06-15 18:08:39 | INFO | train_inner | epoch 038:   4079 / 11284 loss=3.472, nll_loss=1.76, ppl=3.39, wps=69243.4, ups=1.17, wpb=59374.5, bsz=2198.4, num_updates=421200, lr=0.000154083, gnorm=0.368, loss_scale=2, train_wall=82, gb_free=39.6, wall=354140
2023-06-15 18:10:06 | INFO | train_inner | epoch 038:   4179 / 11284 loss=3.475, nll_loss=1.764, ppl=3.4, wps=68172.5, ups=1.15, wpb=59331.5, bsz=2207.5, num_updates=421300, lr=0.000154065, gnorm=0.363, loss_scale=2, train_wall=83, gb_free=39.5, wall=354227
2023-06-15 18:11:33 | INFO | train_inner | epoch 038:   4279 / 11284 loss=3.488, nll_loss=1.778, ppl=3.43, wps=68466.6, ups=1.15, wpb=59345.7, bsz=2297.8, num_updates=421400, lr=0.000154047, gnorm=0.378, loss_scale=2, train_wall=83, gb_free=39.6, wall=354314
2023-06-15 18:13:00 | INFO | train_inner | epoch 038:   4379 / 11284 loss=3.459, nll_loss=1.746, ppl=3.35, wps=68318.7, ups=1.15, wpb=59510.5, bsz=2247.1, num_updates=421500, lr=0.000154029, gnorm=0.368, loss_scale=2, train_wall=83, gb_free=39.6, wall=354401
2023-06-15 18:14:28 | INFO | train_inner | epoch 038:   4479 / 11284 loss=3.48, nll_loss=1.77, ppl=3.41, wps=68010.7, ups=1.14, wpb=59508.8, bsz=2334.4, num_updates=421600, lr=0.00015401, gnorm=0.359, loss_scale=2, train_wall=83, gb_free=39.5, wall=354488
2023-06-15 18:15:55 | INFO | train_inner | epoch 038:   4579 / 11284 loss=3.483, nll_loss=1.773, ppl=3.42, wps=68076.9, ups=1.14, wpb=59615.3, bsz=2201.9, num_updates=421700, lr=0.000153992, gnorm=0.363, loss_scale=2, train_wall=83, gb_free=39.6, wall=354576
2023-06-15 18:17:23 | INFO | train_inner | epoch 038:   4679 / 11284 loss=3.476, nll_loss=1.765, ppl=3.4, wps=68117.5, ups=1.14, wpb=59579.2, bsz=2222.6, num_updates=421800, lr=0.000153974, gnorm=0.359, loss_scale=4, train_wall=83, gb_free=39.6, wall=354663
2023-06-15 18:17:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 18:18:51 | INFO | train_inner | epoch 038:   4780 / 11284 loss=3.47, nll_loss=1.758, ppl=3.38, wps=67728.9, ups=1.14, wpb=59540.1, bsz=2183.6, num_updates=421900, lr=0.000153956, gnorm=0.363, loss_scale=2, train_wall=83, gb_free=39.6, wall=354751
2023-06-15 18:20:17 | INFO | train_inner | epoch 038:   4880 / 11284 loss=3.479, nll_loss=1.768, ppl=3.41, wps=68521.4, ups=1.15, wpb=59491.2, bsz=2208.3, num_updates=422000, lr=0.000153937, gnorm=0.361, loss_scale=2, train_wall=83, gb_free=39.5, wall=354838
2023-06-15 18:21:45 | INFO | train_inner | epoch 038:   4980 / 11284 loss=3.472, nll_loss=1.76, ppl=3.39, wps=68174.4, ups=1.15, wpb=59429.2, bsz=2238.2, num_updates=422100, lr=0.000153919, gnorm=0.362, loss_scale=2, train_wall=83, gb_free=39.6, wall=354925
2023-06-15 18:23:12 | INFO | train_inner | epoch 038:   5080 / 11284 loss=3.484, nll_loss=1.774, ppl=3.42, wps=68106.3, ups=1.15, wpb=59360.1, bsz=2138.5, num_updates=422200, lr=0.000153901, gnorm=0.369, loss_scale=2, train_wall=83, gb_free=39.5, wall=355012
2023-06-15 18:24:38 | INFO | train_inner | epoch 038:   5180 / 11284 loss=3.482, nll_loss=1.772, ppl=3.42, wps=68969.7, ups=1.16, wpb=59509.7, bsz=2165.7, num_updates=422300, lr=0.000153883, gnorm=0.364, loss_scale=2, train_wall=82, gb_free=39.6, wall=355099
2023-06-15 18:26:04 | INFO | train_inner | epoch 038:   5280 / 11284 loss=3.498, nll_loss=1.79, ppl=3.46, wps=68987.1, ups=1.16, wpb=59567.2, bsz=2307.1, num_updates=422400, lr=0.000153864, gnorm=0.362, loss_scale=2, train_wall=82, gb_free=39.4, wall=355185
2023-06-15 18:27:30 | INFO | train_inner | epoch 038:   5380 / 11284 loss=3.481, nll_loss=1.771, ppl=3.41, wps=69541.3, ups=1.17, wpb=59441.1, bsz=2271.3, num_updates=422500, lr=0.000153846, gnorm=0.384, loss_scale=2, train_wall=81, gb_free=39.6, wall=355270
2023-06-15 18:28:53 | INFO | train_inner | epoch 038:   5480 / 11284 loss=3.478, nll_loss=1.768, ppl=3.41, wps=72120.8, ups=1.21, wpb=59786, bsz=2182.1, num_updates=422600, lr=0.000153828, gnorm=0.37, loss_scale=2, train_wall=79, gb_free=39.5, wall=355353
2023-06-15 18:30:16 | INFO | train_inner | epoch 038:   5580 / 11284 loss=3.481, nll_loss=1.771, ppl=3.41, wps=71553.2, ups=1.2, wpb=59548.5, bsz=2175, num_updates=422700, lr=0.00015381, gnorm=0.364, loss_scale=2, train_wall=79, gb_free=39.6, wall=355437
2023-06-15 18:31:39 | INFO | train_inner | epoch 038:   5680 / 11284 loss=3.466, nll_loss=1.755, ppl=3.37, wps=71643.4, ups=1.2, wpb=59645.4, bsz=2213, num_updates=422800, lr=0.000153792, gnorm=0.372, loss_scale=2, train_wall=79, gb_free=39.6, wall=355520
2023-06-15 18:32:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-06-15 18:33:03 | INFO | train_inner | epoch 038:   5781 / 11284 loss=3.476, nll_loss=1.766, ppl=3.4, wps=70960.7, ups=1.19, wpb=59518.3, bsz=2159.4, num_updates=422900, lr=0.000153773, gnorm=0.36, loss_scale=2, train_wall=80, gb_free=39.5, wall=355604
2023-06-15 18:34:26 | INFO | train_inner | epoch 038:   5881 / 11284 loss=3.476, nll_loss=1.766, ppl=3.4, wps=71924.2, ups=1.21, wpb=59600.2, bsz=2164.7, num_updates=423000, lr=0.000153755, gnorm=0.367, loss_scale=2, train_wall=79, gb_free=39.6, wall=355687
