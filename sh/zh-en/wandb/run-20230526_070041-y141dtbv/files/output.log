2023-05-26 07:00:45 | INFO | fairseq_cli.train | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir='', seed=42, cpu=False, tpu=False, bf16=False, fp16=True, memory_efficient_bf16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir='/project/jonmay_231/linghaoj/concat-src-only/concat_models', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, checkpoint_suffix='', quantization_config_path=None, profile=False, wandb_project='reproduce-doc-mt', wandb_entity=None, wandb_id=None, criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', task='document_translation', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4096, max_sentences=None, required_batch_size_multiple=8, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', test_subset='test', validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=4096, max_sentences_valid=None, curriculum=0, distributed_world_size=2, distributed_rank=0, distributed_backend='nccl', distributed_init_method='tcp://localhost:10905', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, fast_stat_sync=False, broadcast_buffers=False, distributed_wrapper='DDP', slowmo_momentum=None, slowmo_algorithm='LocalSGD', localsgd_frequency=3, nprocs_per_node=2, arch='contextual_mega', max_epoch=0, max_update=200000, stop_time_hours=0, clip_norm=0.1, clip_mode='total', sentence_avg=False, update_freq=[16], lr=[0.001], stop_min_lr=-1, use_bmuf=False, save_dir='/project/jonmay_231/linghaoj/reproduce/ckpt/mega-1-1-0.2-sf[zh-en]', restore_file='checkpoint_last.pt', finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=5, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='bleu', maximize_best_checkpoint_metric=True, patience=-1, rel_pos_bias='simple', context_loss=False, coword_dropout=0.0, coword_dropout_type='sample', multi_encoder=False, label_smoothing=0.1, adam_betas='(0.9, 0.98)', adam_eps=1e-08, weight_decay=0.01, use_old_adam=False, warmup_updates=4000, warmup_init_lr=-1, data='/project/jonmay_231/linghaoj/canmt/bwb/data/bin', source_lang='zh', target_lang='en', load_alignments=False, left_pad_source='True', left_pad_target='False', max_source_positions=1024, max_target_positions=1024, upsample_primary=1, truncate_source=False, num_batch_buckets=0, eval_bleu=True, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_tokenized_bleu=False, eval_bleu_remove_bpe='sentencepiece', eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_print_samples=True, source_context_size=1, target_context_size=1, sample_context_size=False, break_tag='<brk>', pos_drop_probs=None, next_sent_ctx=False, shuffle_sample=True, encoder_layers=6, decoder_layers=6, share_decoder_input_output_embed=True, activation_fn='silu', attention_activation_fn='softmax', encoder_n_dim=16, encoder_chunk_size=-1, normalization_type='layernorm', dropout=0.2, attention_dropout=0.0, hidden_dropout=0.0, activation_dropout=0.0, no_seed_provided=False, encoder_embed_path=None, encoder_embed_dim=512, encoder_hidden_dim=1024, encoder_ffn_embed_dim=1024, encoder_z_dim=128, decoder_embed_path=None, decoder_embed_dim=512, decoder_hidden_dim=1024, decoder_ffn_embed_dim=1024, decoder_z_dim=128, decoder_n_dim=16, decoder_chunk_size=-1, decoder_input_dim=512, feature_dropout=False, normalize_before=False, normalize_embedding=False, no_scale_embedding=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_all_embeddings=False, adaptive_input=False, truncation_length=1024, tie_adaptive_weights=False)
2023-05-26 07:00:45 | INFO | fairseq.tasks.translation | [zh] dictionary: 36776 types
2023-05-26 07:00:45 | INFO | fairseq.tasks.translation | [en] dictionary: 34088 types
2023-05-26 07:00:45 | INFO | fairseq.data.data_utils | loaded 2619 examples from: /project/jonmay_231/linghaoj/canmt/bwb/data/bin/valid.zh-en.zh
2023-05-26 07:00:45 | INFO | fairseq.data.data_utils | loaded 2619 examples from: /project/jonmay_231/linghaoj/canmt/bwb/data/bin/valid.zh-en.en
2023-05-26 07:00:46 | INFO | fairseq_cli.train | ContextualMegaModel(
  (encoder): ContextualMegaEncoder(
    (embedding_dropout): FairseqDropout(p=0.2)
    (embed_tokens): Embedding(36776, 512, padding_idx=1)
    (layers): ModuleList(
      (0): MegaEncoderLayer(
        (mega_layer): MovingAverageGatedAttention(
          edim=512, zdim=128, hdim=1024, ndim=16, chunk=-1, attn_act=softmax, prenorm=False
          (dropout): FairseqDropout(p=0.2)
          (hidden_dropout): FairseqDropout(p=0.0)
          (attention_dropout): FairseqDropout(p=0.0)
          (norm): SequenceNorm(
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (move): MultiHeadEMA(edim=512, ndim=16, bidirectional=True, trunction=1024)
          (v_proj): Linear(in_features=512, out_features=1024, bias=True)
          (mx_proj): Linear(in_features=512, out_features=2176, bias=True)
          (h_proj): Linear(in_features=1024, out_features=512, bias=True)
          (rel_pos_bias): SimpleRelativePositionalBias(max positions=1024)
        )
        (nffn): NormalizedFeedForwardNetwork(
          edim=512, hdim=1024, act=silu, prenorm=False
          (dropout): FairseqDropout(p=0.2)
          (hidden_dropout): FairseqDropout(p=0.0)
          (norm): SequenceNorm(
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
        )
      )
      (1): MegaEncoderLayer(
        (mega_layer): MovingAverageGatedAttention(
          edim=512, zdim=128, hdim=1024, ndim=16, chunk=-1, attn_act=softmax, prenorm=False
          (dropout): FairseqDropout(p=0.2)
          (hidden_dropout): FairseqDropout(p=0.0)
          (attention_dropout): FairseqDropout(p=0.0)
          (norm): SequenceNorm(
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (move): MultiHeadEMA(edim=512, ndim=16, bidirectional=True, trunction=1024)
          (v_proj): Linear(in_features=512, out_features=1024, bias=True)
          (mx_proj): Linear(in_features=512, out_features=2176, bias=True)
          (h_proj): Linear(in_features=1024, out_features=512, bias=True)
          (rel_pos_bias): SimpleRelativePositionalBias(max positions=1024)
        )
        (nffn): NormalizedFeedForwardNetwork(
          edim=512, hdim=1024, act=silu, prenorm=False
          (dropout): FairseqDropout(p=0.2)
          (hidden_dropout): FairseqDropout(p=0.0)
          (norm): SequenceNorm(
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
        )
      )
      (2): MegaEncoderLayer(
        (mega_layer): MovingAverageGatedAttention(
          edim=512, zdim=128, hdim=1024, ndim=16, chunk=-1, attn_act=softmax, prenorm=False
          (dropout): FairseqDropout(p=0.2)
          (hidden_dropout): FairseqDropout(p=0.0)
          (attention_dropout): FairseqDropout(p=0.0)
          (norm): SequenceNorm(
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (move): MultiHeadEMA(edim=512, ndim=16, bidirectional=True, trunction=1024)
          (v_proj): Linear(in_features=512, out_features=1024, bias=True)
          (mx_proj): Linear(in_features=512, out_features=2176, bias=True)
          (h_proj): Linear(in_features=1024, out_features=512, bias=True)
          (rel_pos_bias): SimpleRelativePositionalBias(max positions=1024)
        )
        (nffn): NormalizedFeedForwardNetwork(
          edim=512, hdim=1024, act=silu, prenorm=False
          (dropout): FairseqDropout(p=0.2)
          (hidden_dropout): FairseqDropout(p=0.0)
          (norm): SequenceNorm(
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
        )
      )
      (3): MegaEncoderLayer(
        (mega_layer): MovingAverageGatedAttention(
          edim=512, zdim=128, hdim=1024, ndim=16, chunk=-1, attn_act=softmax, prenorm=False
          (dropout): FairseqDropout(p=0.2)
          (hidden_dropout): FairseqDropout(p=0.0)
          (attention_dropout): FairseqDropout(p=0.0)
          (norm): SequenceNorm(
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (move): MultiHeadEMA(edim=512, ndim=16, bidirectional=True, trunction=1024)
          (v_proj): Linear(in_features=512, out_features=1024, bias=True)
          (mx_proj): Linear(in_features=512, out_features=2176, bias=True)
          (h_proj): Linear(in_features=1024, out_features=512, bias=True)
          (rel_pos_bias): SimpleRelativePositionalBias(max positions=1024)
        )
        (nffn): NormalizedFeedForwardNetwork(
          edim=512, hdim=1024, act=silu, prenorm=False
          (dropout): FairseqDropout(p=0.2)
          (hidden_dropout): FairseqDropout(p=0.0)
          (norm): SequenceNorm(
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
        )
      )
      (4): MegaEncoderLayer(
        (mega_layer): MovingAverageGatedAttention(
          edim=512, zdim=128, hdim=1024, ndim=16, chunk=-1, attn_act=softmax, prenorm=False
          (dropout): FairseqDropout(p=0.2)
          (hidden_dropout): FairseqDropout(p=0.0)
          (attention_dropout): FairseqDropout(p=0.0)
          (norm): SequenceNorm(
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (move): MultiHeadEMA(edim=512, ndim=16, bidirectional=True, trunction=1024)
          (v_proj): Linear(in_features=512, out_features=1024, bias=True)
          (mx_proj): Linear(in_features=512, out_features=2176, bias=True)
          (h_proj): Linear(in_features=1024, out_features=512, bias=True)
          (rel_pos_bias): SimpleRelativePositionalBias(max positions=1024)
        )
        (nffn): NormalizedFeedForwardNetwork(
          edim=512, hdim=1024, act=silu, prenorm=False
          (dropout): FairseqDropout(p=0.2)
          (hidden_dropout): FairseqDropout(p=0.0)
          (norm): SequenceNorm(
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
        )
      )
      (5): MegaEncoderLayer(
        (mega_layer): MovingAverageGatedAttention(
          edim=512, zdim=128, hdim=1024, ndim=16, chunk=-1, attn_act=softmax, prenorm=False
          (dropout): FairseqDropout(p=0.2)
          (hidden_dropout): FairseqDropout(p=0.0)
          (attention_dropout): FairseqDropout(p=0.0)
          (norm): SequenceNorm(
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (move): MultiHeadEMA(edim=512, ndim=16, bidirectional=True, trunction=1024)
          (v_proj): Linear(in_features=512, out_features=1024, bias=True)
          (mx_proj): Linear(in_features=512, out_features=2176, bias=True)
          (h_proj): Linear(in_features=1024, out_features=512, bias=True)
          (rel_pos_bias): SimpleRelativePositionalBias(max positions=1024)
        )
        (nffn): NormalizedFeedForwardNetwork(
          edim=512, hdim=1024, act=silu, prenorm=False
          (dropout): FairseqDropout(p=0.2)
          (hidden_dropout): FairseqDropout(p=0.0)
          (norm): SequenceNorm(
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
        )
      )
    )
  )
  (decoder): ContextualMegaDecoder(
    (embedding_dropout): FairseqDropout(p=0.2)
    (embed_tokens): Embedding(34088, 512, padding_idx=1)
    (layers): ModuleList(
      (0): MegaDecoderLayer(
        (mega_layer): MovingAverageGatedAttention(
          edim=512, zdim=128, hdim=1024, ndim=16, chunk=-1, attn_act=softmax, prenorm=False
          (dropout): FairseqDropout(p=0.2)
          (hidden_dropout): FairseqDropout(p=0.0)
          (attention_dropout): FairseqDropout(p=0.0)
          (norm): SequenceNorm(
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (move): MultiHeadEMA(edim=512, ndim=16, bidirectional=False, trunction=1024)
          (v_proj): Linear(in_features=512, out_features=1024, bias=True)
          (mx_proj): Linear(in_features=512, out_features=2176, bias=True)
          (h_proj): Linear(in_features=1024, out_features=512, bias=True)
          (rel_pos_bias): SimpleRelativePositionalBias(max positions=1024)
        )
        (cross_attn): GatedCrossAttention(
          edim=512, zdim=128, ndim=16, attn_act=softmax, prenorm=False
          (dropout): FairseqDropout(p=0.2)
          (hidden_dropout): FairseqDropout(p=0.0)
          (attention_dropout): FairseqDropout(p=0.0)
          (norm): SequenceNorm(
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (k_proj): Linear(in_features=512, out_features=128, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=1152, bias=True)
          (h_proj): Linear(in_features=512, out_features=512, bias=True)
          (rel_pos_bias): SimpleRelativePositionalBias(max positions=1024)
        )
        (nffn): NormalizedFeedForwardNetwork(
          edim=512, hdim=1024, act=silu, prenorm=False
          (dropout): FairseqDropout(p=0.2)
          (hidden_dropout): FairseqDropout(p=0.0)
          (norm): SequenceNorm(
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
        )
      )
      (1): MegaDecoderLayer(
        (mega_layer): MovingAverageGatedAttention(
          edim=512, zdim=128, hdim=1024, ndim=16, chunk=-1, attn_act=softmax, prenorm=False
          (dropout): FairseqDropout(p=0.2)
          (hidden_dropout): FairseqDropout(p=0.0)
          (attention_dropout): FairseqDropout(p=0.0)
          (norm): SequenceNorm(
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (move): MultiHeadEMA(edim=512, ndim=16, bidirectional=False, trunction=1024)
          (v_proj): Linear(in_features=512, out_features=1024, bias=True)
          (mx_proj): Linear(in_features=512, out_features=2176, bias=True)
          (h_proj): Linear(in_features=1024, out_features=512, bias=True)
          (rel_pos_bias): SimpleRelativePositionalBias(max positions=1024)
        )
        (cross_attn): GatedCrossAttention(
          edim=512, zdim=128, ndim=16, attn_act=softmax, prenorm=False
          (dropout): FairseqDropout(p=0.2)
          (hidden_dropout): FairseqDropout(p=0.0)
          (attention_dropout): FairseqDropout(p=0.0)
          (norm): SequenceNorm(
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (k_proj): Linear(in_features=512, out_features=128, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=1152, bias=True)
          (h_proj): Linear(in_features=512, out_features=512, bias=True)
          (rel_pos_bias): SimpleRelativePositionalBias(max positions=1024)
        )
        (nffn): NormalizedFeedForwardNetwork(
          edim=512, hdim=1024, act=silu, prenorm=False
          (dropout): FairseqDropout(p=0.2)
          (hidden_dropout): FairseqDropout(p=0.0)
          (norm): SequenceNorm(
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
        )
      )
      (2): MegaDecoderLayer(
        (mega_layer): MovingAverageGatedAttention(
          edim=512, zdim=128, hdim=1024, ndim=16, chunk=-1, attn_act=softmax, prenorm=False
          (dropout): FairseqDropout(p=0.2)
          (hidden_dropout): FairseqDropout(p=0.0)
          (attention_dropout): FairseqDropout(p=0.0)
          (norm): SequenceNorm(
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (move): MultiHeadEMA(edim=512, ndim=16, bidirectional=False, trunction=1024)
          (v_proj): Linear(in_features=512, out_features=1024, bias=True)
          (mx_proj): Linear(in_features=512, out_features=2176, bias=True)
          (h_proj): Linear(in_features=1024, out_features=512, bias=True)
          (rel_pos_bias): SimpleRelativePositionalBias(max positions=1024)
        )
        (cross_attn): GatedCrossAttention(
          edim=512, zdim=128, ndim=16, attn_act=softmax, prenorm=False
          (dropout): FairseqDropout(p=0.2)
          (hidden_dropout): FairseqDropout(p=0.0)
          (attention_dropout): FairseqDropout(p=0.0)
          (norm): SequenceNorm(
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (k_proj): Linear(in_features=512, out_features=128, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=1152, bias=True)
          (h_proj): Linear(in_features=512, out_features=512, bias=True)
          (rel_pos_bias): SimpleRelativePositionalBias(max positions=1024)
        )
        (nffn): NormalizedFeedForwardNetwork(
          edim=512, hdim=1024, act=silu, prenorm=False
          (dropout): FairseqDropout(p=0.2)
          (hidden_dropout): FairseqDropout(p=0.0)
          (norm): SequenceNorm(
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
        )
      )
      (3): MegaDecoderLayer(
        (mega_layer): MovingAverageGatedAttention(
          edim=512, zdim=128, hdim=1024, ndim=16, chunk=-1, attn_act=softmax, prenorm=False
          (dropout): FairseqDropout(p=0.2)
          (hidden_dropout): FairseqDropout(p=0.0)
          (attention_dropout): FairseqDropout(p=0.0)
          (norm): SequenceNorm(
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (move): MultiHeadEMA(edim=512, ndim=16, bidirectional=False, trunction=1024)
          (v_proj): Linear(in_features=512, out_features=1024, bias=True)
          (mx_proj): Linear(in_features=512, out_features=2176, bias=True)
          (h_proj): Linear(in_features=1024, out_features=512, bias=True)
          (rel_pos_bias): SimpleRelativePositionalBias(max positions=1024)
        )
        (cross_attn): GatedCrossAttention(
          edim=512, zdim=128, ndim=16, attn_act=softmax, prenorm=False
          (dropout): FairseqDropout(p=0.2)
          (hidden_dropout): FairseqDropout(p=0.0)
          (attention_dropout): FairseqDropout(p=0.0)
          (norm): SequenceNorm(
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (k_proj): Linear(in_features=512, out_features=128, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=1152, bias=True)
          (h_proj): Linear(in_features=512, out_features=512, bias=True)
          (rel_pos_bias): SimpleRelativePositionalBias(max positions=1024)
        )
        (nffn): NormalizedFeedForwardNetwork(
          edim=512, hdim=1024, act=silu, prenorm=False
          (dropout): FairseqDropout(p=0.2)
          (hidden_dropout): FairseqDropout(p=0.0)
          (norm): SequenceNorm(
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
        )
      )
      (4): MegaDecoderLayer(
        (mega_layer): MovingAverageGatedAttention(
          edim=512, zdim=128, hdim=1024, ndim=16, chunk=-1, attn_act=softmax, prenorm=False
          (dropout): FairseqDropout(p=0.2)
          (hidden_dropout): FairseqDropout(p=0.0)
          (attention_dropout): FairseqDropout(p=0.0)
          (norm): SequenceNorm(
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (move): MultiHeadEMA(edim=512, ndim=16, bidirectional=False, trunction=1024)
          (v_proj): Linear(in_features=512, out_features=1024, bias=True)
          (mx_proj): Linear(in_features=512, out_features=2176, bias=True)
          (h_proj): Linear(in_features=1024, out_features=512, bias=True)
          (rel_pos_bias): SimpleRelativePositionalBias(max positions=1024)
        )
        (cross_attn): GatedCrossAttention(
          edim=512, zdim=128, ndim=16, attn_act=softmax, prenorm=False
          (dropout): FairseqDropout(p=0.2)
          (hidden_dropout): FairseqDropout(p=0.0)
          (attention_dropout): FairseqDropout(p=0.0)
          (norm): SequenceNorm(
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (k_proj): Linear(in_features=512, out_features=128, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=1152, bias=True)
          (h_proj): Linear(in_features=512, out_features=512, bias=True)
          (rel_pos_bias): SimpleRelativePositionalBias(max positions=1024)
        )
        (nffn): NormalizedFeedForwardNetwork(
          edim=512, hdim=1024, act=silu, prenorm=False
          (dropout): FairseqDropout(p=0.2)
          (hidden_dropout): FairseqDropout(p=0.0)
          (norm): SequenceNorm(
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
        )
      )
      (5): MegaDecoderLayer(
        (mega_layer): MovingAverageGatedAttention(
          edim=512, zdim=128, hdim=1024, ndim=16, chunk=-1, attn_act=softmax, prenorm=False
          (dropout): FairseqDropout(p=0.2)
          (hidden_dropout): FairseqDropout(p=0.0)
          (attention_dropout): FairseqDropout(p=0.0)
          (norm): SequenceNorm(
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (move): MultiHeadEMA(edim=512, ndim=16, bidirectional=False, trunction=1024)
          (v_proj): Linear(in_features=512, out_features=1024, bias=True)
          (mx_proj): Linear(in_features=512, out_features=2176, bias=True)
          (h_proj): Linear(in_features=1024, out_features=512, bias=True)
          (rel_pos_bias): SimpleRelativePositionalBias(max positions=1024)
        )
        (cross_attn): GatedCrossAttention(
          edim=512, zdim=128, ndim=16, attn_act=softmax, prenorm=False
          (dropout): FairseqDropout(p=0.2)
          (hidden_dropout): FairseqDropout(p=0.0)
          (attention_dropout): FairseqDropout(p=0.0)
          (norm): SequenceNorm(
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (k_proj): Linear(in_features=512, out_features=128, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=1152, bias=True)
          (h_proj): Linear(in_features=512, out_features=512, bias=True)
          (rel_pos_bias): SimpleRelativePositionalBias(max positions=1024)
        )
        (nffn): NormalizedFeedForwardNetwork(
          edim=512, hdim=1024, act=silu, prenorm=False
          (dropout): FairseqDropout(p=0.2)
          (hidden_dropout): FairseqDropout(p=0.0)
          (norm): SequenceNorm(
            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
        )
      )
    )
    (output_projection): Linear(in_features=512, out_features=34088, bias=False)
  )
)
2023-05-26 07:00:46 | INFO | fairseq_cli.train | task: document_translation (ConcatTranslationTask)
2023-05-26 07:00:46 | INFO | fairseq_cli.train | model: contextual_mega (ContextualMegaModel)
2023-05-26 07:00:46 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2023-05-26 07:00:46 | INFO | fairseq_cli.train | num. model params: 82641902 (num. trained: 82641902)
2023-05-26 07:00:46 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2023-05-26 07:00:46 | INFO | fairseq.utils | ***********************CUDA enviroments for all 2 workers***********************
2023-05-26 07:00:46 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 44.369 GB ; name = NVIDIA A40
2023-05-26 07:00:46 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 44.369 GB ; name = NVIDIA A40
2023-05-26 07:00:46 | INFO | fairseq.utils | ***********************CUDA enviroments for all 2 workers***********************
2023-05-26 07:00:46 | INFO | fairseq_cli.train | training on 2 devices (GPUs/TPUs)
2023-05-26 07:00:46 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None
2023-05-26 07:00:46 | INFO | fairseq.trainer | no existing checkpoint found /project/jonmay_231/linghaoj/reproduce/ckpt/mega-1-1-0.2-sf[zh-en]/checkpoint_last.pt
2023-05-26 07:00:46 | INFO | fairseq.trainer | loading train data for epoch 1
2023-05-26 07:00:47 | INFO | fairseq.data.data_utils | loaded 9878328 examples from: /project/jonmay_231/linghaoj/canmt/bwb/data/bin/train.zh-en.zh
2023-05-26 07:00:49 | INFO | fairseq.data.data_utils | loaded 9878328 examples from: /project/jonmay_231/linghaoj/canmt/bwb/data/bin/train.zh-en.en
/home1/linghaoj/anaconda3/envs/env-mega/lib/python3.9/site-packages/torch/nn/parallel/distributed.py:629: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.
  warnings.warn(
2023-05-26 07:03:39 | INFO | fairseq.trainer | begin training epoch 1
2023-05-26 07:03:54 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 64.0
2023-05-26 07:03:54 | INFO | torch.nn.parallel.distributed | Reducer buckets have been rebuilt in this iteration.
2023-05-26 07:03:58 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 07:04:02 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 07:06:04 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 07:07:28 | INFO | train_inner | epoch 001:    104 / 6686 loss=15.426, nll_loss=15.314, ppl=40736.9, wps=27902.4, ups=0.49, wpb=57238.5, bsz=1488.3, num_updates=100, lr=2.5e-05, gnorm=2.566, clip=100, loss_scale=13, train_wall=201, wall=402
2023-05-26 07:10:49 | INFO | train_inner | epoch 001:    204 / 6686 loss=11.339, nll_loss=10.807, ppl=1791.63, wps=28547.1, ups=0.5, wpb=57189.2, bsz=1472.2, num_updates=200, lr=5e-05, gnorm=0.667, clip=100, loss_scale=8, train_wall=195, wall=603
2023-05-26 07:14:07 | INFO | train_inner | epoch 001:    304 / 6686 loss=9.747, nll_loss=8.934, ppl=488.94, wps=28959.1, ups=0.51, wpb=57299, bsz=1485.8, num_updates=300, lr=7.5e-05, gnorm=0.314, clip=100, loss_scale=8, train_wall=194, wall=801
2023-05-26 07:17:24 | INFO | train_inner | epoch 001:    404 / 6686 loss=9.13, nll_loss=8.209, ppl=295.84, wps=28928.9, ups=0.51, wpb=57107.2, bsz=1449.8, num_updates=400, lr=0.0001, gnorm=0.297, clip=100, loss_scale=8, train_wall=194, wall=998
2023-05-26 07:20:42 | INFO | train_inner | epoch 001:    504 / 6686 loss=8.733, nll_loss=7.743, ppl=214.26, wps=28961.3, ups=0.51, wpb=57212.7, bsz=1444.7, num_updates=500, lr=0.000125, gnorm=0.358, clip=100, loss_scale=8, train_wall=194, wall=1196
2023-05-26 07:24:00 | INFO | train_inner | epoch 001:    604 / 6686 loss=8.477, nll_loss=7.444, ppl=174.1, wps=28904.8, ups=0.5, wpb=57269.2, bsz=1489.8, num_updates=600, lr=0.00015, gnorm=0.411, clip=100, loss_scale=10, train_wall=194, wall=1394
2023-05-26 07:27:18 | INFO | train_inner | epoch 001:    704 / 6686 loss=8.279, nll_loss=7.212, ppl=148.24, wps=28785.3, ups=0.5, wpb=57093, bsz=1470.2, num_updates=700, lr=0.000175, gnorm=0.414, clip=100, loss_scale=16, train_wall=194, wall=1592
2023-05-26 07:30:36 | INFO | train_inner | epoch 001:    804 / 6686 loss=8.093, nll_loss=6.995, ppl=127.54, wps=28895.5, ups=0.5, wpb=57231.1, bsz=1478, num_updates=800, lr=0.0002, gnorm=0.389, clip=100, loss_scale=16, train_wall=194, wall=1790
2023-05-26 07:33:54 | INFO | train_inner | epoch 001:    904 / 6686 loss=7.948, nll_loss=6.826, ppl=113.47, wps=28965.4, ups=0.5, wpb=57360.4, bsz=1494.3, num_updates=900, lr=0.000225, gnorm=0.402, clip=100, loss_scale=16, train_wall=194, wall=1988
2023-05-26 07:37:12 | INFO | train_inner | epoch 001:   1004 / 6686 loss=7.808, nll_loss=6.664, ppl=101.43, wps=28993.2, ups=0.51, wpb=57198.9, bsz=1491.4, num_updates=1000, lr=0.00025, gnorm=0.396, clip=100, loss_scale=16, train_wall=193, wall=2185
2023-05-26 07:40:30 | INFO | train_inner | epoch 001:   1104 / 6686 loss=7.678, nll_loss=6.515, ppl=91.43, wps=28928.6, ups=0.5, wpb=57298.1, bsz=1481.9, num_updates=1100, lr=0.000275, gnorm=0.394, clip=100, loss_scale=19, train_wall=194, wall=2383
2023-05-26 07:43:47 | INFO | train_inner | epoch 001:   1204 / 6686 loss=7.53, nll_loss=6.345, ppl=81.27, wps=28968.3, ups=0.51, wpb=57235.3, bsz=1481.4, num_updates=1200, lr=0.0003, gnorm=0.4, clip=100, loss_scale=32, train_wall=194, wall=2581
2023-05-26 07:46:01 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 07:47:07 | INFO | train_inner | epoch 001:   1305 / 6686 loss=7.365, nll_loss=6.156, ppl=71.29, wps=28722.6, ups=0.5, wpb=57336.1, bsz=1489.9, num_updates=1300, lr=0.000325, gnorm=0.417, clip=100, loss_scale=27, train_wall=196, wall=2781
2023-05-26 07:50:25 | INFO | train_inner | epoch 001:   1405 / 6686 loss=7.199, nll_loss=5.965, ppl=62.49, wps=28925.8, ups=0.5, wpb=57344.4, bsz=1503.6, num_updates=1400, lr=0.00035, gnorm=0.406, clip=100, loss_scale=16, train_wall=194, wall=2979
2023-05-26 07:53:43 | INFO | train_inner | epoch 001:   1505 / 6686 loss=7.037, nll_loss=5.779, ppl=54.92, wps=28883.8, ups=0.51, wpb=57171, bsz=1483.7, num_updates=1500, lr=0.000375, gnorm=0.442, clip=100, loss_scale=16, train_wall=194, wall=3177
2023-05-26 07:57:01 | INFO | train_inner | epoch 001:   1605 / 6686 loss=6.855, nll_loss=5.571, ppl=47.52, wps=28914.7, ups=0.5, wpb=57259.8, bsz=1482.6, num_updates=1600, lr=0.0004, gnorm=0.441, clip=100, loss_scale=16, train_wall=194, wall=3375
2023-05-26 08:00:19 | INFO | train_inner | epoch 001:   1705 / 6686 loss=6.665, nll_loss=5.353, ppl=40.86, wps=28955.4, ups=0.51, wpb=57300.7, bsz=1486.2, num_updates=1700, lr=0.000425, gnorm=0.432, clip=100, loss_scale=16, train_wall=194, wall=3573
2023-05-26 08:03:08 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 08:03:37 | INFO | train_inner | epoch 001:   1806 / 6686 loss=6.507, nll_loss=5.171, ppl=36.02, wps=28832.1, ups=0.5, wpb=57139.8, bsz=1442.6, num_updates=1800, lr=0.00045, gnorm=0.431, clip=100, loss_scale=17, train_wall=194, wall=3771
2023-05-26 08:05:45 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 08:06:57 | INFO | train_inner | epoch 001:   1907 / 6686 loss=6.336, nll_loss=4.975, ppl=31.44, wps=28690.8, ups=0.5, wpb=57294, bsz=1459.8, num_updates=1900, lr=0.000475, gnorm=0.427, clip=100, loss_scale=13, train_wall=196, wall=3971
2023-05-26 08:10:15 | INFO | train_inner | epoch 001:   2007 / 6686 loss=6.177, nll_loss=4.792, ppl=27.7, wps=28922.5, ups=0.5, wpb=57294.4, bsz=1516.8, num_updates=2000, lr=0.0005, gnorm=0.411, clip=100, loss_scale=8, train_wall=194, wall=4169
2023-05-26 08:13:31 | INFO | train_inner | epoch 001:   2107 / 6686 loss=6.064, nll_loss=4.662, ppl=25.32, wps=29067.5, ups=0.51, wpb=57105.8, bsz=1472.6, num_updates=2100, lr=0.000525, gnorm=0.415, clip=100, loss_scale=8, train_wall=193, wall=4365
2023-05-26 08:16:49 | INFO | train_inner | epoch 001:   2207 / 6686 loss=5.962, nll_loss=4.545, ppl=23.35, wps=28947.9, ups=0.51, wpb=57299, bsz=1493, num_updates=2200, lr=0.00055, gnorm=0.424, clip=100, loss_scale=8, train_wall=194, wall=4563
2023-05-26 08:20:07 | INFO | train_inner | epoch 001:   2307 / 6686 loss=5.866, nll_loss=4.435, ppl=21.63, wps=28959.4, ups=0.51, wpb=57142.7, bsz=1469.4, num_updates=2300, lr=0.000575, gnorm=0.388, clip=100, loss_scale=8, train_wall=193, wall=4761
2023-05-26 08:23:24 | INFO | train_inner | epoch 001:   2407 / 6686 loss=5.782, nll_loss=4.339, ppl=20.24, wps=28958.9, ups=0.51, wpb=57143.5, bsz=1479.7, num_updates=2400, lr=0.0006, gnorm=0.386, clip=100, loss_scale=10, train_wall=193, wall=4958
2023-05-26 08:26:42 | INFO | train_inner | epoch 001:   2507 / 6686 loss=5.701, nll_loss=4.248, ppl=18.99, wps=28856.7, ups=0.51, wpb=57026.8, bsz=1478.6, num_updates=2500, lr=0.000625, gnorm=0.388, clip=100, loss_scale=16, train_wall=194, wall=5155
2023-05-26 08:29:59 | INFO | train_inner | epoch 001:   2607 / 6686 loss=5.623, nll_loss=4.159, ppl=17.86, wps=29010.7, ups=0.51, wpb=57404.4, bsz=1499, num_updates=2600, lr=0.00065, gnorm=0.361, clip=100, loss_scale=16, train_wall=194, wall=5353
2023-05-26 08:33:18 | INFO | train_inner | epoch 001:   2707 / 6686 loss=5.569, nll_loss=4.097, ppl=17.12, wps=28904.9, ups=0.5, wpb=57245.5, bsz=1504.2, num_updates=2700, lr=0.000675, gnorm=0.358, clip=100, loss_scale=16, train_wall=194, wall=5551
2023-05-26 08:36:35 | INFO | train_inner | epoch 001:   2807 / 6686 loss=5.534, nll_loss=4.058, ppl=16.66, wps=29104.9, ups=0.51, wpb=57459.5, bsz=1453.9, num_updates=2800, lr=0.0007, gnorm=0.363, clip=100, loss_scale=16, train_wall=194, wall=5749
2023-05-26 08:39:52 | INFO | train_inner | epoch 001:   2907 / 6686 loss=5.487, nll_loss=4.005, ppl=16.06, wps=28982.2, ups=0.51, wpb=57209.6, bsz=1461.4, num_updates=2900, lr=0.000725, gnorm=0.362, clip=100, loss_scale=18, train_wall=194, wall=5946
2023-05-26 08:42:28 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 08:43:12 | INFO | train_inner | epoch 001:   3008 / 6686 loss=5.435, nll_loss=3.947, ppl=15.42, wps=28657.1, ups=0.5, wpb=57197.7, bsz=1481.4, num_updates=3000, lr=0.00075, gnorm=0.352, clip=100, loss_scale=28, train_wall=196, wall=6146
2023-05-26 08:46:29 | INFO | train_inner | epoch 001:   3108 / 6686 loss=5.4, nll_loss=3.909, ppl=15.02, wps=29031, ups=0.51, wpb=57212.5, bsz=1492.2, num_updates=3100, lr=0.000775, gnorm=0.329, clip=100, loss_scale=16, train_wall=193, wall=6343
2023-05-26 08:49:46 | INFO | train_inner | epoch 001:   3208 / 6686 loss=5.37, nll_loss=3.875, ppl=14.67, wps=28950.1, ups=0.51, wpb=57013.2, bsz=1467.9, num_updates=3200, lr=0.0008, gnorm=0.323, clip=100, loss_scale=16, train_wall=193, wall=6540
2023-05-26 08:53:03 | INFO | train_inner | epoch 001:   3308 / 6686 loss=5.319, nll_loss=3.817, ppl=14.1, wps=29032.6, ups=0.51, wpb=57317.6, bsz=1476.2, num_updates=3300, lr=0.000825, gnorm=0.333, clip=100, loss_scale=16, train_wall=194, wall=6737
2023-05-26 08:56:21 | INFO | train_inner | epoch 001:   3408 / 6686 loss=5.299, nll_loss=3.796, ppl=13.89, wps=28950.6, ups=0.51, wpb=57161.2, bsz=1476.9, num_updates=3400, lr=0.00085, gnorm=0.334, clip=100, loss_scale=16, train_wall=194, wall=6935
2023-05-26 08:59:24 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 08:59:40 | INFO | train_inner | epoch 001:   3509 / 6686 loss=5.259, nll_loss=3.751, ppl=13.46, wps=28777.7, ups=0.5, wpb=57185.3, bsz=1463.6, num_updates=3500, lr=0.000875, gnorm=0.324, clip=100, loss_scale=16, train_wall=195, wall=7133
2023-05-26 09:02:57 | INFO | train_inner | epoch 001:   3609 / 6686 loss=5.241, nll_loss=3.732, ppl=13.28, wps=28914.1, ups=0.51, wpb=57152.8, bsz=1465.9, num_updates=3600, lr=0.0009, gnorm=0.33, clip=100, loss_scale=16, train_wall=194, wall=7331
2023-05-26 09:06:15 | INFO | train_inner | epoch 001:   3709 / 6686 loss=5.215, nll_loss=3.703, ppl=13.02, wps=28916.2, ups=0.51, wpb=57227.4, bsz=1489.1, num_updates=3700, lr=0.000925, gnorm=0.319, clip=100, loss_scale=16, train_wall=194, wall=7529
2023-05-26 09:09:32 | INFO | train_inner | epoch 001:   3809 / 6686 loss=5.185, nll_loss=3.669, ppl=12.72, wps=28983.8, ups=0.51, wpb=57197.5, bsz=1462.2, num_updates=3800, lr=0.00095, gnorm=0.316, clip=100, loss_scale=16, train_wall=194, wall=7726
2023-05-26 09:12:49 | INFO | train_inner | epoch 001:   3909 / 6686 loss=5.166, nll_loss=3.648, ppl=12.54, wps=28986.1, ups=0.51, wpb=56815.4, bsz=1461.8, num_updates=3900, lr=0.000975, gnorm=0.326, clip=100, loss_scale=16, train_wall=192, wall=7922
2023-05-26 09:16:05 | INFO | train_inner | epoch 001:   4009 / 6686 loss=5.141, nll_loss=3.621, ppl=12.3, wps=28993.9, ups=0.51, wpb=57106.1, bsz=1443, num_updates=4000, lr=0.001, gnorm=0.312, clip=100, loss_scale=16, train_wall=193, wall=8119
2023-05-26 09:16:29 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 09:19:24 | INFO | train_inner | epoch 001:   4110 / 6686 loss=5.113, nll_loss=3.589, ppl=12.04, wps=28774.3, ups=0.5, wpb=57215.5, bsz=1501.6, num_updates=4100, lr=0.00098773, gnorm=0.31, clip=100, loss_scale=17, train_wall=195, wall=8318
2023-05-26 09:22:42 | INFO | train_inner | epoch 001:   4210 / 6686 loss=5.111, nll_loss=3.587, ppl=12.02, wps=28872.7, ups=0.51, wpb=57004.4, bsz=1481.4, num_updates=4200, lr=0.0009759, gnorm=0.305, clip=100, loss_scale=16, train_wall=194, wall=8516
2023-05-26 09:26:00 | INFO | train_inner | epoch 001:   4310 / 6686 loss=5.077, nll_loss=3.55, ppl=11.71, wps=28752.8, ups=0.5, wpb=57127.4, bsz=1496.5, num_updates=4300, lr=0.000964486, gnorm=0.31, clip=100, loss_scale=16, train_wall=195, wall=8714
2023-05-26 09:29:18 | INFO | train_inner | epoch 001:   4410 / 6686 loss=5.045, nll_loss=3.515, ppl=11.43, wps=29017.6, ups=0.51, wpb=57316.4, bsz=1484.2, num_updates=4400, lr=0.000953463, gnorm=0.299, clip=100, loss_scale=16, train_wall=194, wall=8912
2023-05-26 09:32:35 | INFO | train_inner | epoch 001:   4510 / 6686 loss=5.03, nll_loss=3.498, ppl=11.3, wps=28977.3, ups=0.51, wpb=57085, bsz=1475.8, num_updates=4500, lr=0.000942809, gnorm=0.3, clip=100, loss_scale=16, train_wall=193, wall=9109
2023-05-26 09:33:53 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 09:35:54 | INFO | train_inner | epoch 001:   4611 / 6686 loss=5.018, nll_loss=3.485, ppl=11.19, wps=28797.8, ups=0.5, wpb=57180.9, bsz=1477.2, num_updates=4600, lr=0.000932505, gnorm=0.303, clip=100, loss_scale=19, train_wall=195, wall=9307
2023-05-26 09:39:11 | INFO | train_inner | epoch 001:   4711 / 6686 loss=4.996, nll_loss=3.461, ppl=11.01, wps=28975.1, ups=0.51, wpb=57188.3, bsz=1476.9, num_updates=4700, lr=0.000922531, gnorm=0.294, clip=100, loss_scale=16, train_wall=194, wall=9505
2023-05-26 09:42:29 | INFO | train_inner | epoch 001:   4811 / 6686 loss=4.974, nll_loss=3.437, ppl=10.83, wps=28978.2, ups=0.51, wpb=57261.8, bsz=1476.4, num_updates=4800, lr=0.000912871, gnorm=0.28, clip=100, loss_scale=16, train_wall=194, wall=9702
2023-05-26 09:45:46 | INFO | train_inner | epoch 001:   4911 / 6686 loss=4.961, nll_loss=3.422, ppl=10.71, wps=28983.7, ups=0.51, wpb=57165.3, bsz=1476.9, num_updates=4900, lr=0.000903508, gnorm=0.281, clip=100, loss_scale=16, train_wall=193, wall=9900
2023-05-26 09:49:03 | INFO | train_inner | epoch 001:   5011 / 6686 loss=4.946, nll_loss=3.406, ppl=10.6, wps=29042.3, ups=0.51, wpb=57164.3, bsz=1464, num_updates=5000, lr=0.000894427, gnorm=0.284, clip=100, loss_scale=16, train_wall=193, wall=10096
2023-05-26 09:50:57 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 09:52:21 | INFO | train_inner | epoch 001:   5112 / 6686 loss=4.933, nll_loss=3.39, ppl=10.49, wps=28719.7, ups=0.5, wpb=57094, bsz=1465.5, num_updates=5100, lr=0.000885615, gnorm=0.276, clip=100, loss_scale=17, train_wall=195, wall=10295
2023-05-26 09:55:39 | INFO | train_inner | epoch 001:   5212 / 6686 loss=4.915, nll_loss=3.371, ppl=10.35, wps=28986.2, ups=0.51, wpb=57275.5, bsz=1483.2, num_updates=5200, lr=0.000877058, gnorm=0.289, clip=100, loss_scale=16, train_wall=194, wall=10493
2023-05-26 09:58:56 | INFO | train_inner | epoch 001:   5312 / 6686 loss=4.905, nll_loss=3.36, ppl=10.26, wps=28931.5, ups=0.51, wpb=57092.9, bsz=1495.4, num_updates=5300, lr=0.000868744, gnorm=0.289, clip=100, loss_scale=16, train_wall=194, wall=10690
2023-05-26 10:02:13 | INFO | train_inner | epoch 001:   5412 / 6686 loss=4.892, nll_loss=3.346, ppl=10.17, wps=29005.1, ups=0.51, wpb=57091.2, bsz=1477.1, num_updates=5400, lr=0.000860663, gnorm=0.275, clip=100, loss_scale=16, train_wall=193, wall=10887
2023-05-26 10:05:30 | INFO | train_inner | epoch 001:   5512 / 6686 loss=4.883, nll_loss=3.336, ppl=10.1, wps=29143.1, ups=0.51, wpb=57466, bsz=1449.6, num_updates=5500, lr=0.000852803, gnorm=0.277, clip=100, loss_scale=16, train_wall=194, wall=11084
2023-05-26 10:08:13 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 10:08:49 | INFO | train_inner | epoch 001:   5613 / 6686 loss=4.87, nll_loss=3.322, ppl=10, wps=28753.8, ups=0.5, wpb=57016.5, bsz=1460.6, num_updates=5600, lr=0.000845154, gnorm=0.278, clip=100, loss_scale=18, train_wall=194, wall=11283
2023-05-26 10:09:11 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 10:12:09 | INFO | train_inner | epoch 001:   5714 / 6686 loss=4.854, nll_loss=3.303, ppl=9.87, wps=28511.8, ups=0.5, wpb=57077.8, bsz=1480.1, num_updates=5700, lr=0.000837708, gnorm=0.274, clip=100, loss_scale=9, train_wall=196, wall=11483
2023-05-26 10:15:27 | INFO | train_inner | epoch 001:   5814 / 6686 loss=4.83, nll_loss=3.277, ppl=9.69, wps=29012.8, ups=0.51, wpb=57377.1, bsz=1483.9, num_updates=5800, lr=0.000830455, gnorm=0.275, clip=100, loss_scale=8, train_wall=194, wall=11680
2023-05-26 10:18:45 | INFO | train_inner | epoch 001:   5914 / 6686 loss=4.832, nll_loss=3.279, ppl=9.71, wps=28919.6, ups=0.5, wpb=57308.1, bsz=1492, num_updates=5900, lr=0.000823387, gnorm=0.265, clip=100, loss_scale=8, train_wall=194, wall=11879
2023-05-26 10:22:02 | INFO | train_inner | epoch 001:   6014 / 6686 loss=4.827, nll_loss=3.274, ppl=9.67, wps=28983.5, ups=0.51, wpb=57147.6, bsz=1475.2, num_updates=6000, lr=0.000816497, gnorm=0.273, clip=100, loss_scale=8, train_wall=193, wall=12076
2023-05-26 10:25:20 | INFO | train_inner | epoch 001:   6114 / 6686 loss=4.815, nll_loss=3.261, ppl=9.59, wps=28977.5, ups=0.51, wpb=57242, bsz=1476.2, num_updates=6100, lr=0.000809776, gnorm=0.265, clip=100, loss_scale=8, train_wall=194, wall=12273
2023-05-26 10:28:36 | INFO | train_inner | epoch 001:   6214 / 6686 loss=4.814, nll_loss=3.259, ppl=9.58, wps=28978.2, ups=0.51, wpb=57054.3, bsz=1456.2, num_updates=6200, lr=0.000803219, gnorm=0.268, clip=100, loss_scale=14, train_wall=193, wall=12470
2023-05-26 10:31:54 | INFO | train_inner | epoch 001:   6314 / 6686 loss=4.794, nll_loss=3.238, ppl=9.44, wps=28924, ups=0.51, wpb=57202.7, bsz=1487.3, num_updates=6300, lr=0.000796819, gnorm=0.271, clip=100, loss_scale=16, train_wall=194, wall=12668
2023-05-26 10:35:12 | INFO | train_inner | epoch 001:   6414 / 6686 loss=4.777, nll_loss=3.219, ppl=9.31, wps=28944.1, ups=0.51, wpb=57200.2, bsz=1502.6, num_updates=6400, lr=0.000790569, gnorm=0.258, clip=100, loss_scale=16, train_wall=194, wall=12866
2023-05-26 10:38:29 | INFO | train_inner | epoch 001:   6514 / 6686 loss=4.796, nll_loss=3.24, ppl=9.45, wps=29038.8, ups=0.51, wpb=57146.6, bsz=1448.2, num_updates=6500, lr=0.000784465, gnorm=0.263, clip=100, loss_scale=16, train_wall=193, wall=13062
2023-05-26 10:41:46 | INFO | train_inner | epoch 001:   6614 / 6686 loss=4.771, nll_loss=3.212, ppl=9.27, wps=28879.4, ups=0.51, wpb=57012.4, bsz=1498, num_updates=6600, lr=0.000778499, gnorm=0.262, clip=100, loss_scale=16, train_wall=194, wall=13260
2023-05-26 10:42:57 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 10:44:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-26 10:44:12 | INFO | fairseq.tasks.translation | example hypothesis: Why? Why? Was he unhappy? Why was he unhappy? Why was he unhappy? Why was he so unhappy?
2023-05-26 10:44:12 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-26 10:44:14 | INFO | fairseq.tasks.translation | example hypothesis: After a while, I will let you lose, not even your trousers are left! I’m not sure if I can get out of it.
2023-05-26 10:44:14 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-26 10:44:15 | INFO | fairseq.tasks.translation | example hypothesis: Shen Liangchuan had just heaved a sigh of relief when he heard her say, “I’m going to call you in the same room!”
2023-05-26 10:44:15 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-26 10:44:17 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved and entered the elevator.
2023-05-26 10:44:17 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-26 10:44:20 | INFO | fairseq.tasks.translation | example hypothesis: As soon as she raised her head, she saw Song Cheng standing in the distance. Song Cheng was standing in the distance.
2023-05-26 10:44:20 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-26 10:44:21 | INFO | fairseq.tasks.translation | example hypothesis: Song Cheng patted his chest and said, “I’m scared to death! Where’s Wang Chuan?”
2023-05-26 10:44:21 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-26 10:44:23 | INFO | fairseq.tasks.translation | example hypothesis: I said, “I won’t go. I won’t be able to eat it,” I said, “I can’t eat it.”
2023-05-26 10:44:23 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-26 10:44:24 | INFO | fairseq.tasks.translation | example hypothesis: The crowd was skeptical, but Wang Wenhao had insisted on Wang Wenhao.
2023-05-26 10:44:24 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-26 10:44:27 | INFO | fairseq.tasks.translation | example hypothesis: With his identity, even if Baili Hongzhuang didn’t cure him, she would still have to cure him!
2023-05-26 10:44:27 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-26 10:44:29 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian: “Mr. Shen, I, I’ve left too much blood and my brain is missing oxygen. I can’t figure it out. Or do you give me a notification?” Shen Liangchuan’
2023-05-26 10:44:29 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-26 10:44:32 | INFO | fairseq.tasks.translation | example hypothesis: He didn’t know why this matter would spread to so many people. Since he couldn’t conceal it, he might as well just say it out loud. However, he didn’t know why Li Yuyue was injured.
2023-05-26 10:44:32 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-26 10:44:34 | INFO | fairseq.tasks.translation | example hypothesis: Ye Qing Ling’s voice was deliberately lowered, but it was unable to conceal the viciousness and ruthlessness in the tone of her voice.
2023-05-26 10:44:34 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-26 10:44:36 | INFO | fairseq.tasks.translation | example hypothesis: Different rank beast pets had the same strength, but the beast pet was precious and rare. Ordinary people would not have it, and even an official’s disciple would not be able to possess it. However, this was a very rare
2023-05-26 10:44:36 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-26 10:44:38 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chixia gritted her teeth and cursed in a low voice, "What's wrong with you?"
2023-05-26 10:44:38 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-26 10:44:41 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang had concealed herself well, Di BeiChen still saw the ripples in her eyes, and a hint of warmth could be seen in his eyes.
2023-05-26 10:44:41 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-26 10:44:43 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia walked in, not to mention the guests who had entered, she didn't even see a few waiters. However, Fang Chi Xia didn't know what to do with Fang Chi Xia.
2023-05-26 10:44:43 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-26 10:44:46 | INFO | fairseq.tasks.translation | example hypothesis: This person was the fourth young miss of the Ye family – Ye Qingling.
2023-05-26 10:44:46 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-26 10:44:49 | INFO | fairseq.tasks.translation | example hypothesis: Because at this moment, she felt that her chin was about to break.
2023-05-26 10:44:49 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-26 10:44:52 | INFO | fairseq.tasks.translation | example hypothesis: “Good Mu Zi, help me. If it wasn't because of you, that old fellow wouldn't have targeted me,” Mu Zi said with a smile.
2023-05-26 10:44:52 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-26 10:44:54 | INFO | fairseq.tasks.translation | example hypothesis: Baili Yuyan was even more excited. This matter was completely caused by her director. Previously, Bai Li Hongzhuang had treated her like this. This time, she would definitely make Bai Li Hongzhuang unhappy.
2023-05-26 10:44:54 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-26 10:44:56 | INFO | fairseq.tasks.translation | example hypothesis: How could that be? They also have four mages over there, so they won’t submit so easily. After arguing for a long time, I finally decided to use a method to control the kingdom in the future.”
2023-05-26 10:44:56 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-26 10:44:58 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a little. Originally, he had been looking for a reason for Li Yuyue to not participate in the Royal Hunting Competition. However, Li Chengqian didn’t know what to do.
2023-05-26 10:44:58 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-26 10:45:01 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, how’s my standard? They’re all the most outstanding people in the country. My magic is so weak, right?”
2023-05-26 10:45:01 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-26 10:45:07 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yibei’s meaning was that if Fang Chixia didn’t want to go, then she didn’t need to go. If Fang Chixia didn’t want to go, then she wouldn’t have to go. If Fang Chixia didn’t want to go, then she wouldn’t have to go.
2023-05-26 10:45:07 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-26 10:45:11 | INFO | fairseq.tasks.translation | example hypothesis: She tilted her head and saw five palm marks on her cheeks that were extremely eye-catching. They were swollen at a speed visible to the naked eye. When she reached out and touched them, she couldn’t help but let out a hissing sound. It was really painful.
2023-05-26 10:45:11 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-26 10:45:14 | INFO | fairseq.tasks.translation | example hypothesis: This... How could this be the charm that that piece of trash was able to emit? Could it be that this was the charm of that trash?
2023-05-26 10:45:14 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-26 10:45:15 | INFO | fairseq.tasks.translation | example hypothesis: How could Wang Wenhao find the report agency? The chief editor should have called to inform her not to come to the newspaper. However, these three people... had schemed against her!
2023-05-26 10:45:15 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-26 10:45:21 | INFO | fairseq.tasks.translation | example hypothesis: I was delighted when I heard Teacher Di’s compliment, so I pulled back the energy ball with my left hand and sent out a light sword to strike Teacher Zhen. The light sword was unexpectedly successfully struck, and I was shocked. After taking a closer look, I realized that it was just an afterimage. Teacher Zhen had already moved behind me and shouted, “Berserk Space.”
2023-05-26 10:45:21 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-26 10:45:27 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Originally, we proposed three rounds of competition, but they couldn’t say that it’s fair, because we have Teacher Di and Teacher Zhen, their ranking is higher than theirs, and they proposed five matches to win three wins. Because the competition was brought up by us, we could only listen to them in the end. Three days later, we will have a secret competition in the Royal Martial Arts Tournament. If we don’t win, we will
2023-05-26 10:45:27 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-26 10:45:30 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Di used the Light Element Level 7 spell, Light Lightning, and I didn’t use this spell, because I didn’t have a good control over it. Teacher Di sent out nine Light Lightning to surround me and formed a simple spell formation that allowed me to escape in a short distance. After that, all of the Light Lightning exploded and formed a powerful attack.
2023-05-26 10:45:30 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-26 10:45:35 | INFO | fairseq.tasks.translation | example hypothesis: As soon as Ma Ke and his two teachers walked to the other side, Teacher Zhen sent me a small Dimensional Slash. As expected of the number one Magician on the continent, the powerful suction force that he released was much stronger than mine. A small spatial crack appeared beside me, and a powerful suction force immediately swept over.
2023-05-26 10:45:35 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-26 10:45:37 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.726 | nll_loss 3.119 | ppl 8.69 | bleu 16.02 | wps 862.7 | wpb 2420.8 | bsz 84.5 | num_updates 6671
2023-05-26 10:45:37 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-26 10:45:40 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/mega-1-1-0.2-sf[zh-en]/checkpoint_best.pt (epoch 1 @ 6671 updates, score 16.02) (writing took 2.72644513938576 seconds)
2023-05-26 10:45:40 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-05-26 10:45:40 | INFO | train | epoch 001 | loss 6.074 | nll_loss 4.688 | ppl 25.78 | wps 28692.3 | ups 0.5 | wpb 57189.7 | bsz 1477.5 | num_updates 6671 | lr 0.000774345 | gnorm 0.374 | clip 100 | loss_scale 15 | train_wall 12963 | wall 13494
2023-05-26 10:45:40 | INFO | fairseq.trainer | begin training epoch 2
2023-05-26 10:46:45 | INFO | train_inner | epoch 002:     29 / 6686 loss=4.765, nll_loss=3.206, ppl=9.23, wps=18936.7, ups=0.33, wpb=56687.8, bsz=1454.2, num_updates=6700, lr=0.000772667, gnorm=0.26, clip=100, loss_scale=16, train_wall=197, wall=13559
2023-05-26 10:50:08 | INFO | train_inner | epoch 002:    129 / 6686 loss=4.739, nll_loss=3.176, ppl=9.04, wps=28180.9, ups=0.49, wpb=57165.1, bsz=1457.8, num_updates=6800, lr=0.000766965, gnorm=0.258, clip=100, loss_scale=16, train_wall=197, wall=13762
2023-05-26 10:53:28 | INFO | train_inner | epoch 002:    229 / 6686 loss=4.736, nll_loss=3.174, ppl=9.02, wps=28514.2, ups=0.5, wpb=57000.9, bsz=1469.8, num_updates=6900, lr=0.000761387, gnorm=0.254, clip=100, loss_scale=16, train_wall=195, wall=13962
2023-05-26 10:56:46 | INFO | train_inner | epoch 002:    329 / 6686 loss=4.721, nll_loss=3.156, ppl=8.92, wps=29000.2, ups=0.51, wpb=57265.9, bsz=1478.2, num_updates=7000, lr=0.000755929, gnorm=0.264, clip=100, loss_scale=16, train_wall=193, wall=14159
2023-05-26 11:00:03 | INFO | train_inner | epoch 002:    429 / 6686 loss=4.732, nll_loss=3.169, ppl=8.99, wps=29035.1, ups=0.51, wpb=57363.3, bsz=1476.6, num_updates=7100, lr=0.000750587, gnorm=0.251, clip=100, loss_scale=16, train_wall=194, wall=14357
2023-05-26 11:01:38 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 11:03:23 | INFO | train_inner | epoch 002:    530 / 6686 loss=4.722, nll_loss=3.158, ppl=8.93, wps=28746.7, ups=0.5, wpb=57394.2, bsz=1469.8, num_updates=7200, lr=0.000745356, gnorm=0.262, clip=100, loss_scale=16, train_wall=196, wall=14557
2023-05-26 11:06:40 | INFO | train_inner | epoch 002:    630 / 6686 loss=4.713, nll_loss=3.148, ppl=8.87, wps=28973.1, ups=0.51, wpb=57263.6, bsz=1473.7, num_updates=7300, lr=0.000740233, gnorm=0.255, clip=100, loss_scale=16, train_wall=194, wall=14754
2023-05-26 11:09:58 | INFO | train_inner | epoch 002:    730 / 6686 loss=4.696, nll_loss=3.128, ppl=8.75, wps=28946.7, ups=0.51, wpb=57253, bsz=1476, num_updates=7400, lr=0.000735215, gnorm=0.256, clip=100, loss_scale=16, train_wall=194, wall=14952
2023-05-26 11:13:15 | INFO | train_inner | epoch 002:    830 / 6686 loss=4.706, nll_loss=3.141, ppl=8.82, wps=29087.1, ups=0.51, wpb=57131, bsz=1472.9, num_updates=7500, lr=0.000730297, gnorm=0.258, clip=100, loss_scale=16, train_wall=193, wall=15149
2023-05-26 11:16:32 | INFO | train_inner | epoch 002:    930 / 6686 loss=4.7, nll_loss=3.134, ppl=8.78, wps=28963.3, ups=0.51, wpb=57143.9, bsz=1478.3, num_updates=7600, lr=0.000725476, gnorm=0.248, clip=100, loss_scale=16, train_wall=194, wall=15346
2023-05-26 11:18:32 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 11:19:51 | INFO | train_inner | epoch 002:   1031 / 6686 loss=4.69, nll_loss=3.123, ppl=8.71, wps=28632.8, ups=0.5, wpb=57041, bsz=1466.1, num_updates=7700, lr=0.00072075, gnorm=0.25, clip=100, loss_scale=16, train_wall=195, wall=15545
2023-05-26 11:23:09 | INFO | train_inner | epoch 002:   1131 / 6686 loss=4.686, nll_loss=3.118, ppl=8.68, wps=28834.8, ups=0.51, wpb=57091.4, bsz=1477.7, num_updates=7800, lr=0.000716115, gnorm=0.259, clip=100, loss_scale=16, train_wall=194, wall=15743
2023-05-26 11:26:27 | INFO | train_inner | epoch 002:   1231 / 6686 loss=4.671, nll_loss=3.102, ppl=8.58, wps=28960.7, ups=0.51, wpb=57329.6, bsz=1489.6, num_updates=7900, lr=0.000711568, gnorm=0.251, clip=100, loss_scale=16, train_wall=194, wall=15941
2023-05-26 11:29:44 | INFO | train_inner | epoch 002:   1331 / 6686 loss=4.677, nll_loss=3.109, ppl=8.63, wps=29010.4, ups=0.51, wpb=57191.9, bsz=1472.2, num_updates=8000, lr=0.000707107, gnorm=0.246, clip=100, loss_scale=16, train_wall=193, wall=16138
2023-05-26 11:33:02 | INFO | train_inner | epoch 002:   1431 / 6686 loss=4.671, nll_loss=3.102, ppl=8.59, wps=28914.8, ups=0.51, wpb=57225.2, bsz=1468.4, num_updates=8100, lr=0.000702728, gnorm=0.253, clip=100, loss_scale=16, train_wall=194, wall=16336
2023-05-26 11:33:14 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 11:36:22 | INFO | train_inner | epoch 002:   1532 / 6686 loss=4.665, nll_loss=3.095, ppl=8.55, wps=28626.3, ups=0.5, wpb=57113.6, bsz=1461.1, num_updates=8200, lr=0.00069843, gnorm=0.25, clip=100, loss_scale=8, train_wall=196, wall=16536
2023-05-26 11:39:39 | INFO | train_inner | epoch 002:   1632 / 6686 loss=4.659, nll_loss=3.089, ppl=8.51, wps=28898.8, ups=0.51, wpb=57142.3, bsz=1480.9, num_updates=8300, lr=0.00069421, gnorm=0.243, clip=100, loss_scale=8, train_wall=194, wall=16733
2023-05-26 11:42:57 | INFO | train_inner | epoch 002:   1732 / 6686 loss=4.657, nll_loss=3.087, ppl=8.5, wps=28932, ups=0.51, wpb=57216.3, bsz=1493.2, num_updates=8400, lr=0.000690066, gnorm=0.239, clip=100, loss_scale=8, train_wall=194, wall=16931
2023-05-26 11:46:15 | INFO | train_inner | epoch 002:   1832 / 6686 loss=4.658, nll_loss=3.089, ppl=8.51, wps=28930.3, ups=0.51, wpb=57124, bsz=1465, num_updates=8500, lr=0.000685994, gnorm=0.241, clip=100, loss_scale=8, train_wall=194, wall=17129
2023-05-26 11:49:32 | INFO | train_inner | epoch 002:   1932 / 6686 loss=4.66, nll_loss=3.091, ppl=8.52, wps=28934.2, ups=0.51, wpb=57029.4, bsz=1458.8, num_updates=8600, lr=0.000681994, gnorm=0.243, clip=100, loss_scale=8, train_wall=193, wall=17326
2023-05-26 11:52:31 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 11:52:51 | INFO | train_inner | epoch 002:   2033 / 6686 loss=4.638, nll_loss=3.066, ppl=8.38, wps=28790.9, ups=0.5, wpb=57257.3, bsz=1492.6, num_updates=8700, lr=0.000678064, gnorm=0.243, clip=100, loss_scale=14, train_wall=195, wall=17525
2023-05-26 11:56:08 | INFO | train_inner | epoch 002:   2133 / 6686 loss=4.643, nll_loss=3.072, ppl=8.41, wps=29000.4, ups=0.51, wpb=57161.5, bsz=1470.2, num_updates=8800, lr=0.0006742, gnorm=0.246, clip=100, loss_scale=8, train_wall=193, wall=17722
2023-05-26 11:59:26 | INFO | train_inner | epoch 002:   2233 / 6686 loss=4.63, nll_loss=3.057, ppl=8.32, wps=28891.7, ups=0.5, wpb=57225.2, bsz=1492.6, num_updates=8900, lr=0.000670402, gnorm=0.247, clip=100, loss_scale=8, train_wall=194, wall=17920
2023-05-26 12:02:43 | INFO | train_inner | epoch 002:   2333 / 6686 loss=4.625, nll_loss=3.052, ppl=8.29, wps=29062, ups=0.51, wpb=57344, bsz=1478.6, num_updates=9000, lr=0.000666667, gnorm=0.239, clip=100, loss_scale=8, train_wall=194, wall=18117
2023-05-26 12:06:00 | INFO | train_inner | epoch 002:   2433 / 6686 loss=4.625, nll_loss=3.052, ppl=8.29, wps=29047.4, ups=0.51, wpb=57307, bsz=1473.8, num_updates=9100, lr=0.000662994, gnorm=0.242, clip=100, loss_scale=8, train_wall=193, wall=18314
2023-05-26 12:09:18 | INFO | train_inner | epoch 002:   2533 / 6686 loss=4.616, nll_loss=3.042, ppl=8.24, wps=28871.3, ups=0.51, wpb=57113, bsz=1477, num_updates=9200, lr=0.00065938, gnorm=0.24, clip=100, loss_scale=8, train_wall=194, wall=18512
2023-05-26 12:12:36 | INFO | train_inner | epoch 002:   2633 / 6686 loss=4.615, nll_loss=3.04, ppl=8.23, wps=28946.1, ups=0.5, wpb=57333, bsz=1483.9, num_updates=9300, lr=0.000655826, gnorm=0.242, clip=100, loss_scale=16, train_wall=194, wall=18710
2023-05-26 12:15:54 | INFO | train_inner | epoch 002:   2733 / 6686 loss=4.614, nll_loss=3.04, ppl=8.22, wps=29066.4, ups=0.51, wpb=57348, bsz=1499.1, num_updates=9400, lr=0.000652328, gnorm=0.236, clip=100, loss_scale=16, train_wall=193, wall=18908
2023-05-26 12:19:11 | INFO | train_inner | epoch 002:   2833 / 6686 loss=4.609, nll_loss=3.035, ppl=8.19, wps=29040.8, ups=0.51, wpb=57193.8, bsz=1475.1, num_updates=9500, lr=0.000648886, gnorm=0.236, clip=100, loss_scale=16, train_wall=193, wall=19104
2023-05-26 12:22:28 | INFO | train_inner | epoch 002:   2933 / 6686 loss=4.604, nll_loss=3.028, ppl=8.16, wps=28934.2, ups=0.51, wpb=56998.3, bsz=1475.2, num_updates=9600, lr=0.000645497, gnorm=0.231, clip=100, loss_scale=16, train_wall=193, wall=19301
2023-05-26 12:25:45 | INFO | train_inner | epoch 002:   3033 / 6686 loss=4.613, nll_loss=3.039, ppl=8.22, wps=28994.5, ups=0.51, wpb=57174.4, bsz=1483.4, num_updates=9700, lr=0.000642161, gnorm=0.236, clip=100, loss_scale=16, train_wall=193, wall=19499
2023-05-26 12:26:52 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 12:27:49 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 12:29:06 | INFO | train_inner | epoch 002:   3135 / 6686 loss=4.611, nll_loss=3.037, ppl=8.21, wps=28365, ups=0.5, wpb=57121.8, bsz=1457.4, num_updates=9800, lr=0.000638877, gnorm=0.239, clip=100, loss_scale=16, train_wall=197, wall=19700
2023-05-26 12:32:24 | INFO | train_inner | epoch 002:   3235 / 6686 loss=4.601, nll_loss=3.025, ppl=8.14, wps=28963.4, ups=0.51, wpb=57192, bsz=1469.5, num_updates=9900, lr=0.000635642, gnorm=0.243, clip=100, loss_scale=8, train_wall=194, wall=19898
2023-05-26 12:35:40 | INFO | train_inner | epoch 002:   3335 / 6686 loss=4.591, nll_loss=3.015, ppl=8.08, wps=29058.3, ups=0.51, wpb=57132.9, bsz=1464.3, num_updates=10000, lr=0.000632456, gnorm=0.235, clip=100, loss_scale=8, train_wall=193, wall=20094
2023-05-26 12:38:58 | INFO | train_inner | epoch 002:   3435 / 6686 loss=4.6, nll_loss=3.025, ppl=8.14, wps=28943.7, ups=0.51, wpb=57238.8, bsz=1480.1, num_updates=10100, lr=0.000629317, gnorm=0.248, clip=100, loss_scale=8, train_wall=194, wall=20292
2023-05-26 12:42:15 | INFO | train_inner | epoch 002:   3535 / 6686 loss=4.584, nll_loss=3.007, ppl=8.04, wps=29099.2, ups=0.51, wpb=57367.5, bsz=1489.8, num_updates=10200, lr=0.000626224, gnorm=0.239, clip=100, loss_scale=8, train_wall=193, wall=20489
2023-05-26 12:44:44 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 12:45:35 | INFO | train_inner | epoch 002:   3636 / 6686 loss=4.581, nll_loss=3.003, ppl=8.02, wps=28706.9, ups=0.5, wpb=57285.5, bsz=1484.8, num_updates=10300, lr=0.000623177, gnorm=0.235, clip=100, loss_scale=8, train_wall=196, wall=20689
2023-05-26 12:48:52 | INFO | train_inner | epoch 002:   3736 / 6686 loss=4.591, nll_loss=3.015, ppl=8.09, wps=28948.6, ups=0.51, wpb=57096.4, bsz=1491, num_updates=10400, lr=0.000620174, gnorm=0.232, clip=100, loss_scale=8, train_wall=193, wall=20886
2023-05-26 12:52:10 | INFO | train_inner | epoch 002:   3836 / 6686 loss=4.588, nll_loss=3.012, ppl=8.06, wps=28909.6, ups=0.51, wpb=57212.7, bsz=1475.4, num_updates=10500, lr=0.000617213, gnorm=0.233, clip=100, loss_scale=8, train_wall=194, wall=21084
2023-05-26 12:55:28 | INFO | train_inner | epoch 002:   3936 / 6686 loss=4.58, nll_loss=3.002, ppl=8.01, wps=28902.7, ups=0.51, wpb=57134.5, bsz=1468.4, num_updates=10600, lr=0.000614295, gnorm=0.23, clip=100, loss_scale=8, train_wall=194, wall=21281
2023-05-26 12:58:45 | INFO | train_inner | epoch 002:   4036 / 6686 loss=4.562, nll_loss=2.982, ppl=7.9, wps=28998.3, ups=0.51, wpb=57165.4, bsz=1476.8, num_updates=10700, lr=0.000611418, gnorm=0.232, clip=100, loss_scale=8, train_wall=193, wall=21479
2023-05-26 13:02:02 | INFO | train_inner | epoch 002:   4136 / 6686 loss=4.568, nll_loss=2.99, ppl=7.94, wps=28957.9, ups=0.51, wpb=57200.7, bsz=1493.8, num_updates=10800, lr=0.000608581, gnorm=0.241, clip=100, loss_scale=9, train_wall=194, wall=21676
2023-05-26 13:05:19 | INFO | train_inner | epoch 002:   4236 / 6686 loss=4.571, nll_loss=2.992, ppl=7.96, wps=29071.3, ups=0.51, wpb=57286.1, bsz=1463.5, num_updates=10900, lr=0.000605783, gnorm=0.238, clip=100, loss_scale=16, train_wall=193, wall=21873
2023-05-26 13:08:37 | INFO | train_inner | epoch 002:   4336 / 6686 loss=4.565, nll_loss=2.986, ppl=7.93, wps=28962.8, ups=0.51, wpb=57110.4, bsz=1483.4, num_updates=11000, lr=0.000603023, gnorm=0.238, clip=100, loss_scale=16, train_wall=193, wall=22070
2023-05-26 13:11:54 | INFO | train_inner | epoch 002:   4436 / 6686 loss=4.571, nll_loss=2.993, ppl=7.96, wps=29020.9, ups=0.51, wpb=57230.7, bsz=1466.7, num_updates=11100, lr=0.0006003, gnorm=0.227, clip=100, loss_scale=16, train_wall=193, wall=22268
2023-05-26 13:14:10 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 13:15:14 | INFO | train_inner | epoch 002:   4537 / 6686 loss=4.558, nll_loss=2.979, ppl=7.88, wps=28585.4, ups=0.5, wpb=57113.7, bsz=1494.6, num_updates=11200, lr=0.000597614, gnorm=0.228, clip=100, loss_scale=13, train_wall=196, wall=22467
2023-05-26 13:18:31 | INFO | train_inner | epoch 002:   4637 / 6686 loss=4.549, nll_loss=2.968, ppl=7.82, wps=28964.2, ups=0.51, wpb=57258.2, bsz=1474, num_updates=11300, lr=0.000594964, gnorm=0.234, clip=100, loss_scale=8, train_wall=194, wall=22665
2023-05-26 13:21:48 | INFO | train_inner | epoch 002:   4737 / 6686 loss=4.554, nll_loss=2.974, ppl=7.86, wps=29061.3, ups=0.51, wpb=57062.5, bsz=1474.7, num_updates=11400, lr=0.000592349, gnorm=0.233, clip=100, loss_scale=8, train_wall=193, wall=22861
2023-05-26 13:25:05 | INFO | train_inner | epoch 002:   4837 / 6686 loss=4.546, nll_loss=2.965, ppl=7.81, wps=28914.4, ups=0.51, wpb=57146.8, bsz=1503.5, num_updates=11500, lr=0.000589768, gnorm=0.242, clip=100, loss_scale=8, train_wall=194, wall=23059
2023-05-26 13:28:23 | INFO | train_inner | epoch 002:   4937 / 6686 loss=4.553, nll_loss=2.972, ppl=7.85, wps=28944.6, ups=0.51, wpb=57125, bsz=1461.4, num_updates=11600, lr=0.00058722, gnorm=0.232, clip=100, loss_scale=8, train_wall=193, wall=23256
2023-05-26 13:31:23 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 13:31:42 | INFO | train_inner | epoch 002:   5038 / 6686 loss=4.539, nll_loss=2.957, ppl=7.77, wps=28666.5, ups=0.5, wpb=57279.5, bsz=1506.8, num_updates=11700, lr=0.000584705, gnorm=0.231, clip=100, loss_scale=9, train_wall=196, wall=23456
2023-05-26 13:35:00 | INFO | train_inner | epoch 002:   5138 / 6686 loss=4.543, nll_loss=2.962, ppl=7.79, wps=28996.8, ups=0.51, wpb=57173.9, bsz=1473.4, num_updates=11800, lr=0.000582223, gnorm=0.227, clip=100, loss_scale=8, train_wall=193, wall=23653
2023-05-26 13:38:17 | INFO | train_inner | epoch 002:   5238 / 6686 loss=4.54, nll_loss=2.959, ppl=7.78, wps=29018.2, ups=0.51, wpb=57281.2, bsz=1486.4, num_updates=11900, lr=0.000579771, gnorm=0.227, clip=100, loss_scale=8, train_wall=194, wall=23851
2023-05-26 13:41:34 | INFO | train_inner | epoch 002:   5338 / 6686 loss=4.533, nll_loss=2.951, ppl=7.73, wps=29063.7, ups=0.51, wpb=57283.6, bsz=1479.9, num_updates=12000, lr=0.00057735, gnorm=0.225, clip=100, loss_scale=8, train_wall=193, wall=24048
2023-05-26 13:44:51 | INFO | train_inner | epoch 002:   5438 / 6686 loss=4.538, nll_loss=2.956, ppl=7.76, wps=28914.4, ups=0.51, wpb=57062.1, bsz=1463.4, num_updates=12100, lr=0.00057496, gnorm=0.233, clip=100, loss_scale=8, train_wall=194, wall=24245
2023-05-26 13:48:10 | INFO | train_inner | epoch 002:   5538 / 6686 loss=4.529, nll_loss=2.946, ppl=7.71, wps=28933.1, ups=0.5, wpb=57430.4, bsz=1497.2, num_updates=12200, lr=0.000572598, gnorm=0.232, clip=100, loss_scale=8, train_wall=195, wall=24444
2023-05-26 13:51:27 | INFO | train_inner | epoch 002:   5638 / 6686 loss=4.53, nll_loss=2.947, ppl=7.71, wps=29014.1, ups=0.51, wpb=57285.1, bsz=1464.3, num_updates=12300, lr=0.000570266, gnorm=0.224, clip=100, loss_scale=16, train_wall=194, wall=24641
2023-05-26 13:54:45 | INFO | train_inner | epoch 002:   5738 / 6686 loss=4.529, nll_loss=2.947, ppl=7.71, wps=28989.6, ups=0.51, wpb=57152.7, bsz=1472.4, num_updates=12400, lr=0.000567962, gnorm=0.229, clip=100, loss_scale=16, train_wall=193, wall=24838
2023-05-26 13:58:01 | INFO | train_inner | epoch 002:   5838 / 6686 loss=4.531, nll_loss=2.949, ppl=7.72, wps=29019.6, ups=0.51, wpb=57050.5, bsz=1471.5, num_updates=12500, lr=0.000565685, gnorm=0.221, clip=100, loss_scale=16, train_wall=193, wall=25035
2023-05-26 14:01:04 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 14:01:21 | INFO | train_inner | epoch 002:   5939 / 6686 loss=4.52, nll_loss=2.936, ppl=7.65, wps=28660.4, ups=0.5, wpb=57407.2, bsz=1508.2, num_updates=12600, lr=0.000563436, gnorm=0.224, clip=100, loss_scale=15, train_wall=196, wall=25235
2023-05-26 14:04:40 | INFO | train_inner | epoch 002:   6039 / 6686 loss=4.518, nll_loss=2.934, ppl=7.64, wps=28834.3, ups=0.5, wpb=57214.4, bsz=1475.8, num_updates=12700, lr=0.000561214, gnorm=0.227, clip=100, loss_scale=8, train_wall=195, wall=25434
2023-05-26 14:07:57 | INFO | train_inner | epoch 002:   6139 / 6686 loss=4.527, nll_loss=2.944, ppl=7.7, wps=28945.4, ups=0.51, wpb=57056, bsz=1469.4, num_updates=12800, lr=0.000559017, gnorm=0.224, clip=100, loss_scale=8, train_wall=193, wall=25631
2023-05-26 14:11:15 | INFO | train_inner | epoch 002:   6239 / 6686 loss=4.519, nll_loss=2.936, ppl=7.65, wps=28922.1, ups=0.51, wpb=57135.3, bsz=1465.4, num_updates=12900, lr=0.000556846, gnorm=0.23, clip=100, loss_scale=8, train_wall=194, wall=25828
2023-05-26 14:14:32 | INFO | train_inner | epoch 002:   6339 / 6686 loss=4.514, nll_loss=2.93, ppl=7.62, wps=28891.5, ups=0.51, wpb=57191.1, bsz=1489.3, num_updates=13000, lr=0.0005547, gnorm=0.227, clip=100, loss_scale=8, train_wall=194, wall=26026
2023-05-26 14:17:50 | INFO | train_inner | epoch 002:   6439 / 6686 loss=4.508, nll_loss=2.923, ppl=7.58, wps=28944.2, ups=0.51, wpb=57228.8, bsz=1481.9, num_updates=13100, lr=0.000552579, gnorm=0.223, clip=100, loss_scale=8, train_wall=194, wall=26224
2023-05-26 14:21:08 | INFO | train_inner | epoch 002:   6539 / 6686 loss=4.506, nll_loss=2.921, ppl=7.57, wps=28910, ups=0.51, wpb=57157.3, bsz=1478.6, num_updates=13200, lr=0.000550482, gnorm=0.226, clip=100, loss_scale=16, train_wall=194, wall=26422
2023-05-26 14:24:25 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 14:24:27 | INFO | train_inner | epoch 002:   6640 / 6686 loss=4.507, nll_loss=2.923, ppl=7.58, wps=28712.7, ups=0.5, wpb=57214, bsz=1473, num_updates=13300, lr=0.000548408, gnorm=0.224, clip=100, loss_scale=16, train_wall=195, wall=26621
2023-05-26 14:25:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-26 14:26:02 | INFO | fairseq.tasks.translation | example hypothesis: Why? Why would he be unhappy? Why would he be unhappy? Why would he be unhappy? Why would he be
2023-05-26 14:26:02 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-26 14:26:04 | INFO | fairseq.tasks.translation | example hypothesis: I’ll make you lose so badly that you won’t even have a pair of pants left in a short while!
2023-05-26 14:26:04 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-26 14:26:05 | INFO | fairseq.tasks.translation | example hypothesis: Shen Liangchuan had just let out a sigh of relief when he heard her say, “I’m calling you in the same room!”
2023-05-26 14:26:05 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-26 14:26:07 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved and entered the elevator.
2023-05-26 14:26:07 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-26 14:26:10 | INFO | fairseq.tasks.translation | example hypothesis: As soon as she raised her head, she saw Song Cheng standing in the distance! “Miss Qiao!”
2023-05-26 14:26:10 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-26 14:26:11 | INFO | fairseq.tasks.translation | example hypothesis: Only then did Song Cheng pat his chest, “I’m scared to death! Where’s Wang Chuan?”
2023-05-26 14:26:11 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-26 14:26:13 | INFO | fairseq.tasks.translation | example hypothesis: I said, “I won’t go, I won’t be able to eat it if I don’t.”
2023-05-26 14:26:13 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-26 14:26:14 | INFO | fairseq.tasks.translation | example hypothesis: Everyone didn’t believe it, but Wang Wenhao insisted that he would side with Wang Wenhao.
2023-05-26 14:26:14 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-26 14:26:16 | INFO | fairseq.tasks.translation | example hypothesis: With his identity, even if Bai Li Hongzhuang didn’t treat him, she would still treat him!
2023-05-26 14:26:16 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-26 14:26:19 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian said, “Mr. Shen, I... I’ve left too much blood. My brain is out of oxygen and I can’t think of a way to come out. Either you give me a hint
2023-05-26 14:26:19 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-26 14:26:22 | INFO | fairseq.tasks.translation | example hypothesis: He didn’t know why this matter would be heard by so many people. Since he couldn’t hide it, he might as well say it out loud. However, he didn’t know why Li Yuyue’s injury
2023-05-26 14:26:22 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-26 14:26:23 | INFO | fairseq.tasks.translation | example hypothesis: Ye Qing Ling’s voice was deliberately lowered, but it was unable to conceal the evilness and ruthlessness in her tone.
2023-05-26 14:26:23 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-26 14:26:26 | INFO | fairseq.tasks.translation | example hypothesis: The strength of a different level of beast pet wasn’t the same, but a beast pet was precious and rare. It was simply impossible for an ordinary person to possess it. Even an official’s disciple wouldn’t be able
2023-05-26 14:26:26 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-26 14:26:28 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chixia gritted her teeth and cursed in a low voice, "I'm sorry..."
2023-05-26 14:26:28 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-26 14:26:30 | INFO | fairseq.tasks.translation | example hypothesis: Even though Bai Li Hongzhuang had concealed her face very well, Di Beichen still saw a flash of emotion in her eyes, and there was a hint of warmth in his eyes.
2023-05-26 14:26:30 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-26 14:26:32 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia walked in, not to mention the guests who were living in the resort, not even a few of the waitresses were present. She was the only one in the village.
2023-05-26 14:26:32 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-26 14:26:35 | INFO | fairseq.tasks.translation | example hypothesis: This person was none other than the Fourth Young Lady of the Ye Family, Ye Qingling.
2023-05-26 14:26:35 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-26 14:26:39 | INFO | fairseq.tasks.translation | example hypothesis: Because at this moment, she felt that her chin was about to shatter.
2023-05-26 14:26:39 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-26 14:26:42 | INFO | fairseq.tasks.translation | example hypothesis: “Alright, Mu Zi, help me. If it wasn't for you, that old fellow wouldn't have locked onto me.” Mu Zi said with a smile.
2023-05-26 14:26:42 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-26 14:26:44 | INFO | fairseq.tasks.translation | example hypothesis: Bai Li Yu Yan was even more excited. This matter was completely directed by her. Earlier, Bai Li Hong Zhuang had treated her like that. This time, she would definitely make Bai Li Hong Zhuang feel bad.
2023-05-26 14:26:44 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-26 14:26:46 | INFO | fairseq.tasks.translation | example hypothesis: How is that possible? They are also four mages, so of course they won’t submit so easily. After arguing for a long time, they finally decided to use a method to obtain control over the Kingdom of A Xia in the future.”
2023-05-26 14:26:46 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-26 14:26:48 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a bit. Originally, he had been looking for a reason for Li Yuyue to not be able to participate in the Royal Family’s hunting competition.
2023-05-26 14:26:48 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-26 14:26:51 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my level okay? They’re all the most outstanding talents in the country, so why am I so weak in magic?”
2023-05-26 14:26:51 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-26 14:26:57 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yibei’s meaning was that if Fang Chixia didn’t want to go, then there was no need for her to go. If Fang Chixia didn’t want to go, then there was no need for her to go. If Fang Chixia didn’t want to go, then there was no need for her to go.
2023-05-26 14:26:57 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-26 14:27:00 | INFO | fairseq.tasks.translation | example hypothesis: She tilted her head to the side and saw five palm prints on her cheek. They were very obvious and swollen at a speed visible to the naked eye. She stretched out her hand to touch it, and she couldn’t help but let out a hissing sound. It was so painful.
2023-05-26 14:27:00 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-26 14:27:04 | INFO | fairseq.tasks.translation | example hypothesis: This... How could this be the charm that that good-for-nothing was able to emit?
2023-05-26 14:27:04 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-26 14:27:05 | INFO | fairseq.tasks.translation | example hypothesis: How did Wang Wenhao find the news agency? The chief editor should have called her to inform her that she didn’t want to come to the newspaper, but these three people... had plotted against her!
2023-05-26 14:27:05 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-26 14:27:11 | INFO | fairseq.tasks.translation | example hypothesis: After hearing Teacher Di’s praise, I was delighted. I put away the energy ball with my left hand and sent out a light sword towards Teacher Zhen with my right hand. The light sword was actually able to successfully hit Teacher Zhen, causing me to be shocked. When I took a closer look, I realized that it was only an afterimage. Teacher Zhen had already moved behind me, and
2023-05-26 14:27:11 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-26 14:27:17 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Originally, our side proposed three rounds of two wins, but their side couldn’t say that it was unfair, because we have Teacher Di and Teacher Zhen, and our ranking is even higher than them. They proposed to win five rounds, and because the competition was proposed by us, we can only listen to them in the end. Three days later, we will secretly compete in the Royal Family’s martial arts arena, and we will be able to win
2023-05-26 14:27:17 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-26 14:27:20 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Di used a light spell of the seventh level of light spell, Lightning Combo. I didn’t use much of this spell, because it was not ideal to control it. Teacher Di released nine lightning bolts to surround me, forming a simple spell that prevented me from escaping in a short distance. After that, each of the lightning bolts exploded one after another to form a powerful attack.
2023-05-26 14:27:20 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-26 14:27:26 | INFO | fairseq.tasks.translation | example hypothesis: As soon as Ma Ke and the two teachers walked to the other side of the courtyard, Teacher Zhen sent a small Dimensional Slash at me. As expected of the number one magician on the continent, the powerful suction force of his Lesser Dimensional Slash was actually much stronger than mine. A small spatial crack appeared beside me, and a powerful suction force immediately swept over. After a short while, a small space crack appeared in front of me and a powerful suction force immediately swept over.
2023-05-26 14:27:26 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-26 14:27:27 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.569 | nll_loss 2.952 | ppl 7.74 | bleu 16.93 | wps 866.2 | wpb 2420.8 | bsz 84.5 | num_updates 13346 | best_bleu 16.93
2023-05-26 14:27:27 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-26 14:27:33 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/mega-1-1-0.2-sf[zh-en]/checkpoint_best.pt (epoch 2 @ 13346 updates, score 16.93) (writing took 6.155343390069902 seconds)
2023-05-26 14:27:33 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-05-26 14:27:33 | INFO | train | epoch 002 | loss 4.604 | nll_loss 3.028 | ppl 8.16 | wps 28674.5 | ups 0.5 | wpb 57190.4 | bsz 1477.5 | num_updates 13346 | lr 0.000547463 | gnorm 0.239 | clip 100 | loss_scale 12 | train_wall 12951 | wall 26807
2023-05-26 14:27:33 | INFO | fairseq.trainer | begin training epoch 3
2023-05-26 14:29:37 | INFO | train_inner | epoch 003:     54 / 6686 loss=4.49, nll_loss=2.902, ppl=7.48, wps=18308.1, ups=0.32, wpb=56691.1, bsz=1467.4, num_updates=13400, lr=0.000546358, gnorm=0.228, clip=100, loss_scale=8, train_wall=195, wall=26931
2023-05-26 14:33:04 | INFO | train_inner | epoch 003:    154 / 6686 loss=4.478, nll_loss=2.889, ppl=7.41, wps=27587.1, ups=0.48, wpb=57209.9, bsz=1475.2, num_updates=13500, lr=0.000544331, gnorm=0.223, clip=100, loss_scale=8, train_wall=195, wall=27138
2023-05-26 14:36:27 | INFO | train_inner | epoch 003:    254 / 6686 loss=4.478, nll_loss=2.889, ppl=7.41, wps=28218.8, ups=0.49, wpb=57295.1, bsz=1473.3, num_updates=13600, lr=0.000542326, gnorm=0.23, clip=100, loss_scale=8, train_wall=195, wall=27341
2023-05-26 14:39:46 | INFO | train_inner | epoch 003:    354 / 6686 loss=4.463, nll_loss=2.872, ppl=7.32, wps=28805.8, ups=0.5, wpb=57216.7, bsz=1494.8, num_updates=13700, lr=0.000540343, gnorm=0.224, clip=100, loss_scale=8, train_wall=194, wall=27540
2023-05-26 14:43:04 | INFO | train_inner | epoch 003:    454 / 6686 loss=4.475, nll_loss=2.886, ppl=7.39, wps=28894.5, ups=0.51, wpb=57164.2, bsz=1468.9, num_updates=13800, lr=0.000538382, gnorm=0.22, clip=100, loss_scale=8, train_wall=194, wall=27738
2023-05-26 14:44:04 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 14:46:23 | INFO | train_inner | epoch 003:    555 / 6686 loss=4.484, nll_loss=2.896, ppl=7.45, wps=28645.5, ups=0.5, wpb=57188.3, bsz=1471.1, num_updates=13900, lr=0.000536442, gnorm=0.223, clip=100, loss_scale=10, train_wall=196, wall=27937
2023-05-26 14:49:42 | INFO | train_inner | epoch 003:    655 / 6686 loss=4.474, nll_loss=2.885, ppl=7.39, wps=28872, ups=0.5, wpb=57283.2, bsz=1456.6, num_updates=14000, lr=0.000534522, gnorm=0.227, clip=100, loss_scale=8, train_wall=195, wall=28136
2023-05-26 14:53:00 | INFO | train_inner | epoch 003:    755 / 6686 loss=4.476, nll_loss=2.887, ppl=7.4, wps=28884.1, ups=0.51, wpb=57134.2, bsz=1474.3, num_updates=14100, lr=0.000532624, gnorm=0.228, clip=100, loss_scale=8, train_wall=194, wall=28333
2023-05-26 14:56:17 | INFO | train_inner | epoch 003:    855 / 6686 loss=4.469, nll_loss=2.88, ppl=7.36, wps=28918.8, ups=0.51, wpb=57122.2, bsz=1502.2, num_updates=14200, lr=0.000530745, gnorm=0.232, clip=100, loss_scale=8, train_wall=194, wall=28531
2023-05-26 14:59:36 | INFO | train_inner | epoch 003:    955 / 6686 loss=4.471, nll_loss=2.882, ppl=7.37, wps=28882.5, ups=0.5, wpb=57315, bsz=1495.8, num_updates=14300, lr=0.000528886, gnorm=0.227, clip=100, loss_scale=8, train_wall=195, wall=28729
2023-05-26 15:02:53 | INFO | train_inner | epoch 003:   1055 / 6686 loss=4.472, nll_loss=2.883, ppl=7.38, wps=28938.5, ups=0.51, wpb=57180.5, bsz=1485, num_updates=14400, lr=0.000527046, gnorm=0.216, clip=100, loss_scale=13, train_wall=194, wall=28927
2023-05-26 15:04:20 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 15:06:12 | INFO | train_inner | epoch 003:   1156 / 6686 loss=4.465, nll_loss=2.875, ppl=7.34, wps=28657.3, ups=0.5, wpb=57113.8, bsz=1474.6, num_updates=14500, lr=0.000525226, gnorm=0.223, clip=100, loss_scale=11, train_wall=195, wall=29126
2023-05-26 15:09:29 | INFO | train_inner | epoch 003:   1256 / 6686 loss=4.472, nll_loss=2.882, ppl=7.37, wps=29044.8, ups=0.51, wpb=57192.7, bsz=1460, num_updates=14600, lr=0.000523424, gnorm=0.228, clip=100, loss_scale=8, train_wall=193, wall=29323
2023-05-26 15:12:47 | INFO | train_inner | epoch 003:   1356 / 6686 loss=4.474, nll_loss=2.885, ppl=7.39, wps=28993.5, ups=0.51, wpb=57249.5, bsz=1467.9, num_updates=14700, lr=0.000521641, gnorm=0.232, clip=100, loss_scale=8, train_wall=194, wall=29521
2023-05-26 15:16:04 | INFO | train_inner | epoch 003:   1456 / 6686 loss=4.459, nll_loss=2.868, ppl=7.3, wps=28925.2, ups=0.51, wpb=57089.9, bsz=1468.4, num_updates=14800, lr=0.000519875, gnorm=0.227, clip=100, loss_scale=8, train_wall=194, wall=29718
2023-05-26 15:19:23 | INFO | train_inner | epoch 003:   1556 / 6686 loss=4.463, nll_loss=2.874, ppl=7.33, wps=28822.9, ups=0.5, wpb=57152.1, bsz=1477.5, num_updates=14900, lr=0.000518128, gnorm=0.227, clip=100, loss_scale=8, train_wall=194, wall=29916
2023-05-26 15:21:35 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 15:22:42 | INFO | train_inner | epoch 003:   1657 / 6686 loss=4.454, nll_loss=2.863, ppl=7.27, wps=28701.5, ups=0.5, wpb=57282.9, bsz=1484.2, num_updates=15000, lr=0.000516398, gnorm=0.224, clip=100, loss_scale=9, train_wall=196, wall=30116
2023-05-26 15:25:59 | INFO | train_inner | epoch 003:   1757 / 6686 loss=4.468, nll_loss=2.879, ppl=7.36, wps=28961, ups=0.51, wpb=57114.5, bsz=1459.4, num_updates=15100, lr=0.000514685, gnorm=0.221, clip=100, loss_scale=8, train_wall=193, wall=30313
2023-05-26 15:29:17 | INFO | train_inner | epoch 003:   1857 / 6686 loss=4.453, nll_loss=2.862, ppl=7.27, wps=29029, ups=0.51, wpb=57291.7, bsz=1480.6, num_updates=15200, lr=0.000512989, gnorm=0.229, clip=100, loss_scale=8, train_wall=194, wall=30511
2023-05-26 15:32:35 | INFO | train_inner | epoch 003:   1957 / 6686 loss=4.449, nll_loss=2.857, ppl=7.25, wps=28912.8, ups=0.51, wpb=57196, bsz=1503.5, num_updates=15300, lr=0.00051131, gnorm=0.22, clip=100, loss_scale=8, train_wall=194, wall=30708
2023-05-26 15:35:52 | INFO | train_inner | epoch 003:   2057 / 6686 loss=4.458, nll_loss=2.868, ppl=7.3, wps=29057.6, ups=0.51, wpb=57279.8, bsz=1460.8, num_updates=15400, lr=0.000509647, gnorm=0.225, clip=100, loss_scale=8, train_wall=193, wall=30906
2023-05-26 15:39:09 | INFO | train_inner | epoch 003:   2157 / 6686 loss=4.459, nll_loss=2.869, ppl=7.3, wps=28952.4, ups=0.51, wpb=57036.9, bsz=1463.6, num_updates=15500, lr=0.000508001, gnorm=0.226, clip=100, loss_scale=10, train_wall=193, wall=31103
2023-05-26 15:39:20 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 15:42:28 | INFO | train_inner | epoch 003:   2258 / 6686 loss=4.457, nll_loss=2.866, ppl=7.29, wps=28655.3, ups=0.5, wpb=57263.6, bsz=1482.9, num_updates=15600, lr=0.00050637, gnorm=0.233, clip=100, loss_scale=8, train_wall=196, wall=31302
2023-05-26 15:45:47 | INFO | train_inner | epoch 003:   2358 / 6686 loss=4.449, nll_loss=2.858, ppl=7.25, wps=28831.9, ups=0.5, wpb=57261, bsz=1486.6, num_updates=15700, lr=0.000504754, gnorm=0.222, clip=100, loss_scale=8, train_wall=195, wall=31501
2023-05-26 15:49:05 | INFO | train_inner | epoch 003:   2458 / 6686 loss=4.453, nll_loss=2.862, ppl=7.27, wps=28913, ups=0.51, wpb=57116.8, bsz=1468.4, num_updates=15800, lr=0.000503155, gnorm=0.224, clip=100, loss_scale=8, train_wall=194, wall=31699
2023-05-26 15:52:22 | INFO | train_inner | epoch 003:   2558 / 6686 loss=4.459, nll_loss=2.869, ppl=7.31, wps=28982.3, ups=0.51, wpb=57262.3, bsz=1475.3, num_updates=15900, lr=0.00050157, gnorm=0.223, clip=100, loss_scale=8, train_wall=194, wall=31896
2023-05-26 15:55:40 | INFO | train_inner | epoch 003:   2658 / 6686 loss=4.452, nll_loss=2.861, ppl=7.27, wps=28850.1, ups=0.5, wpb=57194.1, bsz=1480.1, num_updates=16000, lr=0.0005, gnorm=0.22, clip=100, loss_scale=8, train_wall=194, wall=32094
2023-05-26 15:57:35 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 15:59:00 | INFO | train_inner | epoch 003:   2759 / 6686 loss=4.45, nll_loss=2.859, ppl=7.25, wps=28563.2, ups=0.5, wpb=57061.2, bsz=1460.9, num_updates=16100, lr=0.000498445, gnorm=0.228, clip=100, loss_scale=11, train_wall=196, wall=32294
2023-05-26 16:02:18 | INFO | train_inner | epoch 003:   2859 / 6686 loss=4.457, nll_loss=2.867, ppl=7.3, wps=28991.7, ups=0.51, wpb=57326.6, bsz=1469.8, num_updates=16200, lr=0.000496904, gnorm=0.22, clip=100, loss_scale=8, train_wall=194, wall=32492
2023-05-26 16:05:36 | INFO | train_inner | epoch 003:   2959 / 6686 loss=4.445, nll_loss=2.854, ppl=7.23, wps=28917.4, ups=0.5, wpb=57362, bsz=1487.5, num_updates=16300, lr=0.000495377, gnorm=0.215, clip=100, loss_scale=8, train_wall=195, wall=32690
2023-05-26 16:08:54 | INFO | train_inner | epoch 003:   3059 / 6686 loss=4.45, nll_loss=2.859, ppl=7.25, wps=28831.4, ups=0.5, wpb=57112.9, bsz=1490.9, num_updates=16400, lr=0.000493865, gnorm=0.224, clip=100, loss_scale=8, train_wall=194, wall=32888
2023-05-26 16:09:56 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2023-05-26 16:12:14 | INFO | train_inner | epoch 003:   3160 / 6686 loss=4.431, nll_loss=2.837, ppl=7.15, wps=28635.3, ups=0.5, wpb=57175.4, bsz=1489.8, num_updates=16500, lr=0.000492366, gnorm=0.213, clip=100, loss_scale=5, train_wall=196, wall=33088
2023-05-26 16:15:32 | INFO | train_inner | epoch 003:   3260 / 6686 loss=4.451, nll_loss=2.86, ppl=7.26, wps=28982.2, ups=0.51, wpb=57233.7, bsz=1482.1, num_updates=16600, lr=0.000490881, gnorm=0.216, clip=100, loss_scale=4, train_wall=194, wall=33285
2023-05-26 16:18:49 | INFO | train_inner | epoch 003:   3360 / 6686 loss=4.449, nll_loss=2.858, ppl=7.25, wps=28915.7, ups=0.51, wpb=56946.6, bsz=1446.6, num_updates=16700, lr=0.000489409, gnorm=0.226, clip=100, loss_scale=4, train_wall=193, wall=33482
2023-05-26 16:22:06 | INFO | train_inner | epoch 003:   3460 / 6686 loss=4.455, nll_loss=2.865, ppl=7.29, wps=28993.7, ups=0.51, wpb=57127.6, bsz=1458.6, num_updates=16800, lr=0.00048795, gnorm=0.224, clip=100, loss_scale=4, train_wall=193, wall=33679
2023-05-26 16:25:24 | INFO | train_inner | epoch 003:   3560 / 6686 loss=4.44, nll_loss=2.848, ppl=7.2, wps=28885, ups=0.5, wpb=57399.5, bsz=1490.8, num_updates=16900, lr=0.000486504, gnorm=0.218, clip=100, loss_scale=4, train_wall=195, wall=33878
2023-05-26 16:28:42 | INFO | train_inner | epoch 003:   3660 / 6686 loss=4.434, nll_loss=2.841, ppl=7.16, wps=28947.6, ups=0.51, wpb=57196.5, bsz=1485.4, num_updates=17000, lr=0.000485071, gnorm=0.219, clip=100, loss_scale=6, train_wall=194, wall=34076
2023-05-26 16:32:00 | INFO | train_inner | epoch 003:   3760 / 6686 loss=4.438, nll_loss=2.845, ppl=7.19, wps=28930.2, ups=0.51, wpb=57213.6, bsz=1501.2, num_updates=17100, lr=0.000483651, gnorm=0.214, clip=100, loss_scale=8, train_wall=194, wall=34274
2023-05-26 16:35:17 | INFO | train_inner | epoch 003:   3860 / 6686 loss=4.435, nll_loss=2.843, ppl=7.17, wps=28932.6, ups=0.51, wpb=57044.3, bsz=1483.1, num_updates=17200, lr=0.000482243, gnorm=0.222, clip=100, loss_scale=8, train_wall=193, wall=34471
2023-05-26 16:38:34 | INFO | train_inner | epoch 003:   3960 / 6686 loss=4.444, nll_loss=2.853, ppl=7.23, wps=28926.4, ups=0.51, wpb=57086.7, bsz=1461, num_updates=17300, lr=0.000480847, gnorm=0.215, clip=100, loss_scale=8, train_wall=194, wall=34668
2023-05-26 16:41:51 | INFO | train_inner | epoch 003:   4060 / 6686 loss=4.443, nll_loss=2.852, ppl=7.22, wps=29014.8, ups=0.51, wpb=57086, bsz=1465.2, num_updates=17400, lr=0.000479463, gnorm=0.216, clip=100, loss_scale=8, train_wall=193, wall=34865
2023-05-26 16:45:09 | INFO | train_inner | epoch 003:   4160 / 6686 loss=4.438, nll_loss=2.846, ppl=7.19, wps=28917.7, ups=0.51, wpb=57224, bsz=1483.4, num_updates=17500, lr=0.000478091, gnorm=0.219, clip=100, loss_scale=12, train_wall=194, wall=35063
2023-05-26 16:45:23 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 16:48:28 | INFO | train_inner | epoch 003:   4261 / 6686 loss=4.423, nll_loss=2.83, ppl=7.11, wps=28764.6, ups=0.5, wpb=57286.1, bsz=1481, num_updates=17600, lr=0.000476731, gnorm=0.226, clip=100, loss_scale=8, train_wall=195, wall=35262
2023-05-26 16:51:46 | INFO | train_inner | epoch 003:   4361 / 6686 loss=4.429, nll_loss=2.836, ppl=7.14, wps=28977.3, ups=0.51, wpb=57298.9, bsz=1486, num_updates=17700, lr=0.000475383, gnorm=0.223, clip=100, loss_scale=8, train_wall=194, wall=35460
2023-05-26 16:55:04 | INFO | train_inner | epoch 003:   4461 / 6686 loss=4.414, nll_loss=2.82, ppl=7.06, wps=28955.5, ups=0.51, wpb=57267.5, bsz=1508.8, num_updates=17800, lr=0.000474045, gnorm=0.219, clip=100, loss_scale=8, train_wall=194, wall=35657
2023-05-26 16:58:21 | INFO | train_inner | epoch 003:   4561 / 6686 loss=4.425, nll_loss=2.832, ppl=7.12, wps=28929.1, ups=0.51, wpb=57198.3, bsz=1502.5, num_updates=17900, lr=0.000472719, gnorm=0.227, clip=100, loss_scale=8, train_wall=194, wall=35855
2023-05-26 17:01:39 | INFO | train_inner | epoch 003:   4661 / 6686 loss=4.426, nll_loss=2.833, ppl=7.12, wps=28917.7, ups=0.51, wpb=57157.8, bsz=1481, num_updates=18000, lr=0.000471405, gnorm=0.225, clip=100, loss_scale=8, train_wall=194, wall=36053
2023-05-26 17:02:30 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 17:04:59 | INFO | train_inner | epoch 003:   4762 / 6686 loss=4.415, nll_loss=2.82, ppl=7.06, wps=28619.3, ups=0.5, wpb=57199.7, bsz=1489.8, num_updates=18100, lr=0.0004701, gnorm=0.225, clip=100, loss_scale=9, train_wall=196, wall=36253
2023-05-26 17:08:16 | INFO | train_inner | epoch 003:   4862 / 6686 loss=4.432, nll_loss=2.839, ppl=7.16, wps=28962.9, ups=0.51, wpb=57004.6, bsz=1455.4, num_updates=18200, lr=0.000468807, gnorm=0.222, clip=100, loss_scale=8, train_wall=193, wall=36449
2023-05-26 17:11:34 | INFO | train_inner | epoch 003:   4962 / 6686 loss=4.426, nll_loss=2.833, ppl=7.13, wps=28892.8, ups=0.5, wpb=57241.9, bsz=1472.4, num_updates=18300, lr=0.000467525, gnorm=0.22, clip=100, loss_scale=8, train_wall=194, wall=36648
2023-05-26 17:14:51 | INFO | train_inner | epoch 003:   5062 / 6686 loss=4.432, nll_loss=2.84, ppl=7.16, wps=28951.1, ups=0.51, wpb=57055.6, bsz=1467, num_updates=18400, lr=0.000466252, gnorm=0.226, clip=100, loss_scale=8, train_wall=193, wall=36845
2023-05-26 17:18:09 | INFO | train_inner | epoch 003:   5162 / 6686 loss=4.417, nll_loss=2.823, ppl=7.08, wps=28975.5, ups=0.51, wpb=57298.1, bsz=1500.2, num_updates=18500, lr=0.000464991, gnorm=0.226, clip=100, loss_scale=8, train_wall=194, wall=37042
2023-05-26 17:20:31 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 17:21:28 | INFO | train_inner | epoch 003:   5263 / 6686 loss=4.43, nll_loss=2.838, ppl=7.15, wps=28702.5, ups=0.5, wpb=57182.5, bsz=1460.1, num_updates=18600, lr=0.000463739, gnorm=0.226, clip=100, loss_scale=11, train_wall=195, wall=37242
2023-05-26 17:23:39 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2023-05-26 17:24:46 | INFO | train_inner | epoch 003:   5364 / 6686 loss=4.419, nll_loss=2.826, ppl=7.09, wps=28686.5, ups=0.5, wpb=56985, bsz=1476.6, num_updates=18700, lr=0.000462497, gnorm=0.217, clip=100, loss_scale=7, train_wall=195, wall=37440
2023-05-26 17:28:04 | INFO | train_inner | epoch 003:   5464 / 6686 loss=4.406, nll_loss=2.81, ppl=7.01, wps=29001.1, ups=0.51, wpb=57409.8, bsz=1501.5, num_updates=18800, lr=0.000461266, gnorm=0.215, clip=100, loss_scale=4, train_wall=194, wall=37638
2023-05-26 17:31:22 | INFO | train_inner | epoch 003:   5564 / 6686 loss=4.421, nll_loss=2.828, ppl=7.1, wps=28954.8, ups=0.51, wpb=57197.7, bsz=1474.8, num_updates=18900, lr=0.000460044, gnorm=0.221, clip=100, loss_scale=4, train_wall=194, wall=37836
2023-05-26 17:34:39 | INFO | train_inner | epoch 003:   5664 / 6686 loss=4.412, nll_loss=2.818, ppl=7.05, wps=29028.8, ups=0.51, wpb=57235.2, bsz=1495, num_updates=19000, lr=0.000458831, gnorm=0.22, clip=100, loss_scale=4, train_wall=193, wall=38033
2023-05-26 17:37:57 | INFO | train_inner | epoch 003:   5764 / 6686 loss=4.417, nll_loss=2.823, ppl=7.08, wps=28942.8, ups=0.51, wpb=57238.7, bsz=1464.6, num_updates=19100, lr=0.000457629, gnorm=0.227, clip=100, loss_scale=4, train_wall=194, wall=38231
2023-05-26 17:41:15 | INFO | train_inner | epoch 003:   5864 / 6686 loss=4.414, nll_loss=2.82, ppl=7.06, wps=28921.3, ups=0.5, wpb=57344.5, bsz=1472.6, num_updates=19200, lr=0.000456435, gnorm=0.211, clip=100, loss_scale=5, train_wall=194, wall=38429
2023-05-26 17:44:33 | INFO | train_inner | epoch 003:   5964 / 6686 loss=4.408, nll_loss=2.813, ppl=7.03, wps=28938.3, ups=0.51, wpb=57152.9, bsz=1501.4, num_updates=19300, lr=0.000455251, gnorm=0.227, clip=100, loss_scale=8, train_wall=194, wall=38627
2023-05-26 17:47:51 | INFO | train_inner | epoch 003:   6064 / 6686 loss=4.414, nll_loss=2.82, ppl=7.06, wps=28953.4, ups=0.51, wpb=57319.6, bsz=1487.4, num_updates=19400, lr=0.000454077, gnorm=0.23, clip=100, loss_scale=8, train_wall=194, wall=38825
2023-05-26 17:51:08 | INFO | train_inner | epoch 003:   6164 / 6686 loss=4.414, nll_loss=2.82, ppl=7.06, wps=28930.2, ups=0.51, wpb=57055.6, bsz=1467.4, num_updates=19500, lr=0.000452911, gnorm=0.214, clip=100, loss_scale=8, train_wall=193, wall=39022
2023-05-26 17:54:27 | INFO | train_inner | epoch 003:   6264 / 6686 loss=4.409, nll_loss=2.815, ppl=7.04, wps=28791, ups=0.5, wpb=57296.1, bsz=1488, num_updates=19600, lr=0.000451754, gnorm=0.223, clip=100, loss_scale=8, train_wall=195, wall=39221
2023-05-26 17:57:45 | INFO | train_inner | epoch 003:   6364 / 6686 loss=4.408, nll_loss=2.813, ppl=7.03, wps=29006.8, ups=0.5, wpb=57447.9, bsz=1449.4, num_updates=19700, lr=0.000450606, gnorm=0.227, clip=100, loss_scale=9, train_wall=194, wall=39419
2023-05-26 17:59:19 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 18:01:04 | INFO | train_inner | epoch 003:   6465 / 6686 loss=4.404, nll_loss=2.809, ppl=7.01, wps=28726.1, ups=0.5, wpb=57259.3, bsz=1487.4, num_updates=19800, lr=0.000449467, gnorm=0.227, clip=100, loss_scale=12, train_wall=196, wall=39618
2023-05-26 18:04:21 | INFO | train_inner | epoch 003:   6565 / 6686 loss=4.42, nll_loss=2.827, ppl=7.09, wps=28945.1, ups=0.51, wpb=56990.8, bsz=1448.6, num_updates=19900, lr=0.000448336, gnorm=0.218, clip=100, loss_scale=8, train_wall=193, wall=39815
2023-05-26 18:07:39 | INFO | train_inner | epoch 003:   6665 / 6686 loss=4.412, nll_loss=2.818, ppl=7.05, wps=28913.9, ups=0.51, wpb=57208.6, bsz=1469.9, num_updates=20000, lr=0.000447214, gnorm=0.221, clip=100, loss_scale=8, train_wall=194, wall=40013
2023-05-26 18:08:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-26 18:08:24 | INFO | fairseq.tasks.translation | example hypothesis: Why? Why was he unhappy? Why was he unhappy? Why was he unhappy? Why was he unhappy? Why did
2023-05-26 18:08:24 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-26 18:08:26 | INFO | fairseq.tasks.translation | example hypothesis: I’ll make you lose so badly that you don’t even have any pants left! I’m going to lose!
2023-05-26 18:08:26 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-26 18:08:27 | INFO | fairseq.tasks.translation | example hypothesis: Shen Liangchuan heaved a sigh of relief. Then, he heard her say, “I’ll call you to the same room as you!”
2023-05-26 18:08:27 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-26 18:08:29 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved and entered the elevator.
2023-05-26 18:08:29 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-26 18:08:32 | INFO | fairseq.tasks.translation | example hypothesis: As soon as she raised her head, she saw Song Cheng standing in the distance! “He’s here!”
2023-05-26 18:08:32 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-26 18:08:33 | INFO | fairseq.tasks.translation | example hypothesis: Only then did Song Cheng pat his chest. “I’m scared to death! Where’s Wang Chuan?”
2023-05-26 18:08:33 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-26 18:08:35 | INFO | fairseq.tasks.translation | example hypothesis: I said, “I won’t go, I won’t be able to eat it.” “No, I won’t.”
2023-05-26 18:08:35 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-26 18:08:36 | INFO | fairseq.tasks.translation | example hypothesis: At first, everyone did not believe him, but Wang Wenhao insisted on him, making public opinion biased towards Wang Wenhao.
2023-05-26 18:08:36 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-26 18:08:39 | INFO | fairseq.tasks.translation | example hypothesis: With his status, even if Baili Hongzhuang didn’t want to treat him, he had to!
2023-05-26 18:08:39 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-26 18:08:41 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian said, “Mr. Shen, I... I’ve left too much blood. My brain is out of oxygen and I can’t think of anything. Why don’t you give me a hint?”
2023-05-26 18:08:41 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-26 18:08:44 | INFO | fairseq.tasks.translation | example hypothesis: He didn’t know why this matter would be heard by so many people. Since he couldn’t hide it anymore, he might as well just say it out loud. However, he didn’t know why Li Yuyue’
2023-05-26 18:08:44 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-26 18:08:46 | INFO | fairseq.tasks.translation | example hypothesis: She deliberately lowered her voice, but there was no way to conceal the viciousness and ruthlessness in her tone. “You... you... you... you...”
2023-05-26 18:08:46 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-26 18:08:48 | INFO | fairseq.tasks.translation | example hypothesis: The strength of a beast pet of different levels was different. However, a beast pet was precious and rare. It was impossible for an ordinary person to possess it. Even an official’s disciple would not be able to possess it.
2023-05-26 18:08:48 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-26 18:08:50 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chixia gritted her teeth and cursed in a low voice, "You're so shameless!"
2023-05-26 18:08:50 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-26 18:08:52 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang had concealed it well, Di Beichen could still see the flash of emotion in her eyes. A hint of warmth could be seen in his eyes.
2023-05-26 18:08:52 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-26 18:08:54 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia walked in, not to mention the guests who stayed, there weren't even a few waiters. The hotel was empty, and the hotel was empty. The hotel was empty.
2023-05-26 18:08:54 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-26 18:08:57 | INFO | fairseq.tasks.translation | example hypothesis: This person was none other than the Ye Family’s Fourth Young Lady, Ye Qingling.
2023-05-26 18:08:57 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-26 18:09:00 | INFO | fairseq.tasks.translation | example hypothesis: At this moment, she felt that her chin was about to break.
2023-05-26 18:09:00 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-26 18:09:03 | INFO | fairseq.tasks.translation | example hypothesis: “Alright, Mu Zi, help me. If it wasn't for you, that old man wouldn't have set his eyes on me,” I said.
2023-05-26 18:09:03 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-26 18:09:05 | INFO | fairseq.tasks.translation | example hypothesis: Bai Li Yu Yan was even more excited. This matter was completely orchestrated by her. Earlier, Bai Li Hong Zhuang treated her like that. This time, she would definitely make Bai Li Hong Zhuang suffer.
2023-05-26 18:09:05 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-26 18:09:07 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How can that be? They are also four Magisters, of course they won’t submit so easily. After arguing for a long time, they decided to use the competition to get control of the Kingdom of E Xia.”
2023-05-26 18:09:07 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-26 18:09:10 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a bit. Originally, he had been looking for a reason for Li Yuyue to not be able to participate in the Royal Family Hunting Competition.
2023-05-26 18:09:10 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-26 18:09:13 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my level good? They’re all the most outstanding talents in the country. Is my magic that weak?” The old demon asked.
2023-05-26 18:09:13 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-26 18:09:18 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yi Bei’s words meant that if Fang Chi Xia didn’t want to go, then he didn’t need to go. However, if Fang Chi Xia didn’t want to go, he wouldn’t be able to do so.
2023-05-26 18:09:18 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-26 18:09:22 | INFO | fairseq.tasks.translation | example hypothesis: She tilted her head and saw that the five palm prints on her cheeks were very conspicuous. They were swollen at a speed visible to the naked eye. She stretched out her hand and touched them. Immediately, she couldn’t help but let out a hissing sound. It was really painful.
2023-05-26 18:09:22 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-26 18:09:25 | INFO | fairseq.tasks.translation | example hypothesis: This... How could this be the charm that could be emitted by that good-for-nothing?
2023-05-26 18:09:25 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-26 18:09:26 | INFO | fairseq.tasks.translation | example hypothesis: How could Wang Wenhao find the news agency? The chief editor should have called her to inform her not to come to the newspaper. It was the right choice, but these three people... had schemed against her!
2023-05-26 18:09:26 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-26 18:09:32 | INFO | fairseq.tasks.translation | example hypothesis: When I heard Teacher Di’s praise, I was delighted. I retracted my energy ball with my left hand, and a light sword shot out from my right hand towards Teacher Zhen. The light sword actually managed to hit me. I was shocked, and upon closer inspection, I realized that it was just an afterimage. Teacher Zhen had already moved to my back and shouted, “Berserk Space
2023-05-26 18:09:32 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-26 18:09:37 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Originally, we proposed a competition of two wins in three rounds, but they said it wasn’t fair because we have Teacher Di and Teacher Zhen. Our ranking is higher than theirs, and they suggested that we win five rounds. Because we were the one who proposed the competition, the competition method could only be decided by them. Three days later, we will have a secret competition at the Royal Martial Arts Arena. The competition will be held three days later.
2023-05-26 18:09:37 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-26 18:09:40 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Di used a Level Seven Light element spell, Light Thunder Burst. I didn’t use much of this spell, because my control over it wasn’t ideal. Teacher Di released nine rays of light and surrounded me, forming a simple formation that prevented me from escaping in a short distance.
2023-05-26 18:09:40 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-26 18:09:46 | INFO | fairseq.tasks.translation | example hypothesis: As soon as Ma Ke and the two teachers reached the other side, Teacher Zhen sent me a small Dimensional Slash. As expected of the continent’s number one Magician. The powerful suction power of his Dimensional Slash was much stronger than mine. A small spatial crack appeared beside me, and a powerful suction force immediately swept over. The two of them were stunned for a moment, then they looked at each other and said, “I don’t know who they’ll send out in the fifth match, but I don’t know who they’ll send out in the fifth match, so you two must try to make a breakthrough in the next two days, because magic power isn’t something that can be improved in a short period of time. Good, Mark, Xing, Si Di, you stay here, let’s start.”
2023-05-26 18:09:46 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-26 18:09:47 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.487 | nll_loss 2.866 | ppl 7.29 | bleu 17.38 | wps 886 | wpb 2420.8 | bsz 84.5 | num_updates 20021 | best_bleu 17.38
2023-05-26 18:09:47 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-26 18:09:54 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/mega-1-1-0.2-sf[zh-en]/checkpoint_best.pt (epoch 3 @ 20021 updates, score 17.38) (writing took 7.166440987959504 seconds)
2023-05-26 18:09:54 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-05-26 18:09:54 | INFO | train | epoch 003 | loss 4.442 | nll_loss 2.851 | ppl 7.21 | wps 28614.5 | ups 0.5 | wpb 57190.5 | bsz 1477.5 | num_updates 20021 | lr 0.000446979 | gnorm 0.223 | clip 100 | loss_scale 8 | train_wall 12962 | wall 40148
2023-05-26 18:09:54 | INFO | fairseq.trainer | begin training epoch 4
2023-05-26 18:12:48 | INFO | train_inner | epoch 004:     79 / 6686 loss=4.375, nll_loss=2.775, ppl=6.85, wps=18337, ups=0.32, wpb=56743.7, bsz=1475, num_updates=20100, lr=0.0004461, gnorm=0.215, clip=100, loss_scale=8, train_wall=196, wall=40322
2023-05-26 18:14:06 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2023-05-26 18:16:15 | INFO | train_inner | epoch 004:    180 / 6686 loss=4.386, nll_loss=2.788, ppl=6.91, wps=27625.7, ups=0.48, wpb=57178.2, bsz=1450, num_updates=20200, lr=0.000444994, gnorm=0.216, clip=100, loss_scale=5, train_wall=197, wall=40529
2023-05-26 18:19:38 | INFO | train_inner | epoch 004:    280 / 6686 loss=4.374, nll_loss=2.774, ppl=6.84, wps=28333.8, ups=0.49, wpb=57357.5, bsz=1484.5, num_updates=20300, lr=0.000443897, gnorm=0.212, clip=100, loss_scale=4, train_wall=195, wall=40732
2023-05-26 18:22:56 | INFO | train_inner | epoch 004:    380 / 6686 loss=4.381, nll_loss=2.782, ppl=6.88, wps=28783.6, ups=0.5, wpb=57049.4, bsz=1456.1, num_updates=20400, lr=0.000442807, gnorm=0.221, clip=100, loss_scale=4, train_wall=194, wall=40930
2023-05-26 18:26:14 | INFO | train_inner | epoch 004:    480 / 6686 loss=4.37, nll_loss=2.77, ppl=6.82, wps=28901.4, ups=0.5, wpb=57240.6, bsz=1493.3, num_updates=20500, lr=0.000441726, gnorm=0.224, clip=100, loss_scale=4, train_wall=194, wall=41128
2023-05-26 18:29:33 | INFO | train_inner | epoch 004:    580 / 6686 loss=4.385, nll_loss=2.787, ppl=6.9, wps=28872.5, ups=0.5, wpb=57277.3, bsz=1477.8, num_updates=20600, lr=0.000440653, gnorm=0.224, clip=100, loss_scale=4, train_wall=194, wall=41326
2023-05-26 18:32:50 | INFO | train_inner | epoch 004:    680 / 6686 loss=4.381, nll_loss=2.783, ppl=6.88, wps=28975.2, ups=0.51, wpb=57195.8, bsz=1467.3, num_updates=20700, lr=0.000439587, gnorm=0.224, clip=100, loss_scale=6, train_wall=193, wall=41524
2023-05-26 18:36:08 | INFO | train_inner | epoch 004:    780 / 6686 loss=4.382, nll_loss=2.784, ppl=6.89, wps=28987.9, ups=0.5, wpb=57424.2, bsz=1495.4, num_updates=20800, lr=0.000438529, gnorm=0.217, clip=100, loss_scale=8, train_wall=194, wall=41722
2023-05-26 18:39:25 | INFO | train_inner | epoch 004:    880 / 6686 loss=4.376, nll_loss=2.777, ppl=6.85, wps=28904.8, ups=0.51, wpb=57035.1, bsz=1462.9, num_updates=20900, lr=0.000437479, gnorm=0.222, clip=100, loss_scale=8, train_wall=194, wall=41919
2023-05-26 18:42:43 | INFO | train_inner | epoch 004:    980 / 6686 loss=4.381, nll_loss=2.783, ppl=6.88, wps=29004, ups=0.51, wpb=57253.7, bsz=1458.9, num_updates=21000, lr=0.000436436, gnorm=0.215, clip=100, loss_scale=8, train_wall=194, wall=42117
2023-05-26 18:46:00 | INFO | train_inner | epoch 004:   1080 / 6686 loss=4.383, nll_loss=2.784, ppl=6.89, wps=28954, ups=0.51, wpb=57046.3, bsz=1456.3, num_updates=21100, lr=0.0004354, gnorm=0.217, clip=100, loss_scale=8, train_wall=193, wall=42314
2023-05-26 18:49:18 | INFO | train_inner | epoch 004:   1180 / 6686 loss=4.371, nll_loss=2.771, ppl=6.82, wps=28876.8, ups=0.5, wpb=57314.2, bsz=1460.6, num_updates=21200, lr=0.000434372, gnorm=0.22, clip=100, loss_scale=11, train_wall=195, wall=42512
2023-05-26 18:51:15 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 18:52:39 | INFO | train_inner | epoch 004:   1281 / 6686 loss=4.384, nll_loss=2.785, ppl=6.89, wps=28519.1, ups=0.5, wpb=57136.3, bsz=1476.2, num_updates=21300, lr=0.000433351, gnorm=0.215, clip=100, loss_scale=13, train_wall=196, wall=42712
2023-05-26 18:55:57 | INFO | train_inner | epoch 004:   1381 / 6686 loss=4.385, nll_loss=2.787, ppl=6.9, wps=28911, ups=0.5, wpb=57284, bsz=1475.7, num_updates=21400, lr=0.000432338, gnorm=0.212, clip=100, loss_scale=8, train_wall=194, wall=42911
2023-05-26 18:59:16 | INFO | train_inner | epoch 004:   1481 / 6686 loss=4.37, nll_loss=2.77, ppl=6.82, wps=28722.5, ups=0.5, wpb=57110.1, bsz=1463.5, num_updates=21500, lr=0.000431331, gnorm=0.224, clip=100, loss_scale=8, train_wall=195, wall=43109
2023-05-26 19:02:33 | INFO | train_inner | epoch 004:   1581 / 6686 loss=4.374, nll_loss=2.775, ppl=6.84, wps=28860.7, ups=0.51, wpb=57107.3, bsz=1481.9, num_updates=21600, lr=0.000430331, gnorm=0.22, clip=100, loss_scale=8, train_wall=194, wall=43307
2023-05-26 19:05:51 | INFO | train_inner | epoch 004:   1681 / 6686 loss=4.37, nll_loss=2.771, ppl=6.82, wps=28916.9, ups=0.51, wpb=57202.9, bsz=1483.9, num_updates=21700, lr=0.000429339, gnorm=0.217, clip=100, loss_scale=8, train_wall=194, wall=43505
2023-05-26 19:09:08 | INFO | train_inner | epoch 004:   1781 / 6686 loss=4.373, nll_loss=2.774, ppl=6.84, wps=29022.6, ups=0.51, wpb=57045.9, bsz=1477.4, num_updates=21800, lr=0.000428353, gnorm=0.222, clip=100, loss_scale=10, train_wall=193, wall=43702
2023-05-26 19:09:31 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 19:12:27 | INFO | train_inner | epoch 004:   1882 / 6686 loss=4.371, nll_loss=2.771, ppl=6.83, wps=28690.2, ups=0.5, wpb=57209.6, bsz=1505.8, num_updates=21900, lr=0.000427374, gnorm=0.222, clip=100, loss_scale=9, train_wall=196, wall=43901
2023-05-26 19:15:46 | INFO | train_inner | epoch 004:   1982 / 6686 loss=4.369, nll_loss=2.77, ppl=6.82, wps=28862.1, ups=0.5, wpb=57251.8, bsz=1496, num_updates=22000, lr=0.000426401, gnorm=0.217, clip=100, loss_scale=8, train_wall=195, wall=44100
2023-05-26 19:19:04 | INFO | train_inner | epoch 004:   2082 / 6686 loss=4.369, nll_loss=2.769, ppl=6.82, wps=28776.2, ups=0.5, wpb=57148.2, bsz=1494.8, num_updates=22100, lr=0.000425436, gnorm=0.219, clip=100, loss_scale=8, train_wall=195, wall=44298
2023-05-26 19:20:13 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2023-05-26 19:22:24 | INFO | train_inner | epoch 004:   2183 / 6686 loss=4.368, nll_loss=2.768, ppl=6.81, wps=28588.5, ups=0.5, wpb=57045.5, bsz=1483.3, num_updates=22200, lr=0.000424476, gnorm=0.227, clip=100, loss_scale=5, train_wall=196, wall=44498
2023-05-26 19:25:41 | INFO | train_inner | epoch 004:   2283 / 6686 loss=4.38, nll_loss=2.782, ppl=6.88, wps=28883.8, ups=0.51, wpb=57091, bsz=1451.4, num_updates=22300, lr=0.000423524, gnorm=0.215, clip=100, loss_scale=4, train_wall=194, wall=44695
2023-05-26 19:28:59 | INFO | train_inner | epoch 004:   2383 / 6686 loss=4.372, nll_loss=2.773, ppl=6.83, wps=28892.9, ups=0.51, wpb=57186.3, bsz=1465, num_updates=22400, lr=0.000422577, gnorm=0.22, clip=100, loss_scale=4, train_wall=194, wall=44893
2023-05-26 19:32:17 | INFO | train_inner | epoch 004:   2483 / 6686 loss=4.359, nll_loss=2.758, ppl=6.76, wps=28921.9, ups=0.51, wpb=57267.7, bsz=1475.3, num_updates=22500, lr=0.000421637, gnorm=0.223, clip=100, loss_scale=4, train_wall=194, wall=45091
2023-05-26 19:35:35 | INFO | train_inner | epoch 004:   2583 / 6686 loss=4.373, nll_loss=2.774, ppl=6.84, wps=28956.1, ups=0.51, wpb=57143.8, bsz=1466.4, num_updates=22600, lr=0.000420703, gnorm=0.235, clip=100, loss_scale=4, train_wall=194, wall=45289
2023-05-26 19:38:53 | INFO | train_inner | epoch 004:   2683 / 6686 loss=4.373, nll_loss=2.774, ppl=6.84, wps=28858.1, ups=0.5, wpb=57288.3, bsz=1472.4, num_updates=22700, lr=0.000419775, gnorm=0.214, clip=100, loss_scale=6, train_wall=195, wall=45487
2023-05-26 19:42:12 | INFO | train_inner | epoch 004:   2783 / 6686 loss=4.37, nll_loss=2.771, ppl=6.82, wps=28877, ups=0.5, wpb=57279.6, bsz=1474.3, num_updates=22800, lr=0.000418854, gnorm=0.22, clip=100, loss_scale=8, train_wall=195, wall=45685
2023-05-26 19:45:30 | INFO | train_inner | epoch 004:   2883 / 6686 loss=4.36, nll_loss=2.76, ppl=6.77, wps=28872.1, ups=0.51, wpb=57149.6, bsz=1495.9, num_updates=22900, lr=0.000417938, gnorm=0.223, clip=100, loss_scale=8, train_wall=194, wall=45883
2023-05-26 19:48:47 | INFO | train_inner | epoch 004:   2983 / 6686 loss=4.363, nll_loss=2.763, ppl=6.79, wps=28957.8, ups=0.51, wpb=57303.8, bsz=1489.8, num_updates=23000, lr=0.000417029, gnorm=0.219, clip=100, loss_scale=8, train_wall=194, wall=46081
2023-05-26 19:52:06 | INFO | train_inner | epoch 004:   3083 / 6686 loss=4.369, nll_loss=2.77, ppl=6.82, wps=28893.6, ups=0.5, wpb=57375.6, bsz=1483.4, num_updates=23100, lr=0.000416125, gnorm=0.218, clip=100, loss_scale=8, train_wall=195, wall=46280
2023-05-26 19:54:29 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 19:55:26 | INFO | train_inner | epoch 004:   3184 / 6686 loss=4.376, nll_loss=2.778, ppl=6.86, wps=28587, ups=0.5, wpb=57181.2, bsz=1466.1, num_updates=23200, lr=0.000415227, gnorm=0.227, clip=100, loss_scale=9, train_wall=196, wall=46480
2023-05-26 19:58:44 | INFO | train_inner | epoch 004:   3284 / 6686 loss=4.356, nll_loss=2.755, ppl=6.75, wps=28968.5, ups=0.51, wpb=57344.3, bsz=1481.6, num_updates=23300, lr=0.000414335, gnorm=0.216, clip=100, loss_scale=8, train_wall=194, wall=46678
2023-05-26 20:02:01 | INFO | train_inner | epoch 004:   3384 / 6686 loss=4.375, nll_loss=2.776, ppl=6.85, wps=28956.3, ups=0.51, wpb=57059.3, bsz=1472.2, num_updates=23400, lr=0.000413449, gnorm=0.22, clip=100, loss_scale=8, train_wall=193, wall=46875
2023-05-26 20:05:18 | INFO | train_inner | epoch 004:   3484 / 6686 loss=4.362, nll_loss=2.762, ppl=6.78, wps=28932.6, ups=0.51, wpb=56960, bsz=1492, num_updates=23500, lr=0.000412568, gnorm=0.22, clip=100, loss_scale=8, train_wall=193, wall=47072
2023-05-26 20:08:35 | INFO | train_inner | epoch 004:   3584 / 6686 loss=4.362, nll_loss=2.762, ppl=6.78, wps=28956, ups=0.51, wpb=57119.9, bsz=1464.1, num_updates=23600, lr=0.000411693, gnorm=0.213, clip=100, loss_scale=8, train_wall=193, wall=47269
2023-05-26 20:11:52 | INFO | train_inner | epoch 004:   3684 / 6686 loss=4.374, nll_loss=2.775, ppl=6.84, wps=28941.9, ups=0.51, wpb=57067.9, bsz=1458.6, num_updates=23700, lr=0.000410824, gnorm=0.219, clip=100, loss_scale=9, train_wall=193, wall=47466
2023-05-26 20:15:10 | INFO | train_inner | epoch 004:   3784 / 6686 loss=4.364, nll_loss=2.765, ppl=6.8, wps=28941.4, ups=0.51, wpb=57206.6, bsz=1488, num_updates=23800, lr=0.00040996, gnorm=0.215, clip=100, loss_scale=16, train_wall=194, wall=47664
2023-05-26 20:15:40 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 20:18:30 | INFO | train_inner | epoch 004:   3885 / 6686 loss=4.363, nll_loss=2.763, ppl=6.79, wps=28595.2, ups=0.5, wpb=57140.6, bsz=1462.4, num_updates=23900, lr=0.000409101, gnorm=0.226, clip=100, loss_scale=9, train_wall=196, wall=47864
2023-05-26 20:21:48 | INFO | train_inner | epoch 004:   3985 / 6686 loss=4.354, nll_loss=2.753, ppl=6.74, wps=28869.7, ups=0.5, wpb=57256.8, bsz=1496.1, num_updates=24000, lr=0.000408248, gnorm=0.222, clip=100, loss_scale=8, train_wall=194, wall=48062
2023-05-26 20:25:06 | INFO | train_inner | epoch 004:   4085 / 6686 loss=4.348, nll_loss=2.747, ppl=6.71, wps=28814.5, ups=0.5, wpb=57108.8, bsz=1488.9, num_updates=24100, lr=0.0004074, gnorm=0.215, clip=100, loss_scale=8, train_wall=194, wall=48260
2023-05-26 20:28:24 | INFO | train_inner | epoch 004:   4185 / 6686 loss=4.369, nll_loss=2.77, ppl=6.82, wps=28914, ups=0.51, wpb=57087.5, bsz=1467.1, num_updates=24200, lr=0.000406558, gnorm=0.219, clip=100, loss_scale=8, train_wall=194, wall=48458
2023-05-26 20:31:42 | INFO | train_inner | epoch 004:   4285 / 6686 loss=4.356, nll_loss=2.755, ppl=6.75, wps=28910.3, ups=0.51, wpb=57203.8, bsz=1470.7, num_updates=24300, lr=0.00040572, gnorm=0.213, clip=100, loss_scale=8, train_wall=194, wall=48656
2023-05-26 20:33:16 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 20:35:01 | INFO | train_inner | epoch 004:   4386 / 6686 loss=4.384, nll_loss=2.787, ppl=6.9, wps=28764, ups=0.5, wpb=57360.2, bsz=1452.7, num_updates=24400, lr=0.000404888, gnorm=0.209, clip=100, loss_scale=10, train_wall=196, wall=48855
2023-05-26 20:38:18 | INFO | train_inner | epoch 004:   4486 / 6686 loss=4.36, nll_loss=2.76, ppl=6.77, wps=29052.4, ups=0.51, wpb=57314.5, bsz=1479.2, num_updates=24500, lr=0.000404061, gnorm=0.218, clip=100, loss_scale=8, train_wall=193, wall=49052
2023-05-26 20:41:36 | INFO | train_inner | epoch 004:   4586 / 6686 loss=4.367, nll_loss=2.768, ppl=6.81, wps=28894.1, ups=0.51, wpb=57195, bsz=1472.4, num_updates=24600, lr=0.000403239, gnorm=0.217, clip=100, loss_scale=8, train_wall=194, wall=49250
2023-05-26 20:44:54 | INFO | train_inner | epoch 004:   4686 / 6686 loss=4.358, nll_loss=2.758, ppl=6.76, wps=28930.6, ups=0.51, wpb=57262, bsz=1478.6, num_updates=24700, lr=0.000402422, gnorm=0.217, clip=100, loss_scale=8, train_wall=194, wall=49448
2023-05-26 20:48:12 | INFO | train_inner | epoch 004:   4786 / 6686 loss=4.36, nll_loss=2.76, ppl=6.77, wps=28907.1, ups=0.51, wpb=57229.8, bsz=1461.1, num_updates=24800, lr=0.00040161, gnorm=0.213, clip=100, loss_scale=8, train_wall=194, wall=49646
2023-05-26 20:51:17 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 20:51:33 | INFO | train_inner | epoch 004:   4887 / 6686 loss=4.354, nll_loss=2.753, ppl=6.74, wps=28550.6, ups=0.5, wpb=57164.2, bsz=1479, num_updates=24900, lr=0.000400802, gnorm=0.223, clip=100, loss_scale=11, train_wall=196, wall=49846
2023-05-26 20:54:51 | INFO | train_inner | epoch 004:   4987 / 6686 loss=4.355, nll_loss=2.754, ppl=6.75, wps=28930, ups=0.51, wpb=57283.1, bsz=1482, num_updates=25000, lr=0.0004, gnorm=0.218, clip=100, loss_scale=8, train_wall=194, wall=50044
2023-05-26 20:58:08 | INFO | train_inner | epoch 004:   5087 / 6686 loss=4.341, nll_loss=2.738, ppl=6.67, wps=28956.7, ups=0.51, wpb=57290.9, bsz=1503.9, num_updates=25100, lr=0.000399202, gnorm=0.222, clip=100, loss_scale=8, train_wall=194, wall=50242
2023-05-26 21:01:26 | INFO | train_inner | epoch 004:   5187 / 6686 loss=4.357, nll_loss=2.757, ppl=6.76, wps=28997.9, ups=0.51, wpb=57232.9, bsz=1477.4, num_updates=25200, lr=0.00039841, gnorm=0.218, clip=100, loss_scale=8, train_wall=194, wall=50440
2023-05-26 21:04:43 | INFO | train_inner | epoch 004:   5287 / 6686 loss=4.361, nll_loss=2.761, ppl=6.78, wps=28937.8, ups=0.51, wpb=57176.6, bsz=1470.2, num_updates=25300, lr=0.000397621, gnorm=0.22, clip=100, loss_scale=8, train_wall=194, wall=50637
2023-05-26 21:08:01 | INFO | train_inner | epoch 004:   5387 / 6686 loss=4.342, nll_loss=2.74, ppl=6.68, wps=28916.4, ups=0.51, wpb=57148.6, bsz=1480.8, num_updates=25400, lr=0.000396838, gnorm=0.22, clip=100, loss_scale=8, train_wall=194, wall=50835
2023-05-26 21:08:19 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 21:11:20 | INFO | train_inner | epoch 004:   5488 / 6686 loss=4.36, nll_loss=2.76, ppl=6.78, wps=28645.6, ups=0.5, wpb=57065.4, bsz=1469.1, num_updates=25500, lr=0.000396059, gnorm=0.215, clip=100, loss_scale=8, train_wall=196, wall=51034
2023-05-26 21:14:38 | INFO | train_inner | epoch 004:   5588 / 6686 loss=4.357, nll_loss=2.757, ppl=6.76, wps=28923.8, ups=0.51, wpb=57082.2, bsz=1471, num_updates=25600, lr=0.000395285, gnorm=0.212, clip=100, loss_scale=8, train_wall=194, wall=51231
2023-05-26 21:17:55 | INFO | train_inner | epoch 004:   5688 / 6686 loss=4.348, nll_loss=2.747, ppl=6.71, wps=29050.1, ups=0.51, wpb=57323.3, bsz=1495, num_updates=25700, lr=0.000394515, gnorm=0.228, clip=100, loss_scale=8, train_wall=194, wall=51429
2023-05-26 21:21:13 | INFO | train_inner | epoch 004:   5788 / 6686 loss=4.357, nll_loss=2.757, ppl=6.76, wps=28799.2, ups=0.5, wpb=57179.6, bsz=1471.4, num_updates=25800, lr=0.00039375, gnorm=0.218, clip=100, loss_scale=8, train_wall=195, wall=51627
2023-05-26 21:24:30 | INFO | train_inner | epoch 004:   5888 / 6686 loss=4.351, nll_loss=2.75, ppl=6.73, wps=29059.6, ups=0.51, wpb=57239.8, bsz=1473.3, num_updates=25900, lr=0.000392989, gnorm=0.213, clip=100, loss_scale=8, train_wall=193, wall=51824
2023-05-26 21:26:43 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 21:27:50 | INFO | train_inner | epoch 004:   5989 / 6686 loss=4.35, nll_loss=2.749, ppl=6.72, wps=28640.7, ups=0.5, wpb=57279.3, bsz=1482.2, num_updates=26000, lr=0.000392232, gnorm=0.215, clip=100, loss_scale=12, train_wall=196, wall=52024
2023-05-26 21:31:08 | INFO | train_inner | epoch 004:   6089 / 6686 loss=4.342, nll_loss=2.741, ppl=6.68, wps=28914.8, ups=0.51, wpb=57234.6, bsz=1499.8, num_updates=26100, lr=0.00039148, gnorm=0.225, clip=100, loss_scale=8, train_wall=194, wall=52222
2023-05-26 21:34:26 | INFO | train_inner | epoch 004:   6189 / 6686 loss=4.352, nll_loss=2.752, ppl=6.74, wps=28974.4, ups=0.51, wpb=57228.5, bsz=1498.8, num_updates=26200, lr=0.000390732, gnorm=0.224, clip=100, loss_scale=8, train_wall=194, wall=52420
2023-05-26 21:37:43 | INFO | train_inner | epoch 004:   6289 / 6686 loss=4.338, nll_loss=2.736, ppl=6.66, wps=29009.9, ups=0.51, wpb=57273.5, bsz=1512.2, num_updates=26300, lr=0.000389989, gnorm=0.213, clip=100, loss_scale=8, train_wall=194, wall=52617
2023-05-26 21:41:00 | INFO | train_inner | epoch 004:   6389 / 6686 loss=4.356, nll_loss=2.757, ppl=6.76, wps=29019.9, ups=0.51, wpb=57111.7, bsz=1474.9, num_updates=26400, lr=0.000389249, gnorm=0.225, clip=100, loss_scale=8, train_wall=193, wall=52814
2023-05-26 21:43:50 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 21:44:19 | INFO | train_inner | epoch 004:   6490 / 6686 loss=4.346, nll_loss=2.745, ppl=6.7, wps=28726.5, ups=0.5, wpb=57224.4, bsz=1484.8, num_updates=26500, lr=0.000388514, gnorm=0.207, clip=100, loss_scale=9, train_wall=195, wall=53013
2023-05-26 21:47:37 | INFO | train_inner | epoch 004:   6590 / 6686 loss=4.345, nll_loss=2.744, ppl=6.7, wps=28821.1, ups=0.51, wpb=57064, bsz=1472.9, num_updates=26600, lr=0.000387783, gnorm=0.217, clip=100, loss_scale=8, train_wall=194, wall=53211
2023-05-26 21:50:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-26 21:50:52 | INFO | fairseq.tasks.translation | example hypothesis: [Why?] [Why is he unhappy?] [Why?] [Why?]
2023-05-26 21:50:52 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-26 21:50:53 | INFO | fairseq.tasks.translation | example hypothesis: In a moment, I’ll make you lose so badly that you won’t even have a single piece of pants left!
2023-05-26 21:50:53 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-26 21:50:54 | INFO | fairseq.tasks.translation | example hypothesis: Shen Liangchuan heaved a sigh of relief. Then, he heard her say, “I’ll call you in the same room as you!”
2023-05-26 21:50:54 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-26 21:50:56 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved and entered the elevator.
2023-05-26 21:50:56 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-26 21:50:59 | INFO | fairseq.tasks.translation | example hypothesis: As soon as she raised her head, she saw Song Cheng standing in the distance! He was Song Cheng!
2023-05-26 21:50:59 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-26 21:51:00 | INFO | fairseq.tasks.translation | example hypothesis: Only then did Song Cheng pat his chest. “I’m scared to death! Where’s Wang Chuan?”
2023-05-26 21:51:00 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-26 21:51:02 | INFO | fairseq.tasks.translation | example hypothesis: I said, “I won’t go. I won’t be able to eat it if I don’t.”
2023-05-26 21:51:02 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-26 21:51:03 | INFO | fairseq.tasks.translation | example hypothesis: At first, everyone did not believe it, but Wang Wenhao insisted that he would lean towards Wang Wenhao.
2023-05-26 21:51:03 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-26 21:51:06 | INFO | fairseq.tasks.translation | example hypothesis: With his status, even if Baili Hongzhuang did not want to cure him, he had to!
2023-05-26 21:51:06 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-26 21:51:08 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian said, “Mr. Shen, I, I have left too much blood. My brain is lacking oxygen, so I can’t think of a way to get it out. Or, please give me a
2023-05-26 21:51:08 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-26 21:51:11 | INFO | fairseq.tasks.translation | example hypothesis: He didn’t know why this matter would be heard by so many people. Since he couldn’t cover it up, he might as well say it out loud. However, he didn’t know why Li Yuyue was injured
2023-05-26 21:51:11 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-26 21:51:13 | INFO | fairseq.tasks.translation | example hypothesis: He deliberately lowered his voice, but it couldn’t conceal the viciousness and ruthlessness in his voice. “I’m going to destroy you!”
2023-05-26 21:51:13 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-26 21:51:15 | INFO | fairseq.tasks.translation | example hypothesis: The strength of a beast pet of different levels was different, but a beast pet was precious and rare. It was impossible for an ordinary person to possess it, and even an official’s disciple would not be able to possess it.
2023-05-26 21:51:15 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-26 21:51:17 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chixia gritted her teeth and cursed in a low voice, "I'm sorry!"
2023-05-26 21:51:17 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-26 21:51:19 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang had concealed it very well, Di Beichen could still see the ripples in her eyes that flashed by in a flash. His eyes were filled with warmth.
2023-05-26 21:51:19 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-26 21:51:21 | INFO | fairseq.tasks.translation | example hypothesis: Ever since Fang Chi Xia entered the hotel, not to mention the guests who were living in the hotel, there weren’t even a few waiters who were allowed to stay in the hotel.
2023-05-26 21:51:21 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-26 21:51:24 | INFO | fairseq.tasks.translation | example hypothesis: This person was none other than the Ye family’s fourth young miss – Ye Qingling.
2023-05-26 21:51:24 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-26 21:51:27 | INFO | fairseq.tasks.translation | example hypothesis: Because at this moment, she felt as if her chin was about to shatter.
2023-05-26 21:51:27 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-26 21:51:30 | INFO | fairseq.tasks.translation | example hypothesis: “Good Mu Zi, help me. If it wasn't for you, that old man wouldn't have set his sights on me,” I said.
2023-05-26 21:51:30 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-26 21:51:32 | INFO | fairseq.tasks.translation | example hypothesis: Bai Li Yu Yan was even more excited. This matter was completely directed by her. Earlier, Bai Li Hong Zhuang had treated her like that. This time, she would definitely make Bai Li Hong Zhuang suffer.
2023-05-26 21:51:32 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-26 21:51:34 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How can that be? They are also four mages, of course they won’t submit so easily. After arguing for a long time, they decided to use the competition to get control of the kingdom in the future.”
2023-05-26 21:51:34 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-26 21:51:37 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a bit. Originally, he had been looking for a reason for Li Yuyue’s inability to participate in the royal family’s hunting competition.
2023-05-26 21:51:37 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-26 21:51:40 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my level good? They’re all the most outstanding talents in the country, so how can my magic be so weak?”
2023-05-26 21:51:40 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-26 21:51:45 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yi Bei’s words meant that if Fang Chi Xia didn’t want to go, then he wouldn’t need to go. If Fang Chi Xia didn’t want to go, then he wouldn’t need to go.
2023-05-26 21:51:45 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-26 21:51:49 | INFO | fairseq.tasks.translation | example hypothesis: She tilted her head and saw that the five palm prints on her face were very eye-catching. They were swollen at a speed visible to the naked eye. She reached out her hand to touch them, and she couldn’t help but let out a hissing sound. It really hurt.
2023-05-26 21:51:49 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-26 21:51:52 | INFO | fairseq.tasks.translation | example hypothesis: This... How could it possibly be the charm that that piece of trash was able to emit? [1]
2023-05-26 21:51:52 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-26 21:51:53 | INFO | fairseq.tasks.translation | example hypothesis: How did Wang Wenhao find the news agency? The chief editor should have called her to inform her not to come to the news agency, but the three of them... had schemed against her!
2023-05-26 21:51:53 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-26 21:51:59 | INFO | fairseq.tasks.translation | example hypothesis: Hearing Teacher Di’s praise, I was overjoyed. I retracted my energy ball with my left hand and shot a beam of light towards Teacher Zhen with my right hand. The beam of light actually managed to hit me smoothly. I was shocked, and upon closer inspection, I realized that it was only an afterimage. Teacher Zhen had already moved behind me and shouted, “Berserk Space!”
2023-05-26 21:51:59 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-26 21:52:04 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Originally, we proposed a competition of two wins in three rounds, but on their side, it wasn’t fair, because we have Teacher Di and Teacher Zhen, and their ranking is higher than theirs. They proposed five rounds to win three rounds, and because we proposed the competition, the method of the competition can only be listened to by them. Three days later, we will have a secret competition in the Royal Family’s martial arts arena. We will
2023-05-26 21:52:04 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-26 21:52:07 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Di used a light element level 7 spell, Light Thunder Chain Explosion. I rarely used this spell, because it wasn’t very good at controlling it. Teacher Di released nine lightning bolts to surround me, forming a simple formation that prevented me from escaping in a short distance. After that, the lightning bolts exploded and formed a powerful attack.
2023-05-26 21:52:07 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-26 21:52:12 | INFO | fairseq.tasks.translation | example hypothesis: As soon as Ma Ke and the two teachers walked to the other side, Teacher Zhen sent a small Dimensional Slash at me. As expected of the number one magician on the continent. The powerful suction force of his Dimensional Slash was much stronger than mine. A small spatial crack appeared beside me, and a powerful suction force immediately swept over. The two of them had already made their way to the other side of the courtyard, but they didn’t even have the time to react. They had already made their way to the other side of the courtyard.
2023-05-26 21:52:12 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-26 21:52:14 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.463 | nll_loss 2.84 | ppl 7.16 | bleu 17.84 | wps 895.9 | wpb 2420.8 | bsz 84.5 | num_updates 26696 | best_bleu 17.84
2023-05-26 21:52:14 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-26 21:52:19 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/mega-1-1-0.2-sf[zh-en]/checkpoint_best.pt (epoch 4 @ 26696 updates, score 17.84) (writing took 5.651022055186331 seconds)
2023-05-26 21:52:19 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-05-26 21:52:19 | INFO | train | epoch 004 | loss 4.365 | nll_loss 2.765 | ppl 6.8 | wps 28605.7 | ups 0.5 | wpb 57189.8 | bsz 1477.4 | num_updates 26696 | lr 0.000387085 | gnorm 0.219 | clip 100 | loss_scale 8 | train_wall 12973 | wall 53493
2023-05-26 21:52:19 | INFO | fairseq.trainer | begin training epoch 5
2023-05-26 21:52:33 | INFO | train_inner | epoch 005:      4 / 6686 loss=4.347, nll_loss=2.746, ppl=6.71, wps=19195.9, ups=0.34, wpb=56744.3, bsz=1478.3, num_updates=26700, lr=0.000387056, gnorm=0.219, clip=100, loss_scale=8, train_wall=193, wall=53507
2023-05-26 21:56:02 | INFO | train_inner | epoch 005:    104 / 6686 loss=4.311, nll_loss=2.705, ppl=6.52, wps=27463.9, ups=0.48, wpb=57333.9, bsz=1499.8, num_updates=26800, lr=0.000386334, gnorm=0.214, clip=100, loss_scale=8, train_wall=197, wall=53716
2023-05-26 21:59:24 | INFO | train_inner | epoch 005:    204 / 6686 loss=4.309, nll_loss=2.703, ppl=6.51, wps=28294.4, ups=0.49, wpb=57305.2, bsz=1487.5, num_updates=26900, lr=0.000385615, gnorm=0.221, clip=100, loss_scale=8, train_wall=195, wall=53918
2023-05-26 22:02:41 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 22:02:45 | INFO | train_inner | epoch 005:    305 / 6686 loss=4.327, nll_loss=2.723, ppl=6.6, wps=28481.5, ups=0.5, wpb=57122.5, bsz=1462.7, num_updates=27000, lr=0.0003849, gnorm=0.216, clip=100, loss_scale=8, train_wall=195, wall=54119
2023-05-26 22:06:03 | INFO | train_inner | epoch 005:    405 / 6686 loss=4.33, nll_loss=2.726, ppl=6.62, wps=28882.7, ups=0.5, wpb=57274.5, bsz=1477.8, num_updates=27100, lr=0.000384189, gnorm=0.214, clip=100, loss_scale=8, train_wall=194, wall=54317
2023-05-26 22:09:21 | INFO | train_inner | epoch 005:    505 / 6686 loss=4.316, nll_loss=2.71, ppl=6.55, wps=28962.2, ups=0.5, wpb=57396.6, bsz=1505.8, num_updates=27200, lr=0.000383482, gnorm=0.217, clip=100, loss_scale=8, train_wall=194, wall=54515
2023-05-26 22:12:39 | INFO | train_inner | epoch 005:    605 / 6686 loss=4.316, nll_loss=2.71, ppl=6.54, wps=28910.5, ups=0.51, wpb=57115.5, bsz=1472.2, num_updates=27300, lr=0.00038278, gnorm=0.216, clip=100, loss_scale=8, train_wall=194, wall=54713
2023-05-26 22:15:56 | INFO | train_inner | epoch 005:    705 / 6686 loss=4.335, nll_loss=2.732, ppl=6.64, wps=28955.1, ups=0.51, wpb=57199.5, bsz=1471.6, num_updates=27400, lr=0.00038208, gnorm=0.214, clip=100, loss_scale=8, train_wall=194, wall=54910
2023-05-26 22:19:14 | INFO | train_inner | epoch 005:    805 / 6686 loss=4.328, nll_loss=2.723, ppl=6.6, wps=28907.3, ups=0.51, wpb=57066.9, bsz=1442.6, num_updates=27500, lr=0.000381385, gnorm=0.211, clip=100, loss_scale=8, train_wall=194, wall=55108
2023-05-26 22:20:35 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 22:22:34 | INFO | train_inner | epoch 005:    906 / 6686 loss=4.329, nll_loss=2.725, ppl=6.61, wps=28636, ups=0.5, wpb=57305.9, bsz=1469.8, num_updates=27600, lr=0.000380693, gnorm=0.212, clip=100, loss_scale=10, train_wall=196, wall=55308
2023-05-26 22:25:51 | INFO | train_inner | epoch 005:   1006 / 6686 loss=4.321, nll_loss=2.716, ppl=6.57, wps=29111, ups=0.51, wpb=57247, bsz=1472.5, num_updates=27700, lr=0.000380006, gnorm=0.216, clip=100, loss_scale=8, train_wall=193, wall=55505
2023-05-26 22:29:08 | INFO | train_inner | epoch 005:   1106 / 6686 loss=4.32, nll_loss=2.715, ppl=6.57, wps=28961.7, ups=0.51, wpb=57123.8, bsz=1492.2, num_updates=27800, lr=0.000379322, gnorm=0.22, clip=100, loss_scale=8, train_wall=193, wall=55702
2023-05-26 22:32:26 | INFO | train_inner | epoch 005:   1206 / 6686 loss=4.328, nll_loss=2.724, ppl=6.61, wps=28904.6, ups=0.5, wpb=57307.9, bsz=1471.8, num_updates=27900, lr=0.000378641, gnorm=0.216, clip=100, loss_scale=8, train_wall=194, wall=55900
2023-05-26 22:35:44 | INFO | train_inner | epoch 005:   1306 / 6686 loss=4.326, nll_loss=2.721, ppl=6.59, wps=28931.8, ups=0.51, wpb=57171.5, bsz=1458.7, num_updates=28000, lr=0.000377964, gnorm=0.214, clip=100, loss_scale=8, train_wall=194, wall=56098
2023-05-26 22:38:29 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 22:39:03 | INFO | train_inner | epoch 005:   1407 / 6686 loss=4.334, nll_loss=2.731, ppl=6.64, wps=28692, ups=0.5, wpb=57109.1, bsz=1446.4, num_updates=28100, lr=0.000377291, gnorm=0.219, clip=100, loss_scale=11, train_wall=195, wall=56297
2023-05-26 22:42:20 | INFO | train_inner | epoch 005:   1507 / 6686 loss=4.327, nll_loss=2.724, ppl=6.61, wps=29077.1, ups=0.51, wpb=57270.1, bsz=1468.9, num_updates=28200, lr=0.000376622, gnorm=0.212, clip=100, loss_scale=8, train_wall=193, wall=56494
2023-05-26 22:45:37 | INFO | train_inner | epoch 005:   1607 / 6686 loss=4.328, nll_loss=2.724, ppl=6.61, wps=28960.2, ups=0.51, wpb=57168.8, bsz=1472.2, num_updates=28300, lr=0.000375956, gnorm=0.214, clip=100, loss_scale=8, train_wall=193, wall=56691
2023-05-26 22:48:55 | INFO | train_inner | epoch 005:   1707 / 6686 loss=4.315, nll_loss=2.71, ppl=6.54, wps=28844.6, ups=0.5, wpb=57129.9, bsz=1480.3, num_updates=28400, lr=0.000375293, gnorm=0.219, clip=100, loss_scale=8, train_wall=194, wall=56889
2023-05-26 22:52:12 | INFO | train_inner | epoch 005:   1807 / 6686 loss=4.316, nll_loss=2.711, ppl=6.55, wps=29057.1, ups=0.51, wpb=57278.8, bsz=1502.2, num_updates=28500, lr=0.000374634, gnorm=0.212, clip=100, loss_scale=8, train_wall=193, wall=57086
2023-05-26 22:55:30 | INFO | train_inner | epoch 005:   1907 / 6686 loss=4.318, nll_loss=2.713, ppl=6.56, wps=28925.2, ups=0.51, wpb=57072.1, bsz=1482.6, num_updates=28600, lr=0.000373979, gnorm=0.213, clip=100, loss_scale=8, train_wall=193, wall=57284
2023-05-26 22:55:57 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 22:58:49 | INFO | train_inner | epoch 005:   2008 / 6686 loss=4.321, nll_loss=2.716, ppl=6.57, wps=28736.9, ups=0.5, wpb=57245.8, bsz=1487.2, num_updates=28700, lr=0.000373327, gnorm=0.219, clip=100, loss_scale=9, train_wall=195, wall=57483
2023-05-26 23:02:07 | INFO | train_inner | epoch 005:   2108 / 6686 loss=4.326, nll_loss=2.722, ppl=6.6, wps=29002.7, ups=0.51, wpb=57313.7, bsz=1465, num_updates=28800, lr=0.000372678, gnorm=0.213, clip=100, loss_scale=8, train_wall=194, wall=57680
2023-05-26 23:05:25 | INFO | train_inner | epoch 005:   2208 / 6686 loss=4.329, nll_loss=2.725, ppl=6.61, wps=28726.1, ups=0.51, wpb=56878.8, bsz=1459.2, num_updates=28900, lr=0.000372033, gnorm=0.212, clip=100, loss_scale=8, train_wall=194, wall=57878
2023-05-26 23:08:38 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2023-05-26 23:08:44 | INFO | train_inner | epoch 005:   2309 / 6686 loss=4.326, nll_loss=2.722, ppl=6.6, wps=28648.5, ups=0.5, wpb=57010.7, bsz=1445, num_updates=29000, lr=0.000371391, gnorm=0.216, clip=100, loss_scale=8, train_wall=195, wall=58077
2023-05-26 23:12:01 | INFO | train_inner | epoch 005:   2409 / 6686 loss=4.32, nll_loss=2.715, ppl=6.57, wps=28997.6, ups=0.51, wpb=57241, bsz=1489.6, num_updates=29100, lr=0.000370752, gnorm=0.219, clip=100, loss_scale=4, train_wall=193, wall=58275
2023-05-26 23:15:20 | INFO | train_inner | epoch 005:   2509 / 6686 loss=4.317, nll_loss=2.712, ppl=6.55, wps=28905.1, ups=0.5, wpb=57394.8, bsz=1487.8, num_updates=29200, lr=0.000370117, gnorm=0.217, clip=100, loss_scale=4, train_wall=195, wall=58473
2023-05-26 23:18:37 | INFO | train_inner | epoch 005:   2609 / 6686 loss=4.316, nll_loss=2.711, ppl=6.55, wps=28877.6, ups=0.51, wpb=57041.1, bsz=1457.1, num_updates=29300, lr=0.000369484, gnorm=0.224, clip=100, loss_scale=4, train_wall=194, wall=58671
2023-05-26 23:21:55 | INFO | train_inner | epoch 005:   2709 / 6686 loss=4.312, nll_loss=2.707, ppl=6.53, wps=28924.6, ups=0.51, wpb=57274.3, bsz=1495.8, num_updates=29400, lr=0.000368856, gnorm=0.211, clip=100, loss_scale=4, train_wall=194, wall=58869
2023-05-26 23:25:12 | INFO | train_inner | epoch 005:   2809 / 6686 loss=4.321, nll_loss=2.716, ppl=6.57, wps=28974.7, ups=0.51, wpb=57192.2, bsz=1477.6, num_updates=29500, lr=0.00036823, gnorm=0.234, clip=100, loss_scale=4, train_wall=193, wall=59066
2023-05-26 23:28:30 | INFO | train_inner | epoch 005:   2909 / 6686 loss=4.32, nll_loss=2.715, ppl=6.57, wps=28942.3, ups=0.51, wpb=57040.3, bsz=1477.6, num_updates=29600, lr=0.000367607, gnorm=0.211, clip=100, loss_scale=8, train_wall=193, wall=59263
2023-05-26 23:31:47 | INFO | train_inner | epoch 005:   3009 / 6686 loss=4.319, nll_loss=2.715, ppl=6.57, wps=28981.8, ups=0.51, wpb=57164.6, bsz=1483.4, num_updates=29700, lr=0.000366988, gnorm=0.214, clip=100, loss_scale=8, train_wall=193, wall=59461
2023-05-26 23:35:04 | INFO | train_inner | epoch 005:   3109 / 6686 loss=4.317, nll_loss=2.712, ppl=6.55, wps=28932.4, ups=0.51, wpb=57106, bsz=1490.7, num_updates=29800, lr=0.000366372, gnorm=0.225, clip=100, loss_scale=8, train_wall=194, wall=59658
2023-05-26 23:38:23 | INFO | train_inner | epoch 005:   3209 / 6686 loss=4.303, nll_loss=2.697, ppl=6.48, wps=28830.4, ups=0.5, wpb=57220.9, bsz=1487.6, num_updates=29900, lr=0.000365758, gnorm=0.208, clip=100, loss_scale=8, train_wall=195, wall=59857
2023-05-26 23:41:41 | INFO | train_inner | epoch 005:   3309 / 6686 loss=4.314, nll_loss=2.709, ppl=6.54, wps=28898, ups=0.51, wpb=57210.9, bsz=1474.1, num_updates=30000, lr=0.000365148, gnorm=0.212, clip=100, loss_scale=8, train_wall=194, wall=60055
2023-05-26 23:44:39 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 23:45:01 | INFO | train_inner | epoch 005:   3410 / 6686 loss=4.318, nll_loss=2.713, ppl=6.56, wps=28620.3, ups=0.5, wpb=57213.5, bsz=1509.1, num_updates=30100, lr=0.000364541, gnorm=0.215, clip=100, loss_scale=13, train_wall=196, wall=60254
2023-05-26 23:46:28 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2023-05-26 23:48:21 | INFO | train_inner | epoch 005:   3511 / 6686 loss=4.314, nll_loss=2.708, ppl=6.54, wps=28509, ups=0.5, wpb=57152.4, bsz=1467.4, num_updates=30200, lr=0.000363937, gnorm=0.221, clip=100, loss_scale=6, train_wall=197, wall=60455
2023-05-26 23:51:38 | INFO | train_inner | epoch 005:   3611 / 6686 loss=4.312, nll_loss=2.707, ppl=6.53, wps=29009.2, ups=0.51, wpb=57194.5, bsz=1484.2, num_updates=30300, lr=0.000363336, gnorm=0.226, clip=100, loss_scale=4, train_wall=193, wall=60652
2023-05-26 23:54:55 | INFO | train_inner | epoch 005:   3711 / 6686 loss=4.312, nll_loss=2.707, ppl=6.53, wps=28980, ups=0.51, wpb=57165.5, bsz=1496.8, num_updates=30400, lr=0.000362738, gnorm=0.216, clip=100, loss_scale=4, train_wall=193, wall=60849
2023-05-26 23:58:13 | INFO | train_inner | epoch 005:   3811 / 6686 loss=4.322, nll_loss=2.718, ppl=6.58, wps=28914.5, ups=0.51, wpb=57136.8, bsz=1462.7, num_updates=30500, lr=0.000362143, gnorm=0.213, clip=100, loss_scale=4, train_wall=194, wall=61047
2023-05-27 00:01:31 | INFO | train_inner | epoch 005:   3911 / 6686 loss=4.318, nll_loss=2.714, ppl=6.56, wps=28917.3, ups=0.51, wpb=57219.5, bsz=1475, num_updates=30600, lr=0.000361551, gnorm=0.216, clip=100, loss_scale=4, train_wall=194, wall=61245
2023-05-27 00:04:49 | INFO | train_inner | epoch 005:   4011 / 6686 loss=4.308, nll_loss=2.703, ppl=6.51, wps=28977.2, ups=0.51, wpb=57362.8, bsz=1491.9, num_updates=30700, lr=0.000360961, gnorm=0.207, clip=100, loss_scale=6, train_wall=194, wall=61443
2023-05-27 00:08:06 | INFO | train_inner | epoch 005:   4111 / 6686 loss=4.31, nll_loss=2.704, ppl=6.52, wps=28972.5, ups=0.51, wpb=57182, bsz=1479.8, num_updates=30800, lr=0.000360375, gnorm=0.219, clip=100, loss_scale=8, train_wall=194, wall=61640
2023-05-27 00:11:24 | INFO | train_inner | epoch 005:   4211 / 6686 loss=4.308, nll_loss=2.703, ppl=6.51, wps=29033.2, ups=0.51, wpb=57339.6, bsz=1476.6, num_updates=30900, lr=0.000359791, gnorm=0.212, clip=100, loss_scale=8, train_wall=194, wall=61838
2023-05-27 00:14:41 | INFO | train_inner | epoch 005:   4311 / 6686 loss=4.321, nll_loss=2.717, ppl=6.57, wps=28902.1, ups=0.51, wpb=56976.7, bsz=1466.6, num_updates=31000, lr=0.000359211, gnorm=0.219, clip=100, loss_scale=8, train_wall=193, wall=62035
2023-05-27 00:17:59 | INFO | train_inner | epoch 005:   4411 / 6686 loss=4.312, nll_loss=2.707, ppl=6.53, wps=28888, ups=0.5, wpb=57210.3, bsz=1477.6, num_updates=31100, lr=0.000358633, gnorm=0.208, clip=100, loss_scale=8, train_wall=194, wall=62233
2023-05-27 00:20:30 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 00:21:19 | INFO | train_inner | epoch 005:   4512 / 6686 loss=4.306, nll_loss=2.7, ppl=6.5, wps=28711.7, ups=0.5, wpb=57441.3, bsz=1488.6, num_updates=31200, lr=0.000358057, gnorm=0.217, clip=100, loss_scale=9, train_wall=196, wall=62433
2023-05-27 00:24:36 | INFO | train_inner | epoch 005:   4612 / 6686 loss=4.313, nll_loss=2.708, ppl=6.53, wps=29015.3, ups=0.51, wpb=57199.7, bsz=1467, num_updates=31300, lr=0.000357485, gnorm=0.219, clip=100, loss_scale=8, train_wall=193, wall=62630
2023-05-27 00:27:55 | INFO | train_inner | epoch 005:   4712 / 6686 loss=4.317, nll_loss=2.713, ppl=6.56, wps=28826.6, ups=0.5, wpb=57283.4, bsz=1481.4, num_updates=31400, lr=0.000356915, gnorm=0.215, clip=100, loss_scale=8, train_wall=195, wall=62829
2023-05-27 00:31:12 | INFO | train_inner | epoch 005:   4812 / 6686 loss=4.318, nll_loss=2.714, ppl=6.56, wps=28951.8, ups=0.51, wpb=57205.9, bsz=1479.7, num_updates=31500, lr=0.000356348, gnorm=0.216, clip=100, loss_scale=8, train_wall=194, wall=63026
2023-05-27 00:34:30 | INFO | train_inner | epoch 005:   4912 / 6686 loss=4.307, nll_loss=2.702, ppl=6.5, wps=28924.3, ups=0.51, wpb=57189.9, bsz=1477.4, num_updates=31600, lr=0.000355784, gnorm=0.212, clip=100, loss_scale=8, train_wall=194, wall=63224
2023-05-27 00:35:55 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2023-05-27 00:37:49 | INFO | train_inner | epoch 005:   5013 / 6686 loss=4.32, nll_loss=2.716, ppl=6.57, wps=28641.9, ups=0.5, wpb=57027, bsz=1464.5, num_updates=31700, lr=0.000355222, gnorm=0.215, clip=100, loss_scale=6, train_wall=195, wall=63423
2023-05-27 00:41:06 | INFO | train_inner | epoch 005:   5113 / 6686 loss=4.316, nll_loss=2.712, ppl=6.55, wps=29103.1, ups=0.51, wpb=57322, bsz=1480.5, num_updates=31800, lr=0.000354663, gnorm=0.223, clip=100, loss_scale=4, train_wall=193, wall=63620
2023-05-27 00:44:24 | INFO | train_inner | epoch 005:   5213 / 6686 loss=4.299, nll_loss=2.693, ppl=6.47, wps=28996.6, ups=0.51, wpb=57349.4, bsz=1485.4, num_updates=31900, lr=0.000354107, gnorm=0.212, clip=100, loss_scale=4, train_wall=194, wall=63818
2023-05-27 00:47:41 | INFO | train_inner | epoch 005:   5313 / 6686 loss=4.317, nll_loss=2.712, ppl=6.55, wps=28922.2, ups=0.51, wpb=57070.9, bsz=1453.3, num_updates=32000, lr=0.000353553, gnorm=0.214, clip=100, loss_scale=4, train_wall=194, wall=64015
2023-05-27 00:50:59 | INFO | train_inner | epoch 005:   5413 / 6686 loss=4.325, nll_loss=2.722, ppl=6.6, wps=28920.7, ups=0.51, wpb=57113.2, bsz=1451.4, num_updates=32100, lr=0.000353002, gnorm=0.213, clip=100, loss_scale=4, train_wall=194, wall=64213
2023-05-27 00:54:16 | INFO | train_inner | epoch 005:   5513 / 6686 loss=4.317, nll_loss=2.713, ppl=6.56, wps=29029, ups=0.51, wpb=57279.9, bsz=1472.6, num_updates=32200, lr=0.000352454, gnorm=0.218, clip=100, loss_scale=6, train_wall=194, wall=64410
2023-05-27 00:57:34 | INFO | train_inner | epoch 005:   5613 / 6686 loss=4.318, nll_loss=2.715, ppl=6.56, wps=28959.2, ups=0.51, wpb=57210.9, bsz=1466.7, num_updates=32300, lr=0.000351908, gnorm=0.207, clip=100, loss_scale=8, train_wall=194, wall=64608
2023-05-27 01:00:51 | INFO | train_inner | epoch 005:   5713 / 6686 loss=4.313, nll_loss=2.708, ppl=6.53, wps=28924.6, ups=0.51, wpb=57180.6, bsz=1483.7, num_updates=32400, lr=0.000351364, gnorm=0.211, clip=100, loss_scale=8, train_wall=194, wall=64805
2023-05-27 01:04:09 | INFO | train_inner | epoch 005:   5813 / 6686 loss=4.312, nll_loss=2.708, ppl=6.53, wps=28933.1, ups=0.51, wpb=57246.6, bsz=1474, num_updates=32500, lr=0.000350823, gnorm=0.211, clip=100, loss_scale=8, train_wall=194, wall=65003
2023-05-27 01:07:28 | INFO | train_inner | epoch 005:   5913 / 6686 loss=4.296, nll_loss=2.689, ppl=6.45, wps=28927.7, ups=0.5, wpb=57361.9, bsz=1490.4, num_updates=32600, lr=0.000350285, gnorm=0.214, clip=100, loss_scale=8, train_wall=195, wall=65201
2023-05-27 01:10:45 | INFO | train_inner | epoch 005:   6013 / 6686 loss=4.313, nll_loss=2.709, ppl=6.54, wps=28982.6, ups=0.51, wpb=57106.8, bsz=1459.5, num_updates=32700, lr=0.000349749, gnorm=0.211, clip=100, loss_scale=11, train_wall=193, wall=65399
2023-05-27 01:10:47 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 01:10:47 | INFO | train_inner | epoch 005:   6014 / 6686 loss=None, nll_loss=None, ppl=0, wps=0, ups=0, wpb=None, bsz=None, num_updates=None, lr=None, gnorm=None, clip=None, loss_scale=8, train_wall=2, wall=65400
2023-05-27 01:14:04 | INFO | train_inner | epoch 005:   6114 / 6686 loss=4.298, nll_loss=2.692, ppl=6.46, wps=28951.1, ups=0.51, wpb=57147.6, bsz=1482.2, num_updates=32800, lr=0.000349215, gnorm=0.218, clip=100, loss_scale=8, train_wall=194, wall=65598
2023-05-27 01:17:22 | INFO | train_inner | epoch 005:   6214 / 6686 loss=4.312, nll_loss=2.708, ppl=6.53, wps=28977, ups=0.51, wpb=57248, bsz=1479.1, num_updates=32900, lr=0.000348684, gnorm=0.214, clip=100, loss_scale=8, train_wall=194, wall=65795
2023-05-27 01:20:39 | INFO | train_inner | epoch 005:   6314 / 6686 loss=4.303, nll_loss=2.697, ppl=6.48, wps=28905.9, ups=0.51, wpb=57088.2, bsz=1487, num_updates=33000, lr=0.000348155, gnorm=0.212, clip=100, loss_scale=8, train_wall=194, wall=65993
2023-05-27 01:23:56 | INFO | train_inner | epoch 005:   6414 / 6686 loss=4.297, nll_loss=2.691, ppl=6.46, wps=28980.8, ups=0.51, wpb=57173.8, bsz=1505.2, num_updates=33100, lr=0.000347629, gnorm=0.22, clip=100, loss_scale=8, train_wall=193, wall=66190
2023-05-27 01:27:14 | INFO | train_inner | epoch 005:   6514 / 6686 loss=4.299, nll_loss=2.693, ppl=6.46, wps=28954.7, ups=0.51, wpb=57206.9, bsz=1500.4, num_updates=33200, lr=0.000347105, gnorm=0.225, clip=100, loss_scale=8, train_wall=194, wall=66388
2023-05-27 01:29:25 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 01:30:30 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2023-05-27 01:30:36 | INFO | train_inner | epoch 005:   6616 / 6686 loss=4.304, nll_loss=2.698, ppl=6.49, wps=28325.7, ups=0.5, wpb=57149.1, bsz=1483, num_updates=33300, lr=0.000346583, gnorm=0.213, clip=100, loss_scale=12, train_wall=198, wall=66590
2023-05-27 01:32:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-27 01:32:58 | INFO | fairseq.tasks.translation | example hypothesis: Why was he unhappy? Why? Why was he so unhappy? Why was he so unhappy? Why did he feel like
2023-05-27 01:32:58 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-27 01:32:59 | INFO | fairseq.tasks.translation | example hypothesis: In a moment, I’ll make you lose so much that you won’t even have a pair of pants left!
2023-05-27 01:32:59 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-27 01:33:01 | INFO | fairseq.tasks.translation | example hypothesis: Shen Liangchuan heaved a sigh of relief. Then, he heard her say, “I’ll call you in the same room as you!”
2023-05-27 01:33:01 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-27 01:33:02 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved and entered the elevator.
2023-05-27 01:33:02 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-27 01:33:05 | INFO | fairseq.tasks.translation | example hypothesis: As soon as she raised her head, she saw Song Cheng standing in the distance! He was Song Cheng!
2023-05-27 01:33:05 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-27 01:33:07 | INFO | fairseq.tasks.translation | example hypothesis: Only then did Song Cheng pat his chest. “I’m scared to death! Where’s Wang Chuan?”
2023-05-27 01:33:07 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-27 01:33:09 | INFO | fairseq.tasks.translation | example hypothesis: I said, “I’m not going there anymore. I can’t eat it anymore.” I said with a smile.
2023-05-27 01:33:09 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-27 01:33:09 | INFO | fairseq.tasks.translation | example hypothesis: ... ... ... ... ... ...
2023-05-27 01:33:09 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-27 01:33:12 | INFO | fairseq.tasks.translation | example hypothesis: With his status, Bai Li Hongzhuang had no choice but to treat him even if he did not want to!
2023-05-27 01:33:12 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-27 01:33:14 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian said, “Mr. Shen, I, I have left too much blood. My brain is short of oxygen, so I can’t think of anything. Why don’t you give me a hint?”
2023-05-27 01:33:14 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-27 01:33:18 | INFO | fairseq.tasks.translation | example hypothesis: He didn’t know why this matter would be heard by so many people. Since he couldn’t hide it anymore, he might as well say it out loud. However, he didn’t know why Li Yuyue’s
2023-05-27 01:33:18 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-27 01:33:19 | INFO | fairseq.tasks.translation | example hypothesis: She deliberately lowered her voice, but there was no way to conceal the evilness and viciousness in her voice. “You... you... you...”
2023-05-27 01:33:19 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-27 01:33:22 | INFO | fairseq.tasks.translation | example hypothesis: The strength of a beast pet of different levels was different, but a beast pet was precious and rare. Normal people could not have it, and even the children of officials could not have it. However, this beast pet was very rare
2023-05-27 01:33:22 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-27 01:33:24 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chixia cursed under her breath, gritting her teeth. "What are you doing?"
2023-05-27 01:33:24 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-27 01:33:26 | INFO | fairseq.tasks.translation | example hypothesis: Even though Bai Li Hongzhuang’s disguise was very good, Di Beichen could still see the ripples in her eyes that flashed by in a flash. His eyes were filled with warmth.
2023-05-27 01:33:26 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-27 01:33:28 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia entered the hotel, not to mention the guests, he didn’t even see a few waitresses. He didn’t even have a chance to open the door to the hotel.
2023-05-27 01:33:28 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-27 01:33:31 | INFO | fairseq.tasks.translation | example hypothesis: This person was none other than the fourth miss of the Ye family – Ye Qingling.
2023-05-27 01:33:31 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-27 01:33:35 | INFO | fairseq.tasks.translation | example hypothesis: Because at that moment, she felt that her chin was about to shatter.
2023-05-27 01:33:35 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-27 01:33:38 | INFO | fairseq.tasks.translation | example hypothesis: “Alright, Mu Zi, help me. If it wasn't for you, that old fellow wouldn't have set his eyes on me,” I said with a smile.
2023-05-27 01:33:38 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-27 01:33:39 | INFO | fairseq.tasks.translation | example hypothesis: Bai Li Yu Yan was even more excited. She was the director of this matter. Earlier, Bai Li Hong Zhuang had treated her like this. This time, she would definitely make Bai Li Hong Zhuang suffer as well.
2023-05-27 01:33:39 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-27 01:33:42 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How can that be? They’re also four grand mages, so they naturally won’t surrender so easily. After arguing for a long time, they decided to use the competition to obtain control of the kingdom in the future.”
2023-05-27 01:33:42 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-27 01:33:44 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a bit. Originally, he had been looking for a reason for Li Yuyue to not be able to participate in the Imperial Family Hunting Competition.
2023-05-27 01:33:44 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-27 01:33:47 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my level good enough? They’re all the most outstanding talents in the country. Is my magic that weak?” asked Link.
2023-05-27 01:33:47 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-27 01:33:53 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yibei’s words meant that if Fang Chixia didn’t want to go, he wouldn’t have to go. If Fang Chixia didn’t want to go, then he wouldn’t have to go. If Fang Chixia didn’t want to go, he wouldn’t have to go.
2023-05-27 01:33:53 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-27 01:33:57 | INFO | fairseq.tasks.translation | example hypothesis: She tilted her head and saw that the five palm prints on her face were very eye-catching. They were swollen at a speed visible to the naked eye. She reached out her hand to touch them, and she couldn’t help but let out a hissing sound. It was so painful.
2023-05-27 01:33:57 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-27 01:34:00 | INFO | fairseq.tasks.translation | example hypothesis: This... How could this be the charm emitted by that piece of trash? Ye Qing Ling could not help but sigh.
2023-05-27 01:34:00 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-27 01:34:02 | INFO | fairseq.tasks.translation | example hypothesis: How did Wang Wenhao find the news agency? The chief editor should have called her to inform her not to come to the news agency, and that was the best choice. However, these three people... had plotted against her!
2023-05-27 01:34:02 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-27 01:34:08 | INFO | fairseq.tasks.translation | example hypothesis: I was delighted when I heard Teacher Di’s praise. I put away the energy ball with my left hand and sent out a beam of light towards Teacher Zhen with my right hand. The beam sword actually hit me without a hitch. I was shocked, and when I took a closer look, I realized that it was just an afterimage. Teacher Zhen had already moved to my back and shouted,
2023-05-27 01:34:08 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-27 01:34:14 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Originally, we proposed two wins in three rounds, but they said it wasn’t fair because we had Teacher Di and Teacher Zhen. Before the rankings were even higher than theirs, they proposed to win three rounds. Since we proposed the competition, the competition’s method was only up to them. Three days later, we will have a secret competition at the Royal Martial Arts Arena. The competition will be held in the Royal Martial Arts Competition. We will have
2023-05-27 01:34:14 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-27 01:34:16 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Di used a Light Element Level 7 spell, Light Thunder Combo. I rarely used this spell because it was not ideal to control it. Teacher Di used nine lightning bolts to surround me, forming a simple spell formation that prevented me from escaping in a short distance. After that, the lightning bolts exploded and formed a powerful attack.
2023-05-27 01:34:16 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-27 01:34:24 | INFO | fairseq.tasks.translation | example hypothesis: As soon as Ma Ke and the two teachers walked to the other side, Teacher Zhen shot a small dimensional slash at me. As expected of the number one Magician in the continent, the powerful suction force of his small dimensional slash was actually much stronger than mine. A small spatial crack appeared beside me, and a powerful suction force immediately swept over. The two of them were both at the same level of strength as the two of them. The two of them looked at each other and said, “I’m sorry, but I don’t know who they’ll be sending out in the fifth match. I’m not sure who they’ll be sending out in the fifth match, so you two have to try to break through in the next two days. Alright, Mark, Mark, Mark, you and Si Di, you stay here, let’s start.”
2023-05-27 01:34:24 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-27 01:34:24 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.465 | nll_loss 2.851 | ppl 7.21 | bleu 17.27 | wps 851 | wpb 2420.8 | bsz 84.5 | num_updates 33370 | best_bleu 17.84
2023-05-27 01:34:24 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-27 01:34:25 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/mega-1-1-0.2-sf[zh-en]/checkpoint_last.pt (epoch 5 @ 33370 updates, score 17.27) (writing took 1.2081612776964903 seconds)
2023-05-27 01:34:25 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-05-27 01:34:25 | INFO | train | epoch 005 | loss 4.316 | nll_loss 2.711 | ppl 6.55 | wps 28641.8 | ups 0.5 | wpb 57190.5 | bsz 1477.4 | num_updates 33370 | lr 0.00034622 | gnorm 0.216 | clip 100 | loss_scale 7 | train_wall 12958 | wall 66819
2023-05-27 01:34:26 | INFO | fairseq.trainer | begin training epoch 6
2023-05-27 01:35:38 | INFO | train_inner | epoch 006:     30 / 6686 loss=4.293, nll_loss=2.686, ppl=6.44, wps=18806.5, ups=0.33, wpb=56782.6, bsz=1482.3, num_updates=33400, lr=0.000346064, gnorm=0.216, clip=100, loss_scale=4, train_wall=193, wall=66891
2023-05-27 01:39:03 | INFO | train_inner | epoch 006:    130 / 6686 loss=4.279, nll_loss=2.669, ppl=6.36, wps=27933.8, ups=0.49, wpb=57290.4, bsz=1482.6, num_updates=33500, lr=0.000345547, gnorm=0.21, clip=100, loss_scale=4, train_wall=194, wall=67097
2023-05-27 01:42:23 | INFO | train_inner | epoch 006:    230 / 6686 loss=4.277, nll_loss=2.668, ppl=6.35, wps=28465.3, ups=0.5, wpb=57095, bsz=1483.8, num_updates=33600, lr=0.000345033, gnorm=0.213, clip=100, loss_scale=4, train_wall=194, wall=67297
2023-05-27 01:45:42 | INFO | train_inner | epoch 006:    330 / 6686 loss=4.284, nll_loss=2.675, ppl=6.39, wps=28951, ups=0.5, wpb=57401.3, bsz=1466.7, num_updates=33700, lr=0.00034452, gnorm=0.209, clip=100, loss_scale=4, train_wall=194, wall=67495
2023-05-27 01:48:59 | INFO | train_inner | epoch 006:    430 / 6686 loss=4.284, nll_loss=2.675, ppl=6.39, wps=28977.2, ups=0.51, wpb=57094.2, bsz=1470.7, num_updates=33800, lr=0.00034401, gnorm=0.226, clip=100, loss_scale=4, train_wall=193, wall=67692
2023-05-27 01:52:16 | INFO | train_inner | epoch 006:    530 / 6686 loss=4.271, nll_loss=2.661, ppl=6.32, wps=28984.1, ups=0.51, wpb=57324.8, bsz=1493.4, num_updates=33900, lr=0.000343503, gnorm=0.225, clip=100, loss_scale=8, train_wall=194, wall=67890
2023-05-27 01:55:34 | INFO | train_inner | epoch 006:    630 / 6686 loss=4.291, nll_loss=2.682, ppl=6.42, wps=28899, ups=0.51, wpb=57110.8, bsz=1461.5, num_updates=34000, lr=0.000342997, gnorm=0.217, clip=100, loss_scale=8, train_wall=194, wall=68088
2023-05-27 01:58:51 | INFO | train_inner | epoch 006:    730 / 6686 loss=4.281, nll_loss=2.672, ppl=6.37, wps=28961.1, ups=0.51, wpb=56973, bsz=1474.6, num_updates=34100, lr=0.000342494, gnorm=0.215, clip=100, loss_scale=8, train_wall=193, wall=68285
2023-05-27 02:02:08 | INFO | train_inner | epoch 006:    830 / 6686 loss=4.289, nll_loss=2.68, ppl=6.41, wps=28956.9, ups=0.51, wpb=57095.1, bsz=1467.7, num_updates=34200, lr=0.000341993, gnorm=0.217, clip=100, loss_scale=8, train_wall=193, wall=68482
2023-05-27 02:05:25 | INFO | train_inner | epoch 006:    930 / 6686 loss=4.289, nll_loss=2.681, ppl=6.41, wps=28898.8, ups=0.51, wpb=56963.7, bsz=1463.8, num_updates=34300, lr=0.000341494, gnorm=0.212, clip=100, loss_scale=8, train_wall=193, wall=68679
2023-05-27 02:07:12 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 02:08:44 | INFO | train_inner | epoch 006:   1031 / 6686 loss=4.281, nll_loss=2.672, ppl=6.37, wps=28675.4, ups=0.5, wpb=57171.3, bsz=1498.3, num_updates=34400, lr=0.000340997, gnorm=0.217, clip=100, loss_scale=11, train_wall=196, wall=68878
2023-05-27 02:12:02 | INFO | train_inner | epoch 006:   1131 / 6686 loss=4.282, nll_loss=2.673, ppl=6.38, wps=28917.5, ups=0.51, wpb=57163.3, bsz=1489.8, num_updates=34500, lr=0.000340503, gnorm=0.211, clip=100, loss_scale=8, train_wall=194, wall=69076
2023-05-27 02:15:19 | INFO | train_inner | epoch 006:   1231 / 6686 loss=4.286, nll_loss=2.678, ppl=6.4, wps=28929.9, ups=0.51, wpb=57100.8, bsz=1471.4, num_updates=34600, lr=0.00034001, gnorm=0.223, clip=100, loss_scale=8, train_wall=194, wall=69273
2023-05-27 02:18:38 | INFO | train_inner | epoch 006:   1331 / 6686 loss=4.288, nll_loss=2.68, ppl=6.41, wps=28901.3, ups=0.5, wpb=57448.2, bsz=1491.2, num_updates=34700, lr=0.00033952, gnorm=0.213, clip=100, loss_scale=8, train_wall=195, wall=69472
2023-05-27 02:21:56 | INFO | train_inner | epoch 006:   1431 / 6686 loss=4.295, nll_loss=2.688, ppl=6.44, wps=28922.2, ups=0.5, wpb=57303, bsz=1462.1, num_updates=34800, lr=0.000339032, gnorm=0.217, clip=100, loss_scale=8, train_wall=194, wall=69670
2023-05-27 02:24:31 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 02:25:16 | INFO | train_inner | epoch 006:   1532 / 6686 loss=4.285, nll_loss=2.676, ppl=6.39, wps=28621.8, ups=0.5, wpb=57243, bsz=1473, num_updates=34900, lr=0.000338546, gnorm=0.22, clip=100, loss_scale=9, train_wall=196, wall=69870
2023-05-27 02:25:48 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2023-05-27 02:28:36 | INFO | train_inner | epoch 006:   1633 / 6686 loss=4.288, nll_loss=2.68, ppl=6.41, wps=28662.9, ups=0.5, wpb=57238.9, bsz=1463, num_updates=35000, lr=0.000338062, gnorm=0.218, clip=100, loss_scale=5, train_wall=196, wall=70070
2023-05-27 02:31:55 | INFO | train_inner | epoch 006:   1733 / 6686 loss=4.285, nll_loss=2.677, ppl=6.4, wps=28837.3, ups=0.5, wpb=57373.4, bsz=1479, num_updates=35100, lr=0.00033758, gnorm=0.212, clip=100, loss_scale=4, train_wall=195, wall=70269
2023-05-27 02:35:13 | INFO | train_inner | epoch 006:   1833 / 6686 loss=4.285, nll_loss=2.677, ppl=6.39, wps=28941.7, ups=0.5, wpb=57328.3, bsz=1480.9, num_updates=35200, lr=0.0003371, gnorm=0.219, clip=100, loss_scale=4, train_wall=194, wall=70467
2023-05-27 02:38:31 | INFO | train_inner | epoch 006:   1933 / 6686 loss=4.286, nll_loss=2.678, ppl=6.4, wps=29002.6, ups=0.51, wpb=57391.3, bsz=1497.4, num_updates=35300, lr=0.000336622, gnorm=0.228, clip=100, loss_scale=4, train_wall=194, wall=70665
2023-05-27 02:41:50 | INFO | train_inner | epoch 006:   2033 / 6686 loss=4.282, nll_loss=2.673, ppl=6.38, wps=28847.8, ups=0.5, wpb=57262.1, bsz=1485.9, num_updates=35400, lr=0.000336146, gnorm=0.214, clip=100, loss_scale=4, train_wall=195, wall=70863
2023-05-27 02:45:07 | INFO | train_inner | epoch 006:   2133 / 6686 loss=4.29, nll_loss=2.682, ppl=6.42, wps=28988.4, ups=0.51, wpb=57202.7, bsz=1470.2, num_updates=35500, lr=0.000335673, gnorm=0.222, clip=100, loss_scale=7, train_wall=193, wall=71061
2023-05-27 02:48:24 | INFO | train_inner | epoch 006:   2233 / 6686 loss=4.283, nll_loss=2.675, ppl=6.39, wps=29018, ups=0.51, wpb=57153.1, bsz=1481, num_updates=35600, lr=0.000335201, gnorm=0.21, clip=100, loss_scale=8, train_wall=193, wall=71258
2023-05-27 02:51:42 | INFO | train_inner | epoch 006:   2333 / 6686 loss=4.289, nll_loss=2.681, ppl=6.41, wps=28794.2, ups=0.51, wpb=56948.1, bsz=1462.4, num_updates=35700, lr=0.000334731, gnorm=0.217, clip=100, loss_scale=8, train_wall=194, wall=71455
2023-05-27 02:54:59 | INFO | train_inner | epoch 006:   2433 / 6686 loss=4.287, nll_loss=2.679, ppl=6.41, wps=28911.2, ups=0.51, wpb=57076.3, bsz=1449.3, num_updates=35800, lr=0.000334263, gnorm=0.214, clip=100, loss_scale=8, train_wall=194, wall=71653
2023-05-27 02:58:17 | INFO | train_inner | epoch 006:   2533 / 6686 loss=4.285, nll_loss=2.677, ppl=6.4, wps=28939.6, ups=0.51, wpb=57164.3, bsz=1476.8, num_updates=35900, lr=0.000333797, gnorm=0.217, clip=100, loss_scale=8, train_wall=194, wall=71850
2023-05-27 03:00:06 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 03:01:36 | INFO | train_inner | epoch 006:   2634 / 6686 loss=4.285, nll_loss=2.677, ppl=6.39, wps=28619.4, ups=0.5, wpb=57152.9, bsz=1468.4, num_updates=36000, lr=0.000333333, gnorm=0.223, clip=100, loss_scale=9, train_wall=196, wall=72050
2023-05-27 03:04:54 | INFO | train_inner | epoch 006:   2734 / 6686 loss=4.287, nll_loss=2.68, ppl=6.41, wps=28989.3, ups=0.51, wpb=57330.8, bsz=1510.2, num_updates=36100, lr=0.000332871, gnorm=0.226, clip=100, loss_scale=8, train_wall=194, wall=72248
2023-05-27 03:08:12 | INFO | train_inner | epoch 006:   2834 / 6686 loss=4.278, nll_loss=2.668, ppl=6.36, wps=28943.6, ups=0.51, wpb=57279.7, bsz=1469.8, num_updates=36200, lr=0.000332411, gnorm=0.216, clip=100, loss_scale=8, train_wall=194, wall=72446
2023-05-27 03:11:30 | INFO | train_inner | epoch 006:   2934 / 6686 loss=4.287, nll_loss=2.68, ppl=6.41, wps=28900, ups=0.51, wpb=57179.3, bsz=1477.2, num_updates=36300, lr=0.000331953, gnorm=0.216, clip=100, loss_scale=8, train_wall=194, wall=72644
2023-05-27 03:14:47 | INFO | train_inner | epoch 006:   3034 / 6686 loss=4.29, nll_loss=2.683, ppl=6.42, wps=28979.5, ups=0.51, wpb=57072, bsz=1479.8, num_updates=36400, lr=0.000331497, gnorm=0.212, clip=100, loss_scale=8, train_wall=193, wall=72841
2023-05-27 03:18:05 | INFO | train_inner | epoch 006:   3134 / 6686 loss=4.272, nll_loss=2.662, ppl=6.33, wps=28827.7, ups=0.5, wpb=57230.1, bsz=1514.7, num_updates=36500, lr=0.000331042, gnorm=0.209, clip=100, loss_scale=11, train_wall=194, wall=73039
2023-05-27 03:20:16 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 03:21:25 | INFO | train_inner | epoch 006:   3235 / 6686 loss=4.282, nll_loss=2.674, ppl=6.38, wps=28632.8, ups=0.5, wpb=57162.4, bsz=1483.5, num_updates=36600, lr=0.00033059, gnorm=0.228, clip=100, loss_scale=13, train_wall=196, wall=73239
2023-05-27 03:24:43 | INFO | train_inner | epoch 006:   3335 / 6686 loss=4.288, nll_loss=2.681, ppl=6.41, wps=28780.1, ups=0.51, wpb=56870.1, bsz=1457, num_updates=36700, lr=0.000330139, gnorm=0.223, clip=100, loss_scale=8, train_wall=194, wall=73436
2023-05-27 03:28:00 | INFO | train_inner | epoch 006:   3435 / 6686 loss=4.29, nll_loss=2.683, ppl=6.42, wps=28949, ups=0.51, wpb=57238, bsz=1483.8, num_updates=36800, lr=0.00032969, gnorm=0.212, clip=100, loss_scale=8, train_wall=194, wall=73634
2023-05-27 03:31:18 | INFO | train_inner | epoch 006:   3535 / 6686 loss=4.281, nll_loss=2.672, ppl=6.37, wps=28871.7, ups=0.51, wpb=57153.7, bsz=1482.3, num_updates=36900, lr=0.000329243, gnorm=0.223, clip=100, loss_scale=8, train_wall=194, wall=73832
2023-05-27 03:34:37 | INFO | train_inner | epoch 006:   3635 / 6686 loss=4.286, nll_loss=2.679, ppl=6.4, wps=28771.2, ups=0.5, wpb=57070.7, bsz=1487.2, num_updates=37000, lr=0.000328798, gnorm=0.218, clip=100, loss_scale=8, train_wall=194, wall=74030
2023-05-27 03:37:47 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 03:37:56 | INFO | train_inner | epoch 006:   3736 / 6686 loss=4.303, nll_loss=2.697, ppl=6.48, wps=28547.7, ups=0.5, wpb=57002.9, bsz=1446.5, num_updates=37100, lr=0.000328355, gnorm=0.218, clip=100, loss_scale=10, train_wall=196, wall=74230
2023-05-27 03:41:13 | INFO | train_inner | epoch 006:   3836 / 6686 loss=4.287, nll_loss=2.68, ppl=6.41, wps=29025.1, ups=0.51, wpb=57238.1, bsz=1461.4, num_updates=37200, lr=0.000327913, gnorm=0.221, clip=100, loss_scale=8, train_wall=193, wall=74427
2023-05-27 03:44:31 | INFO | train_inner | epoch 006:   3936 / 6686 loss=4.29, nll_loss=2.683, ppl=6.42, wps=28986.6, ups=0.51, wpb=57187.1, bsz=1439.4, num_updates=37300, lr=0.000327473, gnorm=0.219, clip=100, loss_scale=8, train_wall=193, wall=74625
2023-05-27 03:45:30 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2023-05-27 03:47:50 | INFO | train_inner | epoch 006:   4037 / 6686 loss=4.281, nll_loss=2.673, ppl=6.38, wps=28683.2, ups=0.5, wpb=57238, bsz=1504.6, num_updates=37400, lr=0.000327035, gnorm=0.216, clip=100, loss_scale=5, train_wall=196, wall=74824
2023-05-27 03:51:08 | INFO | train_inner | epoch 006:   4137 / 6686 loss=4.272, nll_loss=2.663, ppl=6.33, wps=28983.7, ups=0.51, wpb=57174.6, bsz=1470.7, num_updates=37500, lr=0.000326599, gnorm=0.216, clip=100, loss_scale=4, train_wall=193, wall=75021
2023-05-27 03:54:25 | INFO | train_inner | epoch 006:   4237 / 6686 loss=4.289, nll_loss=2.682, ppl=6.42, wps=28845.8, ups=0.51, wpb=57016.2, bsz=1462.3, num_updates=37600, lr=0.000326164, gnorm=0.218, clip=100, loss_scale=4, train_wall=194, wall=75219
2023-05-27 03:57:42 | INFO | train_inner | epoch 006:   4337 / 6686 loss=4.283, nll_loss=2.675, ppl=6.39, wps=29003.8, ups=0.51, wpb=57169, bsz=1457.8, num_updates=37700, lr=0.000325731, gnorm=0.23, clip=100, loss_scale=4, train_wall=193, wall=75416
2023-05-27 04:01:00 | INFO | train_inner | epoch 006:   4437 / 6686 loss=4.282, nll_loss=2.674, ppl=6.38, wps=28889.6, ups=0.51, wpb=57124.3, bsz=1488.2, num_updates=37800, lr=0.0003253, gnorm=0.213, clip=100, loss_scale=4, train_wall=194, wall=75614
2023-05-27 04:04:18 | INFO | train_inner | epoch 006:   4537 / 6686 loss=4.286, nll_loss=2.679, ppl=6.4, wps=28899.7, ups=0.51, wpb=57141.6, bsz=1468.7, num_updates=37900, lr=0.000324871, gnorm=0.228, clip=100, loss_scale=6, train_wall=194, wall=75812
2023-05-27 04:07:36 | INFO | train_inner | epoch 006:   4637 / 6686 loss=4.284, nll_loss=2.676, ppl=6.39, wps=28863.5, ups=0.5, wpb=57162.9, bsz=1474, num_updates=38000, lr=0.000324443, gnorm=0.221, clip=100, loss_scale=8, train_wall=194, wall=76010
2023-05-27 04:10:54 | INFO | train_inner | epoch 006:   4737 / 6686 loss=4.278, nll_loss=2.67, ppl=6.36, wps=28907.5, ups=0.5, wpb=57296, bsz=1476.8, num_updates=38100, lr=0.000324017, gnorm=0.211, clip=100, loss_scale=8, train_wall=194, wall=76208
2023-05-27 04:14:12 | INFO | train_inner | epoch 006:   4837 / 6686 loss=4.274, nll_loss=2.665, ppl=6.34, wps=28906.7, ups=0.5, wpb=57319.1, bsz=1488.9, num_updates=38200, lr=0.000323592, gnorm=0.22, clip=100, loss_scale=8, train_wall=194, wall=76406
2023-05-27 04:17:31 | INFO | train_inner | epoch 006:   4937 / 6686 loss=4.283, nll_loss=2.675, ppl=6.39, wps=28956.1, ups=0.5, wpb=57487, bsz=1481, num_updates=38300, lr=0.00032317, gnorm=0.207, clip=100, loss_scale=8, train_wall=195, wall=76605
2023-05-27 04:20:49 | INFO | train_inner | epoch 006:   5037 / 6686 loss=4.265, nll_loss=2.655, ppl=6.3, wps=28930.6, ups=0.5, wpb=57293, bsz=1477.2, num_updates=38400, lr=0.000322749, gnorm=0.208, clip=100, loss_scale=12, train_wall=194, wall=76803
2023-05-27 04:20:55 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 04:24:09 | INFO | train_inner | epoch 006:   5138 / 6686 loss=4.272, nll_loss=2.663, ppl=6.33, wps=28619.8, ups=0.5, wpb=57126.9, bsz=1490.1, num_updates=38500, lr=0.000322329, gnorm=0.219, clip=100, loss_scale=8, train_wall=196, wall=77002
2023-05-27 04:27:27 | INFO | train_inner | epoch 006:   5238 / 6686 loss=4.281, nll_loss=2.673, ppl=6.38, wps=28868.4, ups=0.5, wpb=57305.8, bsz=1461.1, num_updates=38600, lr=0.000321911, gnorm=0.215, clip=100, loss_scale=8, train_wall=195, wall=77201
2023-05-27 04:30:45 | INFO | train_inner | epoch 006:   5338 / 6686 loss=4.273, nll_loss=2.664, ppl=6.34, wps=28923.7, ups=0.51, wpb=57268.6, bsz=1494.3, num_updates=38700, lr=0.000321495, gnorm=0.218, clip=100, loss_scale=8, train_wall=194, wall=77399
2023-05-27 04:34:03 | INFO | train_inner | epoch 006:   5438 / 6686 loss=4.276, nll_loss=2.667, ppl=6.35, wps=28974.4, ups=0.51, wpb=57317.3, bsz=1487.4, num_updates=38800, lr=0.000321081, gnorm=0.216, clip=100, loss_scale=8, train_wall=194, wall=77597
2023-05-27 04:37:20 | INFO | train_inner | epoch 006:   5538 / 6686 loss=4.276, nll_loss=2.668, ppl=6.35, wps=28988.3, ups=0.51, wpb=57122, bsz=1480.6, num_updates=38900, lr=0.000320668, gnorm=0.227, clip=100, loss_scale=8, train_wall=193, wall=77794
2023-05-27 04:38:09 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 04:40:40 | INFO | train_inner | epoch 006:   5639 / 6686 loss=4.275, nll_loss=2.666, ppl=6.35, wps=28717.5, ups=0.5, wpb=57318.7, bsz=1488.6, num_updates=39000, lr=0.000320256, gnorm=0.226, clip=100, loss_scale=9, train_wall=196, wall=77993
2023-05-27 04:43:57 | INFO | train_inner | epoch 006:   5739 / 6686 loss=4.268, nll_loss=2.659, ppl=6.31, wps=28952.5, ups=0.51, wpb=57291.3, bsz=1482.2, num_updates=39100, lr=0.000319847, gnorm=0.219, clip=100, loss_scale=8, train_wall=194, wall=78191
2023-05-27 04:47:15 | INFO | train_inner | epoch 006:   5839 / 6686 loss=4.279, nll_loss=2.672, ppl=6.37, wps=29040.2, ups=0.51, wpb=57254.5, bsz=1488.7, num_updates=39200, lr=0.000319438, gnorm=0.218, clip=100, loss_scale=8, train_wall=193, wall=78388
2023-05-27 04:50:32 | INFO | train_inner | epoch 006:   5939 / 6686 loss=4.283, nll_loss=2.675, ppl=6.39, wps=28953.8, ups=0.51, wpb=57261.2, bsz=1466.1, num_updates=39300, lr=0.000319032, gnorm=0.221, clip=100, loss_scale=8, train_wall=194, wall=78586
2023-05-27 04:53:50 | INFO | train_inner | epoch 006:   6039 / 6686 loss=4.272, nll_loss=2.663, ppl=6.33, wps=29069.6, ups=0.51, wpb=57395.2, bsz=1487.1, num_updates=39400, lr=0.000318626, gnorm=0.217, clip=100, loss_scale=8, train_wall=194, wall=78784
2023-05-27 04:57:07 | INFO | train_inner | epoch 006:   6139 / 6686 loss=4.269, nll_loss=2.66, ppl=6.32, wps=29022.1, ups=0.51, wpb=57240.5, bsz=1488.2, num_updates=39500, lr=0.000318223, gnorm=0.217, clip=100, loss_scale=13, train_wall=193, wall=78981
2023-05-27 04:57:25 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 05:00:26 | INFO | train_inner | epoch 006:   6240 / 6686 loss=4.276, nll_loss=2.668, ppl=6.35, wps=28540.1, ups=0.5, wpb=56889.2, bsz=1473.4, num_updates=39600, lr=0.000317821, gnorm=0.207, clip=100, loss_scale=9, train_wall=195, wall=79180
2023-05-27 05:03:44 | INFO | train_inner | epoch 006:   6340 / 6686 loss=4.278, nll_loss=2.67, ppl=6.36, wps=28928.9, ups=0.51, wpb=57086.1, bsz=1474.7, num_updates=39700, lr=0.00031742, gnorm=0.221, clip=100, loss_scale=8, train_wall=194, wall=79378
2023-05-27 05:07:01 | INFO | train_inner | epoch 006:   6440 / 6686 loss=4.283, nll_loss=2.676, ppl=6.39, wps=28974.3, ups=0.51, wpb=57163.7, bsz=1481.4, num_updates=39800, lr=0.000317021, gnorm=0.206, clip=100, loss_scale=8, train_wall=193, wall=79575
2023-05-27 05:10:19 | INFO | train_inner | epoch 006:   6540 / 6686 loss=4.272, nll_loss=2.663, ppl=6.33, wps=28943.9, ups=0.51, wpb=57261.3, bsz=1495.7, num_updates=39900, lr=0.000316624, gnorm=0.222, clip=100, loss_scale=8, train_wall=194, wall=79773
2023-05-27 05:13:36 | INFO | train_inner | epoch 006:   6640 / 6686 loss=4.292, nll_loss=2.686, ppl=6.43, wps=28978.7, ups=0.51, wpb=57020.7, bsz=1448.8, num_updates=40000, lr=0.000316228, gnorm=0.218, clip=100, loss_scale=8, train_wall=193, wall=79969
2023-05-27 05:14:51 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 05:15:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-27 05:15:12 | INFO | fairseq.tasks.translation | example hypothesis: Why was he unhappy? Why? Why was he unhappy? Why was he unhappy? Why was he unhappy? Why was
2023-05-27 05:15:12 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-27 05:15:13 | INFO | fairseq.tasks.translation | example hypothesis: In a while, I’ll make you lose so much that you won’t even have any pants left on you!
2023-05-27 05:15:13 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-27 05:15:14 | INFO | fairseq.tasks.translation | example hypothesis: Shen Liangchuan had just let out a sigh of relief when he heard her say, “I’m calling you to stay in the same room!”
2023-05-27 05:15:14 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-27 05:15:16 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved and entered the elevator.
2023-05-27 05:15:16 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-27 05:15:19 | INFO | fairseq.tasks.translation | example hypothesis: When she raised her head, she saw Song Cheng standing in the distance! Song Cheng was standing in front of her!
2023-05-27 05:15:19 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-27 05:15:20 | INFO | fairseq.tasks.translation | example hypothesis: Only then did Song Cheng pat his chest. “I’m scared to death! Where’s Wang Chuan?”
2023-05-27 05:15:20 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-27 05:15:22 | INFO | fairseq.tasks.translation | example hypothesis: I said, “I’m not going, I can’t eat anymore.” I didn’t want to eat anymore.
2023-05-27 05:15:22 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-27 05:15:23 | INFO | fairseq.tasks.translation | example hypothesis: At first, everyone did not believe him, but Wang Wen Hao insisted that the public opinion was biased towards Wang Wen Hao.
2023-05-27 05:15:23 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-27 05:15:26 | INFO | fairseq.tasks.translation | example hypothesis: With his status, Bai Li Hongzhuang had no choice but to treat him even if he did not want to!
2023-05-27 05:15:26 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-27 05:15:28 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian said, “Mr. Shen, I, I have left too much blood. My brain is lacking oxygen, so I can’t think of anything else. Why don’t you give me a hint?”
2023-05-27 05:15:28 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-27 05:15:31 | INFO | fairseq.tasks.translation | example hypothesis: He didn’t know why this matter would be heard by so many people. Since he couldn’t hide it anymore, he might as well say it out loud. However, he didn’t know why Li Yuyue was injured
2023-05-27 05:15:31 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-27 05:15:33 | INFO | fairseq.tasks.translation | example hypothesis: She deliberately lowered her voice, but it couldn’t hide the viciousness and viciousness in her voice. “I’m not going to destroy you...”
2023-05-27 05:15:33 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-27 05:15:35 | INFO | fairseq.tasks.translation | example hypothesis: The strength of a beast pet of different levels was different, but a beast pet was precious and rare. Normal people could not have it, and not even the children of officials could have it. However, this was not the case.
2023-05-27 05:15:35 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-27 05:15:37 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chixia gritted her teeth and cursed in a low voice, "What are you doing?"
2023-05-27 05:15:37 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-27 05:15:40 | INFO | fairseq.tasks.translation | example hypothesis: Even though Bai Li Hongzhuang’s disguise was well concealed, Di Beichen could still see the ripple in her eyes that flashed across her eyes, and a hint of warmth could be seen in them.
2023-05-27 05:15:40 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-27 05:15:42 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia entered the hotel, not to mention the guests who were staying, she didn’t even see a few waiters. She didn’t even have a single person in her room.
2023-05-27 05:15:42 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-27 05:15:45 | INFO | fairseq.tasks.translation | example hypothesis: This person was none other than the fourth lady of the Ye family, Ye Qingling.
2023-05-27 05:15:45 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-27 05:15:48 | INFO | fairseq.tasks.translation | example hypothesis: Because at this moment, she felt that her chin was about to break.
2023-05-27 05:15:48 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-27 05:15:51 | INFO | fairseq.tasks.translation | example hypothesis: “Good Mu Zi, help me. If it wasn't for you, that old guy wouldn't have set his eyes on me,” I said with a smile.
2023-05-27 05:15:51 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-27 05:15:53 | INFO | fairseq.tasks.translation | example hypothesis: Bai Li Yu Yan was even more excited. This matter was completely directed by her. Earlier, Bai Li Hong Zhuang had treated her that way. This time, she would definitely make Bai Li Hong Zhuang feel bad.
2023-05-27 05:15:53 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-27 05:15:55 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How could that be? They have four grand mages on their side, of course they won’t surrender so easily. After arguing for a long time, they decided to use the competition to obtain control of the kingdom.”
2023-05-27 05:15:55 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-27 05:15:58 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a bit. Originally, he had been looking for a reason for Li Yuyue to not be able to participate in the Imperial Family’s Hunting Competition.
2023-05-27 05:15:58 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-27 05:16:01 | INFO | fairseq.tasks.translation | example hypothesis: “Ms. Xiu, is my level good enough? They’re all the best talents in the country. My magic is so weak, right?”
2023-05-27 05:16:01 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-27 05:16:07 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yi Bei’s words meant that if Fang Chi Xia didn’t want to go, then he didn’t need to go. If Fang Chi Xia didn’t want to go, then he didn’t want to go. If Fang Chi Xia didn’t want to go, then he didn’t want to go.
2023-05-27 05:16:07 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-27 05:16:11 | INFO | fairseq.tasks.translation | example hypothesis: She turned her head to the side and saw that the five palm prints on her face were very eye-catching. At a speed visible to the naked eye, they swelled up. She reached out her hand to touch them, and she couldn’t help but let out a hissing sound. It was so painful.
2023-05-27 05:16:11 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-27 05:16:14 | INFO | fairseq.tasks.translation | example hypothesis: This... how could it be possible for that trash to emit such charm? It was as though she had never seen such a beauty before!
2023-05-27 05:16:14 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-27 05:16:15 | INFO | fairseq.tasks.translation | example hypothesis: How could Wang Wenhao have found the news agency? The chief editor should have called her to inform her not to come to the news agency, but these three people... had plotted against her!
2023-05-27 05:16:15 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-27 05:16:21 | INFO | fairseq.tasks.translation | example hypothesis: Hearing Teacher Di’s praise, I was delighted. I put away the energy ball with my left hand, and sent out a light sword towards Teacher Zhen with my right hand. The light sword actually managed to hit me, and I was shocked. I took a closer look and realized that it was just an afterimage. Teacher Zhen had already moved behind me and shouted, “Berserk Space!”
2023-05-27 05:16:21 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-27 05:16:27 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Originally, we proposed two wins in three rounds, but they said that it wasn’t fair, because we have Teacher Di and Teacher Zhen, and our ranking is higher than theirs. They proposed five rounds and three wins, and since we proposed the competition, we can only listen to them in the end. Three days later, we will have a secret competition in the royal martial arts arena. The competition will be held in the imperial martial arts arena, and
2023-05-27 05:16:27 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-27 05:16:30 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Di used a level-7 light-type spell, Lightning Chain Explosion. I rarely used this spell, because it wasn’t ideal to control it. Teacher Di used nine lightning bolts to surround me, forming a simple formation that prevented me from escaping in a short distance. Then, the lightning bolts exploded and formed a powerful attack.
2023-05-27 05:16:30 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-27 05:16:37 | INFO | fairseq.tasks.translation | example hypothesis: As soon as Ma Ke and the two teachers reached the other side, Teacher Zhen sent out a small dimensional slash towards me. As expected of the number one mage on the continent, the powerful suction force of his small dimensional slash was actually much stronger than mine. A small spatial crack appeared beside me, and a powerful suction force immediately swept over. This was the first time that I’ve seen such a small spatial crack in the courtyard, and I was shocked to find out that it was actually a small dimensional slash. However, I didn’t expect that it was actually a small dimensional slash!
2023-05-27 05:16:37 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-27 05:16:38 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 4.456 | nll_loss 2.85 | ppl 7.21 | bleu 17.26 | wps 854.2 | wpb 2420.8 | bsz 84.5 | num_updates 40045 | best_bleu 17.84
2023-05-27 05:16:38 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-27 05:16:39 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/mega-1-1-0.2-sf[zh-en]/checkpoint_last.pt (epoch 6 @ 40045 updates, score 17.26) (writing took 0.9969755643978715 seconds)
2023-05-27 05:16:39 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-05-27 05:16:39 | INFO | train | epoch 006 | loss 4.282 | nll_loss 2.674 | ppl 6.38 | wps 28631.1 | ups 0.5 | wpb 57189.7 | bsz 1477.5 | num_updates 40045 | lr 0.00031605 | gnorm 0.218 | clip 100 | loss_scale 8 | train_wall 12959 | wall 80152
2023-05-27 05:16:39 | INFO | fairseq.trainer | begin training epoch 7
2023-05-27 05:18:46 | INFO | train_inner | epoch 007:     55 / 6686 loss=4.248, nll_loss=2.636, ppl=6.21, wps=18321.1, ups=0.32, wpb=56792.1, bsz=1497, num_updates=40100, lr=0.000315833, gnorm=0.218, clip=100, loss_scale=9, train_wall=196, wall=80279
2023-05-27 05:22:09 | INFO | train_inner | epoch 007:    155 / 6686 loss=4.249, nll_loss=2.637, ppl=6.22, wps=28102.8, ups=0.49, wpb=57192.3, bsz=1475.1, num_updates=40200, lr=0.00031544, gnorm=0.214, clip=100, loss_scale=8, train_wall=195, wall=80483
2023-05-27 05:25:28 | INFO | train_inner | epoch 007:    255 / 6686 loss=4.258, nll_loss=2.647, ppl=6.26, wps=28697.7, ups=0.5, wpb=56981.7, bsz=1472.1, num_updates=40300, lr=0.000315049, gnorm=0.216, clip=100, loss_scale=8, train_wall=193, wall=80682
2023-05-27 05:28:46 | INFO | train_inner | epoch 007:    355 / 6686 loss=4.251, nll_loss=2.639, ppl=6.23, wps=28798.4, ups=0.5, wpb=57162.8, bsz=1494.9, num_updates=40400, lr=0.000314658, gnorm=0.219, clip=100, loss_scale=8, train_wall=194, wall=80880
2023-05-27 05:32:04 | INFO | train_inner | epoch 007:    455 / 6686 loss=4.254, nll_loss=2.642, ppl=6.24, wps=28845.6, ups=0.5, wpb=57177.1, bsz=1476.2, num_updates=40500, lr=0.00031427, gnorm=0.214, clip=100, loss_scale=8, train_wall=194, wall=81078
2023-05-27 05:34:01 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 05:35:24 | INFO | train_inner | epoch 007:    556 / 6686 loss=4.252, nll_loss=2.64, ppl=6.23, wps=28671.1, ups=0.5, wpb=57279, bsz=1482.6, num_updates=40600, lr=0.000313882, gnorm=0.218, clip=100, loss_scale=9, train_wall=196, wall=81278
2023-05-27 05:38:42 | INFO | train_inner | epoch 007:    656 / 6686 loss=4.244, nll_loss=2.631, ppl=6.19, wps=28968.6, ups=0.5, wpb=57396.4, bsz=1490.6, num_updates=40700, lr=0.000313497, gnorm=0.226, clip=100, loss_scale=8, train_wall=194, wall=81476
2023-05-27 05:41:59 | INFO | train_inner | epoch 007:    756 / 6686 loss=4.249, nll_loss=2.637, ppl=6.22, wps=28993.2, ups=0.51, wpb=57153.1, bsz=1468, num_updates=40800, lr=0.000313112, gnorm=0.212, clip=100, loss_scale=8, train_wall=193, wall=81673
2023-05-27 05:45:17 | INFO | train_inner | epoch 007:    856 / 6686 loss=4.257, nll_loss=2.645, ppl=6.26, wps=28920.3, ups=0.51, wpb=57079.6, bsz=1477.8, num_updates=40900, lr=0.000312729, gnorm=0.213, clip=100, loss_scale=8, train_wall=193, wall=81871
2023-05-27 05:48:35 | INFO | train_inner | epoch 007:    956 / 6686 loss=4.255, nll_loss=2.644, ppl=6.25, wps=28903.6, ups=0.5, wpb=57297.4, bsz=1472, num_updates=41000, lr=0.000312348, gnorm=0.22, clip=100, loss_scale=8, train_wall=194, wall=82069
2023-05-27 05:51:15 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 05:51:55 | INFO | train_inner | epoch 007:   1057 / 6686 loss=4.263, nll_loss=2.653, ppl=6.29, wps=28749.5, ups=0.5, wpb=57430.6, bsz=1453.2, num_updates=41100, lr=0.000311967, gnorm=0.221, clip=100, loss_scale=9, train_wall=196, wall=82269
2023-05-27 05:55:12 | INFO | train_inner | epoch 007:   1157 / 6686 loss=4.253, nll_loss=2.641, ppl=6.24, wps=28958.1, ups=0.51, wpb=57210.6, bsz=1483.5, num_updates=41200, lr=0.000311588, gnorm=0.217, clip=100, loss_scale=8, train_wall=194, wall=82466
2023-05-27 05:58:30 | INFO | train_inner | epoch 007:   1257 / 6686 loss=4.265, nll_loss=2.655, ppl=6.3, wps=28911.5, ups=0.51, wpb=57156, bsz=1469.2, num_updates=41300, lr=0.000311211, gnorm=0.224, clip=100, loss_scale=8, train_wall=194, wall=82664
2023-05-27 06:01:49 | INFO | train_inner | epoch 007:   1357 / 6686 loss=4.252, nll_loss=2.64, ppl=6.23, wps=28941.1, ups=0.5, wpb=57418.7, bsz=1512.6, num_updates=41400, lr=0.000310835, gnorm=0.218, clip=100, loss_scale=8, train_wall=194, wall=82862
2023-05-27 06:05:06 | INFO | train_inner | epoch 007:   1457 / 6686 loss=4.261, nll_loss=2.651, ppl=6.28, wps=28906.7, ups=0.51, wpb=56955.2, bsz=1455.9, num_updates=41500, lr=0.00031046, gnorm=0.218, clip=100, loss_scale=8, train_wall=193, wall=83059
2023-05-27 06:08:23 | INFO | train_inner | epoch 007:   1557 / 6686 loss=4.26, nll_loss=2.649, ppl=6.27, wps=28901.7, ups=0.51, wpb=57207.1, bsz=1478.9, num_updates=41600, lr=0.000310087, gnorm=0.214, clip=100, loss_scale=9, train_wall=194, wall=83257
2023-05-27 06:09:05 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 06:11:44 | INFO | train_inner | epoch 007:   1658 / 6686 loss=4.26, nll_loss=2.649, ppl=6.27, wps=28524.7, ups=0.5, wpb=57076.1, bsz=1454.7, num_updates=41700, lr=0.000309715, gnorm=0.213, clip=100, loss_scale=10, train_wall=196, wall=83457
2023-05-27 06:15:01 | INFO | train_inner | epoch 007:   1758 / 6686 loss=4.266, nll_loss=2.656, ppl=6.3, wps=29026.7, ups=0.51, wpb=57384.7, bsz=1477.8, num_updates=41800, lr=0.000309344, gnorm=0.215, clip=100, loss_scale=8, train_wall=194, wall=83655
2023-05-27 06:16:34 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2023-05-27 06:18:21 | INFO | train_inner | epoch 007:   1859 / 6686 loss=4.271, nll_loss=2.662, ppl=6.33, wps=28620.4, ups=0.5, wpb=57057.2, bsz=1438.1, num_updates=41900, lr=0.000308975, gnorm=0.214, clip=100, loss_scale=6, train_wall=196, wall=83855
2023-05-27 06:21:38 | INFO | train_inner | epoch 007:   1959 / 6686 loss=4.254, nll_loss=2.642, ppl=6.24, wps=28960.3, ups=0.51, wpb=57279.6, bsz=1478.2, num_updates=42000, lr=0.000308607, gnorm=0.216, clip=100, loss_scale=4, train_wall=194, wall=84052
2023-05-27 06:24:56 | INFO | train_inner | epoch 007:   2059 / 6686 loss=4.265, nll_loss=2.655, ppl=6.3, wps=28904.2, ups=0.51, wpb=57144.8, bsz=1468, num_updates=42100, lr=0.00030824, gnorm=0.217, clip=100, loss_scale=4, train_wall=194, wall=84250
2023-05-27 06:28:14 | INFO | train_inner | epoch 007:   2159 / 6686 loss=4.266, nll_loss=2.656, ppl=6.3, wps=28980.9, ups=0.5, wpb=57392.4, bsz=1477.8, num_updates=42200, lr=0.000307875, gnorm=0.214, clip=100, loss_scale=4, train_wall=194, wall=84448
2023-05-27 06:30:52 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2023-05-27 06:31:33 | INFO | train_inner | epoch 007:   2260 / 6686 loss=4.259, nll_loss=2.648, ppl=6.27, wps=28709.8, ups=0.5, wpb=57137.8, bsz=1465.7, num_updates=42300, lr=0.00030751, gnorm=0.216, clip=100, loss_scale=4, train_wall=195, wall=84647
2023-05-27 06:34:51 | INFO | train_inner | epoch 007:   2360 / 6686 loss=4.268, nll_loss=2.658, ppl=6.31, wps=28824.7, ups=0.5, wpb=57131.1, bsz=1476.2, num_updates=42400, lr=0.000307148, gnorm=0.226, clip=100, loss_scale=2, train_wall=194, wall=84845
2023-05-27 06:38:09 | INFO | train_inner | epoch 007:   2460 / 6686 loss=4.266, nll_loss=2.656, ppl=6.3, wps=28839.7, ups=0.51, wpb=57048.3, bsz=1458.4, num_updates=42500, lr=0.000306786, gnorm=0.215, clip=100, loss_scale=2, train_wall=194, wall=85043
2023-05-27 06:41:26 | INFO | train_inner | epoch 007:   2560 / 6686 loss=4.255, nll_loss=2.644, ppl=6.25, wps=28892.8, ups=0.51, wpb=56863.1, bsz=1469.8, num_updates=42600, lr=0.000306426, gnorm=0.212, clip=100, loss_scale=2, train_wall=193, wall=85240
2023-05-27 06:44:44 | INFO | train_inner | epoch 007:   2660 / 6686 loss=4.258, nll_loss=2.647, ppl=6.26, wps=28964.1, ups=0.51, wpb=57314.8, bsz=1464.6, num_updates=42700, lr=0.000306067, gnorm=0.214, clip=100, loss_scale=2, train_wall=194, wall=85438
2023-05-27 06:48:01 | INFO | train_inner | epoch 007:   2760 / 6686 loss=4.25, nll_loss=2.638, ppl=6.23, wps=29018.2, ups=0.51, wpb=57239.9, bsz=1480.8, num_updates=42800, lr=0.000305709, gnorm=0.215, clip=100, loss_scale=2, train_wall=193, wall=85635
2023-05-27 06:51:18 | INFO | train_inner | epoch 007:   2860 / 6686 loss=4.258, nll_loss=2.647, ppl=6.26, wps=28960, ups=0.51, wpb=57122.6, bsz=1476, num_updates=42900, lr=0.000305352, gnorm=0.213, clip=100, loss_scale=4, train_wall=193, wall=85832
2023-05-27 06:54:36 | INFO | train_inner | epoch 007:   2960 / 6686 loss=4.262, nll_loss=2.651, ppl=6.28, wps=28980.2, ups=0.51, wpb=57213.5, bsz=1453.3, num_updates=43000, lr=0.000304997, gnorm=0.22, clip=100, loss_scale=4, train_wall=194, wall=86030
2023-05-27 06:57:53 | INFO | train_inner | epoch 007:   3060 / 6686 loss=4.264, nll_loss=2.654, ppl=6.3, wps=29015, ups=0.51, wpb=57280.5, bsz=1473.1, num_updates=43100, lr=0.000304643, gnorm=0.215, clip=100, loss_scale=4, train_wall=194, wall=86227
2023-05-27 07:01:10 | INFO | train_inner | epoch 007:   3160 / 6686 loss=4.257, nll_loss=2.647, ppl=6.26, wps=28992.4, ups=0.51, wpb=56960.1, bsz=1464.2, num_updates=43200, lr=0.00030429, gnorm=0.223, clip=100, loss_scale=4, train_wall=193, wall=86424
2023-05-27 07:04:28 | INFO | train_inner | epoch 007:   3260 / 6686 loss=4.249, nll_loss=2.637, ppl=6.22, wps=28924.3, ups=0.51, wpb=57247, bsz=1498.2, num_updates=43300, lr=0.000303939, gnorm=0.224, clip=100, loss_scale=4, train_wall=194, wall=86622
2023-05-27 07:07:45 | INFO | train_inner | epoch 007:   3360 / 6686 loss=4.254, nll_loss=2.643, ppl=6.25, wps=29046.3, ups=0.51, wpb=57196.1, bsz=1483.8, num_updates=43400, lr=0.000303588, gnorm=0.217, clip=100, loss_scale=8, train_wall=193, wall=86818
2023-05-27 07:11:02 | INFO | train_inner | epoch 007:   3460 / 6686 loss=4.254, nll_loss=2.642, ppl=6.24, wps=28963.6, ups=0.51, wpb=57162.5, bsz=1462.7, num_updates=43500, lr=0.000303239, gnorm=0.229, clip=100, loss_scale=8, train_wall=194, wall=87016
2023-05-27 07:12:12 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2023-05-27 07:14:22 | INFO | train_inner | epoch 007:   3561 / 6686 loss=4.255, nll_loss=2.644, ppl=6.25, wps=28525.6, ups=0.5, wpb=57196.2, bsz=1491.7, num_updates=43600, lr=0.000302891, gnorm=0.222, clip=100, loss_scale=5, train_wall=197, wall=87216
2023-05-27 07:17:41 | INFO | train_inner | epoch 007:   3661 / 6686 loss=4.263, nll_loss=2.653, ppl=6.29, wps=28838.5, ups=0.5, wpb=57119.5, bsz=1468.6, num_updates=43700, lr=0.000302545, gnorm=0.224, clip=100, loss_scale=4, train_wall=194, wall=87414
2023-05-27 07:20:58 | INFO | train_inner | epoch 007:   3761 / 6686 loss=4.253, nll_loss=2.642, ppl=6.24, wps=28926.9, ups=0.51, wpb=57218.9, bsz=1485.9, num_updates=43800, lr=0.000302199, gnorm=0.214, clip=100, loss_scale=4, train_wall=194, wall=87612
2023-05-27 07:24:16 | INFO | train_inner | epoch 007:   3861 / 6686 loss=4.253, nll_loss=2.642, ppl=6.24, wps=28978.4, ups=0.5, wpb=57413.3, bsz=1485, num_updates=43900, lr=0.000301855, gnorm=0.217, clip=100, loss_scale=4, train_wall=194, wall=87810
2023-05-27 07:27:34 | INFO | train_inner | epoch 007:   3961 / 6686 loss=4.26, nll_loss=2.65, ppl=6.28, wps=29032.7, ups=0.51, wpb=57343.5, bsz=1473, num_updates=44000, lr=0.000301511, gnorm=0.217, clip=100, loss_scale=4, train_wall=194, wall=88008
2023-05-27 07:30:52 | INFO | train_inner | epoch 007:   4061 / 6686 loss=4.251, nll_loss=2.64, ppl=6.23, wps=28979.1, ups=0.51, wpb=57315.3, bsz=1509.9, num_updates=44100, lr=0.000301169, gnorm=0.212, clip=100, loss_scale=6, train_wall=194, wall=88206
2023-05-27 07:34:09 | INFO | train_inner | epoch 007:   4161 / 6686 loss=4.269, nll_loss=2.66, ppl=6.32, wps=29000, ups=0.51, wpb=57295.2, bsz=1484.6, num_updates=44200, lr=0.000300828, gnorm=0.212, clip=100, loss_scale=8, train_wall=194, wall=88403
2023-05-27 07:37:28 | INFO | train_inner | epoch 007:   4261 / 6686 loss=4.24, nll_loss=2.628, ppl=6.18, wps=28858.5, ups=0.5, wpb=57325.3, bsz=1523.8, num_updates=44300, lr=0.000300489, gnorm=0.215, clip=100, loss_scale=8, train_wall=195, wall=88602
2023-05-27 07:40:46 | INFO | train_inner | epoch 007:   4361 / 6686 loss=4.259, nll_loss=2.649, ppl=6.27, wps=28864.9, ups=0.5, wpb=57221.7, bsz=1482.5, num_updates=44400, lr=0.00030015, gnorm=0.213, clip=100, loss_scale=8, train_wall=194, wall=88800
2023-05-27 07:44:04 | INFO | train_inner | epoch 007:   4461 / 6686 loss=4.252, nll_loss=2.641, ppl=6.24, wps=29002.9, ups=0.51, wpb=57347.5, bsz=1498.2, num_updates=44500, lr=0.000299813, gnorm=0.217, clip=100, loss_scale=8, train_wall=194, wall=88998
2023-05-27 07:46:29 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 07:47:24 | INFO | train_inner | epoch 007:   4562 / 6686 loss=4.256, nll_loss=2.646, ppl=6.26, wps=28656.3, ups=0.5, wpb=57318.7, bsz=1480.2, num_updates=44600, lr=0.000299476, gnorm=0.217, clip=100, loss_scale=9, train_wall=196, wall=89198
2023-05-27 07:50:41 | INFO | train_inner | epoch 007:   4662 / 6686 loss=4.254, nll_loss=2.643, ppl=6.25, wps=28862.6, ups=0.51, wpb=56995.3, bsz=1478.6, num_updates=44700, lr=0.000299141, gnorm=0.214, clip=100, loss_scale=8, train_wall=194, wall=89395
2023-05-27 07:53:59 | INFO | train_inner | epoch 007:   4762 / 6686 loss=4.253, nll_loss=2.642, ppl=6.24, wps=28991.5, ups=0.51, wpb=57265, bsz=1486.8, num_updates=44800, lr=0.000298807, gnorm=0.215, clip=100, loss_scale=8, train_wall=194, wall=89593
2023-05-27 07:57:17 | INFO | train_inner | epoch 007:   4862 / 6686 loss=4.253, nll_loss=2.642, ppl=6.24, wps=28847.5, ups=0.51, wpb=57068.6, bsz=1468.2, num_updates=44900, lr=0.000298474, gnorm=0.221, clip=100, loss_scale=8, train_wall=194, wall=89791
2023-05-27 08:00:34 | INFO | train_inner | epoch 007:   4962 / 6686 loss=4.264, nll_loss=2.654, ppl=6.29, wps=29000.2, ups=0.51, wpb=57169.8, bsz=1459, num_updates=45000, lr=0.000298142, gnorm=0.221, clip=100, loss_scale=8, train_wall=193, wall=89988
2023-05-27 08:03:24 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 08:03:54 | INFO | train_inner | epoch 007:   5063 / 6686 loss=4.265, nll_loss=2.656, ppl=6.3, wps=28625, ups=0.5, wpb=57117.5, bsz=1440.8, num_updates=45100, lr=0.000297812, gnorm=0.224, clip=100, loss_scale=8, train_wall=196, wall=90187
2023-05-27 08:07:11 | INFO | train_inner | epoch 007:   5163 / 6686 loss=4.257, nll_loss=2.647, ppl=6.26, wps=29033.7, ups=0.51, wpb=57338.9, bsz=1481.2, num_updates=45200, lr=0.000297482, gnorm=0.212, clip=100, loss_scale=8, train_wall=194, wall=90385
2023-05-27 08:10:29 | INFO | train_inner | epoch 007:   5263 / 6686 loss=4.257, nll_loss=2.646, ppl=6.26, wps=29011.4, ups=0.51, wpb=57311, bsz=1477.9, num_updates=45300, lr=0.000297154, gnorm=0.21, clip=100, loss_scale=8, train_wall=194, wall=90582
2023-05-27 08:13:46 | INFO | train_inner | epoch 007:   5363 / 6686 loss=4.249, nll_loss=2.637, ppl=6.22, wps=28900, ups=0.51, wpb=57175.9, bsz=1477.8, num_updates=45400, lr=0.000296826, gnorm=0.22, clip=100, loss_scale=8, train_wall=194, wall=90780
2023-05-27 08:17:04 | INFO | train_inner | epoch 007:   5463 / 6686 loss=4.246, nll_loss=2.635, ppl=6.21, wps=29018.8, ups=0.51, wpb=57288.9, bsz=1503.3, num_updates=45500, lr=0.0002965, gnorm=0.214, clip=100, loss_scale=8, train_wall=194, wall=90978
2023-05-27 08:20:21 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 08:20:23 | INFO | train_inner | epoch 007:   5564 / 6686 loss=4.261, nll_loss=2.652, ppl=6.28, wps=28632.7, ups=0.5, wpb=57063, bsz=1483.2, num_updates=45600, lr=0.000296174, gnorm=0.215, clip=100, loss_scale=8, train_wall=195, wall=91177
2023-05-27 08:23:21 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2023-05-27 08:23:43 | INFO | train_inner | epoch 007:   5665 / 6686 loss=4.249, nll_loss=2.637, ppl=6.22, wps=28566.8, ups=0.5, wpb=57136.8, bsz=1490.2, num_updates=45700, lr=0.00029585, gnorm=0.211, clip=100, loss_scale=8, train_wall=196, wall=91377
2023-05-27 08:27:00 | INFO | train_inner | epoch 007:   5765 / 6686 loss=4.262, nll_loss=2.652, ppl=6.29, wps=28974, ups=0.51, wpb=57089, bsz=1459.1, num_updates=45800, lr=0.000295527, gnorm=0.217, clip=100, loss_scale=4, train_wall=193, wall=91574
2023-05-27 08:30:18 | INFO | train_inner | epoch 007:   5865 / 6686 loss=4.249, nll_loss=2.638, ppl=6.23, wps=28856.8, ups=0.51, wpb=57052.4, bsz=1483.1, num_updates=45900, lr=0.000295205, gnorm=0.219, clip=100, loss_scale=4, train_wall=194, wall=91772
2023-05-27 08:33:36 | INFO | train_inner | epoch 007:   5965 / 6686 loss=4.265, nll_loss=2.655, ppl=6.3, wps=28888.5, ups=0.51, wpb=57081.7, bsz=1444.6, num_updates=46000, lr=0.000294884, gnorm=0.209, clip=100, loss_scale=4, train_wall=194, wall=91969
2023-05-27 08:36:54 | INFO | train_inner | epoch 007:   6065 / 6686 loss=4.253, nll_loss=2.642, ppl=6.24, wps=28872.1, ups=0.5, wpb=57175.8, bsz=1485.5, num_updates=46100, lr=0.000294564, gnorm=0.22, clip=100, loss_scale=4, train_wall=194, wall=92167
2023-05-27 08:40:12 | INFO | train_inner | epoch 007:   6165 / 6686 loss=4.241, nll_loss=2.628, ppl=6.18, wps=28893.1, ups=0.5, wpb=57246.5, bsz=1507, num_updates=46200, lr=0.000294245, gnorm=0.214, clip=100, loss_scale=4, train_wall=194, wall=92366
2023-05-27 08:43:29 | INFO | train_inner | epoch 007:   6265 / 6686 loss=4.251, nll_loss=2.64, ppl=6.23, wps=29033.9, ups=0.51, wpb=57166.2, bsz=1491.8, num_updates=46300, lr=0.000293927, gnorm=0.21, clip=100, loss_scale=8, train_wall=193, wall=92562
2023-05-27 08:46:46 | INFO | train_inner | epoch 007:   6365 / 6686 loss=4.262, nll_loss=2.652, ppl=6.29, wps=28809.4, ups=0.51, wpb=56985.6, bsz=1493.1, num_updates=46400, lr=0.00029361, gnorm=0.217, clip=100, loss_scale=8, train_wall=194, wall=92760
2023-05-27 08:50:04 | INFO | train_inner | epoch 007:   6465 / 6686 loss=4.255, nll_loss=2.644, ppl=6.25, wps=29031.3, ups=0.51, wpb=57369.9, bsz=1474.8, num_updates=46500, lr=0.000293294, gnorm=0.216, clip=100, loss_scale=8, train_wall=194, wall=92958
2023-05-27 08:53:22 | INFO | train_inner | epoch 007:   6565 / 6686 loss=4.255, nll_loss=2.644, ppl=6.25, wps=28902.8, ups=0.51, wpb=57159.9, bsz=1453.7, num_updates=46600, lr=0.000292979, gnorm=0.223, clip=100, loss_scale=8, train_wall=194, wall=93156
2023-05-27 08:56:40 | INFO | train_inner | epoch 007:   6665 / 6686 loss=4.246, nll_loss=2.635, ppl=6.21, wps=28896.2, ups=0.5, wpb=57281.6, bsz=1498.5, num_updates=46700, lr=0.000292666, gnorm=0.213, clip=100, loss_scale=8, train_wall=194, wall=93354
2023-05-27 08:57:12 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 08:57:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-27 08:57:27 | INFO | fairseq.tasks.translation | example hypothesis: Why? Why?
2023-05-27 08:57:27 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-27 08:57:28 | INFO | fairseq.tasks.translation | example hypothesis: In a bit, I’ll make you lose so much that you won’t even have a pair of pants left behind!
2023-05-27 08:57:28 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-27 08:57:30 | INFO | fairseq.tasks.translation | example hypothesis: Just as Shen Liangchuan heaved a sigh of relief, he heard her open her mouth and say, “I’ll call you to the same room!”
2023-05-27 08:57:30 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-27 08:57:31 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved and entered the elevator.
2023-05-27 08:57:31 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-27 08:57:34 | INFO | fairseq.tasks.translation | example hypothesis: As soon as she raised her head, she saw Song Cheng standing in the distance! It was Song Cheng!
2023-05-27 08:57:34 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-27 08:57:36 | INFO | fairseq.tasks.translation | example hypothesis: Only then did Song Cheng pat his own chest. “I’m scared to death! Where’s Wang Chuan?”
2023-05-27 08:57:36 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-27 08:57:38 | INFO | fairseq.tasks.translation | example hypothesis: I said, “I’m not going, I can’t eat there.” I didn’t want to go anymore.
2023-05-27 08:57:38 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-27 08:57:38 | INFO | fairseq.tasks.translation | example hypothesis: At first, everyone did not believe it, but Wang Wen Hao insisted on him, causing public opinion to lean towards Wang Wen Hao.
2023-05-27 08:57:38 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-27 08:57:41 | INFO | fairseq.tasks.translation | example hypothesis: With his identity, even if Baili Hongzhuang did not want to treat him, he had to!
2023-05-27 08:57:41 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-27 08:57:43 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian said, “Mr. Shen, I, I have left too much blood. My brain is short of oxygen, so I can’t think of anything. Why don’t you give me a hint?”
2023-05-27 08:57:43 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-27 08:57:47 | INFO | fairseq.tasks.translation | example hypothesis: He didn’t know why this matter would be heard by so many people. Since he couldn’t hide it anymore, he might as well say it out loud. However, he didn’t know why Li Yuyue’s
2023-05-27 08:57:47 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-27 08:57:48 | INFO | fairseq.tasks.translation | example hypothesis: She deliberately lowered her voice, but there was no way to hide the viciousness and ruthlessness in her voice. “You... you... you...”
2023-05-27 08:57:48 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-27 08:57:51 | INFO | fairseq.tasks.translation | example hypothesis: The strength of a beast pet of different levels was different, but a beast pet was precious and hard to come by. It was impossible for ordinary people to possess it, and even the children of officials could not possess it. However,
2023-05-27 08:57:51 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-27 08:57:53 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chi Xia gritted his teeth and cursed in a low voice, “You’re too arrogant!”
2023-05-27 08:57:53 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-27 08:57:55 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang had concealed it very well, Di Beichen could still see the ripple in her eyes that flashed by in a flash, and his eyes were filled with warmth.
2023-05-27 08:57:55 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-27 08:57:57 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia entered the hotel, not to mention the guests who were staying, he didn’t even see a few waiters. He didn’t even bother to look at the hotel’s entrance.
2023-05-27 08:57:57 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-27 08:58:00 | INFO | fairseq.tasks.translation | example hypothesis: This person was none other than the fourth young miss of the Ye family, Ye Qing Ling.
2023-05-27 08:58:00 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-27 08:58:04 | INFO | fairseq.tasks.translation | example hypothesis: Because at this moment, she felt that her chin was about to shatter.
2023-05-27 08:58:04 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-27 08:58:07 | INFO | fairseq.tasks.translation | example hypothesis: “Good Mu Zi, help me. If it wasn't for you, that old guy wouldn't have set his eyes on me.” I looked at Mu Zi and said.
2023-05-27 08:58:07 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-27 08:58:09 | INFO | fairseq.tasks.translation | example hypothesis: Bai Li Yu Yan was even more excited. She was the one who directed this matter. Earlier, Bai Li Hong Zhuang had treated her like this. This time, she would definitely make Bai Li Hong Zhuang suffer.
2023-05-27 08:58:09 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-27 08:58:11 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How could that be? They’re also four grand mages, so they wouldn’t surrender so easily. After arguing for a long time, they decided to use the competition to decide how to get control of the kingdom in the future.”
2023-05-27 08:58:11 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-27 08:58:14 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a bit. Originally, he had been looking for a reason for Li Yuyue to not be able to participate in the Imperial Family’s hunting competition.
2023-05-27 08:58:14 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-27 08:58:17 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my level good enough? They’re all the most outstanding talents in the country, and my magic is that weak?” asked Link.
2023-05-27 08:58:17 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-27 08:58:22 | INFO | fairseq.tasks.translation | example hypothesis: What Lou Bei meant was that if Fang Chi Xia didn’t want to go, then he didn’t have to go. If Fang Chi Xia didn’t want to go, then he didn’t want to go. If Fang Chi Xia didn’t want to go, then he had to go.
2023-05-27 08:58:22 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-27 08:58:26 | INFO | fairseq.tasks.translation | example hypothesis: She turned her head to the side and saw that the five palm prints on her face were very conspicuous. They were swollen at a speed visible to the naked eye. She reached out her hand to touch them, and she couldn’t help but let out a hissing sound. It was so painful.
2023-05-27 08:58:26 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-27 08:58:29 | INFO | fairseq.tasks.translation | example hypothesis: This... How could this be the charm that that good-for-nothing was able to emit? [1]
2023-05-27 08:58:29 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-27 08:58:31 | INFO | fairseq.tasks.translation | example hypothesis: How did Wang Wenhao find the news agency? The chief editor should have called her to inform her not to come to the news agency, but the three of them... had plotted against her!
2023-05-27 08:58:31 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-27 08:58:36 | INFO | fairseq.tasks.translation | example hypothesis: Hearing Teacher Di’s praise, I was delighted. I put away the energy ball with my left hand, and sent out a light sword in my right hand towards Teacher Zhen. The light sword actually managed to hit me successfully. I was shocked, and when I took a closer look, I realized that it was just an afterimage. Teacher Zhen had already moved to my back, and shouted,
2023-05-27 08:58:36 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-27 08:58:42 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Originally, we proposed a competition of two wins in three matches, but they said it wasn’t fair, because we have Teacher Di and Teacher Zhen, and our ranking is higher than theirs. They proposed five matches and three wins, and because we were the ones who proposed the competition, the method of the competition can only be listened to in the end. Three days later, there will be a secret competition in the Royal Family’s arena. The competition
2023-05-27 08:58:42 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-27 08:58:45 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Di used the Level 7 Light element spell, Lightning Combo. I rarely used this spell, because it wasn’t ideal to control it. Teacher Di released nine lightning bolts and surrounded me, forming a simple formation that prevented me from escaping in a short distance. Then, the lightning bolts exploded and formed a powerful attack.
2023-05-27 08:58:45 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-27 08:58:52 | INFO | fairseq.tasks.translation | example hypothesis: As soon as Ma Ke and the two teachers walked to the other side, Teacher Zhen immediately launched a small Dimensional Cut. As expected of the number one mage on the continent, the powerful suction force of his small Dimensional Cut was actually much stronger than mine. A small spatial crack appeared by my side, and a powerful suction force immediately swept over. I didn’t know that this was the first time I’d seen a small spatial crack appear beside me, and a powerful suction force immediately swept towards me. This was the first time I’ve seen such a small spatial crack in the courtyard, so I didn’t know who it would be sent out for the fifth match.
2023-05-27 08:58:52 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-27 08:58:52 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 4.454 | nll_loss 2.845 | ppl 7.19 | bleu 17.19 | wps 856.6 | wpb 2420.8 | bsz 84.5 | num_updates 46720 | best_bleu 17.84
2023-05-27 08:58:52 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-27 08:58:53 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/mega-1-1-0.2-sf[zh-en]/checkpoint_last.pt (epoch 7 @ 46720 updates, score 17.19) (writing took 0.9764309199526906 seconds)
2023-05-27 08:58:53 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-05-27 08:58:53 | INFO | train | epoch 007 | loss 4.256 | nll_loss 2.645 | ppl 6.26 | wps 28627.3 | ups 0.5 | wpb 57189.8 | bsz 1477.4 | num_updates 46720 | lr 0.000292603 | gnorm 0.217 | clip 100 | loss_scale 6 | train_wall 12961 | wall 93487
2023-05-27 08:58:53 | INFO | fairseq.trainer | begin training epoch 8
2023-05-27 09:01:50 | INFO | train_inner | epoch 008:     80 / 6686 loss=4.242, nll_loss=2.629, ppl=6.19, wps=18243.5, ups=0.32, wpb=56621, bsz=1446.1, num_updates=46800, lr=0.000292353, gnorm=0.216, clip=100, loss_scale=8, train_wall=196, wall=93664
2023-05-27 09:05:14 | INFO | train_inner | epoch 008:    180 / 6686 loss=4.225, nll_loss=2.61, ppl=6.1, wps=28094.2, ups=0.49, wpb=57151, bsz=1473.4, num_updates=46900, lr=0.000292041, gnorm=0.215, clip=100, loss_scale=8, train_wall=195, wall=93868
2023-05-27 09:08:33 | INFO | train_inner | epoch 008:    280 / 6686 loss=4.231, nll_loss=2.617, ppl=6.13, wps=28770.1, ups=0.5, wpb=57236.2, bsz=1455.6, num_updates=47000, lr=0.00029173, gnorm=0.22, clip=100, loss_scale=8, train_wall=194, wall=94067
2023-05-27 09:11:51 | INFO | train_inner | epoch 008:    380 / 6686 loss=4.222, nll_loss=2.607, ppl=6.09, wps=28832.6, ups=0.5, wpb=57202, bsz=1485, num_updates=47100, lr=0.00029142, gnorm=0.214, clip=100, loss_scale=8, train_wall=195, wall=94265
2023-05-27 09:15:10 | INFO | train_inner | epoch 008:    480 / 6686 loss=4.227, nll_loss=2.612, ppl=6.11, wps=28867, ups=0.5, wpb=57337.8, bsz=1483.7, num_updates=47200, lr=0.000291111, gnorm=0.214, clip=100, loss_scale=8, train_wall=195, wall=94464
2023-05-27 09:16:21 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 09:18:29 | INFO | train_inner | epoch 008:    581 / 6686 loss=4.234, nll_loss=2.62, ppl=6.15, wps=28648.7, ups=0.5, wpb=57154.3, bsz=1479.8, num_updates=47300, lr=0.000290803, gnorm=0.221, clip=100, loss_scale=9, train_wall=195, wall=94663
2023-05-27 09:21:47 | INFO | train_inner | epoch 008:    681 / 6686 loss=4.225, nll_loss=2.61, ppl=6.1, wps=28903.2, ups=0.51, wpb=57130.3, bsz=1505.2, num_updates=47400, lr=0.000290496, gnorm=0.211, clip=100, loss_scale=8, train_wall=194, wall=94861
2023-05-27 09:25:04 | INFO | train_inner | epoch 008:    781 / 6686 loss=4.241, nll_loss=2.629, ppl=6.18, wps=29002, ups=0.51, wpb=57139, bsz=1457.8, num_updates=47500, lr=0.000290191, gnorm=0.209, clip=100, loss_scale=8, train_wall=193, wall=95058
2023-05-27 09:28:22 | INFO | train_inner | epoch 008:    881 / 6686 loss=4.242, nll_loss=2.629, ppl=6.18, wps=28921.5, ups=0.5, wpb=57292.2, bsz=1455.4, num_updates=47600, lr=0.000289886, gnorm=0.228, clip=100, loss_scale=8, train_wall=194, wall=95256
2023-05-27 09:31:40 | INFO | train_inner | epoch 008:    981 / 6686 loss=4.237, nll_loss=2.624, ppl=6.16, wps=28982.7, ups=0.51, wpb=57237.8, bsz=1464.2, num_updates=47700, lr=0.000289581, gnorm=0.223, clip=100, loss_scale=8, train_wall=194, wall=95453
2023-05-27 09:34:01 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 09:34:59 | INFO | train_inner | epoch 008:   1082 / 6686 loss=4.238, nll_loss=2.625, ppl=6.17, wps=28662.1, ups=0.5, wpb=57052.8, bsz=1461, num_updates=47800, lr=0.000289278, gnorm=0.219, clip=100, loss_scale=10, train_wall=195, wall=95653
2023-05-27 09:38:17 | INFO | train_inner | epoch 008:   1182 / 6686 loss=4.229, nll_loss=2.614, ppl=6.12, wps=28819, ups=0.51, wpb=57063, bsz=1500, num_updates=47900, lr=0.000288976, gnorm=0.219, clip=100, loss_scale=8, train_wall=194, wall=95851
2023-05-27 09:41:34 | INFO | train_inner | epoch 008:   1282 / 6686 loss=4.245, nll_loss=2.632, ppl=6.2, wps=28922.9, ups=0.51, wpb=57143.9, bsz=1469.9, num_updates=48000, lr=0.000288675, gnorm=0.224, clip=100, loss_scale=8, train_wall=194, wall=96048
2023-05-27 09:44:52 | INFO | train_inner | epoch 008:   1382 / 6686 loss=4.223, nll_loss=2.607, ppl=6.09, wps=28894.6, ups=0.5, wpb=57276.3, bsz=1488.2, num_updates=48100, lr=0.000288375, gnorm=0.214, clip=100, loss_scale=8, train_wall=194, wall=96246
2023-05-27 09:48:10 | INFO | train_inner | epoch 008:   1482 / 6686 loss=4.24, nll_loss=2.627, ppl=6.18, wps=28927.5, ups=0.51, wpb=57129.2, bsz=1479.3, num_updates=48200, lr=0.000288076, gnorm=0.221, clip=100, loss_scale=8, train_wall=194, wall=96444
2023-05-27 09:51:27 | INFO | train_inner | epoch 008:   1582 / 6686 loss=4.236, nll_loss=2.622, ppl=6.16, wps=29043.3, ups=0.51, wpb=57352.7, bsz=1445.4, num_updates=48300, lr=0.000287777, gnorm=0.215, clip=100, loss_scale=9, train_wall=194, wall=96641
2023-05-27 09:51:31 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 09:54:47 | INFO | train_inner | epoch 008:   1683 / 6686 loss=4.235, nll_loss=2.622, ppl=6.15, wps=28714.2, ups=0.5, wpb=57337, bsz=1508.9, num_updates=48400, lr=0.00028748, gnorm=0.216, clip=100, loss_scale=8, train_wall=196, wall=96841
2023-05-27 09:55:30 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2023-05-27 09:58:06 | INFO | train_inner | epoch 008:   1784 / 6686 loss=4.224, nll_loss=2.61, ppl=6.1, wps=28721.8, ups=0.5, wpb=57212.1, bsz=1485.8, num_updates=48500, lr=0.000287183, gnorm=0.213, clip=100, loss_scale=5, train_wall=195, wall=97040
2023-05-27 10:01:24 | INFO | train_inner | epoch 008:   1884 / 6686 loss=4.237, nll_loss=2.624, ppl=6.16, wps=28854.7, ups=0.5, wpb=57144.2, bsz=1469.7, num_updates=48600, lr=0.000286888, gnorm=0.209, clip=100, loss_scale=4, train_wall=194, wall=97238
2023-05-27 10:04:42 | INFO | train_inner | epoch 008:   1984 / 6686 loss=4.238, nll_loss=2.625, ppl=6.17, wps=28944.7, ups=0.51, wpb=57181.3, bsz=1479, num_updates=48700, lr=0.000286593, gnorm=0.234, clip=100, loss_scale=4, train_wall=194, wall=97436
2023-05-27 10:08:00 | INFO | train_inner | epoch 008:   2084 / 6686 loss=4.243, nll_loss=2.631, ppl=6.19, wps=28910, ups=0.51, wpb=57159.3, bsz=1485.2, num_updates=48800, lr=0.000286299, gnorm=0.22, clip=100, loss_scale=4, train_wall=194, wall=97633
2023-05-27 10:11:17 | INFO | train_inner | epoch 008:   2184 / 6686 loss=4.248, nll_loss=2.636, ppl=6.22, wps=28846.6, ups=0.51, wpb=57060.6, bsz=1466.1, num_updates=48900, lr=0.000286006, gnorm=0.211, clip=100, loss_scale=4, train_wall=194, wall=97831
2023-05-27 10:14:35 | INFO | train_inner | epoch 008:   2284 / 6686 loss=4.24, nll_loss=2.628, ppl=6.18, wps=28951.5, ups=0.51, wpb=57068.3, bsz=1475.3, num_updates=49000, lr=0.000285714, gnorm=0.218, clip=100, loss_scale=7, train_wall=193, wall=98028
2023-05-27 10:17:51 | INFO | train_inner | epoch 008:   2384 / 6686 loss=4.237, nll_loss=2.624, ppl=6.16, wps=29010.5, ups=0.51, wpb=57104.4, bsz=1483.4, num_updates=49100, lr=0.000285423, gnorm=0.218, clip=100, loss_scale=8, train_wall=193, wall=98225
2023-05-27 10:21:09 | INFO | train_inner | epoch 008:   2484 / 6686 loss=4.242, nll_loss=2.629, ppl=6.19, wps=28883.5, ups=0.51, wpb=57002.7, bsz=1487, num_updates=49200, lr=0.000285133, gnorm=0.219, clip=100, loss_scale=8, train_wall=193, wall=98423
2023-05-27 10:24:26 | INFO | train_inner | epoch 008:   2584 / 6686 loss=4.237, nll_loss=2.624, ppl=6.17, wps=29077.2, ups=0.51, wpb=57276.6, bsz=1463.5, num_updates=49300, lr=0.000284844, gnorm=0.213, clip=100, loss_scale=8, train_wall=193, wall=98620
2023-05-27 10:27:44 | INFO | train_inner | epoch 008:   2684 / 6686 loss=4.237, nll_loss=2.624, ppl=6.17, wps=28883.8, ups=0.5, wpb=57213.1, bsz=1487.1, num_updates=49400, lr=0.000284555, gnorm=0.22, clip=100, loss_scale=8, train_wall=194, wall=98818
2023-05-27 10:29:46 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 10:31:04 | INFO | train_inner | epoch 008:   2785 / 6686 loss=4.243, nll_loss=2.631, ppl=6.19, wps=28637.2, ups=0.5, wpb=57181.4, bsz=1481.8, num_updates=49500, lr=0.000284268, gnorm=0.218, clip=100, loss_scale=9, train_wall=196, wall=99017
2023-05-27 10:34:21 | INFO | train_inner | epoch 008:   2885 / 6686 loss=4.236, nll_loss=2.623, ppl=6.16, wps=28927.3, ups=0.51, wpb=57183.5, bsz=1472.2, num_updates=49600, lr=0.000283981, gnorm=0.213, clip=100, loss_scale=8, train_wall=194, wall=99215
2023-05-27 10:37:40 | INFO | train_inner | epoch 008:   2985 / 6686 loss=4.231, nll_loss=2.617, ppl=6.13, wps=28916.2, ups=0.5, wpb=57389.9, bsz=1475.6, num_updates=49700, lr=0.000283695, gnorm=0.224, clip=100, loss_scale=8, train_wall=195, wall=99414
2023-05-27 10:40:58 | INFO | train_inner | epoch 008:   3085 / 6686 loss=4.223, nll_loss=2.608, ppl=6.1, wps=28906.7, ups=0.5, wpb=57281.4, bsz=1486.7, num_updates=49800, lr=0.00028341, gnorm=0.218, clip=100, loss_scale=8, train_wall=194, wall=99612
2023-05-27 10:44:16 | INFO | train_inner | epoch 008:   3185 / 6686 loss=4.239, nll_loss=2.626, ppl=6.17, wps=28831, ups=0.51, wpb=57083.4, bsz=1465.5, num_updates=49900, lr=0.000283126, gnorm=0.22, clip=100, loss_scale=8, train_wall=194, wall=99810
2023-05-27 10:47:34 | INFO | train_inner | epoch 008:   3285 / 6686 loss=4.231, nll_loss=2.617, ppl=6.14, wps=28906.6, ups=0.5, wpb=57313.9, bsz=1462.8, num_updates=50000, lr=0.000282843, gnorm=0.215, clip=100, loss_scale=10, train_wall=195, wall=100008
2023-05-27 10:48:21 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 10:50:52 | INFO | train_inner | epoch 008:   3386 / 6686 loss=4.248, nll_loss=2.636, ppl=6.22, wps=28782.6, ups=0.5, wpb=57084.7, bsz=1465.8, num_updates=50100, lr=0.00028256, gnorm=0.214, clip=100, loss_scale=10, train_wall=194, wall=100206
2023-05-27 10:54:11 | INFO | train_inner | epoch 008:   3486 / 6686 loss=4.24, nll_loss=2.628, ppl=6.18, wps=28978.5, ups=0.5, wpb=57409.7, bsz=1494.2, num_updates=50200, lr=0.000282279, gnorm=0.219, clip=100, loss_scale=8, train_wall=194, wall=100404
2023-05-27 10:57:28 | INFO | train_inner | epoch 008:   3586 / 6686 loss=4.234, nll_loss=2.62, ppl=6.15, wps=28996.2, ups=0.51, wpb=57258.7, bsz=1496.6, num_updates=50300, lr=0.000281998, gnorm=0.215, clip=100, loss_scale=8, train_wall=194, wall=100602
2023-05-27 11:00:46 | INFO | train_inner | epoch 008:   3686 / 6686 loss=4.231, nll_loss=2.618, ppl=6.14, wps=29005.5, ups=0.51, wpb=57433.8, bsz=1480.6, num_updates=50400, lr=0.000281718, gnorm=0.222, clip=100, loss_scale=8, train_wall=194, wall=100800
2023-05-27 11:04:04 | INFO | train_inner | epoch 008:   3786 / 6686 loss=4.244, nll_loss=2.632, ppl=6.2, wps=29002.2, ups=0.51, wpb=57348.3, bsz=1476.1, num_updates=50500, lr=0.000281439, gnorm=0.224, clip=100, loss_scale=8, train_wall=194, wall=100998
2023-05-27 11:05:17 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 11:07:23 | INFO | train_inner | epoch 008:   3887 / 6686 loss=4.234, nll_loss=2.621, ppl=6.15, wps=28644.3, ups=0.5, wpb=57097.7, bsz=1483.2, num_updates=50600, lr=0.000281161, gnorm=0.217, clip=100, loss_scale=8, train_wall=195, wall=101197
2023-05-27 11:10:41 | INFO | train_inner | epoch 008:   3987 / 6686 loss=4.227, nll_loss=2.614, ppl=6.12, wps=29028.9, ups=0.51, wpb=57363.2, bsz=1499.6, num_updates=50700, lr=0.000280883, gnorm=0.215, clip=100, loss_scale=8, train_wall=194, wall=101395
2023-05-27 11:13:58 | INFO | train_inner | epoch 008:   4087 / 6686 loss=4.234, nll_loss=2.621, ppl=6.15, wps=29006.7, ups=0.51, wpb=57138.1, bsz=1479.4, num_updates=50800, lr=0.000280607, gnorm=0.216, clip=100, loss_scale=8, train_wall=193, wall=101592
2023-05-27 11:17:15 | INFO | train_inner | epoch 008:   4187 / 6686 loss=4.237, nll_loss=2.625, ppl=6.17, wps=28873.3, ups=0.51, wpb=57009.8, bsz=1478.7, num_updates=50900, lr=0.000280331, gnorm=0.212, clip=100, loss_scale=8, train_wall=194, wall=101789
2023-05-27 11:20:33 | INFO | train_inner | epoch 008:   4287 / 6686 loss=4.229, nll_loss=2.615, ppl=6.13, wps=28851.5, ups=0.51, wpb=57020.2, bsz=1472.9, num_updates=51000, lr=0.000280056, gnorm=0.225, clip=100, loss_scale=8, train_wall=194, wall=101987
2023-05-27 11:23:51 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 11:23:53 | INFO | train_inner | epoch 008:   4388 / 6686 loss=4.235, nll_loss=2.622, ppl=6.16, wps=28667.7, ups=0.5, wpb=57308.1, bsz=1478.6, num_updates=51100, lr=0.000279782, gnorm=0.219, clip=100, loss_scale=12, train_wall=196, wall=102187
2023-05-27 11:27:11 | INFO | train_inner | epoch 008:   4488 / 6686 loss=4.247, nll_loss=2.636, ppl=6.21, wps=28890.5, ups=0.51, wpb=57195.6, bsz=1480.6, num_updates=51200, lr=0.000279508, gnorm=0.212, clip=100, loss_scale=8, train_wall=194, wall=102385
2023-05-27 11:30:28 | INFO | train_inner | epoch 008:   4588 / 6686 loss=4.241, nll_loss=2.629, ppl=6.19, wps=29024.9, ups=0.51, wpb=57400.1, bsz=1478.5, num_updates=51300, lr=0.000279236, gnorm=0.218, clip=100, loss_scale=8, train_wall=194, wall=102582
2023-05-27 11:33:46 | INFO | train_inner | epoch 008:   4688 / 6686 loss=4.227, nll_loss=2.613, ppl=6.12, wps=28930.5, ups=0.51, wpb=57153.8, bsz=1499.4, num_updates=51400, lr=0.000278964, gnorm=0.216, clip=100, loss_scale=8, train_wall=193, wall=102780
2023-05-27 11:37:04 | INFO | train_inner | epoch 008:   4788 / 6686 loss=4.239, nll_loss=2.626, ppl=6.17, wps=28935.2, ups=0.51, wpb=57175.8, bsz=1491.7, num_updates=51500, lr=0.000278693, gnorm=0.213, clip=100, loss_scale=8, train_wall=194, wall=102977
2023-05-27 11:40:20 | INFO | train_inner | epoch 008:   4888 / 6686 loss=4.241, nll_loss=2.629, ppl=6.19, wps=29027.9, ups=0.51, wpb=57077.6, bsz=1453.5, num_updates=51600, lr=0.000278423, gnorm=0.216, clip=100, loss_scale=8, train_wall=193, wall=103174
2023-05-27 11:40:48 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 11:43:40 | INFO | train_inner | epoch 008:   4989 / 6686 loss=4.237, nll_loss=2.624, ppl=6.17, wps=28630.8, ups=0.5, wpb=57249.8, bsz=1494.4, num_updates=51700, lr=0.000278154, gnorm=0.216, clip=100, loss_scale=8, train_wall=196, wall=103374
2023-05-27 11:46:58 | INFO | train_inner | epoch 008:   5089 / 6686 loss=4.236, nll_loss=2.623, ppl=6.16, wps=28973.1, ups=0.51, wpb=57189.3, bsz=1473.4, num_updates=51800, lr=0.000277885, gnorm=0.217, clip=100, loss_scale=8, train_wall=194, wall=103571
2023-05-27 11:50:15 | INFO | train_inner | epoch 008:   5189 / 6686 loss=4.235, nll_loss=2.623, ppl=6.16, wps=28956.8, ups=0.51, wpb=57209.2, bsz=1472.9, num_updates=51900, lr=0.000277617, gnorm=0.223, clip=100, loss_scale=8, train_wall=194, wall=103769
2023-05-27 11:53:33 | INFO | train_inner | epoch 008:   5289 / 6686 loss=4.237, nll_loss=2.624, ppl=6.16, wps=28999.6, ups=0.51, wpb=57289.6, bsz=1462.5, num_updates=52000, lr=0.00027735, gnorm=0.219, clip=100, loss_scale=8, train_wall=194, wall=103967
2023-05-27 11:56:51 | INFO | train_inner | epoch 008:   5389 / 6686 loss=4.232, nll_loss=2.619, ppl=6.14, wps=28943, ups=0.5, wpb=57347.2, bsz=1481, num_updates=52100, lr=0.000277084, gnorm=0.213, clip=100, loss_scale=8, train_wall=194, wall=104165
2023-05-27 11:58:26 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 12:00:10 | INFO | train_inner | epoch 008:   5490 / 6686 loss=4.238, nll_loss=2.626, ppl=6.17, wps=28714.6, ups=0.5, wpb=57237.8, bsz=1485.2, num_updates=52200, lr=0.000276818, gnorm=0.216, clip=100, loss_scale=10, train_wall=195, wall=104364
2023-05-27 12:03:27 | INFO | train_inner | epoch 008:   5590 / 6686 loss=4.243, nll_loss=2.632, ppl=6.2, wps=29019.6, ups=0.51, wpb=57247.6, bsz=1472.1, num_updates=52300, lr=0.000276553, gnorm=0.231, clip=100, loss_scale=8, train_wall=193, wall=104561
2023-05-27 12:06:45 | INFO | train_inner | epoch 008:   5690 / 6686 loss=4.223, nll_loss=2.609, ppl=6.1, wps=28972.9, ups=0.51, wpb=57200.6, bsz=1479, num_updates=52400, lr=0.000276289, gnorm=0.222, clip=100, loss_scale=8, train_wall=194, wall=104759
2023-05-27 12:10:03 | INFO | train_inner | epoch 008:   5790 / 6686 loss=4.234, nll_loss=2.621, ppl=6.15, wps=28878.4, ups=0.5, wpb=57239.7, bsz=1469.9, num_updates=52500, lr=0.000276026, gnorm=0.213, clip=100, loss_scale=8, train_wall=194, wall=104957
2023-05-27 12:13:21 | INFO | train_inner | epoch 008:   5890 / 6686 loss=4.233, nll_loss=2.62, ppl=6.15, wps=28889.6, ups=0.51, wpb=57169.1, bsz=1488.9, num_updates=52600, lr=0.000275764, gnorm=0.212, clip=100, loss_scale=8, train_wall=194, wall=105155
2023-05-27 12:15:53 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 12:16:40 | INFO | train_inner | epoch 008:   5991 / 6686 loss=4.234, nll_loss=2.622, ppl=6.15, wps=28768.2, ups=0.5, wpb=57339.7, bsz=1486.2, num_updates=52700, lr=0.000275502, gnorm=0.219, clip=100, loss_scale=9, train_wall=195, wall=105354
2023-05-27 12:19:57 | INFO | train_inner | epoch 008:   6091 / 6686 loss=4.231, nll_loss=2.618, ppl=6.14, wps=28989.1, ups=0.51, wpb=57150.3, bsz=1491.7, num_updates=52800, lr=0.000275241, gnorm=0.212, clip=100, loss_scale=8, train_wall=193, wall=105551
2023-05-27 12:23:14 | INFO | train_inner | epoch 008:   6191 / 6686 loss=4.245, nll_loss=2.634, ppl=6.21, wps=29099.5, ups=0.51, wpb=57139.7, bsz=1456.2, num_updates=52900, lr=0.000274981, gnorm=0.215, clip=100, loss_scale=8, train_wall=193, wall=105748
2023-05-27 12:26:31 | INFO | train_inner | epoch 008:   6291 / 6686 loss=4.235, nll_loss=2.623, ppl=6.16, wps=28974.2, ups=0.51, wpb=57183, bsz=1491.9, num_updates=53000, lr=0.000274721, gnorm=0.217, clip=100, loss_scale=8, train_wall=194, wall=105945
2023-05-27 12:29:49 | INFO | train_inner | epoch 008:   6391 / 6686 loss=4.23, nll_loss=2.617, ppl=6.13, wps=28896.9, ups=0.51, wpb=57209.5, bsz=1480.6, num_updates=53100, lr=0.000274462, gnorm=0.224, clip=100, loss_scale=8, train_wall=194, wall=106143
2023-05-27 12:32:45 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 12:33:08 | INFO | train_inner | epoch 008:   6492 / 6686 loss=4.242, nll_loss=2.63, ppl=6.19, wps=28585.3, ups=0.5, wpb=56930.4, bsz=1456.6, num_updates=53200, lr=0.000274204, gnorm=0.217, clip=100, loss_scale=8, train_wall=195, wall=106342
2023-05-27 12:36:26 | INFO | train_inner | epoch 008:   6592 / 6686 loss=4.247, nll_loss=2.636, ppl=6.22, wps=28981, ups=0.51, wpb=57179.9, bsz=1475, num_updates=53300, lr=0.000273947, gnorm=0.21, clip=100, loss_scale=8, train_wall=194, wall=106540
2023-05-27 12:39:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-27 12:39:37 | INFO | fairseq.tasks.translation | example hypothesis: Why? Why?
2023-05-27 12:39:37 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-27 12:39:38 | INFO | fairseq.tasks.translation | example hypothesis: In a while, I’ll make you lose to the point where you don’t even have a pair of pants left!
2023-05-27 12:39:38 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-27 12:39:39 | INFO | fairseq.tasks.translation | example hypothesis: Just as Shen Liangchuan heaved a sigh of relief, he heard her open her mouth and say, “I’ll call you to the same room!”
2023-05-27 12:39:39 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-27 12:39:41 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved and entered the elevator.
2023-05-27 12:39:41 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-27 12:39:44 | INFO | fairseq.tasks.translation | example hypothesis: When she raised her head, she saw Song Cheng standing in the distance! Song Cheng’s face turned red.
2023-05-27 12:39:44 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-27 12:39:45 | INFO | fairseq.tasks.translation | example hypothesis: Only then did Song Cheng pat his chest and said, “I was scared to death! Where’s Wang Chuan?”
2023-05-27 12:39:45 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-27 12:39:47 | INFO | fairseq.tasks.translation | example hypothesis: I said, “I won’t go, I won’t be able to eat there,” I said with a smile.
2023-05-27 12:39:47 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-27 12:39:48 | INFO | fairseq.tasks.translation | example hypothesis: Everyone initially did not believe him, but Wang Wenhao insisted that the public opinion was biased towards Wang Wenhao.
2023-05-27 12:39:48 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-27 12:39:51 | INFO | fairseq.tasks.translation | example hypothesis: With his identity, Baili Hongzhuang had no choice but to treat him even if he did not want to!
2023-05-27 12:39:51 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-27 12:39:53 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian said, “Mr. Shen, I, I have left too much blood. My brain is short of oxygen, so I can’t think of anything. Why don’t you give me a hint?”
2023-05-27 12:39:53 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-27 12:39:56 | INFO | fairseq.tasks.translation | example hypothesis: He didn’t know why this matter would spread to so many people’s ears. Since he couldn’t hide it anymore, he might as well say it out loud. However, he didn’t know why Li Yuyue
2023-05-27 12:39:56 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-27 12:39:58 | INFO | fairseq.tasks.translation | example hypothesis: She deliberately lowered her voice, but there was no way to hide the viciousness and viciousness in her voice. “I’m sorry, I’m sorry...”
2023-05-27 12:39:58 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-27 12:40:01 | INFO | fairseq.tasks.translation | example hypothesis: The strength of a beast pet of a different level was different. However, a beast pet was precious and rare. Ordinary people would not be able to possess one, not even an official’s son. However, a beast pet was
2023-05-27 12:40:01 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-27 12:40:03 | INFO | fairseq.tasks.translation | example hypothesis: "Damn it, I don't know what to do!" Fang Chixia cursed under her teeth.
2023-05-27 12:40:03 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-27 12:40:05 | INFO | fairseq.tasks.translation | example hypothesis: Even though Bai Li Hongzhuang had concealed it very well, Di Beichen could still see the ripples flashing in her eyes, and his eyes were filled with a bit of warmth.
2023-05-27 12:40:05 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-27 12:40:07 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia entered the hotel, not to mention the guests, she didn't even see a few waitresses. She didn't even have the time to look for the guests.
2023-05-27 12:40:07 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-27 12:40:10 | INFO | fairseq.tasks.translation | example hypothesis: This person was none other than the Ye Family's Fourth Young Lady – Ye Qingling.
2023-05-27 12:40:10 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-27 12:40:13 | INFO | fairseq.tasks.translation | example hypothesis: Because at this moment, she felt as if her chin was about to shatter.
2023-05-27 12:40:13 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-27 12:40:16 | INFO | fairseq.tasks.translation | example hypothesis: “Okay, Mu Zi, help me. If it wasn't for you, that old man wouldn't have set his eyes on me,” I said with a smile.
2023-05-27 12:40:16 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-27 12:40:18 | INFO | fairseq.tasks.translation | example hypothesis: Bai Li Yu Yan was even more excited. She was the director of this matter. Earlier, Bai Li Hong Zhuang had treated her like that. This time, she would definitely make Bai Li Hong Zhuang suffer as well.
2023-05-27 12:40:18 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-27 12:40:21 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How could that be? They’re also mages, so they won’t surrender so easily. After arguing for a long time, they decided to use the competition to decide how to get control of the kingdom in the future.”
2023-05-27 12:40:21 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-27 12:40:23 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a bit. Originally, he had been looking for an excuse for Li Yuyue to not be able to participate in the Imperial Family’s Hunting Competition.
2023-05-27 12:40:23 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-27 12:40:26 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my level good enough? They’re all the best talents in the country, and my magic is so weak?” asked Link.
2023-05-27 12:40:26 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-27 12:40:32 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yi Bei’s words meant that if Fang Chi Xia didn’t want to go, then he didn’t need to go. If Fang Chi Xia didn’t want to go, then he wouldn’t have to go. If Fang Chi Xia didn’t want to go, then he wouldn’t have to go.
2023-05-27 12:40:32 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-27 12:40:36 | INFO | fairseq.tasks.translation | example hypothesis: She tilted her head to the side and saw that the five palm prints on her face were very conspicuous. At a speed visible to the naked eye, they swelled up high. She reached out her hand to touch them, and she couldn’t help but let out a hissing sound. It hurt so much.
2023-05-27 12:40:36 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-27 12:40:39 | INFO | fairseq.tasks.translation | example hypothesis: This... how could it be possible for that trash to give off such charm? How could this be possible?
2023-05-27 12:40:39 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-27 12:40:41 | INFO | fairseq.tasks.translation | example hypothesis: How did Wang Wenhao find the news agency? The chief editor clearly should have called her to inform her not to come to the news agency, but these three people... had plotted against her!
2023-05-27 12:40:41 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-27 12:40:46 | INFO | fairseq.tasks.translation | example hypothesis: Hearing Teacher Di’s praise, I was delighted. I retracted the energy ball with my left hand, and a light sword shot out from my right hand towards Teacher Zhen. The light sword actually managed to hit me smoothly. I was shocked, and after a careful look, I realized that it was just an afterimage. Teacher Zhen had already moved behind me, and shouted, “Berserk Space
2023-05-27 12:40:46 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-27 12:40:53 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Originally, we proposed three rounds to win two rounds, but they said it wasn’t fair, because we have Teacher Di and Teacher Zhen. Their rankings are higher than theirs, and they proposed five rounds to win three rounds. Since we were the ones who proposed the competition, the method of the competition can only be listened to by them in the end. Three days later, there will be a secret competition in the Royal Family’s arena. We will
2023-05-27 12:40:53 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-27 12:40:55 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Di used a rank 7 light-type spell, Lightning Chain Explosion. I rarely used this spell because it wasn’t good at controlling it. Teacher Di released nine lightning bolts and surrounded me, forming a simple formation that prevented me from escaping in a short distance. After that, the lightning bolts exploded and formed a powerful attack.
2023-05-27 12:40:55 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-27 12:41:02 | INFO | fairseq.tasks.translation | example hypothesis: As soon as Mar Ke and the two teachers walked to the other side, Teacher Zhen shot a small Dimensional Slash at me. As expected of the continent’s number one mage, the powerful suction force from his small Dimensional Slash was actually much stronger than my own. A small spatial crack appeared beside me, and a powerful suction force immediately swept over. The two of them looked at each other and said, “We’re going to fight for the fifth match! We’re going to fight for the fifth match! We’re going to fight for the fifth match! We’re going to fight! We’re going to fight! We’re going to fight! We’re going to lose! We’re going to lose! We’re going to lose! We’re going to lose!”
2023-05-27 12:41:02 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-27 12:41:03 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 4.459 | nll_loss 2.852 | ppl 7.22 | bleu 17.27 | wps 853.1 | wpb 2420.8 | bsz 84.5 | num_updates 53394 | best_bleu 17.84
2023-05-27 12:41:03 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-27 12:41:04 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/mega-1-1-0.2-sf[zh-en]/checkpoint_last.pt (epoch 8 @ 53394 updates, score 17.27) (writing took 1.1106880167499185 seconds)
2023-05-27 12:41:04 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-05-27 12:41:04 | INFO | train | epoch 008 | loss 4.235 | nll_loss 2.622 | ppl 6.16 | wps 28633.1 | ups 0.5 | wpb 57190.8 | bsz 1477.6 | num_updates 53394 | lr 0.000273706 | gnorm 0.218 | clip 100 | loss_scale 8 | train_wall 12957 | wall 106818
2023-05-27 12:41:04 | INFO | fairseq.trainer | begin training epoch 9
2023-05-27 12:41:25 | INFO | train_inner | epoch 009:      6 / 6686 loss=4.222, nll_loss=2.608, ppl=6.09, wps=18896.6, ups=0.33, wpb=56584.5, bsz=1468.2, num_updates=53400, lr=0.00027369, gnorm=0.223, clip=100, loss_scale=8, train_wall=192, wall=106839
2023-05-27 12:44:52 | INFO | train_inner | epoch 009:    106 / 6686 loss=4.211, nll_loss=2.594, ppl=6.04, wps=27578.3, ups=0.48, wpb=57125.2, bsz=1468.3, num_updates=53500, lr=0.000273434, gnorm=0.214, clip=100, loss_scale=8, train_wall=195, wall=107046
2023-05-27 12:48:13 | INFO | train_inner | epoch 009:    206 / 6686 loss=4.218, nll_loss=2.602, ppl=6.07, wps=28427.6, ups=0.5, wpb=57135.2, bsz=1462.1, num_updates=53600, lr=0.000273179, gnorm=0.221, clip=100, loss_scale=8, train_wall=194, wall=107247
2023-05-27 12:51:32 | INFO | train_inner | epoch 009:    306 / 6686 loss=4.215, nll_loss=2.599, ppl=6.06, wps=28772.2, ups=0.5, wpb=57101.8, bsz=1487.1, num_updates=53700, lr=0.000272925, gnorm=0.216, clip=100, loss_scale=8, train_wall=194, wall=107446
2023-05-27 12:52:04 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 12:54:52 | INFO | train_inner | epoch 009:    407 / 6686 loss=4.217, nll_loss=2.602, ppl=6.07, wps=28523.6, ups=0.5, wpb=57240.6, bsz=1487.8, num_updates=53800, lr=0.000272671, gnorm=0.215, clip=100, loss_scale=9, train_wall=197, wall=107646
2023-05-27 12:58:10 | INFO | train_inner | epoch 009:    507 / 6686 loss=4.21, nll_loss=2.593, ppl=6.03, wps=28852.1, ups=0.51, wpb=56939.9, bsz=1461.4, num_updates=53900, lr=0.000272418, gnorm=0.211, clip=100, loss_scale=8, train_wall=194, wall=107844
2023-05-27 13:01:27 | INFO | train_inner | epoch 009:    607 / 6686 loss=4.222, nll_loss=2.607, ppl=6.09, wps=29020.3, ups=0.51, wpb=57200, bsz=1456.6, num_updates=54000, lr=0.000272166, gnorm=0.221, clip=100, loss_scale=8, train_wall=193, wall=108041
2023-05-27 13:04:37 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2023-05-27 13:04:47 | INFO | train_inner | epoch 009:    708 / 6686 loss=4.216, nll_loss=2.601, ppl=6.07, wps=28650, ups=0.5, wpb=57244.2, bsz=1497.3, num_updates=54100, lr=0.000271914, gnorm=0.216, clip=100, loss_scale=8, train_wall=196, wall=108241
2023-05-27 13:08:05 | INFO | train_inner | epoch 009:    808 / 6686 loss=4.203, nll_loss=2.586, ppl=6, wps=28837.6, ups=0.5, wpb=57114.8, bsz=1497.1, num_updates=54200, lr=0.000271663, gnorm=0.218, clip=100, loss_scale=4, train_wall=194, wall=108439
2023-05-27 13:11:23 | INFO | train_inner | epoch 009:    908 / 6686 loss=4.211, nll_loss=2.595, ppl=6.04, wps=28935.8, ups=0.5, wpb=57313.8, bsz=1482.3, num_updates=54300, lr=0.000271413, gnorm=0.213, clip=100, loss_scale=4, train_wall=194, wall=108637
2023-05-27 13:14:40 | INFO | train_inner | epoch 009:   1008 / 6686 loss=4.22, nll_loss=2.605, ppl=6.08, wps=28917.9, ups=0.51, wpb=57117.7, bsz=1454.9, num_updates=54400, lr=0.000271163, gnorm=0.217, clip=100, loss_scale=4, train_wall=194, wall=108834
2023-05-27 13:17:57 | INFO | train_inner | epoch 009:   1108 / 6686 loss=4.224, nll_loss=2.61, ppl=6.1, wps=28943.6, ups=0.51, wpb=57000.4, bsz=1458.6, num_updates=54500, lr=0.000270914, gnorm=0.225, clip=100, loss_scale=4, train_wall=193, wall=109031
2023-05-27 13:21:14 | INFO | train_inner | epoch 009:   1208 / 6686 loss=4.212, nll_loss=2.596, ppl=6.04, wps=29003.1, ups=0.51, wpb=57185.8, bsz=1458.2, num_updates=54600, lr=0.000270666, gnorm=0.222, clip=100, loss_scale=4, train_wall=193, wall=109228
2023-05-27 13:24:32 | INFO | train_inner | epoch 009:   1308 / 6686 loss=4.213, nll_loss=2.597, ppl=6.05, wps=29030.8, ups=0.51, wpb=57380.8, bsz=1481, num_updates=54700, lr=0.000270418, gnorm=0.216, clip=100, loss_scale=8, train_wall=194, wall=109426
2023-05-27 13:27:50 | INFO | train_inner | epoch 009:   1408 / 6686 loss=4.215, nll_loss=2.599, ppl=6.06, wps=28975.7, ups=0.51, wpb=57207.2, bsz=1484.3, num_updates=54800, lr=0.000270172, gnorm=0.21, clip=100, loss_scale=8, train_wall=194, wall=109623
2023-05-27 13:31:07 | INFO | train_inner | epoch 009:   1508 / 6686 loss=4.224, nll_loss=2.61, ppl=6.1, wps=29009.8, ups=0.51, wpb=57309.4, bsz=1491.1, num_updates=54900, lr=0.000269925, gnorm=0.212, clip=100, loss_scale=8, train_wall=194, wall=109821
2023-05-27 13:34:25 | INFO | train_inner | epoch 009:   1608 / 6686 loss=4.215, nll_loss=2.6, ppl=6.06, wps=28918, ups=0.5, wpb=57322.4, bsz=1494.3, num_updates=55000, lr=0.00026968, gnorm=0.224, clip=100, loss_scale=8, train_wall=194, wall=110019
2023-05-27 13:37:43 | INFO | train_inner | epoch 009:   1708 / 6686 loss=4.221, nll_loss=2.607, ppl=6.09, wps=28989.3, ups=0.51, wpb=57295.3, bsz=1471, num_updates=55100, lr=0.000269435, gnorm=0.213, clip=100, loss_scale=8, train_wall=194, wall=110217
2023-05-27 13:39:45 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 13:41:02 | INFO | train_inner | epoch 009:   1809 / 6686 loss=4.222, nll_loss=2.607, ppl=6.09, wps=28745, ups=0.5, wpb=57191.4, bsz=1456.2, num_updates=55200, lr=0.000269191, gnorm=0.218, clip=100, loss_scale=11, train_wall=195, wall=110416
2023-05-27 13:44:19 | INFO | train_inner | epoch 009:   1909 / 6686 loss=4.226, nll_loss=2.612, ppl=6.11, wps=28970.2, ups=0.51, wpb=57180.7, bsz=1465.1, num_updates=55300, lr=0.000268947, gnorm=0.219, clip=100, loss_scale=8, train_wall=194, wall=110613
2023-05-27 13:47:37 | INFO | train_inner | epoch 009:   2009 / 6686 loss=4.219, nll_loss=2.604, ppl=6.08, wps=28952, ups=0.51, wpb=57174.5, bsz=1473.4, num_updates=55400, lr=0.000268705, gnorm=0.225, clip=100, loss_scale=8, train_wall=194, wall=110811
2023-05-27 13:50:55 | INFO | train_inner | epoch 009:   2109 / 6686 loss=4.21, nll_loss=2.593, ppl=6.04, wps=28946.6, ups=0.5, wpb=57360.9, bsz=1503.5, num_updates=55500, lr=0.000268462, gnorm=0.213, clip=100, loss_scale=8, train_wall=194, wall=111009
2023-05-27 13:54:13 | INFO | train_inner | epoch 009:   2209 / 6686 loss=4.225, nll_loss=2.611, ppl=6.11, wps=28959, ups=0.51, wpb=57231, bsz=1462.6, num_updates=55600, lr=0.000268221, gnorm=0.221, clip=100, loss_scale=8, train_wall=194, wall=111206
2023-05-27 13:57:30 | INFO | train_inner | epoch 009:   2309 / 6686 loss=4.228, nll_loss=2.614, ppl=6.12, wps=28985.6, ups=0.51, wpb=57233.6, bsz=1457.3, num_updates=55700, lr=0.00026798, gnorm=0.208, clip=100, loss_scale=10, train_wall=194, wall=111404
2023-05-27 13:57:46 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 14:00:51 | INFO | train_inner | epoch 009:   2410 / 6686 loss=4.22, nll_loss=2.605, ppl=6.08, wps=28500, ups=0.5, wpb=57124.7, bsz=1467.2, num_updates=55800, lr=0.00026774, gnorm=0.215, clip=100, loss_scale=9, train_wall=197, wall=111604
2023-05-27 14:04:08 | INFO | train_inner | epoch 009:   2510 / 6686 loss=4.222, nll_loss=2.607, ppl=6.09, wps=28872.3, ups=0.51, wpb=57122.5, bsz=1480.3, num_updates=55900, lr=0.0002675, gnorm=0.215, clip=100, loss_scale=8, train_wall=194, wall=111802
2023-05-27 14:07:27 | INFO | train_inner | epoch 009:   2610 / 6686 loss=4.208, nll_loss=2.591, ppl=6.03, wps=28932.1, ups=0.5, wpb=57353.9, bsz=1524.6, num_updates=56000, lr=0.000267261, gnorm=0.224, clip=100, loss_scale=8, train_wall=194, wall=112000
2023-05-27 14:10:45 | INFO | train_inner | epoch 009:   2710 / 6686 loss=4.224, nll_loss=2.61, ppl=6.11, wps=28871.3, ups=0.5, wpb=57287.1, bsz=1472.1, num_updates=56100, lr=0.000267023, gnorm=0.22, clip=100, loss_scale=8, train_wall=195, wall=112199
2023-05-27 14:11:25 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2023-05-27 14:14:04 | INFO | train_inner | epoch 009:   2811 / 6686 loss=4.222, nll_loss=2.608, ppl=6.1, wps=28706.3, ups=0.5, wpb=57186.8, bsz=1491.9, num_updates=56200, lr=0.000266785, gnorm=0.216, clip=100, loss_scale=5, train_wall=195, wall=112398
2023-05-27 14:17:22 | INFO | train_inner | epoch 009:   2911 / 6686 loss=4.224, nll_loss=2.61, ppl=6.1, wps=28866.2, ups=0.51, wpb=57129.7, bsz=1471.7, num_updates=56300, lr=0.000266548, gnorm=0.216, clip=100, loss_scale=4, train_wall=194, wall=112596
2023-05-27 14:20:40 | INFO | train_inner | epoch 009:   3011 / 6686 loss=4.215, nll_loss=2.6, ppl=6.06, wps=29009.3, ups=0.51, wpb=57351.8, bsz=1488.7, num_updates=56400, lr=0.000266312, gnorm=0.216, clip=100, loss_scale=4, train_wall=194, wall=112794
2023-05-27 14:23:57 | INFO | train_inner | epoch 009:   3111 / 6686 loss=4.22, nll_loss=2.605, ppl=6.09, wps=28954.6, ups=0.51, wpb=57072.8, bsz=1475.6, num_updates=56500, lr=0.000266076, gnorm=0.224, clip=100, loss_scale=4, train_wall=193, wall=112991
2023-05-27 14:27:15 | INFO | train_inner | epoch 009:   3211 / 6686 loss=4.222, nll_loss=2.607, ppl=6.09, wps=28809, ups=0.51, wpb=57047.3, bsz=1510.2, num_updates=56600, lr=0.000265841, gnorm=0.221, clip=100, loss_scale=4, train_wall=194, wall=113189
2023-05-27 14:30:32 | INFO | train_inner | epoch 009:   3311 / 6686 loss=4.227, nll_loss=2.613, ppl=6.12, wps=29030, ups=0.51, wpb=57256.9, bsz=1452.8, num_updates=56700, lr=0.000265606, gnorm=0.223, clip=100, loss_scale=7, train_wall=194, wall=113386
2023-05-27 14:33:50 | INFO | train_inner | epoch 009:   3411 / 6686 loss=4.218, nll_loss=2.603, ppl=6.07, wps=28966.9, ups=0.51, wpb=57204.1, bsz=1474.2, num_updates=56800, lr=0.000265372, gnorm=0.212, clip=100, loss_scale=8, train_wall=194, wall=113584
2023-05-27 14:37:07 | INFO | train_inner | epoch 009:   3511 / 6686 loss=4.217, nll_loss=2.602, ppl=6.07, wps=28997.7, ups=0.51, wpb=57274.2, bsz=1472.4, num_updates=56900, lr=0.000265139, gnorm=0.224, clip=100, loss_scale=8, train_wall=194, wall=113781
2023-05-27 14:40:25 | INFO | train_inner | epoch 009:   3611 / 6686 loss=4.219, nll_loss=2.604, ppl=6.08, wps=28953.4, ups=0.51, wpb=57312.7, bsz=1468.6, num_updates=57000, lr=0.000264906, gnorm=0.215, clip=100, loss_scale=8, train_wall=194, wall=113979
2023-05-27 14:43:43 | INFO | train_inner | epoch 009:   3711 / 6686 loss=4.217, nll_loss=2.602, ppl=6.07, wps=28891.9, ups=0.5, wpb=57284, bsz=1473.1, num_updates=57100, lr=0.000264674, gnorm=0.207, clip=100, loss_scale=8, train_wall=195, wall=114177
2023-05-27 14:45:12 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 14:47:03 | INFO | train_inner | epoch 009:   3812 / 6686 loss=4.224, nll_loss=2.61, ppl=6.1, wps=28734.7, ups=0.5, wpb=57331.9, bsz=1486, num_updates=57200, lr=0.000264443, gnorm=0.224, clip=100, loss_scale=8, train_wall=196, wall=114377
2023-05-27 14:50:20 | INFO | train_inner | epoch 009:   3912 / 6686 loss=4.229, nll_loss=2.615, ppl=6.13, wps=28959.1, ups=0.51, wpb=56977, bsz=1465.6, num_updates=57300, lr=0.000264212, gnorm=0.215, clip=100, loss_scale=8, train_wall=193, wall=114574
2023-05-27 14:53:37 | INFO | train_inner | epoch 009:   4012 / 6686 loss=4.206, nll_loss=2.59, ppl=6.02, wps=28947.5, ups=0.51, wpb=57165.4, bsz=1472.4, num_updates=57400, lr=0.000263982, gnorm=0.224, clip=100, loss_scale=8, train_wall=194, wall=114771
2023-05-27 14:56:56 | INFO | train_inner | epoch 009:   4112 / 6686 loss=4.219, nll_loss=2.604, ppl=6.08, wps=28870.9, ups=0.5, wpb=57259.8, bsz=1500, num_updates=57500, lr=0.000263752, gnorm=0.217, clip=100, loss_scale=8, train_wall=194, wall=114969
2023-05-27 15:00:13 | INFO | train_inner | epoch 009:   4212 / 6686 loss=4.215, nll_loss=2.6, ppl=6.06, wps=28949.9, ups=0.51, wpb=57123.6, bsz=1466.6, num_updates=57600, lr=0.000263523, gnorm=0.219, clip=100, loss_scale=8, train_wall=194, wall=115167
2023-05-27 15:02:35 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 15:03:32 | INFO | train_inner | epoch 009:   4313 / 6686 loss=4.213, nll_loss=2.598, ppl=6.05, wps=28672.3, ups=0.5, wpb=57221.1, bsz=1502.4, num_updates=57700, lr=0.000263295, gnorm=0.22, clip=100, loss_scale=9, train_wall=196, wall=115366
2023-05-27 15:06:50 | INFO | train_inner | epoch 009:   4413 / 6686 loss=4.232, nll_loss=2.619, ppl=6.14, wps=28939.8, ups=0.51, wpb=57134.9, bsz=1468.2, num_updates=57800, lr=0.000263067, gnorm=0.225, clip=100, loss_scale=8, train_wall=194, wall=115564
2023-05-27 15:10:08 | INFO | train_inner | epoch 009:   4513 / 6686 loss=4.212, nll_loss=2.597, ppl=6.05, wps=28890.3, ups=0.5, wpb=57231.7, bsz=1486.8, num_updates=57900, lr=0.00026284, gnorm=0.217, clip=100, loss_scale=8, train_wall=194, wall=115762
2023-05-27 15:13:26 | INFO | train_inner | epoch 009:   4613 / 6686 loss=4.229, nll_loss=2.616, ppl=6.13, wps=28974.7, ups=0.51, wpb=57248.8, bsz=1478.4, num_updates=58000, lr=0.000262613, gnorm=0.211, clip=100, loss_scale=8, train_wall=194, wall=115959
2023-05-27 15:16:43 | INFO | train_inner | epoch 009:   4713 / 6686 loss=4.215, nll_loss=2.6, ppl=6.06, wps=28854.8, ups=0.51, wpb=57085.9, bsz=1479.1, num_updates=58100, lr=0.000262387, gnorm=0.216, clip=100, loss_scale=8, train_wall=194, wall=116157
2023-05-27 15:20:02 | INFO | train_inner | epoch 009:   4813 / 6686 loss=4.213, nll_loss=2.598, ppl=6.05, wps=28877.2, ups=0.5, wpb=57290.5, bsz=1507.2, num_updates=58200, lr=0.000262161, gnorm=0.217, clip=100, loss_scale=9, train_wall=195, wall=116356
2023-05-27 15:20:18 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 15:23:21 | INFO | train_inner | epoch 009:   4914 / 6686 loss=4.221, nll_loss=2.606, ppl=6.09, wps=28578.4, ups=0.5, wpb=57055.6, bsz=1464.2, num_updates=58300, lr=0.000261936, gnorm=0.216, clip=100, loss_scale=9, train_wall=196, wall=116555
2023-05-27 15:26:39 | INFO | train_inner | epoch 009:   5014 / 6686 loss=4.223, nll_loss=2.609, ppl=6.1, wps=29008.6, ups=0.51, wpb=57369.2, bsz=1489.1, num_updates=58400, lr=0.000261712, gnorm=0.22, clip=100, loss_scale=8, train_wall=194, wall=116753
2023-05-27 15:29:57 | INFO | train_inner | epoch 009:   5114 / 6686 loss=4.215, nll_loss=2.6, ppl=6.06, wps=28911, ups=0.51, wpb=57136.4, bsz=1481.2, num_updates=58500, lr=0.000261488, gnorm=0.228, clip=100, loss_scale=8, train_wall=194, wall=116951
2023-05-27 15:33:14 | INFO | train_inner | epoch 009:   5214 / 6686 loss=4.21, nll_loss=2.594, ppl=6.04, wps=28944.6, ups=0.51, wpb=57202, bsz=1484, num_updates=58600, lr=0.000261265, gnorm=0.22, clip=100, loss_scale=8, train_wall=194, wall=117148
2023-05-27 15:36:31 | INFO | train_inner | epoch 009:   5314 / 6686 loss=4.22, nll_loss=2.606, ppl=6.09, wps=29014.7, ups=0.51, wpb=57145.4, bsz=1480.2, num_updates=58700, lr=0.000261042, gnorm=0.224, clip=100, loss_scale=8, train_wall=193, wall=117345
2023-05-27 15:37:16 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 15:39:50 | INFO | train_inner | epoch 009:   5415 / 6686 loss=4.218, nll_loss=2.603, ppl=6.08, wps=28686.6, ups=0.5, wpb=56982.5, bsz=1463.8, num_updates=58800, lr=0.00026082, gnorm=0.216, clip=100, loss_scale=8, train_wall=195, wall=117544
2023-05-27 15:43:08 | INFO | train_inner | epoch 009:   5515 / 6686 loss=4.217, nll_loss=2.602, ppl=6.07, wps=28985.5, ups=0.51, wpb=57218.9, bsz=1466.2, num_updates=58900, lr=0.000260599, gnorm=0.208, clip=100, loss_scale=8, train_wall=194, wall=117741
2023-05-27 15:46:25 | INFO | train_inner | epoch 009:   5615 / 6686 loss=4.213, nll_loss=2.598, ppl=6.05, wps=29008.1, ups=0.51, wpb=57202.1, bsz=1495.2, num_updates=59000, lr=0.000260378, gnorm=0.223, clip=100, loss_scale=8, train_wall=193, wall=117939
2023-05-27 15:49:42 | INFO | train_inner | epoch 009:   5715 / 6686 loss=4.222, nll_loss=2.608, ppl=6.1, wps=28982.7, ups=0.51, wpb=57220.7, bsz=1471, num_updates=59100, lr=0.000260157, gnorm=0.221, clip=100, loss_scale=8, train_wall=194, wall=118136
2023-05-27 15:53:00 | INFO | train_inner | epoch 009:   5815 / 6686 loss=4.23, nll_loss=2.617, ppl=6.13, wps=28936.1, ups=0.51, wpb=57130.2, bsz=1469.8, num_updates=59200, lr=0.000259938, gnorm=0.222, clip=100, loss_scale=8, train_wall=194, wall=118333
2023-05-27 15:54:09 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 15:56:19 | INFO | train_inner | epoch 009:   5916 / 6686 loss=4.215, nll_loss=2.6, ppl=6.06, wps=28805.6, ups=0.5, wpb=57539.3, bsz=1486.4, num_updates=59300, lr=0.000259718, gnorm=0.219, clip=100, loss_scale=8, train_wall=196, wall=118533
2023-05-27 15:59:37 | INFO | train_inner | epoch 009:   6016 / 6686 loss=4.222, nll_loss=2.608, ppl=6.1, wps=28873.3, ups=0.51, wpb=57037, bsz=1467.3, num_updates=59400, lr=0.0002595, gnorm=0.22, clip=100, loss_scale=8, train_wall=194, wall=118731
2023-05-27 16:02:54 | INFO | train_inner | epoch 009:   6116 / 6686 loss=4.226, nll_loss=2.612, ppl=6.11, wps=29027.8, ups=0.51, wpb=57173.8, bsz=1461.8, num_updates=59500, lr=0.000259281, gnorm=0.227, clip=100, loss_scale=8, train_wall=193, wall=118928
2023-05-27 16:06:11 | INFO | train_inner | epoch 009:   6216 / 6686 loss=4.234, nll_loss=2.621, ppl=6.15, wps=28920.5, ups=0.51, wpb=57089.7, bsz=1459.3, num_updates=59600, lr=0.000259064, gnorm=0.214, clip=100, loss_scale=8, train_wall=194, wall=119125
2023-05-27 16:09:29 | INFO | train_inner | epoch 009:   6316 / 6686 loss=4.205, nll_loss=2.589, ppl=6.02, wps=28919.3, ups=0.5, wpb=57284, bsz=1503.8, num_updates=59700, lr=0.000258847, gnorm=0.219, clip=100, loss_scale=8, train_wall=194, wall=119323
2023-05-27 16:11:38 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 16:12:49 | INFO | train_inner | epoch 009:   6417 / 6686 loss=4.223, nll_loss=2.609, ppl=6.1, wps=28656.7, ups=0.5, wpb=57295.2, bsz=1479, num_updates=59800, lr=0.00025863, gnorm=0.225, clip=100, loss_scale=10, train_wall=196, wall=119523
2023-05-27 16:16:06 | INFO | train_inner | epoch 009:   6517 / 6686 loss=4.231, nll_loss=2.618, ppl=6.14, wps=28901.1, ups=0.51, wpb=56957.3, bsz=1468.3, num_updates=59900, lr=0.000258414, gnorm=0.213, clip=100, loss_scale=8, train_wall=193, wall=119720
2023-05-27 16:19:24 | INFO | train_inner | epoch 009:   6617 / 6686 loss=4.225, nll_loss=2.612, ppl=6.11, wps=29061.1, ups=0.51, wpb=57363.2, bsz=1475.9, num_updates=60000, lr=0.000258199, gnorm=0.23, clip=100, loss_scale=8, train_wall=194, wall=119918
2023-05-27 16:21:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-27 16:21:46 | INFO | fairseq.tasks.translation | example hypothesis: Why? Why?
2023-05-27 16:21:46 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-27 16:21:48 | INFO | fairseq.tasks.translation | example hypothesis: In a moment, I’ll make you lose to the point where you don’t even have your pants left behind!
2023-05-27 16:21:48 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-27 16:21:49 | INFO | fairseq.tasks.translation | example hypothesis: Shen Liangchuan had just let out a sigh of relief when he heard her say, “I’ll call you in the same room as you!”
2023-05-27 16:21:49 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-27 16:21:51 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved and entered the elevator.
2023-05-27 16:21:51 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-27 16:21:54 | INFO | fairseq.tasks.translation | example hypothesis: As soon as she raised her head, she saw Song Cheng standing in the distance! He was Song Cheng!
2023-05-27 16:21:54 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-27 16:21:55 | INFO | fairseq.tasks.translation | example hypothesis: Only then did Song Cheng pat his chest. “I’m scared to death! Where’s Wang Chuan?”
2023-05-27 16:21:55 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-27 16:21:57 | INFO | fairseq.tasks.translation | example hypothesis: I said, “I won’t go, I won’t be able to eat it,” I said with a smile.
2023-05-27 16:21:57 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-27 16:21:58 | INFO | fairseq.tasks.translation | example hypothesis: Everyone believed it at first, but Wang Wenhao was adamant that the public would lean towards Wang Wen Hao.
2023-05-27 16:21:58 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-27 16:22:01 | INFO | fairseq.tasks.translation | example hypothesis: With his status, even if Baili Hongzhuang did not want to treat him, he had to do so!
2023-05-27 16:22:01 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-27 16:22:03 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian said, “Mr. Shen, I, I have left too much blood. My brain is short of oxygen. I can’t think of anything else. Why don’t you give me a hint?”
2023-05-27 16:22:03 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-27 16:22:06 | INFO | fairseq.tasks.translation | example hypothesis: He didn't know why so many people had heard about this matter. Since he couldn't hide it anymore, he might as well say it out loud. However, he didn't know why Li Yuyue's injury
2023-05-27 16:22:06 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-27 16:22:08 | INFO | fairseq.tasks.translation | example hypothesis: She deliberately lowered her voice, but she was unable to conceal the evilness and ruthlessness in her voice. “I’ll destroy you!”
2023-05-27 16:22:08 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-27 16:22:10 | INFO | fairseq.tasks.translation | example hypothesis: The strength of a beast pet of different levels was different, but a beast pet was precious and hard to come by. It was impossible for ordinary people to possess one, and even officials and children could not possess one. However, the
2023-05-27 16:22:10 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-27 16:22:12 | INFO | fairseq.tasks.translation | example hypothesis: "What are you doing?" Fang Chixia cursed in a low voice while gritting her teeth.
2023-05-27 16:22:12 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-27 16:22:14 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang had concealed it very well, Di Beichen could still see the ripple in her eyes that flashed past her eyes. His eyes were filled with a little warmth.
2023-05-27 16:22:14 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-27 16:22:16 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia entered the hotel, not to mention the guests, she didn’t even see a few waiters. She didn’t even have the chance to see a few of the guests.
2023-05-27 16:22:16 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-27 16:22:20 | INFO | fairseq.tasks.translation | example hypothesis: This person was none other than the Ye Family's fourth young miss – Ye Qing Ling.
2023-05-27 16:22:20 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-27 16:22:23 | INFO | fairseq.tasks.translation | example hypothesis: Because at this moment, she felt that her chin was about to shatter.
2023-05-27 16:22:23 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-27 16:22:26 | INFO | fairseq.tasks.translation | example hypothesis: “Okay, Mu Zi, help me. If it wasn't for you, that old man wouldn't have set his eyes on me either,” I said.
2023-05-27 16:22:26 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-27 16:22:28 | INFO | fairseq.tasks.translation | example hypothesis: Baili Yu Yan was even more excited. This matter was completely directed by her. Previously, Baili Hong Zhuang had treated her like that. This time, she would definitely make Baili Hong Zhuang suffer as well.
2023-05-27 16:22:28 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-27 16:22:30 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How could that be? They’re also four grand mages, of course they won’t surrender so easily. After arguing for a long time, they decided to use the competition to obtain control of the kingdom in the future.”
2023-05-27 16:22:30 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-27 16:22:33 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a little. Originally, he had been looking for a reason for Li Yuyue to not be able to participate in the Imperial Family Hunting Competition.
2023-05-27 16:22:33 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-27 16:22:36 | INFO | fairseq.tasks.translation | example hypothesis: “Ms. Xiu, is my level good enough? They’re all the best talents in the country, and my magic is so weak?” asked Link.
2023-05-27 16:22:36 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-27 16:22:41 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yi Bei’s words meant that if Fang Chi Xia didn’t want to go, then he didn’t have to go. If Fang Chi Xia didn’t want to go, then he wouldn’t have to go. If Fang Chi Xia didn’t want to go, then he wouldn’t go.
2023-05-27 16:22:41 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-27 16:22:45 | INFO | fairseq.tasks.translation | example hypothesis: She tilted her head to the side and saw that the five palm prints on her cheeks were very eye-catching. They were swollen at a speed visible to the naked eye. She reached out her hand to touch them and couldn’t help but let out a hissing sound. It was really painful.
2023-05-27 16:22:45 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-27 16:22:48 | INFO | fairseq.tasks.translation | example hypothesis: This... How could it be possible for that piece of trash to give off such a charm? How could this be possible?
2023-05-27 16:22:48 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-27 16:22:50 | INFO | fairseq.tasks.translation | example hypothesis: How did Wang Wenhao find the news agency? The chief editor should have called her to inform her not to come to the news agency, which was the best choice. However, these three people... had plotted against her!
2023-05-27 16:22:50 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-27 16:22:55 | INFO | fairseq.tasks.translation | example hypothesis: I was delighted to hear Teacher Di’s praise. I retracted my energy ball with my left hand and shot a light sword towards Teacher Zhen with my right. The light sword actually managed to hit Teacher Zhen without a hitch. I was shocked, and upon closer inspection, I realized that it was just an afterimage. Teacher Zhen had already moved behind me, and shouted, “Berserk Space!”
2023-05-27 16:22:55 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-27 16:23:01 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Originally, we proposed a competition of two wins in three games, but they said it wasn’t fair, because we have Teacher Di and Teacher Zhen, whose ranking was higher than theirs, and they proposed five games and three wins. Since we were the ones who proposed the competition, we could only listen to them in the end. Three days later, we will have a secret competition in the Royal Coliseum. The competition will be held in three days, and
2023-05-27 16:23:01 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-27 16:23:04 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Di used the rank 7 light element spell, Lightning Chain Explosion. I didn’t use this spell very often, because my control over it wasn’t ideal. Teacher Di released nine lightning bolts to surround me, forming a simple formation that prevented me from escaping in a short distance. Then, the lightning bolts exploded and formed a powerful attack.
2023-05-27 16:23:04 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-27 16:23:11 | INFO | fairseq.tasks.translation | example hypothesis: As soon as Ma Ke and the two teachers arrived at the other side, Teacher Zhen launched a small Dimensional Slash at me. As expected of the number one Magician on the continent. The powerful suction force from his small Dimensional Slash was actually much stronger than my own. A small spatial crack appeared beside me, and a powerful suction force immediately swept towards me. I didn’t know who Zhang Gong and Si Di would send out in the fifth match, but I didn’t know who they’d send out for the fifth match, so I didn’t know who they’d send out for the fifth match, so both of you have to strive for a breakthrough in these two days.
2023-05-27 16:23:11 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-27 16:23:11 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 4.463 | nll_loss 2.862 | ppl 7.27 | bleu 17.33 | wps 865 | wpb 2420.8 | bsz 84.5 | num_updates 60069 | best_bleu 17.84
2023-05-27 16:23:11 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-27 16:23:12 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/mega-1-1-0.2-sf[zh-en]/checkpoint_last.pt (epoch 9 @ 60069 updates, score 17.33) (writing took 1.248272011987865 seconds)
2023-05-27 16:23:12 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-05-27 16:23:12 | INFO | train | epoch 009 | loss 4.219 | nll_loss 2.604 | ppl 6.08 | wps 28641.4 | ups 0.5 | wpb 57190.6 | bsz 1477.3 | num_updates 60069 | lr 0.000258051 | gnorm 0.218 | clip 100 | loss_scale 8 | train_wall 12959 | wall 120146
2023-05-27 16:23:12 | INFO | fairseq.trainer | begin training epoch 10
2023-05-27 16:24:27 | INFO | train_inner | epoch 010:     31 / 6686 loss=4.21, nll_loss=2.594, ppl=6.04, wps=18706.1, ups=0.33, wpb=56737.1, bsz=1468.8, num_updates=60100, lr=0.000257984, gnorm=0.221, clip=100, loss_scale=8, train_wall=194, wall=120221
2023-05-27 16:27:52 | INFO | train_inner | epoch 010:    131 / 6686 loss=4.199, nll_loss=2.581, ppl=5.98, wps=27964.1, ups=0.49, wpb=57341.2, bsz=1465.6, num_updates=60200, lr=0.00025777, gnorm=0.228, clip=100, loss_scale=8, train_wall=195, wall=120426
2023-05-27 16:30:30 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 16:31:16 | INFO | train_inner | epoch 010:    232 / 6686 loss=4.185, nll_loss=2.565, ppl=5.92, wps=28083.8, ups=0.49, wpb=57159.5, bsz=1482.2, num_updates=60300, lr=0.000257556, gnorm=0.215, clip=100, loss_scale=8, train_wall=196, wall=120630
2023-05-27 16:34:35 | INFO | train_inner | epoch 010:    332 / 6686 loss=4.191, nll_loss=2.573, ppl=5.95, wps=28680.2, ups=0.5, wpb=57133.4, bsz=1504.8, num_updates=60400, lr=0.000257343, gnorm=0.212, clip=100, loss_scale=8, train_wall=195, wall=120829
2023-05-27 16:37:53 | INFO | train_inner | epoch 010:    432 / 6686 loss=4.193, nll_loss=2.575, ppl=5.96, wps=28851.5, ups=0.5, wpb=57170.7, bsz=1490.2, num_updates=60500, lr=0.00025713, gnorm=0.216, clip=100, loss_scale=8, train_wall=194, wall=121027
2023-05-27 16:41:11 | INFO | train_inner | epoch 010:    532 / 6686 loss=4.201, nll_loss=2.583, ppl=5.99, wps=28913, ups=0.51, wpb=57176.8, bsz=1476.3, num_updates=60600, lr=0.000256917, gnorm=0.217, clip=100, loss_scale=8, train_wall=194, wall=121225
2023-05-27 16:44:29 | INFO | train_inner | epoch 010:    632 / 6686 loss=4.198, nll_loss=2.58, ppl=5.98, wps=28830.7, ups=0.5, wpb=57153.2, bsz=1457.5, num_updates=60700, lr=0.000256706, gnorm=0.223, clip=100, loss_scale=8, train_wall=194, wall=121423
2023-05-27 16:46:03 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2023-05-27 16:47:49 | INFO | train_inner | epoch 010:    733 / 6686 loss=4.205, nll_loss=2.589, ppl=6.02, wps=28532.6, ups=0.5, wpb=57039.7, bsz=1483.5, num_updates=60800, lr=0.000256495, gnorm=0.224, clip=100, loss_scale=6, train_wall=196, wall=121623
2023-05-27 16:51:07 | INFO | train_inner | epoch 010:    833 / 6686 loss=4.205, nll_loss=2.589, ppl=6.02, wps=28924.1, ups=0.5, wpb=57296, bsz=1471.4, num_updates=60900, lr=0.000256284, gnorm=0.216, clip=100, loss_scale=4, train_wall=194, wall=121821
2023-05-27 16:54:24 | INFO | train_inner | epoch 010:    933 / 6686 loss=4.202, nll_loss=2.585, ppl=6, wps=29007.9, ups=0.51, wpb=57185.2, bsz=1503.5, num_updates=61000, lr=0.000256074, gnorm=0.216, clip=100, loss_scale=4, train_wall=193, wall=122018
2023-05-27 16:57:42 | INFO | train_inner | epoch 010:   1033 / 6686 loss=4.204, nll_loss=2.587, ppl=6.01, wps=28917, ups=0.51, wpb=57219.6, bsz=1469, num_updates=61100, lr=0.000255864, gnorm=0.217, clip=100, loss_scale=4, train_wall=194, wall=122216
2023-05-27 17:01:01 | INFO | train_inner | epoch 010:   1133 / 6686 loss=4.198, nll_loss=2.58, ppl=5.98, wps=28774, ups=0.5, wpb=57120.7, bsz=1480.7, num_updates=61200, lr=0.000255655, gnorm=0.228, clip=100, loss_scale=4, train_wall=195, wall=122414
2023-05-27 17:04:18 | INFO | train_inner | epoch 010:   1233 / 6686 loss=4.206, nll_loss=2.589, ppl=6.02, wps=28961.3, ups=0.51, wpb=57231.3, bsz=1472, num_updates=61300, lr=0.000255446, gnorm=0.226, clip=100, loss_scale=6, train_wall=194, wall=122612
2023-05-27 17:07:35 | INFO | train_inner | epoch 010:   1333 / 6686 loss=4.207, nll_loss=2.591, ppl=6.03, wps=28958.6, ups=0.51, wpb=57136.2, bsz=1467.8, num_updates=61400, lr=0.000255238, gnorm=0.23, clip=100, loss_scale=8, train_wall=193, wall=122809
2023-05-27 17:10:54 | INFO | train_inner | epoch 010:   1433 / 6686 loss=4.21, nll_loss=2.594, ppl=6.04, wps=28790, ups=0.5, wpb=57198.7, bsz=1467.8, num_updates=61500, lr=0.000255031, gnorm=0.222, clip=100, loss_scale=8, train_wall=195, wall=123008
2023-05-27 17:14:11 | INFO | train_inner | epoch 010:   1533 / 6686 loss=4.211, nll_loss=2.595, ppl=6.04, wps=28947.2, ups=0.51, wpb=57038.5, bsz=1464.5, num_updates=61600, lr=0.000254824, gnorm=0.215, clip=100, loss_scale=8, train_wall=193, wall=123205
2023-05-27 17:17:29 | INFO | train_inner | epoch 010:   1633 / 6686 loss=4.204, nll_loss=2.588, ppl=6.01, wps=29032.1, ups=0.51, wpb=57472.4, bsz=1496.6, num_updates=61700, lr=0.000254617, gnorm=0.215, clip=100, loss_scale=8, train_wall=194, wall=123403
2023-05-27 17:19:59 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 17:20:49 | INFO | train_inner | epoch 010:   1734 / 6686 loss=4.203, nll_loss=2.586, ppl=6.01, wps=28698.2, ups=0.5, wpb=57228.7, bsz=1487.2, num_updates=61800, lr=0.000254411, gnorm=0.217, clip=100, loss_scale=8, train_wall=195, wall=123602
2023-05-27 17:24:06 | INFO | train_inner | epoch 010:   1834 / 6686 loss=4.212, nll_loss=2.596, ppl=6.05, wps=28900.4, ups=0.51, wpb=56991.6, bsz=1473, num_updates=61900, lr=0.000254205, gnorm=0.216, clip=100, loss_scale=8, train_wall=193, wall=123800
2023-05-27 17:27:23 | INFO | train_inner | epoch 010:   1934 / 6686 loss=4.206, nll_loss=2.59, ppl=6.02, wps=28982.3, ups=0.51, wpb=57161, bsz=1472.5, num_updates=62000, lr=0.000254, gnorm=0.212, clip=100, loss_scale=8, train_wall=193, wall=123997
2023-05-27 17:30:41 | INFO | train_inner | epoch 010:   2034 / 6686 loss=4.212, nll_loss=2.597, ppl=6.05, wps=28942.1, ups=0.51, wpb=57290.8, bsz=1468.7, num_updates=62100, lr=0.000253796, gnorm=0.222, clip=100, loss_scale=8, train_wall=194, wall=124195
2023-05-27 17:33:59 | INFO | train_inner | epoch 010:   2134 / 6686 loss=4.215, nll_loss=2.6, ppl=6.06, wps=28812.4, ups=0.51, wpb=56988.8, bsz=1449.2, num_updates=62200, lr=0.000253592, gnorm=0.216, clip=100, loss_scale=8, train_wall=194, wall=124393
2023-05-27 17:37:17 | INFO | train_inner | epoch 010:   2234 / 6686 loss=4.201, nll_loss=2.584, ppl=6, wps=28978, ups=0.51, wpb=57354.7, bsz=1508.2, num_updates=62300, lr=0.000253388, gnorm=0.217, clip=100, loss_scale=9, train_wall=194, wall=124591
2023-05-27 17:38:03 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 17:40:37 | INFO | train_inner | epoch 010:   2335 / 6686 loss=4.203, nll_loss=2.586, ppl=6, wps=28582.4, ups=0.5, wpb=57300.1, bsz=1491.7, num_updates=62400, lr=0.000253185, gnorm=0.216, clip=100, loss_scale=10, train_wall=196, wall=124791
2023-05-27 17:43:56 | INFO | train_inner | epoch 010:   2435 / 6686 loss=4.2, nll_loss=2.583, ppl=5.99, wps=28832.3, ups=0.5, wpb=57215.4, bsz=1484.6, num_updates=62500, lr=0.000252982, gnorm=0.227, clip=100, loss_scale=8, train_wall=195, wall=124990
2023-05-27 17:47:14 | INFO | train_inner | epoch 010:   2535 / 6686 loss=4.2, nll_loss=2.583, ppl=5.99, wps=28970.8, ups=0.5, wpb=57416.5, bsz=1498.2, num_updates=62600, lr=0.00025278, gnorm=0.211, clip=100, loss_scale=8, train_wall=194, wall=125188
2023-05-27 17:50:32 | INFO | train_inner | epoch 010:   2635 / 6686 loss=4.207, nll_loss=2.591, ppl=6.03, wps=28947.8, ups=0.51, wpb=57311.9, bsz=1483.8, num_updates=62700, lr=0.000252578, gnorm=0.233, clip=100, loss_scale=8, train_wall=194, wall=125386
2023-05-27 17:53:49 | INFO | train_inner | epoch 010:   2735 / 6686 loss=4.206, nll_loss=2.59, ppl=6.02, wps=28913.5, ups=0.51, wpb=56991.7, bsz=1474.1, num_updates=62800, lr=0.000252377, gnorm=0.219, clip=100, loss_scale=8, train_wall=193, wall=125583
2023-05-27 17:55:12 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 17:57:09 | INFO | train_inner | epoch 010:   2836 / 6686 loss=4.202, nll_loss=2.586, ppl=6, wps=28718.3, ups=0.5, wpb=57382.8, bsz=1471.1, num_updates=62900, lr=0.000252177, gnorm=0.227, clip=100, loss_scale=9, train_wall=196, wall=125783
2023-05-27 18:00:26 | INFO | train_inner | epoch 010:   2936 / 6686 loss=4.212, nll_loss=2.597, ppl=6.05, wps=28971.9, ups=0.51, wpb=57246.1, bsz=1471.6, num_updates=63000, lr=0.000251976, gnorm=0.214, clip=100, loss_scale=8, train_wall=194, wall=125980
2023-05-27 18:03:44 | INFO | train_inner | epoch 010:   3036 / 6686 loss=4.204, nll_loss=2.587, ppl=6.01, wps=28978.6, ups=0.51, wpb=57370.3, bsz=1471.3, num_updates=63100, lr=0.000251777, gnorm=0.217, clip=100, loss_scale=8, train_wall=194, wall=126178
2023-05-27 18:07:03 | INFO | train_inner | epoch 010:   3136 / 6686 loss=4.202, nll_loss=2.585, ppl=6, wps=28834.3, ups=0.5, wpb=57254.8, bsz=1490.6, num_updates=63200, lr=0.000251577, gnorm=0.219, clip=100, loss_scale=8, train_wall=195, wall=126377
2023-05-27 18:10:20 | INFO | train_inner | epoch 010:   3236 / 6686 loss=4.213, nll_loss=2.598, ppl=6.05, wps=29023.6, ups=0.51, wpb=57141.5, bsz=1453.8, num_updates=63300, lr=0.000251379, gnorm=0.223, clip=100, loss_scale=8, train_wall=193, wall=126574
2023-05-27 18:12:21 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 18:13:40 | INFO | train_inner | epoch 010:   3337 / 6686 loss=4.204, nll_loss=2.588, ppl=6.01, wps=28592.3, ups=0.5, wpb=57249.3, bsz=1465.4, num_updates=63400, lr=0.00025118, gnorm=0.222, clip=100, loss_scale=9, train_wall=196, wall=126774
2023-05-27 18:16:58 | INFO | train_inner | epoch 010:   3437 / 6686 loss=4.214, nll_loss=2.599, ppl=6.06, wps=28854.2, ups=0.5, wpb=57150.1, bsz=1473.4, num_updates=63500, lr=0.000250982, gnorm=0.216, clip=100, loss_scale=8, train_wall=194, wall=126972
2023-05-27 18:20:16 | INFO | train_inner | epoch 010:   3537 / 6686 loss=4.202, nll_loss=2.586, ppl=6, wps=29007.5, ups=0.51, wpb=57277.3, bsz=1474.3, num_updates=63600, lr=0.000250785, gnorm=0.217, clip=100, loss_scale=8, train_wall=194, wall=127169
2023-05-27 18:23:33 | INFO | train_inner | epoch 010:   3637 / 6686 loss=4.212, nll_loss=2.596, ppl=6.05, wps=28941.9, ups=0.51, wpb=57278.8, bsz=1489.8, num_updates=63700, lr=0.000250588, gnorm=0.216, clip=100, loss_scale=8, train_wall=194, wall=127367
2023-05-27 18:26:51 | INFO | train_inner | epoch 010:   3737 / 6686 loss=4.201, nll_loss=2.584, ppl=6, wps=28875.2, ups=0.5, wpb=57180.2, bsz=1475.9, num_updates=63800, lr=0.000250392, gnorm=0.222, clip=100, loss_scale=8, train_wall=194, wall=127565
2023-05-27 18:29:34 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 18:30:12 | INFO | train_inner | epoch 010:   3838 / 6686 loss=4.201, nll_loss=2.584, ppl=6, wps=28570.7, ups=0.5, wpb=57319.9, bsz=1477.1, num_updates=63900, lr=0.000250196, gnorm=0.225, clip=100, loss_scale=9, train_wall=197, wall=127766
2023-05-27 18:33:31 | INFO | train_inner | epoch 010:   3938 / 6686 loss=4.203, nll_loss=2.587, ppl=6.01, wps=28850.2, ups=0.5, wpb=57330.4, bsz=1481.6, num_updates=64000, lr=0.00025, gnorm=0.23, clip=100, loss_scale=8, train_wall=195, wall=127965
2023-05-27 18:36:48 | INFO | train_inner | epoch 010:   4038 / 6686 loss=4.212, nll_loss=2.597, ppl=6.05, wps=28978, ups=0.51, wpb=57092.4, bsz=1453.9, num_updates=64100, lr=0.000249805, gnorm=0.213, clip=100, loss_scale=8, train_wall=193, wall=128162
2023-05-27 18:40:06 | INFO | train_inner | epoch 010:   4138 / 6686 loss=4.212, nll_loss=2.597, ppl=6.05, wps=28885.3, ups=0.51, wpb=57154.8, bsz=1493.4, num_updates=64200, lr=0.00024961, gnorm=0.217, clip=100, loss_scale=8, train_wall=194, wall=128360
2023-05-27 18:43:23 | INFO | train_inner | epoch 010:   4238 / 6686 loss=4.206, nll_loss=2.59, ppl=6.02, wps=28949, ups=0.51, wpb=57123, bsz=1491.2, num_updates=64300, lr=0.000249416, gnorm=0.223, clip=100, loss_scale=8, train_wall=193, wall=128557
2023-05-27 18:46:41 | INFO | train_inner | epoch 010:   4338 / 6686 loss=4.207, nll_loss=2.592, ppl=6.03, wps=28877.8, ups=0.5, wpb=57223.3, bsz=1484.2, num_updates=64400, lr=0.000249222, gnorm=0.225, clip=100, loss_scale=9, train_wall=194, wall=128755
2023-05-27 18:46:51 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 18:50:02 | INFO | train_inner | epoch 010:   4439 / 6686 loss=4.196, nll_loss=2.579, ppl=5.97, wps=28560.4, ups=0.5, wpb=57276.3, bsz=1519, num_updates=64500, lr=0.000249029, gnorm=0.228, clip=100, loss_scale=8, train_wall=197, wall=128956
2023-05-27 18:53:20 | INFO | train_inner | epoch 010:   4539 / 6686 loss=4.202, nll_loss=2.586, ppl=6, wps=28871.4, ups=0.5, wpb=57185.4, bsz=1496.8, num_updates=64600, lr=0.000248836, gnorm=0.216, clip=100, loss_scale=8, train_wall=194, wall=129154
2023-05-27 18:56:37 | INFO | train_inner | epoch 010:   4639 / 6686 loss=4.217, nll_loss=2.603, ppl=6.08, wps=28895.8, ups=0.51, wpb=57029.8, bsz=1468.6, num_updates=64700, lr=0.000248644, gnorm=0.221, clip=100, loss_scale=8, train_wall=194, wall=129351
2023-05-27 18:59:54 | INFO | train_inner | epoch 010:   4739 / 6686 loss=4.214, nll_loss=2.599, ppl=6.06, wps=28981, ups=0.51, wpb=57121.8, bsz=1447.4, num_updates=64800, lr=0.000248452, gnorm=0.23, clip=100, loss_scale=8, train_wall=193, wall=129548
2023-05-27 19:03:12 | INFO | train_inner | epoch 010:   4839 / 6686 loss=4.2, nll_loss=2.583, ppl=5.99, wps=28893.1, ups=0.51, wpb=57031.2, bsz=1498.1, num_updates=64900, lr=0.000248261, gnorm=0.217, clip=100, loss_scale=8, train_wall=193, wall=129746
2023-05-27 19:04:29 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 19:06:32 | INFO | train_inner | epoch 010:   4940 / 6686 loss=4.197, nll_loss=2.579, ppl=5.98, wps=28580.1, ups=0.5, wpb=57250.7, bsz=1481.5, num_updates=65000, lr=0.000248069, gnorm=0.223, clip=100, loss_scale=10, train_wall=196, wall=129946
2023-05-27 19:09:50 | INFO | train_inner | epoch 010:   5040 / 6686 loss=4.216, nll_loss=2.602, ppl=6.07, wps=28991.7, ups=0.51, wpb=57270.6, bsz=1466.3, num_updates=65100, lr=0.000247879, gnorm=0.217, clip=100, loss_scale=8, train_wall=194, wall=130143
2023-05-27 19:13:08 | INFO | train_inner | epoch 010:   5140 / 6686 loss=4.196, nll_loss=2.579, ppl=5.98, wps=28887.9, ups=0.51, wpb=57178.8, bsz=1482.1, num_updates=65200, lr=0.000247689, gnorm=0.215, clip=100, loss_scale=8, train_wall=194, wall=130341
2023-05-27 19:16:25 | INFO | train_inner | epoch 010:   5240 / 6686 loss=4.202, nll_loss=2.586, ppl=6, wps=28871.3, ups=0.51, wpb=57013.2, bsz=1478.6, num_updates=65300, lr=0.000247499, gnorm=0.225, clip=100, loss_scale=8, train_wall=194, wall=130539
2023-05-27 19:19:43 | INFO | train_inner | epoch 010:   5340 / 6686 loss=4.209, nll_loss=2.594, ppl=6.04, wps=28820.5, ups=0.5, wpb=57191.1, bsz=1487.8, num_updates=65400, lr=0.00024731, gnorm=0.216, clip=100, loss_scale=8, train_wall=195, wall=130737
2023-05-27 19:21:56 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 19:23:03 | INFO | train_inner | epoch 010:   5441 / 6686 loss=4.211, nll_loss=2.596, ppl=6.05, wps=28537.9, ups=0.5, wpb=57082, bsz=1463, num_updates=65500, lr=0.000247121, gnorm=0.232, clip=100, loss_scale=9, train_wall=196, wall=130937
2023-05-27 19:26:21 | INFO | train_inner | epoch 010:   5541 / 6686 loss=4.206, nll_loss=2.59, ppl=6.02, wps=28927.4, ups=0.51, wpb=57204.9, bsz=1477.8, num_updates=65600, lr=0.000246932, gnorm=0.212, clip=100, loss_scale=8, train_wall=194, wall=131135
2023-05-27 19:29:40 | INFO | train_inner | epoch 010:   5641 / 6686 loss=4.204, nll_loss=2.588, ppl=6.01, wps=28800.5, ups=0.5, wpb=57149.1, bsz=1489.5, num_updates=65700, lr=0.000246744, gnorm=0.223, clip=100, loss_scale=8, train_wall=195, wall=131334
2023-05-27 19:32:57 | INFO | train_inner | epoch 010:   5741 / 6686 loss=4.204, nll_loss=2.588, ppl=6.01, wps=28975, ups=0.51, wpb=57256.4, bsz=1467.3, num_updates=65800, lr=0.000246557, gnorm=0.215, clip=100, loss_scale=8, train_wall=194, wall=131531
2023-05-27 19:36:15 | INFO | train_inner | epoch 010:   5841 / 6686 loss=4.204, nll_loss=2.589, ppl=6.01, wps=29020.9, ups=0.51, wpb=57248.5, bsz=1483.1, num_updates=65900, lr=0.00024637, gnorm=0.218, clip=100, loss_scale=8, train_wall=193, wall=131728
2023-05-27 19:38:51 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 19:39:19 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2023-05-27 19:39:37 | INFO | train_inner | epoch 010:   5943 / 6686 loss=4.197, nll_loss=2.58, ppl=5.98, wps=28273.3, ups=0.49, wpb=57239, bsz=1470.8, num_updates=66000, lr=0.000246183, gnorm=0.216, clip=100, loss_scale=8, train_wall=198, wall=131931
2023-05-27 19:42:54 | INFO | train_inner | epoch 010:   6043 / 6686 loss=4.205, nll_loss=2.589, ppl=6.02, wps=28998.4, ups=0.51, wpb=57220, bsz=1471.1, num_updates=66100, lr=0.000245997, gnorm=0.224, clip=100, loss_scale=4, train_wall=194, wall=132128
2023-05-27 19:46:12 | INFO | train_inner | epoch 010:   6143 / 6686 loss=4.208, nll_loss=2.593, ppl=6.03, wps=29063, ups=0.51, wpb=57340.9, bsz=1465.1, num_updates=66200, lr=0.000245811, gnorm=0.223, clip=100, loss_scale=4, train_wall=193, wall=132325
2023-05-27 19:49:30 | INFO | train_inner | epoch 010:   6243 / 6686 loss=4.203, nll_loss=2.587, ppl=6.01, wps=28831.9, ups=0.5, wpb=57171.9, bsz=1477.6, num_updates=66300, lr=0.000245625, gnorm=0.226, clip=100, loss_scale=4, train_wall=194, wall=132524
2023-05-27 19:52:47 | INFO | train_inner | epoch 010:   6343 / 6686 loss=4.202, nll_loss=2.586, ppl=6, wps=28918.1, ups=0.51, wpb=57110.9, bsz=1475.6, num_updates=66400, lr=0.00024544, gnorm=0.226, clip=100, loss_scale=4, train_wall=193, wall=132721
2023-05-27 19:56:06 | INFO | train_inner | epoch 010:   6443 / 6686 loss=4.2, nll_loss=2.584, ppl=6, wps=28864.3, ups=0.5, wpb=57179.5, bsz=1473.8, num_updates=66500, lr=0.000245256, gnorm=0.217, clip=100, loss_scale=4, train_wall=194, wall=132919
2023-05-27 19:59:23 | INFO | train_inner | epoch 010:   6543 / 6686 loss=4.216, nll_loss=2.602, ppl=6.07, wps=28914.7, ups=0.51, wpb=57179.2, bsz=1447.8, num_updates=66600, lr=0.000245072, gnorm=0.22, clip=100, loss_scale=8, train_wall=194, wall=133117
2023-05-27 20:01:33 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2023-05-27 20:02:42 | INFO | train_inner | epoch 010:   6644 / 6686 loss=4.207, nll_loss=2.592, ppl=6.03, wps=28697.3, ups=0.5, wpb=56994.9, bsz=1460.3, num_updates=66700, lr=0.000244888, gnorm=0.23, clip=100, loss_scale=7, train_wall=195, wall=133316
2023-05-27 20:04:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-27 20:04:09 | INFO | fairseq.tasks.translation | example hypothesis: Why? Why would he be so angry? Why would he be angry? Why would he be so angry? Why would
2023-05-27 20:04:09 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-27 20:04:10 | INFO | fairseq.tasks.translation | example hypothesis: In a moment, I’ll make you lose to the point that you don’t even have your pants left behind!
2023-05-27 20:04:10 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-27 20:04:12 | INFO | fairseq.tasks.translation | example hypothesis: Shen Liangchuan had just heaved a sigh of relief when he heard her say, “I’ll call for you to stay in the same room!”
2023-05-27 20:04:12 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-27 20:04:13 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved and entered the elevator.
2023-05-27 20:04:13 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-27 20:04:16 | INFO | fairseq.tasks.translation | example hypothesis: As soon as she raised her head, she saw Song Cheng standing in the distance! “What’s wrong?”
2023-05-27 20:04:16 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-27 20:04:17 | INFO | fairseq.tasks.translation | example hypothesis: Only then did Song Cheng pat his own chest. “That scared me to death! Where’s Wang Chuan?”
2023-05-27 20:04:17 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-27 20:04:20 | INFO | fairseq.tasks.translation | example hypothesis: I said, “I’m not going there anymore, I can’t eat it anymore.” I said with a smile.
2023-05-27 20:04:20 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-27 20:04:20 | INFO | fairseq.tasks.translation | example hypothesis: At first, everyone didn’t believe it, but Wang Wenhao insisted that he was the one who was biased towards Wang Wenhao.
2023-05-27 20:04:20 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-27 20:04:23 | INFO | fairseq.tasks.translation | example hypothesis: With his status, even if Baili Hongzhuang did not want to treat him, she had to!
2023-05-27 20:04:23 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-27 20:04:25 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian said, “Mr. Shen, I, I have left too much blood. My brain is short of oxygen, and I can’t think of anything. Why don’t you give me a hint?”
2023-05-27 20:04:25 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-27 20:04:28 | INFO | fairseq.tasks.translation | example hypothesis: He didn't know why this matter would be heard by so many people, but since he couldn't hide it anymore, he might as well say it out loud. However, he didn't know why Li Yuyue'
2023-05-27 20:04:28 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-27 20:04:30 | INFO | fairseq.tasks.translation | example hypothesis: She deliberately lowered her voice, but there was no way to hide the viciousness and ruthlessness in her voice. “I’m going to kill you!”
2023-05-27 20:04:30 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-27 20:04:32 | INFO | fairseq.tasks.translation | example hypothesis: The strength of a beast pet of different levels was different. However, a beast pet was precious and hard to come by. It was impossible for an ordinary person to possess one. Even the children of officials couldn’t possess one.
2023-05-27 20:04:32 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-27 20:04:34 | INFO | fairseq.tasks.translation | example hypothesis: "Damn it!" Fang Chixia clenched his teeth and cursed in a low voice.
2023-05-27 20:04:34 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-27 20:04:37 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang had concealed it very well, Di Beichen could still see the ripples in her eyes that flashed by in a flash. His eyes were filled with warmth.
2023-05-27 20:04:37 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-27 20:04:39 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia entered the hotel, he didn’t even see a few waiters, let alone the guests who were staying in the hotel. He didn’t even see a single waiter.
2023-05-27 20:04:39 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-27 20:04:42 | INFO | fairseq.tasks.translation | example hypothesis: This person was none other than the fourth young miss of the Ye Family, Ye Qingling.
2023-05-27 20:04:42 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-27 20:04:45 | INFO | fairseq.tasks.translation | example hypothesis: Because at this moment, she felt that her chin was about to shatter.
2023-05-27 20:04:45 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-27 20:04:48 | INFO | fairseq.tasks.translation | example hypothesis: “Okay, Mu Zi, help me. If it wasn’t for you, that old guy wouldn’t have set his eyes on me,” I said.
2023-05-27 20:04:48 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-27 20:04:50 | INFO | fairseq.tasks.translation | example hypothesis: Baili Yuyan was even more excited. This matter was completely directed by her. Previously, Baili Hongzhuang had treated her like that. This time, she would definitely make Baili Hongzhuang not have a good time.
2023-05-27 20:04:50 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-27 20:04:52 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How could that be? They’re also four grand mages, so they won’t surrender so easily. After arguing for a long time, they decided to use the competition to get control of the kingdom in the future.”
2023-05-27 20:04:52 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-27 20:04:55 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a little. Originally, he had been looking for a reason for Li Yuyue to not be able to participate in the Imperial Family Hunting Competition.
2023-05-27 20:04:55 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-27 20:04:57 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my level good enough? They’re all the best talents in the country, but my magic is so weak?” I asked.
2023-05-27 20:04:57 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-27 20:05:03 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yibei’s words meant that if Fang Chixia didn’t want to go, then he didn’t need to go. If Fang Chixia didn’t want to go, then he didn’t have to go. If Fang Chixia didn’t want to go, then he had to go.
2023-05-27 20:05:03 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-27 20:05:07 | INFO | fairseq.tasks.translation | example hypothesis: She turned her head and saw that the five palm prints on her face were very conspicuous. At a speed visible to the naked eye, they were swollen up. She reached out her hand and touched them. Immediately, she couldn’t help but let out a hissing sound. It really hurt.
2023-05-27 20:05:07 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-27 20:05:10 | INFO | fairseq.tasks.translation | example hypothesis: This... How could it be possible for that piece of trash to give off such a charm? How could it be possible?
2023-05-27 20:05:10 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-27 20:05:11 | INFO | fairseq.tasks.translation | example hypothesis: How did Wang Wenhao find the news agency? The chief editor should have called her to inform her not to come to the news agency, but the three of them... had plotted against her!
2023-05-27 20:05:11 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-27 20:05:17 | INFO | fairseq.tasks.translation | example hypothesis: I was delighted to hear Teacher Di’s praise. I put away the energy ball with my left hand and shot out a light sword towards Teacher Zhen with my right hand. The light sword actually managed to hit me smoothly. I was shocked, and upon closer inspection, I realized that it was just an afterimage. Teacher Zhen had already moved to my back and shouted, “Berserk Space!”
2023-05-27 20:05:17 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-27 20:05:23 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Originally, we proposed a three-match two-win competition, but they said it wasn’t fair because we have Teacher Di and Teacher Zhen, who ranked before them. They proposed to win three rounds in five rounds, and since we proposed the competition, we could only listen to them in the end. Three days later, there will be a secret competition in the Royal Family’s arena. The competition will be held in three days’ time, and
2023-05-27 20:05:23 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-27 20:05:25 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Di used the Level 7 Light element spell, Lightning Chain Explosion. I rarely used this spell because I didn’t have an ideal control over it. Teacher Di released nine lightning bolts and surrounded me, forming a simple formation that prevented me from escaping in a short distance. Then, the lightning bolts exploded and formed a powerful attack.
2023-05-27 20:05:25 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-27 20:05:33 | INFO | fairseq.tasks.translation | example hypothesis: As soon as Ma Ke and the two teachers reached the other side, Teacher Zhen launched a small Dimensional Slash at me. As expected of the continent’s number one Mage, the powerful suction force he released was actually much stronger than mine. A small spatial rift appeared beside me, and a powerful suction force immediately swept towards me. I didn’t know who Zhang Gong and Si Di would send out for the fifth match, but I didn’t know who they would send out for the fifth match, so Teacher Di said, “Although that’s the case, we don’t know who they’ll be sending out for the fifth match. Therefore, Chang Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong Gong
2023-05-27 20:05:33 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-27 20:05:33 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 4.46 | nll_loss 2.85 | ppl 7.21 | bleu 17.36 | wps 871.3 | wpb 2420.8 | bsz 84.5 | num_updates 66742 | best_bleu 17.84
2023-05-27 20:05:33 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-27 20:05:35 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/mega-1-1-0.2-sf[zh-en]/checkpoint_last.pt (epoch 10 @ 66742 updates, score 17.36) (writing took 1.5923684323206544 seconds)
2023-05-27 20:05:35 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-05-27 20:05:35 | INFO | train | epoch 010 | loss 4.205 | nll_loss 2.588 | ppl 6.01 | wps 28603.1 | ups 0.5 | wpb 57190.5 | bsz 1477.4 | num_updates 66742 | lr 0.000244811 | gnorm 0.22 | clip 100 | loss_scale 7 | train_wall 12972 | wall 133489
2023-05-27 20:05:35 | INFO | fairseq.trainer | begin training epoch 11
2023-05-27 20:07:44 | INFO | train_inner | epoch 011:     58 / 6686 loss=4.186, nll_loss=2.568, ppl=5.93, wps=18732.1, ups=0.33, wpb=56627.1, bsz=1473.5, num_updates=66800, lr=0.000244704, gnorm=0.221, clip=100, loss_scale=4, train_wall=194, wall=133618
2023-05-27 20:11:08 | INFO | train_inner | epoch 011:    158 / 6686 loss=4.176, nll_loss=2.556, ppl=5.88, wps=28113.1, ups=0.49, wpb=57187.3, bsz=1470.4, num_updates=66900, lr=0.000244521, gnorm=0.216, clip=100, loss_scale=4, train_wall=195, wall=133821
2023-05-27 20:14:28 | INFO | train_inner | epoch 011:    258 / 6686 loss=4.176, nll_loss=2.556, ppl=5.88, wps=28560.6, ups=0.5, wpb=57179.8, bsz=1490.9, num_updates=67000, lr=0.000244339, gnorm=0.217, clip=100, loss_scale=4, train_wall=195, wall=134022
2023-05-27 20:17:45 | INFO | train_inner | epoch 011:    358 / 6686 loss=4.194, nll_loss=2.576, ppl=5.96, wps=29047.4, ups=0.51, wpb=57203.1, bsz=1452.6, num_updates=67100, lr=0.000244157, gnorm=0.222, clip=100, loss_scale=4, train_wall=193, wall=134219
2023-05-27 20:21:02 | INFO | train_inner | epoch 011:    458 / 6686 loss=4.186, nll_loss=2.567, ppl=5.92, wps=29077.5, ups=0.51, wpb=57295.5, bsz=1477.4, num_updates=67200, lr=0.000243975, gnorm=0.218, clip=100, loss_scale=5, train_wall=193, wall=134416
2023-05-27 20:24:20 | INFO | train_inner | epoch 011:    558 / 6686 loss=4.187, nll_loss=2.568, ppl=5.93, wps=28887.5, ups=0.5, wpb=57331.4, bsz=1476.8, num_updates=67300, lr=0.000243794, gnorm=0.217, clip=100, loss_scale=8, train_wall=195, wall=134614
2023-05-27 20:27:38 | INFO | train_inner | epoch 011:    658 / 6686 loss=4.181, nll_loss=2.562, ppl=5.9, wps=28914.5, ups=0.51, wpb=57092, bsz=1459.4, num_updates=67400, lr=0.000243613, gnorm=0.226, clip=100, loss_scale=8, train_wall=194, wall=134812
2023-05-27 20:30:55 | INFO | train_inner | epoch 011:    758 / 6686 loss=4.185, nll_loss=2.566, ppl=5.92, wps=28971.5, ups=0.51, wpb=57124.1, bsz=1463.8, num_updates=67500, lr=0.000243432, gnorm=0.216, clip=100, loss_scale=8, train_wall=193, wall=135009
2023-05-27 20:34:13 | INFO | train_inner | epoch 011:    858 / 6686 loss=4.193, nll_loss=2.576, ppl=5.96, wps=28927.4, ups=0.51, wpb=57252.7, bsz=1474.2, num_updates=67600, lr=0.000243252, gnorm=0.22, clip=100, loss_scale=8, train_wall=194, wall=135207
2023-05-27 20:37:28 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 20:37:32 | INFO | train_inner | epoch 011:    959 / 6686 loss=4.18, nll_loss=2.561, ppl=5.9, wps=28715.7, ups=0.5, wpb=57093.2, bsz=1483.4, num_updates=67700, lr=0.000243072, gnorm=0.216, clip=100, loss_scale=9, train_wall=195, wall=135406
2023-05-27 20:40:50 | INFO | train_inner | epoch 011:   1059 / 6686 loss=4.187, nll_loss=2.568, ppl=5.93, wps=28871.6, ups=0.5, wpb=57305.1, bsz=1500.1, num_updates=67800, lr=0.000242893, gnorm=0.217, clip=100, loss_scale=8, train_wall=195, wall=135604
2023-05-27 20:44:08 | INFO | train_inner | epoch 011:   1159 / 6686 loss=4.18, nll_loss=2.561, ppl=5.9, wps=28949, ups=0.51, wpb=57212.7, bsz=1510.4, num_updates=67900, lr=0.000242714, gnorm=0.221, clip=100, loss_scale=8, train_wall=194, wall=135802
2023-05-27 20:47:26 | INFO | train_inner | epoch 011:   1259 / 6686 loss=4.187, nll_loss=2.568, ppl=5.93, wps=28942.1, ups=0.51, wpb=57246.4, bsz=1487, num_updates=68000, lr=0.000242536, gnorm=0.229, clip=100, loss_scale=8, train_wall=194, wall=135999
2023-05-27 20:50:44 | INFO | train_inner | epoch 011:   1359 / 6686 loss=4.18, nll_loss=2.561, ppl=5.9, wps=28839.4, ups=0.5, wpb=57292.8, bsz=1502.6, num_updates=68100, lr=0.000242357, gnorm=0.224, clip=100, loss_scale=8, train_wall=195, wall=136198
2023-05-27 20:54:02 | INFO | train_inner | epoch 011:   1459 / 6686 loss=4.196, nll_loss=2.579, ppl=5.98, wps=29006.8, ups=0.51, wpb=57219.7, bsz=1489.9, num_updates=68200, lr=0.00024218, gnorm=0.223, clip=100, loss_scale=8, train_wall=193, wall=136395
2023-05-27 20:54:51 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 20:57:20 | INFO | train_inner | epoch 011:   1560 / 6686 loss=4.203, nll_loss=2.586, ppl=6.01, wps=28792.9, ups=0.5, wpb=57110.1, bsz=1456.3, num_updates=68300, lr=0.000242002, gnorm=0.219, clip=100, loss_scale=9, train_wall=195, wall=136594
2023-05-27 21:00:39 | INFO | train_inner | epoch 011:   1660 / 6686 loss=4.186, nll_loss=2.568, ppl=5.93, wps=28869.1, ups=0.5, wpb=57357.9, bsz=1501.4, num_updates=68400, lr=0.000241825, gnorm=0.221, clip=100, loss_scale=8, train_wall=195, wall=136792
2023-05-27 21:03:56 | INFO | train_inner | epoch 011:   1760 / 6686 loss=4.192, nll_loss=2.575, ppl=5.96, wps=28960.2, ups=0.51, wpb=57206.8, bsz=1466.7, num_updates=68500, lr=0.000241649, gnorm=0.212, clip=100, loss_scale=8, train_wall=194, wall=136990
2023-05-27 21:06:54 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2023-05-27 21:07:16 | INFO | train_inner | epoch 011:   1861 / 6686 loss=4.187, nll_loss=2.568, ppl=5.93, wps=28699.6, ups=0.5, wpb=57239, bsz=1455.4, num_updates=68600, lr=0.000241473, gnorm=0.226, clip=100, loss_scale=8, train_wall=196, wall=137189
2023-05-27 21:10:33 | INFO | train_inner | epoch 011:   1961 / 6686 loss=4.195, nll_loss=2.578, ppl=5.97, wps=29051.2, ups=0.51, wpb=57261.8, bsz=1494.6, num_updates=68700, lr=0.000241297, gnorm=0.217, clip=100, loss_scale=4, train_wall=193, wall=137386
2023-05-27 21:13:50 | INFO | train_inner | epoch 011:   2061 / 6686 loss=4.188, nll_loss=2.57, ppl=5.94, wps=28962.2, ups=0.51, wpb=57183.8, bsz=1470.6, num_updates=68800, lr=0.000241121, gnorm=0.211, clip=100, loss_scale=4, train_wall=194, wall=137584
2023-05-27 21:17:08 | INFO | train_inner | epoch 011:   2161 / 6686 loss=4.193, nll_loss=2.576, ppl=5.96, wps=28849.5, ups=0.5, wpb=57163.2, bsz=1477.5, num_updates=68900, lr=0.000240946, gnorm=0.224, clip=100, loss_scale=4, train_wall=194, wall=137782
2023-05-27 21:20:25 | INFO | train_inner | epoch 011:   2261 / 6686 loss=4.199, nll_loss=2.582, ppl=5.99, wps=29062.5, ups=0.51, wpb=57320, bsz=1464.1, num_updates=69000, lr=0.000240772, gnorm=0.222, clip=100, loss_scale=4, train_wall=193, wall=137979
2023-05-27 21:23:43 | INFO | train_inner | epoch 011:   2361 / 6686 loss=4.192, nll_loss=2.574, ppl=5.96, wps=28974.9, ups=0.51, wpb=57103.7, bsz=1483.1, num_updates=69100, lr=0.000240597, gnorm=0.219, clip=100, loss_scale=4, train_wall=193, wall=138176
2023-05-27 21:27:01 | INFO | train_inner | epoch 011:   2461 / 6686 loss=4.189, nll_loss=2.571, ppl=5.94, wps=28875.7, ups=0.5, wpb=57257.2, bsz=1487.3, num_updates=69200, lr=0.000240424, gnorm=0.229, clip=100, loss_scale=8, train_wall=194, wall=138375
2023-05-27 21:30:18 | INFO | train_inner | epoch 011:   2561 / 6686 loss=4.194, nll_loss=2.577, ppl=5.97, wps=28942.8, ups=0.51, wpb=56993.2, bsz=1466, num_updates=69300, lr=0.00024025, gnorm=0.219, clip=100, loss_scale=8, train_wall=193, wall=138572
2023-05-27 21:33:35 | INFO | train_inner | epoch 011:   2661 / 6686 loss=4.194, nll_loss=2.577, ppl=5.97, wps=28883.2, ups=0.51, wpb=57105.5, bsz=1469.1, num_updates=69400, lr=0.000240077, gnorm=0.223, clip=100, loss_scale=8, train_wall=194, wall=138769
2023-05-27 21:36:52 | INFO | train_inner | epoch 011:   2761 / 6686 loss=4.206, nll_loss=2.59, ppl=6.02, wps=29064.8, ups=0.51, wpb=57095.4, bsz=1455.6, num_updates=69500, lr=0.000239904, gnorm=0.221, clip=100, loss_scale=8, train_wall=193, wall=138966
2023-05-27 21:40:09 | INFO | train_inner | epoch 011:   2861 / 6686 loss=4.196, nll_loss=2.579, ppl=5.97, wps=28941.4, ups=0.51, wpb=57116.8, bsz=1467.4, num_updates=69600, lr=0.000239732, gnorm=0.227, clip=100, loss_scale=8, train_wall=194, wall=139163
2023-05-27 21:41:01 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 21:43:29 | INFO | train_inner | epoch 011:   2962 / 6686 loss=4.187, nll_loss=2.569, ppl=5.93, wps=28686.1, ups=0.5, wpb=57146.9, bsz=1460.5, num_updates=69700, lr=0.00023956, gnorm=0.223, clip=100, loss_scale=9, train_wall=195, wall=139362
2023-05-27 21:46:46 | INFO | train_inner | epoch 011:   3062 / 6686 loss=4.2, nll_loss=2.584, ppl=6, wps=28848.7, ups=0.51, wpb=56957.9, bsz=1463, num_updates=69800, lr=0.000239388, gnorm=0.228, clip=100, loss_scale=8, train_wall=194, wall=139560
2023-05-27 21:50:04 | INFO | train_inner | epoch 011:   3162 / 6686 loss=4.188, nll_loss=2.57, ppl=5.94, wps=28913.1, ups=0.51, wpb=57239.9, bsz=1480.1, num_updates=69900, lr=0.000239217, gnorm=0.217, clip=100, loss_scale=8, train_wall=194, wall=139758
2023-05-27 21:53:21 | INFO | train_inner | epoch 011:   3262 / 6686 loss=4.202, nll_loss=2.586, ppl=6, wps=29082.8, ups=0.51, wpb=57236.6, bsz=1464.7, num_updates=70000, lr=0.000239046, gnorm=0.219, clip=100, loss_scale=8, train_wall=193, wall=139955
2023-05-27 21:53:52 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2023-05-27 21:56:41 | INFO | train_inner | epoch 011:   3363 / 6686 loss=4.182, nll_loss=2.563, ppl=5.91, wps=28689.8, ups=0.5, wpb=57365.6, bsz=1501.4, num_updates=70100, lr=0.000238875, gnorm=0.215, clip=100, loss_scale=5, train_wall=196, wall=140155
2023-05-27 21:59:59 | INFO | train_inner | epoch 011:   3463 / 6686 loss=4.191, nll_loss=2.573, ppl=5.95, wps=29015.5, ups=0.51, wpb=57415, bsz=1501.9, num_updates=70200, lr=0.000238705, gnorm=0.229, clip=100, loss_scale=4, train_wall=194, wall=140352
2023-05-27 22:03:16 | INFO | train_inner | epoch 011:   3563 / 6686 loss=4.205, nll_loss=2.589, ppl=6.01, wps=29053.9, ups=0.51, wpb=57228.4, bsz=1453.7, num_updates=70300, lr=0.000238535, gnorm=0.216, clip=100, loss_scale=4, train_wall=193, wall=140549
2023-05-27 22:06:33 | INFO | train_inner | epoch 011:   3663 / 6686 loss=4.184, nll_loss=2.566, ppl=5.92, wps=29017.1, ups=0.51, wpb=57244.7, bsz=1473.4, num_updates=70400, lr=0.000238366, gnorm=0.22, clip=100, loss_scale=4, train_wall=194, wall=140747
2023-05-27 22:09:51 | INFO | train_inner | epoch 011:   3763 / 6686 loss=4.186, nll_loss=2.567, ppl=5.93, wps=28992.5, ups=0.5, wpb=57486.3, bsz=1467.8, num_updates=70500, lr=0.000238197, gnorm=0.219, clip=100, loss_scale=4, train_wall=195, wall=140945
2023-05-27 22:13:09 | INFO | train_inner | epoch 011:   3863 / 6686 loss=4.192, nll_loss=2.575, ppl=5.96, wps=28968.7, ups=0.51, wpb=57279.2, bsz=1487.2, num_updates=70600, lr=0.000238028, gnorm=0.216, clip=100, loss_scale=7, train_wall=194, wall=141143
2023-05-27 22:16:26 | INFO | train_inner | epoch 011:   3963 / 6686 loss=4.198, nll_loss=2.581, ppl=5.98, wps=29036.1, ups=0.51, wpb=57113.1, bsz=1467.4, num_updates=70700, lr=0.000237859, gnorm=0.225, clip=100, loss_scale=8, train_wall=193, wall=141339
2023-05-27 22:19:43 | INFO | train_inner | epoch 011:   4063 / 6686 loss=4.2, nll_loss=2.584, ppl=6, wps=28967.8, ups=0.51, wpb=57127.4, bsz=1474, num_updates=70800, lr=0.000237691, gnorm=0.222, clip=100, loss_scale=8, train_wall=193, wall=141537
2023-05-27 22:23:00 | INFO | train_inner | epoch 011:   4163 / 6686 loss=4.199, nll_loss=2.582, ppl=5.99, wps=28893.2, ups=0.51, wpb=57051.9, bsz=1478.4, num_updates=70900, lr=0.000237524, gnorm=0.219, clip=100, loss_scale=8, train_wall=194, wall=141734
2023-05-27 22:26:17 | INFO | train_inner | epoch 011:   4263 / 6686 loss=4.192, nll_loss=2.575, ppl=5.96, wps=28970.5, ups=0.51, wpb=57118.7, bsz=1475.8, num_updates=71000, lr=0.000237356, gnorm=0.226, clip=100, loss_scale=8, train_wall=193, wall=141931
2023-05-27 22:27:37 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 22:29:36 | INFO | train_inner | epoch 011:   4364 / 6686 loss=4.203, nll_loss=2.587, ppl=6.01, wps=28724.9, ups=0.5, wpb=57117.8, bsz=1471.9, num_updates=71100, lr=0.000237189, gnorm=0.22, clip=100, loss_scale=8, train_wall=195, wall=142130
2023-05-27 22:32:54 | INFO | train_inner | epoch 011:   4464 / 6686 loss=4.19, nll_loss=2.573, ppl=5.95, wps=28943.4, ups=0.51, wpb=57271.8, bsz=1468.5, num_updates=71200, lr=0.000237023, gnorm=0.218, clip=100, loss_scale=8, train_wall=194, wall=142328
2023-05-27 22:36:12 | INFO | train_inner | epoch 011:   4564 / 6686 loss=4.195, nll_loss=2.578, ppl=5.97, wps=28925.6, ups=0.51, wpb=57188.3, bsz=1480.3, num_updates=71300, lr=0.000236856, gnorm=0.227, clip=100, loss_scale=8, train_wall=194, wall=142526
2023-05-27 22:38:36 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2023-05-27 22:39:31 | INFO | train_inner | epoch 011:   4665 / 6686 loss=4.198, nll_loss=2.581, ppl=5.98, wps=28608.2, ups=0.5, wpb=57069.8, bsz=1467, num_updates=71400, lr=0.000236691, gnorm=0.226, clip=100, loss_scale=7, train_wall=196, wall=142725
2023-05-27 22:42:48 | INFO | train_inner | epoch 011:   4765 / 6686 loss=4.196, nll_loss=2.579, ppl=5.98, wps=29059.7, ups=0.51, wpb=57209, bsz=1496.2, num_updates=71500, lr=0.000236525, gnorm=0.217, clip=100, loss_scale=4, train_wall=193, wall=142922
2023-05-27 22:46:06 | INFO | train_inner | epoch 011:   4865 / 6686 loss=4.191, nll_loss=2.573, ppl=5.95, wps=28928.8, ups=0.51, wpb=57254.6, bsz=1487.8, num_updates=71600, lr=0.00023636, gnorm=0.215, clip=100, loss_scale=4, train_wall=194, wall=143120
2023-05-27 22:49:23 | INFO | train_inner | epoch 011:   4965 / 6686 loss=4.205, nll_loss=2.589, ppl=6.02, wps=28902.6, ups=0.51, wpb=56892.5, bsz=1473.8, num_updates=71700, lr=0.000236195, gnorm=0.229, clip=100, loss_scale=4, train_wall=193, wall=143317
2023-05-27 22:52:40 | INFO | train_inner | epoch 011:   5065 / 6686 loss=4.2, nll_loss=2.584, ppl=6, wps=28966.8, ups=0.51, wpb=57200.9, bsz=1477, num_updates=71800, lr=0.00023603, gnorm=0.221, clip=100, loss_scale=4, train_wall=194, wall=143514
2023-05-27 22:55:58 | INFO | train_inner | epoch 011:   5165 / 6686 loss=4.194, nll_loss=2.577, ppl=5.97, wps=28888.7, ups=0.51, wpb=57151.4, bsz=1479.8, num_updates=71900, lr=0.000235866, gnorm=0.221, clip=100, loss_scale=5, train_wall=194, wall=143712
2023-05-27 22:59:16 | INFO | train_inner | epoch 011:   5265 / 6686 loss=4.194, nll_loss=2.577, ppl=5.97, wps=28893.1, ups=0.51, wpb=57079.3, bsz=1487.8, num_updates=72000, lr=0.000235702, gnorm=0.225, clip=100, loss_scale=8, train_wall=194, wall=143910
2023-05-27 23:02:33 | INFO | train_inner | epoch 011:   5365 / 6686 loss=4.201, nll_loss=2.585, ppl=6, wps=29009.6, ups=0.51, wpb=57217.5, bsz=1471, num_updates=72100, lr=0.000235539, gnorm=0.23, clip=100, loss_scale=8, train_wall=194, wall=144107
2023-05-27 23:05:50 | INFO | train_inner | epoch 011:   5465 / 6686 loss=4.194, nll_loss=2.577, ppl=5.97, wps=28974.6, ups=0.51, wpb=57157.6, bsz=1473, num_updates=72200, lr=0.000235376, gnorm=0.225, clip=100, loss_scale=8, train_wall=193, wall=144304
2023-05-27 23:07:31 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2023-05-27 23:09:09 | INFO | train_inner | epoch 011:   5566 / 6686 loss=4.189, nll_loss=2.572, ppl=5.94, wps=28709.2, ups=0.5, wpb=57094, bsz=1505.7, num_updates=72300, lr=0.000235213, gnorm=0.22, clip=100, loss_scale=6, train_wall=195, wall=144503
2023-05-27 23:12:27 | INFO | train_inner | epoch 011:   5666 / 6686 loss=4.202, nll_loss=2.587, ppl=6.01, wps=28924.3, ups=0.5, wpb=57335.7, bsz=1480, num_updates=72400, lr=0.00023505, gnorm=0.219, clip=100, loss_scale=4, train_wall=195, wall=144701
2023-05-27 23:15:45 | INFO | train_inner | epoch 011:   5766 / 6686 loss=4.199, nll_loss=2.582, ppl=5.99, wps=29007.5, ups=0.51, wpb=57233.3, bsz=1452.9, num_updates=72500, lr=0.000234888, gnorm=0.217, clip=100, loss_scale=4, train_wall=194, wall=144899
2023-05-27 23:19:02 | INFO | train_inner | epoch 011:   5866 / 6686 loss=4.206, nll_loss=2.59, ppl=6.02, wps=28909.4, ups=0.51, wpb=57078, bsz=1477.1, num_updates=72600, lr=0.000234726, gnorm=0.217, clip=100, loss_scale=4, train_wall=194, wall=145096
2023-05-27 23:22:20 | INFO | train_inner | epoch 011:   5966 / 6686 loss=4.182, nll_loss=2.564, ppl=5.91, wps=28911.9, ups=0.5, wpb=57278.3, bsz=1500.2, num_updates=72700, lr=0.000234565, gnorm=0.226, clip=100, loss_scale=4, train_wall=194, wall=145294
2023-05-27 23:25:37 | INFO | train_inner | epoch 011:   6066 / 6686 loss=4.2, nll_loss=2.584, ppl=6, wps=29064.1, ups=0.51, wpb=57256.3, bsz=1471.6, num_updates=72800, lr=0.000234404, gnorm=0.214, clip=100, loss_scale=6, train_wall=193, wall=145491
2023-05-27 23:28:55 | INFO | train_inner | epoch 011:   6166 / 6686 loss=4.189, nll_loss=2.571, ppl=5.94, wps=28937.4, ups=0.51, wpb=57238.3, bsz=1496, num_updates=72900, lr=0.000234243, gnorm=0.22, clip=100, loss_scale=8, train_wall=194, wall=145689
2023-05-27 23:32:12 | INFO | train_inner | epoch 011:   6266 / 6686 loss=4.186, nll_loss=2.568, ppl=5.93, wps=29119.6, ups=0.51, wpb=57342.7, bsz=1476.7, num_updates=73000, lr=0.000234082, gnorm=0.224, clip=100, loss_scale=8, train_wall=193, wall=145886
2023-05-27 23:35:29 | INFO | train_inner | epoch 011:   6366 / 6686 loss=4.214, nll_loss=2.6, ppl=6.06, wps=28958.9, ups=0.51, wpb=57034.5, bsz=1466.8, num_updates=73100, lr=0.000233922, gnorm=0.22, clip=100, loss_scale=8, train_wall=193, wall=146083
2023-05-27 23:38:46 | INFO | train_inner | epoch 011:   6466 / 6686 loss=4.188, nll_loss=2.57, ppl=5.94, wps=29112, ups=0.51, wpb=57316.5, bsz=1492.6, num_updates=73200, lr=0.000233762, gnorm=0.23, clip=100, loss_scale=8, train_wall=193, wall=146280
2023-05-27 23:42:00 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 23:42:06 | INFO | train_inner | epoch 011:   6567 / 6686 loss=4.189, nll_loss=2.572, ppl=5.94, wps=28576.1, ups=0.5, wpb=57146.6, bsz=1485, num_updates=73300, lr=0.000233603, gnorm=0.224, clip=100, loss_scale=10, train_wall=196, wall=146480
2023-05-27 23:45:24 | INFO | train_inner | epoch 011:   6667 / 6686 loss=4.191, nll_loss=2.574, ppl=5.96, wps=28877.9, ups=0.5, wpb=57317.7, bsz=1482.3, num_updates=73400, lr=0.000233444, gnorm=0.22, clip=100, loss_scale=8, train_wall=195, wall=146678
2023-05-27 23:46:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-27 23:46:06 | INFO | fairseq.tasks.translation | example hypothesis: Why? Why?
2023-05-27 23:46:06 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-27 23:46:07 | INFO | fairseq.tasks.translation | example hypothesis: In a moment, I’ll make you lose to the point that you don’t even have your pants left on you!
2023-05-27 23:46:07 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-27 23:46:09 | INFO | fairseq.tasks.translation | example hypothesis: Just as Shen Liangchuan heaved a sigh of relief, she opened her mouth and said, “I’ll call for you to stay in the same room!”
2023-05-27 23:46:09 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-27 23:46:10 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved and entered the elevator.
2023-05-27 23:46:10 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-27 23:46:13 | INFO | fairseq.tasks.translation | example hypothesis: As soon as she raised her head, she saw Song Cheng standing in the distance! He was Song Cheng!
2023-05-27 23:46:13 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-27 23:46:15 | INFO | fairseq.tasks.translation | example hypothesis: Only then did Song Cheng pat his chest and said, “I was scared to death! Where’s Wang Chuan?”
2023-05-27 23:46:15 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-27 23:46:17 | INFO | fairseq.tasks.translation | example hypothesis: I said, “I won’t go, I won’t be able to eat it.” I said with a smile.
2023-05-27 23:46:17 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-27 23:46:17 | INFO | fairseq.tasks.translation | example hypothesis: Everyone didn’t believe it at first, but Wang Wenhao insisted that the public leaned towards Wang Wenhao.
2023-05-27 23:46:17 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-27 23:46:20 | INFO | fairseq.tasks.translation | example hypothesis: With his status and status, Baili Hongzhuang had no choice but to treat him even if he had to!
2023-05-27 23:46:20 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-27 23:46:22 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian said, “Mr. Shen, I, I have left too much blood. My brain is lacking oxygen, so I can’t think of anything. Why don’t you give me a hint?” Qiao
2023-05-27 23:46:22 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-27 23:46:26 | INFO | fairseq.tasks.translation | example hypothesis: He didn't know why this matter would reach so many people's ears. Since he couldn't hide it anymore, he might as well say it out loud. However, he didn't know why Li Yuyue'
2023-05-27 23:46:26 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-27 23:46:27 | INFO | fairseq.tasks.translation | example hypothesis: Ye Qing Ling deliberately lowered her voice, but she couldn’t hide the viciousness and ruthlessness in her voice. “I’ll destroy you!”
2023-05-27 23:46:27 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-27 23:46:30 | INFO | fairseq.tasks.translation | example hypothesis: The strength of a beast pet of different levels was different, but a beast pet was precious and hard to come by. It was impossible for an ordinary person to possess one, and even the descendants of officials would not be able to possess
2023-05-27 23:46:30 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-27 23:46:32 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chixia clenched his teeth and cursed in a low voice, "How dare you..."
2023-05-27 23:46:32 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-27 23:46:34 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang had concealed it very well, Di Beichen could still see the waves flashing through her eyes, and a trace of warmth could be seen in his eyes.
2023-05-27 23:46:34 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-27 23:46:36 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia walked in, not to mention the guests, he didn’t even see a few waiters. He didn’t even bother to look at the guests, he just walked in.
2023-05-27 23:46:36 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-27 23:46:39 | INFO | fairseq.tasks.translation | example hypothesis: This person was none other than the fourth young miss of the Ye family, Ye Qingling.
2023-05-27 23:46:39 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-27 23:46:42 | INFO | fairseq.tasks.translation | example hypothesis: Because at this moment, she felt that her chin was about to break.
2023-05-27 23:46:42 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-27 23:46:45 | INFO | fairseq.tasks.translation | example hypothesis: “Good Mu Zi, help me. If it wasn’t for you, that old man wouldn’t have set his eyes on me,” I said with a smile.
2023-05-27 23:46:45 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-27 23:46:47 | INFO | fairseq.tasks.translation | example hypothesis: Baili Yuyan was even more excited. This matter was completely directed by her. Earlier, Baili Hongzhuang had treated her like that. This time, she would definitely make Baili Hongzhuang suffer as well.
2023-05-27 23:46:47 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-27 23:46:49 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How could that be? They’re also four grand mages, of course they won’t submit so easily. After arguing for a long time, they decided to use the competition to obtain control of the kingdom in the future.”
2023-05-27 23:46:49 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-27 23:46:52 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a little. Originally, he had been looking for an excuse for Li Yuyue not being able to participate in the royal family’s hunting competition.
2023-05-27 23:46:52 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-27 23:46:55 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my level good enough? They’re all the best talents in the country, but my magic is so weak?” The old demon asked.
2023-05-27 23:46:55 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-27 23:47:01 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yibei’s meaning was that if Fang Chixia didn’t want to go, then he didn’t need to go. If Fang Chixia didn’t want to go, then he wouldn’t have to go. If Fang Chixia didn’t want to go, then he had to go.
2023-05-27 23:47:01 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-27 23:47:04 | INFO | fairseq.tasks.translation | example hypothesis: She tilted her head and saw that the five palm prints on her cheeks were very obvious. The five palm prints were swollen at a speed visible to the naked eye. She reached out her hand to touch them, and she couldn’t help but let out a hissing sound. It really hurt.
2023-05-27 23:47:04 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-27 23:47:07 | INFO | fairseq.tasks.translation | example hypothesis: This... How could this be the charm emitted by that piece of trash? How could she possibly have such a charm?
2023-05-27 23:47:07 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-27 23:47:09 | INFO | fairseq.tasks.translation | example hypothesis: How did Wang Wenhao find the news agency? The chief editor should have called her to tell her not to come to the news agency, but the three of them... had plotted against her!
2023-05-27 23:47:09 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-27 23:47:15 | INFO | fairseq.tasks.translation | example hypothesis: Hearing Teacher Di’s praise, I was overjoyed. I retracted the energy ball with my left hand and sent a light sword towards Teacher Zhen with my right hand. The light sword actually managed to hit me smoothly. I was shocked, but upon closer inspection, I realized that it was just an afterimage. Teacher Zhen had already moved behind me, and shouted, “Berserk Space!”
2023-05-27 23:47:15 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-27 23:47:20 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Originally, we proposed three matches and two wins, but they said that it wasn’t fair, because we had Teacher Di and Teacher Zhen, and their ranking was higher than theirs, so they asked for five matches and three victories. Since we were the ones who suggested the match, we could only listen to them in the end. Three days later, we will have a secret competition in the Royal Martial Arts Arena. The competition will be held three days later
2023-05-27 23:47:20 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-27 23:47:23 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Zhen used the Level 7 Light element spell, Light Lightning Combo. I rarely used this spell because I didn’t have good control over it. Teacher Zhen released nine lightning bolts to surround me, forming a simple formation that prevented me from escaping in a short distance. Then, the lightning would explode and form a powerful attack.
2023-05-27 23:47:23 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-27 23:47:30 | INFO | fairseq.tasks.translation | example hypothesis: As soon as Ma Ke and the two teachers arrived at the other side, Teacher Zhen sent me a small Dimensional Cut. As expected of the number one Mage in the continent. The powerful suction force of his small Dimensional Cut was actually much stronger than my own. A small spatial rift appeared beside me, and a powerful suction force immediately swept over. The two of us were able to make a breakthrough in the next two days. However, I didn’t expect that I would be able to make a breakthrough in the next two days. It’s just that I didn’t expect that I’d be able to make a breakthrough in the next two days. It’s just that I didn’t expect that I’d be able to make a breakthrough in such a short period of time.
2023-05-27 23:47:30 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-27 23:47:30 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 4.463 | nll_loss 2.853 | ppl 7.23 | bleu 17.38 | wps 868.5 | wpb 2420.8 | bsz 84.5 | num_updates 73419 | best_bleu 17.84
2023-05-27 23:47:30 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-27 23:47:31 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/mega-1-1-0.2-sf[zh-en]/checkpoint_last.pt (epoch 11 @ 73419 updates, score 17.38) (writing took 0.9900466846302152 seconds)
2023-05-27 23:47:31 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-05-27 23:47:31 | INFO | train | epoch 011 | loss 4.192 | nll_loss 2.575 | ppl 5.96 | wps 28674.7 | ups 0.5 | wpb 57189.4 | bsz 1477.5 | num_updates 73419 | lr 0.000233413 | gnorm 0.221 | clip 100 | loss_scale 7 | train_wall 12955 | wall 146805
2023-05-27 23:47:31 | INFO | fairseq.trainer | begin training epoch 12
2023-05-27 23:50:29 | INFO | train_inner | epoch 012:     81 / 6686 loss=4.174, nll_loss=2.554, ppl=5.87, wps=18608.7, ups=0.33, wpb=56713.8, bsz=1472.2, num_updates=73500, lr=0.000233285, gnorm=0.221, clip=100, loss_scale=8, train_wall=194, wall=146983
2023-05-27 23:53:52 | INFO | train_inner | epoch 012:    181 / 6686 loss=4.166, nll_loss=2.544, ppl=5.83, wps=28200.3, ups=0.49, wpb=57190.8, bsz=1474.4, num_updates=73600, lr=0.000233126, gnorm=0.222, clip=100, loss_scale=8, train_wall=194, wall=147186
2023-05-27 23:57:11 | INFO | train_inner | epoch 012:    281 / 6686 loss=4.173, nll_loss=2.553, ppl=5.87, wps=28678.8, ups=0.5, wpb=57126.5, bsz=1477.6, num_updates=73700, lr=0.000232968, gnorm=0.216, clip=100, loss_scale=8, train_wall=194, wall=147385
2023-05-28 00:00:29 | INFO | train_inner | epoch 012:    381 / 6686 loss=4.177, nll_loss=2.557, ppl=5.88, wps=28992, ups=0.51, wpb=57381.2, bsz=1479.9, num_updates=73800, lr=0.00023281, gnorm=0.219, clip=100, loss_scale=8, train_wall=194, wall=147583
2023-05-28 00:00:53 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-28 00:03:48 | INFO | train_inner | epoch 012:    482 / 6686 loss=4.177, nll_loss=2.557, ppl=5.89, wps=28594.9, ups=0.5, wpb=56962.1, bsz=1450.9, num_updates=73900, lr=0.000232653, gnorm=0.217, clip=100, loss_scale=8, train_wall=195, wall=147782
2023-05-28 00:07:06 | INFO | train_inner | epoch 012:    582 / 6686 loss=4.176, nll_loss=2.556, ppl=5.88, wps=28870.5, ups=0.51, wpb=57132.5, bsz=1478.2, num_updates=74000, lr=0.000232495, gnorm=0.217, clip=100, loss_scale=8, train_wall=194, wall=147980
2023-05-28 00:10:24 | INFO | train_inner | epoch 012:    682 / 6686 loss=4.178, nll_loss=2.558, ppl=5.89, wps=28913.8, ups=0.51, wpb=57212.3, bsz=1477.7, num_updates=74100, lr=0.000232338, gnorm=0.221, clip=100, loss_scale=8, train_wall=194, wall=148178
2023-05-28 00:13:42 | INFO | train_inner | epoch 012:    782 / 6686 loss=4.179, nll_loss=2.559, ppl=5.89, wps=28937.2, ups=0.51, wpb=57217.5, bsz=1469.4, num_updates=74200, lr=0.000232182, gnorm=0.233, clip=100, loss_scale=8, train_wall=194, wall=148376
2023-05-28 00:16:51 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2023-05-28 00:17:01 | INFO | train_inner | epoch 012:    883 / 6686 loss=4.186, nll_loss=2.567, ppl=5.93, wps=28707.6, ups=0.5, wpb=57082.5, bsz=1459.8, num_updates=74300, lr=0.000232025, gnorm=0.225, clip=100, loss_scale=8, train_wall=195, wall=148575
2023-05-28 00:20:19 | INFO | train_inner | epoch 012:    983 / 6686 loss=4.17, nll_loss=2.55, ppl=5.86, wps=28863, ups=0.51, wpb=57128.5, bsz=1496.9, num_updates=74400, lr=0.000231869, gnorm=0.228, clip=100, loss_scale=4, train_wall=194, wall=148772
2023-05-28 00:23:36 | INFO | train_inner | epoch 012:   1083 / 6686 loss=4.181, nll_loss=2.562, ppl=5.9, wps=28977.5, ups=0.51, wpb=57131, bsz=1484.2, num_updates=74500, lr=0.000231714, gnorm=0.227, clip=100, loss_scale=4, train_wall=193, wall=148970
2023-05-28 00:26:53 | INFO | train_inner | epoch 012:   1183 / 6686 loss=4.183, nll_loss=2.564, ppl=5.92, wps=29006.7, ups=0.51, wpb=57163.1, bsz=1462.2, num_updates=74600, lr=0.000231558, gnorm=0.22, clip=100, loss_scale=4, train_wall=193, wall=149167
2023-05-28 00:30:11 | INFO | train_inner | epoch 012:   1283 / 6686 loss=4.177, nll_loss=2.557, ppl=5.89, wps=28973.2, ups=0.5, wpb=57406.9, bsz=1492.1, num_updates=74700, lr=0.000231403, gnorm=0.226, clip=100, loss_scale=4, train_wall=194, wall=149365
2023-05-28 00:33:28 | INFO | train_inner | epoch 012:   1383 / 6686 loss=4.18, nll_loss=2.56, ppl=5.9, wps=29043.1, ups=0.51, wpb=57190.7, bsz=1445.8, num_updates=74800, lr=0.000231249, gnorm=0.218, clip=100, loss_scale=4, train_wall=193, wall=149562
2023-05-28 00:36:46 | INFO | train_inner | epoch 012:   1483 / 6686 loss=4.168, nll_loss=2.547, ppl=5.84, wps=28919.5, ups=0.5, wpb=57267.3, bsz=1496.2, num_updates=74900, lr=0.000231094, gnorm=0.227, clip=100, loss_scale=8, train_wall=194, wall=149760
2023-05-28 00:40:04 | INFO | train_inner | epoch 012:   1583 / 6686 loss=4.18, nll_loss=2.561, ppl=5.9, wps=28819.7, ups=0.5, wpb=57082.8, bsz=1475.5, num_updates=75000, lr=0.00023094, gnorm=0.216, clip=100, loss_scale=8, train_wall=194, wall=149958
2023-05-28 00:43:22 | INFO | train_inner | epoch 012:   1683 / 6686 loss=4.17, nll_loss=2.549, ppl=5.85, wps=28907.5, ups=0.51, wpb=57156.3, bsz=1493.2, num_updates=75100, lr=0.000230786, gnorm=0.22, clip=100, loss_scale=8, train_wall=194, wall=150156
2023-05-28 00:46:40 | INFO | train_inner | epoch 012:   1783 / 6686 loss=4.178, nll_loss=2.559, ppl=5.89, wps=28913.9, ups=0.5, wpb=57272.5, bsz=1485.8, num_updates=75200, lr=0.000230633, gnorm=0.223, clip=100, loss_scale=8, train_wall=194, wall=150354
2023-05-28 00:49:58 | INFO | train_inner | epoch 012:   1883 / 6686 loss=4.177, nll_loss=2.558, ppl=5.89, wps=28940.6, ups=0.51, wpb=57244.8, bsz=1479.2, num_updates=75300, lr=0.00023048, gnorm=0.219, clip=100, loss_scale=8, train_wall=194, wall=150551
2023-05-28 00:51:07 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-28 00:53:17 | INFO | train_inner | epoch 012:   1984 / 6686 loss=4.183, nll_loss=2.564, ppl=5.91, wps=28640.3, ups=0.5, wpb=57230.7, bsz=1484.1, num_updates=75400, lr=0.000230327, gnorm=0.229, clip=100, loss_scale=9, train_wall=196, wall=150751
2023-05-28 00:56:35 | INFO | train_inner | epoch 012:   2084 / 6686 loss=4.192, nll_loss=2.575, ppl=5.96, wps=28959.5, ups=0.51, wpb=57153.7, bsz=1475.4, num_updates=75500, lr=0.000230174, gnorm=0.226, clip=100, loss_scale=8, train_wall=194, wall=150949
2023-05-28 00:59:53 | INFO | train_inner | epoch 012:   2184 / 6686 loss=4.186, nll_loss=2.567, ppl=5.93, wps=28854.4, ups=0.51, wpb=57088.6, bsz=1471.8, num_updates=75600, lr=0.000230022, gnorm=0.236, clip=100, loss_scale=8, train_wall=194, wall=151147
2023-05-28 01:03:11 | INFO | train_inner | epoch 012:   2284 / 6686 loss=4.182, nll_loss=2.563, ppl=5.91, wps=28898.7, ups=0.51, wpb=57210.9, bsz=1476.9, num_updates=75700, lr=0.00022987, gnorm=0.223, clip=100, loss_scale=8, train_wall=194, wall=151344
2023-05-28 01:06:27 | INFO | train_inner | epoch 012:   2384 / 6686 loss=4.185, nll_loss=2.567, ppl=5.93, wps=28996.3, ups=0.51, wpb=56921.5, bsz=1460.3, num_updates=75800, lr=0.000229718, gnorm=0.227, clip=100, loss_scale=8, train_wall=193, wall=151541
2023-05-28 01:08:12 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-28 01:09:46 | INFO | train_inner | epoch 012:   2485 / 6686 loss=4.177, nll_loss=2.558, ppl=5.89, wps=28678.7, ups=0.5, wpb=57185.4, bsz=1491.9, num_updates=75900, lr=0.000229567, gnorm=0.22, clip=100, loss_scale=9, train_wall=195, wall=151740
2023-05-28 01:10:16 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2023-05-28 01:13:07 | INFO | train_inner | epoch 012:   2586 / 6686 loss=4.179, nll_loss=2.56, ppl=5.9, wps=28547.7, ups=0.5, wpb=57176.2, bsz=1485.5, num_updates=76000, lr=0.000229416, gnorm=0.236, clip=100, loss_scale=5, train_wall=196, wall=151940
2023-05-28 01:16:24 | INFO | train_inner | epoch 012:   2686 / 6686 loss=4.176, nll_loss=2.557, ppl=5.89, wps=28909.7, ups=0.51, wpb=57155.4, bsz=1479.8, num_updates=76100, lr=0.000229265, gnorm=0.226, clip=100, loss_scale=4, train_wall=194, wall=152138
2023-05-28 01:19:42 | INFO | train_inner | epoch 012:   2786 / 6686 loss=4.175, nll_loss=2.555, ppl=5.88, wps=28917.7, ups=0.51, wpb=57201.5, bsz=1492.6, num_updates=76200, lr=0.000229114, gnorm=0.22, clip=100, loss_scale=4, train_wall=194, wall=152336
2023-05-28 01:23:00 | INFO | train_inner | epoch 012:   2886 / 6686 loss=4.188, nll_loss=2.57, ppl=5.94, wps=29000.3, ups=0.51, wpb=57300.3, bsz=1495.2, num_updates=76300, lr=0.000228964, gnorm=0.215, clip=100, loss_scale=4, train_wall=194, wall=152534
2023-05-28 01:26:18 | INFO | train_inner | epoch 012:   2986 / 6686 loss=4.174, nll_loss=2.554, ppl=5.87, wps=28888.9, ups=0.5, wpb=57381, bsz=1506.9, num_updates=76400, lr=0.000228814, gnorm=0.235, clip=100, loss_scale=4, train_wall=195, wall=152732
2023-05-28 01:29:36 | INFO | train_inner | epoch 012:   3086 / 6686 loss=4.177, nll_loss=2.558, ppl=5.89, wps=28954.7, ups=0.51, wpb=57137.2, bsz=1467.3, num_updates=76500, lr=0.000228665, gnorm=0.214, clip=100, loss_scale=7, train_wall=193, wall=152930
2023-05-28 01:32:53 | INFO | train_inner | epoch 012:   3186 / 6686 loss=4.189, nll_loss=2.572, ppl=5.94, wps=28999.9, ups=0.51, wpb=57116.6, bsz=1462.6, num_updates=76600, lr=0.000228515, gnorm=0.22, clip=100, loss_scale=8, train_wall=193, wall=153127
2023-05-28 01:36:11 | INFO | train_inner | epoch 012:   3286 / 6686 loss=4.187, nll_loss=2.569, ppl=5.94, wps=28883.6, ups=0.51, wpb=57164.5, bsz=1484.3, num_updates=76700, lr=0.000228366, gnorm=0.219, clip=100, loss_scale=8, train_wall=194, wall=153324
2023-05-28 01:39:27 | INFO | train_inner | epoch 012:   3386 / 6686 loss=4.181, nll_loss=2.563, ppl=5.91, wps=29029.4, ups=0.51, wpb=57152.4, bsz=1475.8, num_updates=76800, lr=0.000228218, gnorm=0.222, clip=100, loss_scale=8, train_wall=193, wall=153521
2023-05-28 01:42:46 | INFO | train_inner | epoch 012:   3486 / 6686 loss=4.176, nll_loss=2.557, ppl=5.88, wps=28813.1, ups=0.5, wpb=57215.7, bsz=1478.9, num_updates=76900, lr=0.000228069, gnorm=0.226, clip=100, loss_scale=8, train_wall=194, wall=153720
2023-05-28 01:44:03 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-28 01:46:07 | INFO | train_inner | epoch 012:   3587 / 6686 loss=4.187, nll_loss=2.569, ppl=5.93, wps=28503, ups=0.5, wpb=57223, bsz=1477.9, num_updates=77000, lr=0.000227921, gnorm=0.227, clip=100, loss_scale=8, train_wall=197, wall=153921
2023-05-28 01:49:24 | INFO | train_inner | epoch 012:   3687 / 6686 loss=4.186, nll_loss=2.568, ppl=5.93, wps=28947.7, ups=0.51, wpb=57110.7, bsz=1492.5, num_updates=77100, lr=0.000227773, gnorm=0.23, clip=100, loss_scale=8, train_wall=193, wall=154118
2023-05-28 01:52:43 | INFO | train_inner | epoch 012:   3787 / 6686 loss=4.187, nll_loss=2.569, ppl=5.93, wps=28897.7, ups=0.5, wpb=57429.6, bsz=1479.9, num_updates=77200, lr=0.000227626, gnorm=0.229, clip=100, loss_scale=8, train_wall=195, wall=154317
2023-05-28 01:56:01 | INFO | train_inner | epoch 012:   3887 / 6686 loss=4.183, nll_loss=2.564, ppl=5.91, wps=28887.5, ups=0.5, wpb=57249.2, bsz=1478.9, num_updates=77300, lr=0.000227478, gnorm=0.216, clip=100, loss_scale=8, train_wall=194, wall=154515
2023-05-28 01:59:19 | INFO | train_inner | epoch 012:   3987 / 6686 loss=4.189, nll_loss=2.572, ppl=5.94, wps=28887, ups=0.5, wpb=57256.7, bsz=1469, num_updates=77400, lr=0.000227331, gnorm=0.229, clip=100, loss_scale=8, train_wall=194, wall=154713
2023-05-28 02:01:15 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-28 02:02:39 | INFO | train_inner | epoch 012:   4088 / 6686 loss=4.189, nll_loss=2.572, ppl=5.95, wps=28639.8, ups=0.5, wpb=57081.1, bsz=1459.8, num_updates=77500, lr=0.000227185, gnorm=0.219, clip=100, loss_scale=9, train_wall=195, wall=154912
2023-05-28 02:05:56 | INFO | train_inner | epoch 012:   4188 / 6686 loss=4.177, nll_loss=2.558, ppl=5.89, wps=28990.6, ups=0.51, wpb=57094.8, bsz=1480, num_updates=77600, lr=0.000227038, gnorm=0.223, clip=100, loss_scale=8, train_wall=193, wall=155109
2023-05-28 02:09:12 | INFO | train_inner | epoch 012:   4288 / 6686 loss=4.184, nll_loss=2.566, ppl=5.92, wps=29043.4, ups=0.51, wpb=57198.3, bsz=1472.2, num_updates=77700, lr=0.000226892, gnorm=0.224, clip=100, loss_scale=8, train_wall=193, wall=155306
2023-05-28 02:12:30 | INFO | train_inner | epoch 012:   4388 / 6686 loss=4.183, nll_loss=2.564, ppl=5.92, wps=28949.1, ups=0.51, wpb=57297.7, bsz=1482, num_updates=77800, lr=0.000226746, gnorm=0.226, clip=100, loss_scale=8, train_wall=194, wall=155504
2023-05-28 02:15:48 | INFO | train_inner | epoch 012:   4488 / 6686 loss=4.179, nll_loss=2.56, ppl=5.9, wps=28826, ups=0.51, wpb=56969.9, bsz=1495, num_updates=77900, lr=0.000226601, gnorm=0.233, clip=100, loss_scale=8, train_wall=194, wall=155702
2023-05-28 02:18:34 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-28 02:19:08 | INFO | train_inner | epoch 012:   4589 / 6686 loss=4.193, nll_loss=2.576, ppl=5.96, wps=28697.5, ups=0.5, wpb=57293.4, bsz=1456.9, num_updates=78000, lr=0.000226455, gnorm=0.219, clip=100, loss_scale=9, train_wall=196, wall=155902
2023-05-28 02:22:26 | INFO | train_inner | epoch 012:   4689 / 6686 loss=4.178, nll_loss=2.559, ppl=5.89, wps=28959.8, ups=0.51, wpb=57344.1, bsz=1505, num_updates=78100, lr=0.00022631, gnorm=0.224, clip=100, loss_scale=8, train_wall=194, wall=156100
2023-05-28 02:25:43 | INFO | train_inner | epoch 012:   4789 / 6686 loss=4.176, nll_loss=2.557, ppl=5.89, wps=28961.8, ups=0.51, wpb=57209.6, bsz=1471.4, num_updates=78200, lr=0.000226166, gnorm=0.219, clip=100, loss_scale=8, train_wall=194, wall=156297
2023-05-28 02:29:00 | INFO | train_inner | epoch 012:   4889 / 6686 loss=4.189, nll_loss=2.571, ppl=5.94, wps=29040.8, ups=0.51, wpb=57167.5, bsz=1479, num_updates=78300, lr=0.000226021, gnorm=0.226, clip=100, loss_scale=8, train_wall=193, wall=156494
2023-05-28 02:32:18 | INFO | train_inner | epoch 012:   4989 / 6686 loss=4.173, nll_loss=2.554, ppl=5.87, wps=28953.2, ups=0.51, wpb=57209.7, bsz=1497.2, num_updates=78400, lr=0.000225877, gnorm=0.225, clip=100, loss_scale=8, train_wall=194, wall=156692
2023-05-28 02:35:35 | INFO | train_inner | epoch 012:   5089 / 6686 loss=4.185, nll_loss=2.567, ppl=5.92, wps=28967.8, ups=0.51, wpb=57234.1, bsz=1482.7, num_updates=78500, lr=0.000225733, gnorm=0.216, clip=100, loss_scale=8, train_wall=194, wall=156889
2023-05-28 02:36:07 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-28 02:38:55 | INFO | train_inner | epoch 012:   5190 / 6686 loss=4.179, nll_loss=2.56, ppl=5.9, wps=28736.3, ups=0.5, wpb=57365.8, bsz=1485.2, num_updates=78600, lr=0.000225589, gnorm=0.219, clip=100, loss_scale=9, train_wall=196, wall=157089
2023-05-28 02:42:13 | INFO | train_inner | epoch 012:   5290 / 6686 loss=4.176, nll_loss=2.557, ppl=5.88, wps=28874.9, ups=0.5, wpb=57324.7, bsz=1466.8, num_updates=78700, lr=0.000225446, gnorm=0.225, clip=100, loss_scale=8, train_wall=195, wall=157287
2023-05-28 02:45:30 | INFO | train_inner | epoch 012:   5390 / 6686 loss=4.191, nll_loss=2.574, ppl=5.95, wps=29054.2, ups=0.51, wpb=57220.3, bsz=1448.2, num_updates=78800, lr=0.000225303, gnorm=0.225, clip=100, loss_scale=8, train_wall=193, wall=157484
2023-05-28 02:48:47 | INFO | train_inner | epoch 012:   5490 / 6686 loss=4.191, nll_loss=2.574, ppl=5.96, wps=28969.8, ups=0.51, wpb=57071.9, bsz=1484.6, num_updates=78900, lr=0.00022516, gnorm=0.224, clip=100, loss_scale=8, train_wall=193, wall=157681
2023-05-28 02:52:05 | INFO | train_inner | epoch 012:   5590 / 6686 loss=4.188, nll_loss=2.57, ppl=5.94, wps=28907.9, ups=0.51, wpb=57078.7, bsz=1477, num_updates=79000, lr=0.000225018, gnorm=0.215, clip=100, loss_scale=8, train_wall=194, wall=157879
2023-05-28 02:53:04 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-28 02:55:24 | INFO | train_inner | epoch 012:   5691 / 6686 loss=4.21, nll_loss=2.595, ppl=6.04, wps=28771.7, ups=0.5, wpb=57315.2, bsz=1470.4, num_updates=79100, lr=0.000224875, gnorm=0.22, clip=100, loss_scale=8, train_wall=195, wall=158078
2023-05-28 02:58:42 | INFO | train_inner | epoch 012:   5791 / 6686 loss=4.188, nll_loss=2.571, ppl=5.94, wps=28820.2, ups=0.5, wpb=57174.1, bsz=1483.2, num_updates=79200, lr=0.000224733, gnorm=0.22, clip=100, loss_scale=8, train_wall=195, wall=158276
2023-05-28 03:02:00 | INFO | train_inner | epoch 012:   5891 / 6686 loss=4.177, nll_loss=2.558, ppl=5.89, wps=29020.2, ups=0.51, wpb=57207.9, bsz=1493.7, num_updates=79300, lr=0.000224592, gnorm=0.226, clip=100, loss_scale=8, train_wall=193, wall=158473
2023-05-28 03:05:18 | INFO | train_inner | epoch 012:   5991 / 6686 loss=4.193, nll_loss=2.576, ppl=5.96, wps=28925.8, ups=0.5, wpb=57364.8, bsz=1467.7, num_updates=79400, lr=0.00022445, gnorm=0.224, clip=100, loss_scale=8, train_wall=195, wall=158672
2023-05-28 03:08:34 | INFO | train_inner | epoch 012:   6091 / 6686 loss=4.199, nll_loss=2.583, ppl=5.99, wps=29029.4, ups=0.51, wpb=57004.1, bsz=1452.3, num_updates=79500, lr=0.000224309, gnorm=0.231, clip=100, loss_scale=8, train_wall=193, wall=158868
2023-05-28 03:09:59 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-28 03:11:54 | INFO | train_inner | epoch 012:   6192 / 6686 loss=4.188, nll_loss=2.57, ppl=5.94, wps=28611.2, ups=0.5, wpb=57176.5, bsz=1450.8, num_updates=79600, lr=0.000224168, gnorm=0.221, clip=100, loss_scale=8, train_wall=196, wall=159068
2023-05-28 03:15:12 | INFO | train_inner | epoch 012:   6292 / 6686 loss=4.186, nll_loss=2.569, ppl=5.93, wps=28887.1, ups=0.5, wpb=57240.6, bsz=1465.7, num_updates=79700, lr=0.000224027, gnorm=0.218, clip=100, loss_scale=8, train_wall=194, wall=159266
2023-05-28 03:18:30 | INFO | train_inner | epoch 012:   6392 / 6686 loss=4.18, nll_loss=2.562, ppl=5.9, wps=28898.6, ups=0.51, wpb=57091.1, bsz=1453, num_updates=79800, lr=0.000223887, gnorm=0.224, clip=100, loss_scale=8, train_wall=194, wall=159464
2023-05-28 03:21:48 | INFO | train_inner | epoch 012:   6492 / 6686 loss=4.172, nll_loss=2.553, ppl=5.87, wps=28995.5, ups=0.5, wpb=57424.1, bsz=1504.4, num_updates=79900, lr=0.000223747, gnorm=0.231, clip=100, loss_scale=8, train_wall=194, wall=159662
2023-05-28 03:25:05 | INFO | train_inner | epoch 012:   6592 / 6686 loss=4.182, nll_loss=2.565, ppl=5.92, wps=28900.8, ups=0.51, wpb=57108.5, bsz=1492.9, num_updates=80000, lr=0.000223607, gnorm=0.227, clip=100, loss_scale=8, train_wall=194, wall=159859
2023-05-28 03:27:13 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-28 03:28:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-28 03:28:14 | INFO | fairseq.tasks.translation | example hypothesis: Why? Was he unhappy? Why? Why was he unhappy? Why was he unhappy? Why was he unhappy? Why
2023-05-28 03:28:14 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-28 03:28:15 | INFO | fairseq.tasks.translation | example hypothesis: In a moment, I’ll make you lose to the point that you don’t even have your pants left on you!
2023-05-28 03:28:15 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-28 03:28:17 | INFO | fairseq.tasks.translation | example hypothesis: Shen Liangchuan had just let out a sigh of relief when he heard her say, “I’ll call for you to stay in the same room!”
2023-05-28 03:28:17 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-28 03:28:19 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved and entered the elevator.
2023-05-28 03:28:19 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-28 03:28:22 | INFO | fairseq.tasks.translation | example hypothesis: When she raised her head, she saw Song Cheng standing in the distance! He was Song Cheng’s wife!
2023-05-28 03:28:22 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-28 03:28:23 | INFO | fairseq.tasks.translation | example hypothesis: Only then did Song Cheng pat his chest and said, “I was scared to death! Where’s Wang Chuan?”
2023-05-28 03:28:23 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-28 03:28:25 | INFO | fairseq.tasks.translation | example hypothesis: I said, “I won’t go, I won’t be able to eat anymore.” I said with a smile.
2023-05-28 03:28:25 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-28 03:28:26 | INFO | fairseq.tasks.translation | example hypothesis: .... ... ... ... ... ... ... ...
2023-05-28 03:28:26 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-28 03:28:28 | INFO | fairseq.tasks.translation | example hypothesis: With his status, Bai Li Hongzhuang had no choice but to treat him even if he did not want to!
2023-05-28 03:28:28 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-28 03:28:31 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian said, “Mr. Shen, I, I have left too much blood and my brain is short of oxygen, so I can’t think of anything. Why don’t you give me a hint?”
2023-05-28 03:28:31 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-28 03:28:34 | INFO | fairseq.tasks.translation | example hypothesis: He didn't know why this matter would spread to so many people's ears. Since he couldn't hide it anymore, he might as well say it out loud. However, he didn't know why Li Yuyue
2023-05-28 03:28:34 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-28 03:28:35 | INFO | fairseq.tasks.translation | example hypothesis: She deliberately lowered her voice, but she couldn’t hide the viciousness and viciousness in her voice. “I’m sorry, I’m sorry...”
2023-05-28 03:28:35 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-28 03:28:38 | INFO | fairseq.tasks.translation | example hypothesis: The strength of a beast pet of different levels was different, but a beast pet was precious and hard to come by. It was impossible for ordinary people to have one, and even the children of officials and children of the government couldn’
2023-05-28 03:28:38 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-28 03:28:40 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chi Xia gritted his teeth and cursed in a low voice, "You're too arrogant..."
2023-05-28 03:28:40 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-28 03:28:42 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang had concealed it very well, Di Beichen could still see the ripples in her eyes that flashed for a moment, and a trace of warmth filled his eyes.
2023-05-28 03:28:42 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-28 03:28:44 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia walked in, not to mention the guests, there weren’t even a few waiters. She was the only one in the resort, and she didn’t have any customers.
2023-05-28 03:28:44 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-28 03:28:47 | INFO | fairseq.tasks.translation | example hypothesis: This person was none other than the fourth young miss of the Ye family, Ye Qingling.
2023-05-28 03:28:47 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-28 03:28:50 | INFO | fairseq.tasks.translation | example hypothesis: Because at that moment, she felt that her chin was about to shatter.
2023-05-28 03:28:50 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-28 03:28:53 | INFO | fairseq.tasks.translation | example hypothesis: “Okay, Mu Zi, help me. If it wasn't for you, that old guy wouldn't have set his eyes on me,” I said as I looked at Mu Zi.
2023-05-28 03:28:53 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-28 03:28:55 | INFO | fairseq.tasks.translation | example hypothesis: Baili Yu Yan was even more excited. She was the one who was the one who directed this. Earlier, Baili Hongzhuang had treated her like that. This time, she would definitely make Baili Hongzhuang suffer.
2023-05-28 03:28:55 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-28 03:28:57 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How could that be? They have four grand mages on their side, they won’t surrender so easily. After arguing for a long time, they decided to use the competition to get control of the kingdom in the future.”
2023-05-28 03:28:57 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-28 03:29:00 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a little. Originally, he had been looking for an excuse for Li Yuyue not being able to participate in the royal family’s hunting competition.
2023-05-28 03:29:00 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-28 03:29:03 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my level good enough? They’re all the most talented people in the country, but my magic is that weak?”
2023-05-28 03:29:03 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-28 03:29:09 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yibei’s words meant that if Fang Chi Xia didn’t want to go, then he didn’t need to go. If Fang Chi Xia didn’t want to go, then he didn’t have to go. If Fang Chi Xia didn’t want to go, then he had to go.
2023-05-28 03:29:09 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-28 03:29:12 | INFO | fairseq.tasks.translation | example hypothesis: She tilted her head to the side and saw that the five palm prints on her face were very conspicuous. They were swollen at a speed visible to the naked eye. She reached out her hand to touch them and couldn’t help but let out a hissing sound. It really hurt.
2023-05-28 03:29:12 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-28 03:29:15 | INFO | fairseq.tasks.translation | example hypothesis: This... How could it be possible for that piece of trash to be able to emit such a charm?
2023-05-28 03:29:15 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-28 03:29:17 | INFO | fairseq.tasks.translation | example hypothesis: How did Wang Wenhao find the news agency? The chief editor should have called her to inform her not to come to the news agency, but the three of them... were plotting against her!
2023-05-28 03:29:17 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-28 03:29:23 | INFO | fairseq.tasks.translation | example hypothesis: I was delighted to hear Teacher Di’s praise. I retracted the energy ball with my left hand and shot out a beam of light towards Teacher Zhen with my right hand. The beam sword actually hit me successfully. I was shocked, but when I looked carefully, I realized that it was just an afterimage. Teacher Zhen had already moved to my back and shouted, “Berserk Space!”
2023-05-28 03:29:23 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-28 03:29:28 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Originally, we proposed a competition of three games and two wins, but they said it wasn’t fair, because we have Teacher Di and Teacher Zhen, who are ranked higher than them, and they proposed three wins in five games. Since we were the ones who suggested the competition, we can only listen to them in the end. Three days later, we will have a secret competition in the Royal Coliseum. The competition will be held in three days, and
2023-05-28 03:29:28 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-28 03:29:31 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Zhen used the rank 7 light element spell, Lightning Combo. I rarely used this spell because I didn’t have good control over it. Teacher Zhen released nine lightning bolts and surrounded me, forming a simple formation that prevented me from escaping in a short distance. Then, the lightning bolts exploded and formed a powerful attack power.
2023-05-28 03:29:31 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-28 03:29:37 | INFO | fairseq.tasks.translation | example hypothesis: As soon as Ma Ke and the two teachers walked to the other side, Teacher Zhen sent me a small dimensional slash. As expected of the number one magician in the continent. The powerful suction force from his small dimensional slash was much stronger than my own. A small spatial crack appeared beside me, and a powerful suction force immediately swept over. This was the first time I’ve seen a small spatial crack. It was a spatial crack in the middle of the courtyard. When I saw it, I couldn’t help but feel a chill down my spine. I didn’t expect that I’d be able to make a breakthrough in these two days.
2023-05-28 03:29:37 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-28 03:29:38 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.452 | nll_loss 2.845 | ppl 7.18 | bleu 17.7 | wps 874.2 | wpb 2420.8 | bsz 84.5 | num_updates 80093 | best_bleu 17.84
2023-05-28 03:29:38 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-28 03:29:39 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/mega-1-1-0.2-sf[zh-en]/checkpoint_last.pt (epoch 12 @ 80093 updates, score 17.7) (writing took 1.214674917049706 seconds)
2023-05-28 03:29:39 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-05-28 03:29:39 | INFO | train | epoch 012 | loss 4.182 | nll_loss 2.563 | ppl 5.91 | wps 28638.5 | ups 0.5 | wpb 57190.4 | bsz 1477.4 | num_updates 80093 | lr 0.000223477 | gnorm 0.223 | clip 100 | loss_scale 7 | train_wall 12958 | wall 160133
2023-05-28 03:29:39 | INFO | fairseq.trainer | begin training epoch 13
2023-05-28 03:30:01 | INFO | train_inner | epoch 013:      7 / 6686 loss=4.191, nll_loss=2.574, ppl=5.96, wps=19234.2, ups=0.34, wpb=56912.2, bsz=1469.4, num_updates=80100, lr=0.000223467, gnorm=0.221, clip=100, loss_scale=9, train_wall=194, wall=160155
2023-05-28 03:33:28 | INFO | train_inner | epoch 013:    107 / 6686 loss=4.148, nll_loss=2.524, ppl=5.75, wps=27770.1, ups=0.48, wpb=57321.9, bsz=1457.1, num_updates=80200, lr=0.000223328, gnorm=0.213, clip=100, loss_scale=8, train_wall=195, wall=160362
2023-05-28 03:36:50 | INFO | train_inner | epoch 013:    207 / 6686 loss=4.151, nll_loss=2.528, ppl=5.77, wps=28349.3, ups=0.5, wpb=57249.4, bsz=1486.7, num_updates=80300, lr=0.000223189, gnorm=0.22, clip=100, loss_scale=8, train_wall=195, wall=160564
2023-05-28 03:40:08 | INFO | train_inner | epoch 013:    307 / 6686 loss=4.157, nll_loss=2.535, ppl=5.8, wps=28799.1, ups=0.5, wpb=57123.5, bsz=1493.4, num_updates=80400, lr=0.00022305, gnorm=0.221, clip=100, loss_scale=8, train_wall=194, wall=160762
2023-05-28 03:43:26 | INFO | train_inner | epoch 013:    407 / 6686 loss=4.171, nll_loss=2.55, ppl=5.86, wps=28862.4, ups=0.5, wpb=57221.6, bsz=1469.9, num_updates=80500, lr=0.000222911, gnorm=0.218, clip=100, loss_scale=8, train_wall=194, wall=160960
2023-05-28 03:46:13 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-28 03:46:46 | INFO | train_inner | epoch 013:    508 / 6686 loss=4.154, nll_loss=2.531, ppl=5.78, wps=28761.3, ups=0.5, wpb=57466, bsz=1504.7, num_updates=80600, lr=0.000222773, gnorm=0.214, clip=100, loss_scale=9, train_wall=196, wall=161160
2023-05-28 03:50:03 | INFO | train_inner | epoch 013:    608 / 6686 loss=4.169, nll_loss=2.549, ppl=5.85, wps=29004.7, ups=0.51, wpb=57138.6, bsz=1456.2, num_updates=80700, lr=0.000222635, gnorm=0.228, clip=100, loss_scale=8, train_wall=193, wall=161357
2023-05-28 03:53:21 | INFO | train_inner | epoch 013:    708 / 6686 loss=4.175, nll_loss=2.555, ppl=5.88, wps=28928.1, ups=0.51, wpb=57111.2, bsz=1459.3, num_updates=80800, lr=0.000222497, gnorm=0.228, clip=100, loss_scale=8, train_wall=194, wall=161554
2023-05-28 03:56:38 | INFO | train_inner | epoch 013:    808 / 6686 loss=4.17, nll_loss=2.55, ppl=5.86, wps=29062.1, ups=0.51, wpb=57353.2, bsz=1474.5, num_updates=80900, lr=0.00022236, gnorm=0.216, clip=100, loss_scale=8, train_wall=193, wall=161752
2023-05-28 03:59:55 | INFO | train_inner | epoch 013:    908 / 6686 loss=4.17, nll_loss=2.55, ppl=5.86, wps=28976.1, ups=0.51, wpb=57130.7, bsz=1479.7, num_updates=81000, lr=0.000222222, gnorm=0.221, clip=100, loss_scale=8, train_wall=193, wall=161949
2023-05-28 04:03:12 | INFO | train_inner | epoch 013:   1008 / 6686 loss=4.162, nll_loss=2.54, ppl=5.82, wps=29027.2, ups=0.51, wpb=57205.4, bsz=1490.3, num_updates=81100, lr=0.000222085, gnorm=0.235, clip=100, loss_scale=8, train_wall=193, wall=162146
2023-05-28 04:03:18 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-28 04:06:32 | INFO | train_inner | epoch 013:   1109 / 6686 loss=4.16, nll_loss=2.539, ppl=5.81, wps=28724.6, ups=0.5, wpb=57337.2, bsz=1479.6, num_updates=81200, lr=0.000221948, gnorm=0.229, clip=100, loss_scale=8, train_wall=196, wall=162346
2023-05-28 04:09:50 | INFO | train_inner | epoch 013:   1209 / 6686 loss=4.172, nll_loss=2.552, ppl=5.86, wps=28887.3, ups=0.51, wpb=57134, bsz=1493.8, num_updates=81300, lr=0.000221812, gnorm=0.216, clip=100, loss_scale=8, train_wall=194, wall=162543
2023-05-28 04:13:07 | INFO | train_inner | epoch 013:   1309 / 6686 loss=4.169, nll_loss=2.548, ppl=5.85, wps=29031.1, ups=0.51, wpb=57386.9, bsz=1467.5, num_updates=81400, lr=0.000221676, gnorm=0.213, clip=100, loss_scale=8, train_wall=194, wall=162741
2023-05-28 04:16:24 | INFO | train_inner | epoch 013:   1409 / 6686 loss=4.178, nll_loss=2.559, ppl=5.89, wps=28962.4, ups=0.51, wpb=57100.4, bsz=1448.3, num_updates=81500, lr=0.00022154, gnorm=0.226, clip=100, loss_scale=8, train_wall=193, wall=162938
2023-05-28 04:19:42 | INFO | train_inner | epoch 013:   1509 / 6686 loss=4.167, nll_loss=2.546, ppl=5.84, wps=28920.4, ups=0.51, wpb=57127.3, bsz=1510.1, num_updates=81600, lr=0.000221404, gnorm=0.223, clip=100, loss_scale=8, train_wall=194, wall=163136
2023-05-28 04:20:43 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-28 04:23:01 | INFO | train_inner | epoch 013:   1610 / 6686 loss=4.176, nll_loss=2.557, ppl=5.88, wps=28711.1, ups=0.5, wpb=57062.8, bsz=1463.2, num_updates=81700, lr=0.000221268, gnorm=0.227, clip=100, loss_scale=9, train_wall=195, wall=163335
2023-05-28 04:26:19 | INFO | train_inner | epoch 013:   1710 / 6686 loss=4.167, nll_loss=2.547, ppl=5.84, wps=28910.3, ups=0.51, wpb=57230, bsz=1481.7, num_updates=81800, lr=0.000221133, gnorm=0.221, clip=100, loss_scale=8, train_wall=194, wall=163533
2023-05-28 04:29:36 | INFO | train_inner | epoch 013:   1810 / 6686 loss=4.18, nll_loss=2.561, ppl=5.9, wps=28877.3, ups=0.51, wpb=57051.3, bsz=1464.9, num_updates=81900, lr=0.000220998, gnorm=0.226, clip=100, loss_scale=8, train_wall=194, wall=163730
2023-05-28 04:32:54 | INFO | train_inner | epoch 013:   1910 / 6686 loss=4.179, nll_loss=2.561, ppl=5.9, wps=28981.1, ups=0.51, wpb=57235.1, bsz=1473.1, num_updates=82000, lr=0.000220863, gnorm=0.222, clip=100, loss_scale=8, train_wall=194, wall=163928
2023-05-28 04:36:11 | INFO | train_inner | epoch 013:   2010 / 6686 loss=4.177, nll_loss=2.558, ppl=5.89, wps=28880.7, ups=0.51, wpb=57045.5, bsz=1458, num_updates=82100, lr=0.000220729, gnorm=0.218, clip=100, loss_scale=8, train_wall=194, wall=164125
2023-05-28 04:37:36 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-28 04:39:31 | INFO | train_inner | epoch 013:   2111 / 6686 loss=4.166, nll_loss=2.546, ppl=5.84, wps=28660.1, ups=0.5, wpb=57245.9, bsz=1480.6, num_updates=82200, lr=0.000220594, gnorm=0.227, clip=100, loss_scale=8, train_wall=196, wall=164325
2023-05-28 04:42:48 | INFO | train_inner | epoch 013:   2211 / 6686 loss=4.169, nll_loss=2.549, ppl=5.85, wps=28915.9, ups=0.51, wpb=57097.8, bsz=1474.5, num_updates=82300, lr=0.00022046, gnorm=0.221, clip=100, loss_scale=8, train_wall=194, wall=164522
2023-05-28 04:44:15 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2023-05-28 04:46:07 | INFO | train_inner | epoch 013:   2312 / 6686 loss=4.165, nll_loss=2.545, ppl=5.83, wps=28756.3, ups=0.5, wpb=57150.7, bsz=1465.7, num_updates=82400, lr=0.000220326, gnorm=0.231, clip=100, loss_scale=6, train_wall=195, wall=164721
2023-05-28 04:49:26 | INFO | train_inner | epoch 013:   2412 / 6686 loss=4.17, nll_loss=2.55, ppl=5.85, wps=28803.9, ups=0.5, wpb=57151.7, bsz=1489.8, num_updates=82500, lr=0.000220193, gnorm=0.22, clip=100, loss_scale=4, train_wall=195, wall=164920
2023-05-28 04:52:44 | INFO | train_inner | epoch 013:   2512 / 6686 loss=4.174, nll_loss=2.554, ppl=5.87, wps=28880.8, ups=0.5, wpb=57199.5, bsz=1463.5, num_updates=82600, lr=0.000220059, gnorm=0.213, clip=100, loss_scale=4, train_wall=194, wall=165118
2023-05-28 04:56:02 | INFO | train_inner | epoch 013:   2612 / 6686 loss=4.173, nll_loss=2.553, ppl=5.87, wps=28886.4, ups=0.51, wpb=57132.6, bsz=1480.7, num_updates=82700, lr=0.000219926, gnorm=0.22, clip=100, loss_scale=4, train_wall=194, wall=165315
2023-05-28 04:59:19 | INFO | train_inner | epoch 013:   2712 / 6686 loss=4.18, nll_loss=2.562, ppl=5.9, wps=28957.8, ups=0.51, wpb=57334.7, bsz=1483.1, num_updates=82800, lr=0.000219793, gnorm=0.225, clip=100, loss_scale=4, train_wall=194, wall=165513
2023-05-28 05:02:37 | INFO | train_inner | epoch 013:   2812 / 6686 loss=4.17, nll_loss=2.55, ppl=5.86, wps=28865, ups=0.51, wpb=57093.5, bsz=1509.8, num_updates=82900, lr=0.000219661, gnorm=0.226, clip=100, loss_scale=6, train_wall=194, wall=165711
2023-05-28 05:05:55 | INFO | train_inner | epoch 013:   2912 / 6686 loss=4.165, nll_loss=2.544, ppl=5.83, wps=28855.3, ups=0.51, wpb=56969.4, bsz=1468.2, num_updates=83000, lr=0.000219529, gnorm=0.224, clip=100, loss_scale=8, train_wall=194, wall=165909
2023-05-28 05:09:12 | INFO | train_inner | epoch 013:   3012 / 6686 loss=4.172, nll_loss=2.552, ppl=5.86, wps=29044, ups=0.51, wpb=57202, bsz=1471.5, num_updates=83100, lr=0.000219396, gnorm=0.224, clip=100, loss_scale=8, train_wall=193, wall=166106
2023-05-28 05:12:29 | INFO | train_inner | epoch 013:   3112 / 6686 loss=4.173, nll_loss=2.554, ppl=5.87, wps=28938.9, ups=0.51, wpb=57176.5, bsz=1490.9, num_updates=83200, lr=0.000219265, gnorm=0.222, clip=100, loss_scale=8, train_wall=194, wall=166303
2023-05-28 05:15:47 | INFO | train_inner | epoch 013:   3212 / 6686 loss=4.181, nll_loss=2.562, ppl=5.91, wps=28883.2, ups=0.51, wpb=57127.5, bsz=1465, num_updates=83300, lr=0.000219133, gnorm=0.221, clip=100, loss_scale=8, train_wall=194, wall=166501
2023-05-28 05:18:39 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-28 05:19:07 | INFO | train_inner | epoch 013:   3313 / 6686 loss=4.171, nll_loss=2.551, ppl=5.86, wps=28634.5, ups=0.5, wpb=57132, bsz=1484.2, num_updates=83400, lr=0.000219001, gnorm=0.215, clip=100, loss_scale=10, train_wall=196, wall=166700
2023-05-28 05:22:25 | INFO | train_inner | epoch 013:   3413 / 6686 loss=4.174, nll_loss=2.555, ppl=5.88, wps=28980.9, ups=0.5, wpb=57395.3, bsz=1483.6, num_updates=83500, lr=0.00021887, gnorm=0.224, clip=100, loss_scale=8, train_wall=194, wall=166899
2023-05-28 05:25:42 | INFO | train_inner | epoch 013:   3513 / 6686 loss=4.174, nll_loss=2.555, ppl=5.87, wps=28957.1, ups=0.51, wpb=57059.6, bsz=1491.8, num_updates=83600, lr=0.000218739, gnorm=0.215, clip=100, loss_scale=8, train_wall=193, wall=167096
2023-05-28 05:29:00 | INFO | train_inner | epoch 013:   3613 / 6686 loss=4.18, nll_loss=2.562, ppl=5.9, wps=28970.9, ups=0.51, wpb=57348.4, bsz=1470.1, num_updates=83700, lr=0.000218609, gnorm=0.229, clip=100, loss_scale=8, train_wall=194, wall=167294
2023-05-28 05:32:17 | INFO | train_inner | epoch 013:   3713 / 6686 loss=4.184, nll_loss=2.566, ppl=5.92, wps=28994.3, ups=0.51, wpb=57292.9, bsz=1466, num_updates=83800, lr=0.000218478, gnorm=0.227, clip=100, loss_scale=8, train_wall=194, wall=167491
2023-05-28 05:35:34 | INFO | train_inner | epoch 013:   3813 / 6686 loss=4.163, nll_loss=2.543, ppl=5.83, wps=28998.2, ups=0.51, wpb=57192.6, bsz=1506.6, num_updates=83900, lr=0.000218348, gnorm=0.23, clip=100, loss_scale=8, train_wall=193, wall=167688
2023-05-28 05:35:42 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-28 05:38:55 | INFO | train_inner | epoch 013:   3914 / 6686 loss=4.178, nll_loss=2.56, ppl=5.9, wps=28621.2, ups=0.5, wpb=57326.1, bsz=1493.2, num_updates=84000, lr=0.000218218, gnorm=0.228, clip=100, loss_scale=8, train_wall=197, wall=167889
2023-05-28 05:42:12 | INFO | train_inner | epoch 013:   4014 / 6686 loss=4.167, nll_loss=2.547, ppl=5.84, wps=28973.8, ups=0.51, wpb=57272.4, bsz=1482.3, num_updates=84100, lr=0.000218088, gnorm=0.221, clip=100, loss_scale=8, train_wall=194, wall=168086
2023-05-28 05:45:29 | INFO | train_inner | epoch 013:   4114 / 6686 loss=4.17, nll_loss=2.55, ppl=5.86, wps=29170.5, ups=0.51, wpb=57315.5, bsz=1475.9, num_updates=84200, lr=0.000217959, gnorm=0.218, clip=100, loss_scale=8, train_wall=193, wall=168283
2023-05-28 05:48:47 | INFO | train_inner | epoch 013:   4214 / 6686 loss=4.183, nll_loss=2.565, ppl=5.92, wps=28912.6, ups=0.5, wpb=57273.4, bsz=1473.4, num_updates=84300, lr=0.000217829, gnorm=0.22, clip=100, loss_scale=8, train_wall=194, wall=168481
2023-05-28 05:52:03 | INFO | train_inner | epoch 013:   4314 / 6686 loss=4.187, nll_loss=2.569, ppl=5.94, wps=29104.3, ups=0.51, wpb=57131.2, bsz=1466.1, num_updates=84400, lr=0.0002177, gnorm=0.226, clip=100, loss_scale=8, train_wall=193, wall=168677
2023-05-28 05:52:53 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-28 05:55:23 | INFO | train_inner | epoch 013:   4415 / 6686 loss=4.18, nll_loss=2.562, ppl=5.9, wps=28712.9, ups=0.5, wpb=57190, bsz=1483.1, num_updates=84500, lr=0.000217571, gnorm=0.227, clip=100, loss_scale=9, train_wall=195, wall=168876
2023-05-28 05:58:40 | INFO | train_inner | epoch 013:   4515 / 6686 loss=4.178, nll_loss=2.56, ppl=5.9, wps=28999.8, ups=0.51, wpb=57251.6, bsz=1485.8, num_updates=84600, lr=0.000217443, gnorm=0.233, clip=100, loss_scale=8, train_wall=194, wall=169074
2023-05-28 06:01:58 | INFO | train_inner | epoch 013:   4615 / 6686 loss=4.175, nll_loss=2.556, ppl=5.88, wps=28843.2, ups=0.5, wpb=57116.6, bsz=1471.3, num_updates=84700, lr=0.000217314, gnorm=0.226, clip=100, loss_scale=8, train_wall=194, wall=169272
2023-05-28 06:05:15 | INFO | train_inner | epoch 013:   4715 / 6686 loss=4.178, nll_loss=2.56, ppl=5.9, wps=28922.5, ups=0.51, wpb=57085.4, bsz=1473.1, num_updates=84800, lr=0.000217186, gnorm=0.229, clip=100, loss_scale=8, train_wall=194, wall=169469
2023-05-28 06:08:32 | INFO | train_inner | epoch 013:   4815 / 6686 loss=4.172, nll_loss=2.552, ppl=5.86, wps=29015.7, ups=0.51, wpb=57191.5, bsz=1479.8, num_updates=84900, lr=0.000217058, gnorm=0.232, clip=100, loss_scale=8, train_wall=193, wall=169666
2023-05-28 06:09:46 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-28 06:11:53 | INFO | train_inner | epoch 013:   4916 / 6686 loss=4.173, nll_loss=2.554, ppl=5.87, wps=28616.4, ups=0.5, wpb=57253.5, bsz=1474.6, num_updates=85000, lr=0.00021693, gnorm=0.225, clip=100, loss_scale=8, train_wall=196, wall=169866
2023-05-28 06:15:10 | INFO | train_inner | epoch 013:   5016 / 6686 loss=4.177, nll_loss=2.558, ppl=5.89, wps=28991.9, ups=0.51, wpb=57147.9, bsz=1490, num_updates=85100, lr=0.000216803, gnorm=0.223, clip=100, loss_scale=8, train_wall=193, wall=170064
2023-05-28 06:18:26 | INFO | train_inner | epoch 013:   5116 / 6686 loss=4.173, nll_loss=2.554, ppl=5.87, wps=29051.1, ups=0.51, wpb=57145.2, bsz=1455.4, num_updates=85200, lr=0.000216676, gnorm=0.224, clip=100, loss_scale=8, train_wall=193, wall=170260
2023-05-28 06:21:44 | INFO | train_inner | epoch 013:   5216 / 6686 loss=4.169, nll_loss=2.549, ppl=5.85, wps=28887, ups=0.51, wpb=57117.5, bsz=1491, num_updates=85300, lr=0.000216549, gnorm=0.217, clip=100, loss_scale=8, train_wall=194, wall=170458
2023-05-28 06:25:01 | INFO | train_inner | epoch 013:   5316 / 6686 loss=4.175, nll_loss=2.556, ppl=5.88, wps=29088.4, ups=0.51, wpb=57235.4, bsz=1482.6, num_updates=85400, lr=0.000216422, gnorm=0.222, clip=100, loss_scale=8, train_wall=193, wall=170655
2023-05-28 06:26:44 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-28 06:28:20 | INFO | train_inner | epoch 013:   5417 / 6686 loss=4.173, nll_loss=2.553, ppl=5.87, wps=28716.8, ups=0.5, wpb=57290.5, bsz=1479.1, num_updates=85500, lr=0.000216295, gnorm=0.223, clip=100, loss_scale=8, train_wall=196, wall=170854
2023-05-28 06:31:38 | INFO | train_inner | epoch 013:   5517 / 6686 loss=4.175, nll_loss=2.556, ppl=5.88, wps=28955.2, ups=0.51, wpb=57289.6, bsz=1487, num_updates=85600, lr=0.000216169, gnorm=0.221, clip=100, loss_scale=8, train_wall=194, wall=171052
2023-05-28 06:34:55 | INFO | train_inner | epoch 013:   5617 / 6686 loss=4.172, nll_loss=2.552, ppl=5.87, wps=29103.5, ups=0.51, wpb=57246.4, bsz=1475.3, num_updates=85700, lr=0.000216043, gnorm=0.218, clip=100, loss_scale=8, train_wall=193, wall=171249
2023-05-28 06:38:12 | INFO | train_inner | epoch 013:   5717 / 6686 loss=4.178, nll_loss=2.56, ppl=5.9, wps=28893.2, ups=0.51, wpb=57038.7, bsz=1476.8, num_updates=85800, lr=0.000215917, gnorm=0.22, clip=100, loss_scale=8, train_wall=194, wall=171446
2023-05-28 06:41:30 | INFO | train_inner | epoch 013:   5817 / 6686 loss=4.176, nll_loss=2.557, ppl=5.88, wps=28893.4, ups=0.51, wpb=57106.1, bsz=1484.9, num_updates=85900, lr=0.000215791, gnorm=0.224, clip=100, loss_scale=8, train_wall=194, wall=171644
2023-05-28 06:44:32 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-28 06:44:50 | INFO | train_inner | epoch 013:   5918 / 6686 loss=4.179, nll_loss=2.561, ppl=5.9, wps=28655.9, ups=0.5, wpb=57168.4, bsz=1488.5, num_updates=86000, lr=0.000215666, gnorm=0.224, clip=100, loss_scale=10, train_wall=196, wall=171843
2023-05-28 06:48:07 | INFO | train_inner | epoch 013:   6018 / 6686 loss=4.181, nll_loss=2.562, ppl=5.91, wps=28921.7, ups=0.51, wpb=57215.7, bsz=1469.7, num_updates=86100, lr=0.00021554, gnorm=0.227, clip=100, loss_scale=8, train_wall=194, wall=172041
2023-05-28 06:51:25 | INFO | train_inner | epoch 013:   6118 / 6686 loss=4.184, nll_loss=2.567, ppl=5.93, wps=28949, ups=0.51, wpb=57269.3, bsz=1473.2, num_updates=86200, lr=0.000215415, gnorm=0.223, clip=100, loss_scale=8, train_wall=194, wall=172239
2023-05-28 06:54:43 | INFO | train_inner | epoch 013:   6218 / 6686 loss=4.192, nll_loss=2.576, ppl=5.96, wps=28951.5, ups=0.51, wpb=57158.2, bsz=1449, num_updates=86300, lr=0.00021529, gnorm=0.215, clip=100, loss_scale=8, train_wall=194, wall=172436
