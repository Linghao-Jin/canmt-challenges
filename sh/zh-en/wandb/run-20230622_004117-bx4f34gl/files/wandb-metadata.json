{
    "os": "Linux-3.10.0-1160.71.1.el7.x86_64-x86_64-with-glibc2.17",
    "python": "3.9.15",
    "heartbeatAt": "2023-06-22T07:41:18.377697",
    "startedAt": "2023-06-22T07:41:17.206241",
    "docker": null,
    "cuda": null,
    "args": [
        "/project/jonmay_231/linghaoj/canmt/bwb/data/bin",
        "--user-dir",
        "/project/jonmay_231/linghaoj/reproduce/concat_models",
        "--save-dir",
        "/project/jonmay_231/linghaoj/reproduce/ckpt/mega-1-1-0.2[zh-en][new]",
        "--task",
        "document_translation",
        "-s",
        "zh",
        "-t",
        "en",
        "--arch",
        "contextual_mega",
        "--encoder-layers",
        "6",
        "--decoder-layers",
        "6",
        "--share-decoder-input-output-embed",
        "--activation-fn",
        "silu",
        "--attention-activation-fn",
        "softmax",
        "--encoder-n-dim",
        "16",
        "--encoder-chunk-size",
        "-1",
        "--normalization-type",
        "layernorm",
        "--ddp-backend",
        "c10d",
        "--optimizer",
        "adam",
        "--adam-betas",
        "(0.9, 0.98)",
        "--adam-eps",
        "1e-8",
        "--clip-norm",
        "0.1",
        "--lr",
        "1e-3",
        "--lr-scheduler",
        "inverse_sqrt",
        "--warmup-updates",
        "4000",
        "--dropout",
        "0.2",
        "--attention-dropout",
        "0.0",
        "--hidden-dropout",
        "0.0",
        "--activation-dropout",
        "0.0",
        "--weight-decay",
        "0.01",
        "--criterion",
        "label_smoothed_cross_entropy",
        "--label-smoothing",
        "0.1",
        "--max-tokens",
        "4096",
        "--update-freq",
        "16",
        "--seed",
        "42",
        "--max-update",
        "200000",
        "--eval-bleu",
        "--eval-bleu-print-samples",
        "--eval-bleu-remove-bpe",
        "sentencepiece",
        "--eval-bleu-args",
        "{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}",
        "--best-checkpoint-metric",
        "bleu",
        "--maximize-best-checkpoint-metric",
        "--no-epoch-checkpoints",
        "--keep-last-epochs",
        "5",
        "--fp16",
        "--next-sent-ctx",
        "--wandb-project",
        "reproduce-doc-mt"
    ],
    "state": "running",
    "program": "/home1/linghaoj/anaconda3/envs/env-mega/bin/fairseq-train",
    "host": "d13-07.hpc.usc.edu",
    "username": "linghaoj",
    "executable": "/home1/linghaoj/anaconda3/envs/env-mega/bin/python3.9",
    "cpu_count": 32,
    "cpu_count_logical": 32,
    "cpu_freq": {
        "current": 2100.0,
        "min": 0.0,
        "max": 0.0
    },
    "cpu_freq_per_core": [
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2100.0,
            "min": 0.0,
            "max": 0.0
        }
    ],
    "disk": {
        "total": 93.68971633911133,
        "used": 3.0391387939453125
    },
    "gpu": "Tesla V100-PCIE-32GB",
    "gpu_count": 2,
    "gpu_devices": [
        {
            "name": "Tesla V100-PCIE-32GB",
            "memory_total": 34359738368
        },
        {
            "name": "Tesla V100-PCIE-32GB",
            "memory_total": 34359738368
        }
    ],
    "memory": {
        "total": 187.37943267822266
    }
}
