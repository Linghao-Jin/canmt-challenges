2023-05-25 18:20:05 | INFO | fairseq_cli.train | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir='', seed=42, cpu=False, tpu=False, bf16=False, fp16=True, memory_efficient_bf16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir='/project/jonmay_231/linghaoj/concat-src-only/concat_models', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, checkpoint_suffix='', quantization_config_path=None, profile=False, wandb_project='reproduce-doc-mt', wandb_entity=None, wandb_id=None, criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', task='document_translation', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4096, max_sentences=None, required_batch_size_multiple=8, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', test_subset='test', validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=4096, max_sentences_valid=None, curriculum=0, distributed_world_size=2, distributed_rank=0, distributed_backend='nccl', distributed_init_method='tcp://localhost:15486', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, fast_stat_sync=False, broadcast_buffers=False, distributed_wrapper='DDP', slowmo_momentum=None, slowmo_algorithm='LocalSGD', localsgd_frequency=3, nprocs_per_node=2, arch='contextual_transformer', max_epoch=0, max_update=300000, stop_time_hours=0, clip_norm=0.1, clip_mode='total', sentence_avg=False, update_freq=[16], lr=[0.001], stop_min_lr=-1, use_bmuf=False, save_dir='/project/jonmay_231/linghaoj/reproduce/ckpt/concat-1-1-0.2-sf[zh-en]', restore_file='checkpoint_last.pt', finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=5, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='bleu', maximize_best_checkpoint_metric=True, patience=-1, no_token_positional_embeddings=False, no_cross_attention=False, cross_self_attention=False, encoder_layerdrop=0, decoder_layerdrop=0, encoder_layers_to_keep=None, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, context_loss=False, coword_dropout=0.0, coword_dropout_type='sample', multi_encoder=False, label_smoothing=0.1, adam_betas='(0.9, 0.98)', adam_eps=1e-08, weight_decay=0.01, use_old_adam=False, warmup_updates=4000, warmup_init_lr=-1, data='/project/jonmay_231/linghaoj/canmt/bwb/data/bin', source_lang='zh', target_lang='en', load_alignments=False, left_pad_source='True', left_pad_target='False', max_source_positions=1024, max_target_positions=1024, upsample_primary=1, truncate_source=False, num_batch_buckets=0, eval_bleu=True, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_tokenized_bleu=False, eval_bleu_remove_bpe='sentencepiece', eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_print_samples=True, source_context_size=1, target_context_size=1, sample_context_size=False, break_tag='<brk>', pos_drop_probs=None, next_sent_ctx=False, shuffle_sample=True, share_decoder_input_output_embed=True, dropout=0.2, no_seed_provided=False, encoder_embed_path=None, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_attention_heads=8, encoder_normalize_before=False, encoder_learned_pos=False, decoder_embed_path=None, decoder_embed_dim=512, decoder_ffn_embed_dim=2048, decoder_layers=6, decoder_attention_heads=8, decoder_normalize_before=False, decoder_learned_pos=False, attention_dropout=0.0, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_all_embeddings=False, adaptive_input=False, decoder_output_dim=512, decoder_input_dim=512, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False)
2023-05-25 18:20:05 | INFO | fairseq.tasks.translation | [zh] dictionary: 36776 types
2023-05-25 18:20:05 | INFO | fairseq.tasks.translation | [en] dictionary: 34088 types
2023-05-25 18:20:05 | INFO | fairseq.data.data_utils | loaded 2619 examples from: /project/jonmay_231/linghaoj/canmt/bwb/data/bin/valid.zh-en.zh
2023-05-25 18:20:05 | INFO | fairseq.data.data_utils | loaded 2619 examples from: /project/jonmay_231/linghaoj/canmt/bwb/data/bin/valid.zh-en.en
2023-05-25 18:20:06 | INFO | fairseq_cli.train | ContextualTransformerModel(
  (encoder): ContextualTransformerEncoder(
    (dropout_module): FairseqDropout(p=0.2)
    (embed_tokens): Embedding(36776, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout(p=0.0)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout(p=0.2)
        (activation_dropout_module): FairseqDropout(p=0.0)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout(p=0.0)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout(p=0.2)
        (activation_dropout_module): FairseqDropout(p=0.0)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout(p=0.0)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout(p=0.2)
        (activation_dropout_module): FairseqDropout(p=0.0)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout(p=0.0)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout(p=0.2)
        (activation_dropout_module): FairseqDropout(p=0.0)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout(p=0.0)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout(p=0.2)
        (activation_dropout_module): FairseqDropout(p=0.0)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout(p=0.0)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout(p=0.2)
        (activation_dropout_module): FairseqDropout(p=0.0)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): ContextualTransformerDecoder(
    (dropout_module): FairseqDropout(p=0.2)
    (embed_tokens): Embedding(34088, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout(p=0.2)
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout(p=0.0)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout(p=0.0)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout(p=0.0)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout(p=0.2)
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout(p=0.0)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout(p=0.0)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout(p=0.0)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout(p=0.2)
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout(p=0.0)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout(p=0.0)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout(p=0.0)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout(p=0.2)
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout(p=0.0)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout(p=0.0)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout(p=0.0)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout(p=0.2)
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout(p=0.0)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout(p=0.0)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout(p=0.0)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout(p=0.2)
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout(p=0.0)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout(p=0.0)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout(p=0.0)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=34088, bias=False)
  )
)
2023-05-25 18:20:06 | INFO | fairseq_cli.train | task: document_translation (ConcatTranslationTask)
2023-05-25 18:20:06 | INFO | fairseq_cli.train | model: contextual_transformer (ContextualTransformerModel)
2023-05-25 18:20:06 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2023-05-25 18:20:06 | INFO | fairseq_cli.train | num. model params: 80420864 (num. trained: 80420864)
2023-05-25 18:20:06 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2023-05-25 18:20:06 | INFO | fairseq.utils | ***********************CUDA enviroments for all 2 workers***********************
2023-05-25 18:20:06 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 44.369 GB ; name = NVIDIA A40
2023-05-25 18:20:06 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 44.369 GB ; name = NVIDIA A40
2023-05-25 18:20:06 | INFO | fairseq.utils | ***********************CUDA enviroments for all 2 workers***********************
2023-05-25 18:20:06 | INFO | fairseq_cli.train | training on 2 devices (GPUs/TPUs)
2023-05-25 18:20:06 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None
2023-05-25 18:20:06 | INFO | fairseq.trainer | no existing checkpoint found /project/jonmay_231/linghaoj/reproduce/ckpt/concat-1-1-0.2-sf[zh-en]/checkpoint_last.pt
2023-05-25 18:20:06 | INFO | fairseq.trainer | loading train data for epoch 1
2023-05-25 18:20:07 | INFO | fairseq.data.data_utils | loaded 9878328 examples from: /project/jonmay_231/linghaoj/canmt/bwb/data/bin/train.zh-en.zh
2023-05-25 18:20:10 | INFO | fairseq.data.data_utils | loaded 9878328 examples from: /project/jonmay_231/linghaoj/canmt/bwb/data/bin/train.zh-en.en
/home1/linghaoj/anaconda3/envs/env-mega/lib/python3.9/site-packages/torch/nn/parallel/distributed.py:629: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.
  warnings.warn(
2023-05-25 18:23:26 | INFO | fairseq.trainer | begin training epoch 1
2023-05-25 18:23:37 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 64.0
2023-05-25 18:23:37 | INFO | torch.nn.parallel.distributed | Reducer buckets have been rebuilt in this iteration.
2023-05-25 18:23:39 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-25 18:23:41 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-25 18:25:37 | INFO | train_inner | epoch 001:    103 / 6686 loss=13.663, nll_loss=13.424, ppl=10993.1, wps=49976.4, ups=0.87, wpb=57226.9, bsz=1488.7, num_updates=100, lr=2.5e-05, gnorm=2.389, clip=100, loss_scale=16, train_wall=109, wall=331
2023-05-25 18:27:28 | INFO | train_inner | epoch 001:    203 / 6686 loss=11.373, nll_loss=10.85, ppl=1845.23, wps=51277.2, ups=0.9, wpb=57217.4, bsz=1473.7, num_updates=200, lr=5e-05, gnorm=1.136, clip=100, loss_scale=16, train_wall=106, wall=443
2023-05-25 18:29:18 | INFO | train_inner | epoch 001:    303 / 6686 loss=10.1, nll_loss=9.342, ppl=649.01, wps=52518.8, ups=0.92, wpb=57290.2, bsz=1485.7, num_updates=300, lr=7.5e-05, gnorm=1.062, clip=100, loss_scale=16, train_wall=105, wall=552
2023-05-25 18:31:06 | INFO | train_inner | epoch 001:    403 / 6686 loss=9.549, nll_loss=8.688, ppl=412.56, wps=52538.9, ups=0.92, wpb=57106.4, bsz=1451.2, num_updates=400, lr=0.0001, gnorm=1.25, clip=100, loss_scale=16, train_wall=105, wall=660
2023-05-25 18:32:55 | INFO | train_inner | epoch 001:    503 / 6686 loss=9.123, nll_loss=8.192, ppl=292.45, wps=52675.4, ups=0.92, wpb=57195.4, bsz=1443.2, num_updates=500, lr=0.000125, gnorm=1.318, clip=100, loss_scale=16, train_wall=105, wall=769
2023-05-25 18:34:44 | INFO | train_inner | epoch 001:    603 / 6686 loss=8.799, nll_loss=7.812, ppl=224.65, wps=52654.6, ups=0.92, wpb=57279.4, bsz=1489, num_updates=600, lr=0.00015, gnorm=1.237, clip=100, loss_scale=30, train_wall=105, wall=878
2023-05-25 18:36:32 | INFO | train_inner | epoch 001:    703 / 6686 loss=8.564, nll_loss=7.536, ppl=185.61, wps=52477.9, ups=0.92, wpb=57083.1, bsz=1471.5, num_updates=700, lr=0.000175, gnorm=1.175, clip=100, loss_scale=32, train_wall=105, wall=986
2023-05-25 18:38:21 | INFO | train_inner | epoch 001:    803 / 6686 loss=8.36, nll_loss=7.299, ppl=157.43, wps=52736.7, ups=0.92, wpb=57245.1, bsz=1477, num_updates=800, lr=0.0002, gnorm=1.14, clip=100, loss_scale=32, train_wall=105, wall=1095
2023-05-25 18:40:09 | INFO | train_inner | epoch 001:    903 / 6686 loss=8.188, nll_loss=7.099, ppl=137.14, wps=52879.5, ups=0.92, wpb=57350.8, bsz=1495.3, num_updates=900, lr=0.000225, gnorm=1.103, clip=100, loss_scale=32, train_wall=105, wall=1204
2023-05-25 18:41:58 | INFO | train_inner | epoch 001:   1003 / 6686 loss=8.042, nll_loss=6.929, ppl=121.82, wps=52723.3, ups=0.92, wpb=57184.1, bsz=1488.3, num_updates=1000, lr=0.00025, gnorm=1.085, clip=100, loss_scale=32, train_wall=105, wall=1312
2023-05-25 18:43:04 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-25 18:43:48 | INFO | train_inner | epoch 001:   1104 / 6686 loss=7.907, nll_loss=6.773, ppl=109.35, wps=52247.1, ups=0.91, wpb=57304.9, bsz=1481.8, num_updates=1100, lr=0.000275, gnorm=1.023, clip=100, loss_scale=44, train_wall=106, wall=1422
2023-05-25 18:45:36 | INFO | train_inner | epoch 001:   1204 / 6686 loss=7.775, nll_loss=6.62, ppl=98.33, wps=52805.2, ups=0.92, wpb=57235.3, bsz=1481.4, num_updates=1200, lr=0.0003, gnorm=0.942, clip=100, loss_scale=32, train_wall=105, wall=1530
2023-05-25 18:47:24 | INFO | train_inner | epoch 001:   1304 / 6686 loss=7.659, nll_loss=6.485, ppl=89.57, wps=52886.5, ups=0.92, wpb=57351.3, bsz=1490.1, num_updates=1300, lr=0.000325, gnorm=0.935, clip=100, loss_scale=32, train_wall=105, wall=1638
2023-05-25 18:49:13 | INFO | train_inner | epoch 001:   1404 / 6686 loss=7.56, nll_loss=6.371, ppl=82.74, wps=52656.8, ups=0.92, wpb=57345.6, bsz=1501, num_updates=1400, lr=0.00035, gnorm=0.871, clip=100, loss_scale=32, train_wall=105, wall=1747
2023-05-25 18:51:02 | INFO | train_inner | epoch 001:   1504 / 6686 loss=7.471, nll_loss=6.267, ppl=77.01, wps=52690.1, ups=0.92, wpb=57161.2, bsz=1486.6, num_updates=1500, lr=0.000375, gnorm=0.834, clip=100, loss_scale=32, train_wall=105, wall=1856
2023-05-25 18:52:34 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-25 18:52:51 | INFO | train_inner | epoch 001:   1605 / 6686 loss=7.369, nll_loss=6.149, ppl=70.97, wps=52226.3, ups=0.91, wpb=57264.5, bsz=1483, num_updates=1600, lr=0.0004, gnorm=0.796, clip=100, loss_scale=36, train_wall=106, wall=1966
2023-05-25 18:54:40 | INFO | train_inner | epoch 001:   1705 / 6686 loss=7.27, nll_loss=6.035, ppl=65.59, wps=52709.8, ups=0.92, wpb=57300.7, bsz=1486.2, num_updates=1700, lr=0.000425, gnorm=0.777, clip=100, loss_scale=32, train_wall=105, wall=2074
2023-05-25 18:56:28 | INFO | train_inner | epoch 001:   1805 / 6686 loss=7.18, nll_loss=5.931, ppl=61.01, wps=52934.9, ups=0.93, wpb=57164, bsz=1443.8, num_updates=1800, lr=0.00045, gnorm=0.76, clip=100, loss_scale=32, train_wall=104, wall=2182
2023-05-25 18:58:17 | INFO | train_inner | epoch 001:   1905 / 6686 loss=7.066, nll_loss=5.799, ppl=55.68, wps=52688.3, ups=0.92, wpb=57280, bsz=1462, num_updates=1900, lr=0.000475, gnorm=0.754, clip=100, loss_scale=32, train_wall=105, wall=2291
2023-05-25 19:00:05 | INFO | train_inner | epoch 001:   2005 / 6686 loss=6.932, nll_loss=5.647, ppl=50.09, wps=52756, ups=0.92, wpb=57305, bsz=1514.8, num_updates=2000, lr=0.0005, gnorm=0.75, clip=100, loss_scale=32, train_wall=105, wall=2400
2023-05-25 19:01:51 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-25 19:01:55 | INFO | train_inner | epoch 001:   2106 / 6686 loss=6.787, nll_loss=5.479, ppl=44.61, wps=52364.1, ups=0.92, wpb=57120.8, bsz=1474.2, num_updates=2100, lr=0.000525, gnorm=0.76, clip=100, loss_scale=33, train_wall=105, wall=2509
2023-05-25 19:03:43 | INFO | train_inner | epoch 001:   2206 / 6686 loss=6.632, nll_loss=5.302, ppl=39.46, wps=52734.3, ups=0.92, wpb=57288.6, bsz=1488.4, num_updates=2200, lr=0.00055, gnorm=0.768, clip=100, loss_scale=32, train_wall=105, wall=2617
2023-05-25 19:04:28 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-25 19:05:33 | INFO | train_inner | epoch 001:   2307 / 6686 loss=6.51, nll_loss=5.161, ppl=35.79, wps=52273.6, ups=0.91, wpb=57146.4, bsz=1474.9, num_updates=2300, lr=0.000575, gnorm=0.781, clip=100, loss_scale=22, train_wall=106, wall=2727
2023-05-25 19:07:21 | INFO | train_inner | epoch 001:   2407 / 6686 loss=6.368, nll_loss=4.998, ppl=31.96, wps=52620.1, ups=0.92, wpb=57143.5, bsz=1479.7, num_updates=2400, lr=0.0006, gnorm=0.723, clip=100, loss_scale=16, train_wall=105, wall=2835
2023-05-25 19:09:10 | INFO | train_inner | epoch 001:   2507 / 6686 loss=6.227, nll_loss=4.837, ppl=28.57, wps=52589.8, ups=0.92, wpb=57026.8, bsz=1478.6, num_updates=2500, lr=0.000625, gnorm=0.746, clip=100, loss_scale=16, train_wall=105, wall=2944
2023-05-25 19:10:58 | INFO | train_inner | epoch 001:   2607 / 6686 loss=6.071, nll_loss=4.658, ppl=25.24, wps=52867.8, ups=0.92, wpb=57404.4, bsz=1499, num_updates=2600, lr=0.00065, gnorm=0.712, clip=100, loss_scale=16, train_wall=105, wall=3052
2023-05-25 19:12:47 | INFO | train_inner | epoch 001:   2707 / 6686 loss=5.951, nll_loss=4.521, ppl=22.95, wps=52672.9, ups=0.92, wpb=57245.5, bsz=1504.2, num_updates=2700, lr=0.000675, gnorm=0.679, clip=100, loss_scale=16, train_wall=105, wall=3161
2023-05-25 19:14:35 | INFO | train_inner | epoch 001:   2807 / 6686 loss=5.872, nll_loss=4.43, ppl=21.56, wps=52916.5, ups=0.92, wpb=57459.5, bsz=1453.9, num_updates=2800, lr=0.0007, gnorm=0.659, clip=100, loss_scale=24, train_wall=105, wall=3270
2023-05-25 19:15:26 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-25 19:16:25 | INFO | train_inner | epoch 001:   2908 / 6686 loss=5.775, nll_loss=4.32, ppl=19.97, wps=52310.9, ups=0.91, wpb=57198.1, bsz=1462.4, num_updates=2900, lr=0.000725, gnorm=0.615, clip=100, loss_scale=23, train_wall=106, wall=3379
2023-05-25 19:18:13 | INFO | train_inner | epoch 001:   3008 / 6686 loss=5.693, nll_loss=4.226, ppl=18.72, wps=52742, ups=0.92, wpb=57199.6, bsz=1480.8, num_updates=3000, lr=0.00075, gnorm=0.597, clip=100, loss_scale=16, train_wall=105, wall=3487
2023-05-25 19:20:02 | INFO | train_inner | epoch 001:   3108 / 6686 loss=5.624, nll_loss=4.148, ppl=17.72, wps=52817.8, ups=0.92, wpb=57212.5, bsz=1492.2, num_updates=3100, lr=0.000775, gnorm=0.577, clip=100, loss_scale=16, train_wall=105, wall=3596
2023-05-25 19:21:50 | INFO | train_inner | epoch 001:   3208 / 6686 loss=5.575, nll_loss=4.092, ppl=17.06, wps=52629.4, ups=0.92, wpb=57013.2, bsz=1467.9, num_updates=3200, lr=0.0008, gnorm=0.557, clip=100, loss_scale=16, train_wall=105, wall=3704
2023-05-25 19:23:39 | INFO | train_inner | epoch 001:   3308 / 6686 loss=5.507, nll_loss=4.016, ppl=16.18, wps=52749.3, ups=0.92, wpb=57317.6, bsz=1476.2, num_updates=3300, lr=0.000825, gnorm=0.538, clip=100, loss_scale=16, train_wall=105, wall=3813
2023-05-25 19:25:08 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-25 19:25:28 | INFO | train_inner | epoch 001:   3409 / 6686 loss=5.467, nll_loss=3.972, ppl=15.69, wps=52232, ups=0.91, wpb=57172.1, bsz=1476.7, num_updates=3400, lr=0.00085, gnorm=0.527, clip=100, loss_scale=20, train_wall=106, wall=3922
2023-05-25 19:27:16 | INFO | train_inner | epoch 001:   3509 / 6686 loss=5.417, nll_loss=3.916, ppl=15.09, wps=52792.1, ups=0.92, wpb=57180.2, bsz=1461.5, num_updates=3500, lr=0.000875, gnorm=0.532, clip=100, loss_scale=16, train_wall=105, wall=4030
2023-05-25 19:29:05 | INFO | train_inner | epoch 001:   3609 / 6686 loss=5.39, nll_loss=3.886, ppl=14.78, wps=52628.9, ups=0.92, wpb=57152.8, bsz=1465.9, num_updates=3600, lr=0.0009, gnorm=0.501, clip=100, loss_scale=16, train_wall=105, wall=4139
2023-05-25 19:30:54 | INFO | train_inner | epoch 001:   3709 / 6686 loss=5.358, nll_loss=3.85, ppl=14.42, wps=52639.8, ups=0.92, wpb=57227.4, bsz=1489.1, num_updates=3700, lr=0.000925, gnorm=0.506, clip=100, loss_scale=16, train_wall=105, wall=4248
2023-05-25 19:32:42 | INFO | train_inner | epoch 001:   3809 / 6686 loss=5.319, nll_loss=3.807, ppl=14, wps=52728, ups=0.92, wpb=57197.5, bsz=1462.2, num_updates=3800, lr=0.00095, gnorm=0.491, clip=100, loss_scale=16, train_wall=105, wall=4356
2023-05-25 19:34:30 | INFO | train_inner | epoch 001:   3909 / 6686 loss=5.293, nll_loss=3.779, ppl=13.72, wps=52705.9, ups=0.93, wpb=56815.4, bsz=1461.8, num_updates=3900, lr=0.000975, gnorm=0.483, clip=100, loss_scale=17, train_wall=104, wall=4464
2023-05-25 19:34:39 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-25 19:36:19 | INFO | train_inner | epoch 001:   4010 / 6686 loss=5.266, nll_loss=3.749, ppl=13.45, wps=52155.7, ups=0.91, wpb=57099.2, bsz=1444.6, num_updates=4000, lr=0.001, gnorm=0.479, clip=100, loss_scale=17, train_wall=106, wall=4574
2023-05-25 19:38:08 | INFO | train_inner | epoch 001:   4110 / 6686 loss=5.232, nll_loss=3.711, ppl=13.1, wps=52865.9, ups=0.92, wpb=57208.7, bsz=1500.4, num_updates=4100, lr=0.00098773, gnorm=0.459, clip=100, loss_scale=16, train_wall=105, wall=4682
2023-05-25 19:39:56 | INFO | train_inner | epoch 001:   4210 / 6686 loss=5.23, nll_loss=3.709, ppl=13.08, wps=52610.1, ups=0.92, wpb=57004.4, bsz=1481.4, num_updates=4200, lr=0.0009759, gnorm=0.45, clip=100, loss_scale=16, train_wall=105, wall=4790
2023-05-25 19:41:44 | INFO | train_inner | epoch 001:   4310 / 6686 loss=5.189, nll_loss=3.664, ppl=12.68, wps=52698.5, ups=0.92, wpb=57127.4, bsz=1496.5, num_updates=4300, lr=0.000964486, gnorm=0.441, clip=100, loss_scale=16, train_wall=105, wall=4899
2023-05-25 19:43:33 | INFO | train_inner | epoch 001:   4410 / 6686 loss=5.155, nll_loss=3.627, ppl=12.35, wps=52816.9, ups=0.92, wpb=57316.4, bsz=1484.2, num_updates=4400, lr=0.000953463, gnorm=0.433, clip=100, loss_scale=16, train_wall=105, wall=5007
2023-05-25 19:45:21 | INFO | train_inner | epoch 001:   4510 / 6686 loss=5.134, nll_loss=3.604, ppl=12.16, wps=52698, ups=0.92, wpb=57085, bsz=1475.8, num_updates=4500, lr=0.000942809, gnorm=0.418, clip=100, loss_scale=29, train_wall=105, wall=5115
2023-05-25 19:47:10 | INFO | train_inner | epoch 001:   4610 / 6686 loss=5.117, nll_loss=3.585, ppl=12, wps=52770.6, ups=0.92, wpb=57219.9, bsz=1482.2, num_updates=4600, lr=0.000932505, gnorm=0.427, clip=100, loss_scale=32, train_wall=105, wall=5224
2023-05-25 19:48:58 | INFO | train_inner | epoch 001:   4710 / 6686 loss=5.098, nll_loss=3.564, ppl=11.83, wps=52670.2, ups=0.92, wpb=57157.8, bsz=1473.4, num_updates=4700, lr=0.000922531, gnorm=0.416, clip=100, loss_scale=32, train_wall=105, wall=5332
2023-05-25 19:50:47 | INFO | train_inner | epoch 001:   4810 / 6686 loss=5.07, nll_loss=3.534, ppl=11.58, wps=52753.9, ups=0.92, wpb=57284, bsz=1478.6, num_updates=4800, lr=0.000912871, gnorm=0.411, clip=100, loss_scale=32, train_wall=105, wall=5441
2023-05-25 19:52:35 | INFO | train_inner | epoch 001:   4910 / 6686 loss=5.055, nll_loss=3.517, ppl=11.45, wps=52797.3, ups=0.92, wpb=57160.6, bsz=1474.8, num_updates=4900, lr=0.000903508, gnorm=0.391, clip=100, loss_scale=32, train_wall=105, wall=5549
2023-05-25 19:53:16 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-25 19:54:24 | INFO | train_inner | epoch 001:   5011 / 6686 loss=5.038, nll_loss=3.499, ppl=11.3, wps=52234.5, ups=0.91, wpb=57139.4, bsz=1464.6, num_updates=5000, lr=0.000894427, gnorm=0.406, clip=100, loss_scale=34, train_wall=106, wall=5659
2023-05-25 19:56:13 | INFO | train_inner | epoch 001:   5111 / 6686 loss=5.022, nll_loss=3.481, ppl=11.17, wps=52789.8, ups=0.92, wpb=57097.7, bsz=1464.7, num_updates=5100, lr=0.000885615, gnorm=0.383, clip=100, loss_scale=32, train_wall=104, wall=5767
2023-05-25 19:58:01 | INFO | train_inner | epoch 001:   5211 / 6686 loss=5.005, nll_loss=3.462, ppl=11.02, wps=52797.8, ups=0.92, wpb=57279, bsz=1483, num_updates=5200, lr=0.000877058, gnorm=0.379, clip=100, loss_scale=32, train_wall=105, wall=5875
2023-05-25 19:59:49 | INFO | train_inner | epoch 001:   5311 / 6686 loss=4.99, nll_loss=3.445, ppl=10.89, wps=52689.8, ups=0.92, wpb=57074.7, bsz=1494.7, num_updates=5300, lr=0.000868744, gnorm=0.374, clip=100, loss_scale=32, train_wall=105, wall=5984
2023-05-25 20:01:38 | INFO | train_inner | epoch 001:   5411 / 6686 loss=4.976, nll_loss=3.431, ppl=10.79, wps=52819.7, ups=0.93, wpb=57092.3, bsz=1476.1, num_updates=5400, lr=0.000860663, gnorm=0.385, clip=100, loss_scale=32, train_wall=104, wall=6092
2023-05-25 20:03:26 | INFO | train_inner | epoch 001:   5511 / 6686 loss=4.963, nll_loss=3.417, ppl=10.68, wps=52874, ups=0.92, wpb=57493.1, bsz=1451, num_updates=5500, lr=0.000852803, gnorm=0.37, clip=100, loss_scale=49, train_wall=105, wall=6200
2023-05-25 20:03:32 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-25 20:05:16 | INFO | train_inner | epoch 001:   5612 / 6686 loss=4.95, nll_loss=3.402, ppl=10.57, wps=52163.3, ups=0.92, wpb=56994.8, bsz=1459.4, num_updates=5600, lr=0.000845154, gnorm=0.372, clip=100, loss_scale=33, train_wall=106, wall=6310
2023-05-25 20:07:04 | INFO | train_inner | epoch 001:   5712 / 6686 loss=4.935, nll_loss=3.385, ppl=10.45, wps=52724.4, ups=0.92, wpb=57091.4, bsz=1479.4, num_updates=5700, lr=0.000837708, gnorm=0.384, clip=100, loss_scale=32, train_wall=105, wall=6418
2023-05-25 20:08:53 | INFO | train_inner | epoch 001:   5812 / 6686 loss=4.908, nll_loss=3.356, ppl=10.24, wps=52792.7, ups=0.92, wpb=57377.7, bsz=1486.1, num_updates=5800, lr=0.000830455, gnorm=0.369, clip=100, loss_scale=32, train_wall=105, wall=6527
2023-05-25 20:10:41 | INFO | train_inner | epoch 001:   5912 / 6686 loss=4.909, nll_loss=3.357, ppl=10.25, wps=52701.7, ups=0.92, wpb=57301.6, bsz=1492.3, num_updates=5900, lr=0.000823387, gnorm=0.361, clip=100, loss_scale=32, train_wall=105, wall=6635
2023-05-25 20:12:30 | INFO | train_inner | epoch 001:   6012 / 6686 loss=4.901, nll_loss=3.349, ppl=10.19, wps=52714.9, ups=0.92, wpb=57128.2, bsz=1476.2, num_updates=6000, lr=0.000816497, gnorm=0.353, clip=100, loss_scale=32, train_wall=105, wall=6744
2023-05-25 20:13:18 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-25 20:14:19 | INFO | train_inner | epoch 001:   6113 / 6686 loss=4.888, nll_loss=3.334, ppl=10.08, wps=52377.1, ups=0.92, wpb=57237.4, bsz=1471.6, num_updates=6100, lr=0.000809776, gnorm=0.356, clip=100, loss_scale=41, train_wall=106, wall=6853
2023-05-25 20:16:07 | INFO | train_inner | epoch 001:   6213 / 6686 loss=4.886, nll_loss=3.333, ppl=10.08, wps=52699.9, ups=0.92, wpb=57079.8, bsz=1456.2, num_updates=6200, lr=0.000803219, gnorm=0.355, clip=100, loss_scale=32, train_wall=105, wall=6961
2023-05-25 20:17:56 | INFO | train_inner | epoch 001:   6313 / 6686 loss=4.863, nll_loss=3.307, ppl=9.9, wps=52765.2, ups=0.92, wpb=57190.7, bsz=1489.3, num_updates=6300, lr=0.000796819, gnorm=0.357, clip=100, loss_scale=32, train_wall=105, wall=7070
2023-05-25 20:19:44 | INFO | train_inner | epoch 001:   6413 / 6686 loss=4.851, nll_loss=3.294, ppl=9.81, wps=52830.3, ups=0.92, wpb=57198.3, bsz=1500.5, num_updates=6400, lr=0.000790569, gnorm=0.347, clip=100, loss_scale=32, train_wall=105, wall=7178
2023-05-25 20:21:32 | INFO | train_inner | epoch 001:   6513 / 6686 loss=4.865, nll_loss=3.31, ppl=9.92, wps=52896.9, ups=0.93, wpb=57141.8, bsz=1448, num_updates=6500, lr=0.000784465, gnorm=0.358, clip=100, loss_scale=32, train_wall=104, wall=7286
2023-05-25 20:22:46 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-25 20:23:21 | INFO | train_inner | epoch 001:   6614 / 6686 loss=4.841, nll_loss=3.283, ppl=9.73, wps=52190.4, ups=0.92, wpb=57016.4, bsz=1497.4, num_updates=6600, lr=0.000778499, gnorm=0.339, clip=100, loss_scale=36, train_wall=105, wall=7395
2023-05-25 20:24:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-25 20:24:43 | INFO | fairseq.tasks.translation | example hypothesis: Why? Why?
2023-05-25 20:24:43 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-25 20:24:44 | INFO | fairseq.tasks.translation | example hypothesis: I’ll let you lose your pants in a while!
2023-05-25 20:24:44 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-25 20:24:44 | INFO | fairseq.tasks.translation | example hypothesis: Shen Liangchuan heaved a sigh of relief when she heard her voice, “I’ll call you in the same room!”
2023-05-25 20:24:44 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-25 20:24:45 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved her hand and entered the elevator.
2023-05-25 20:24:45 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-25 20:24:46 | INFO | fairseq.tasks.translation | example hypothesis: She looked up and saw Song Cheng standing in the distance!
2023-05-25 20:24:46 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-25 20:24:46 | INFO | fairseq.tasks.translation | example hypothesis: Song Cheng patted his chest. “I’m scared to death! Where’s Wang Chuan?”
2023-05-25 20:24:46 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-25 20:24:47 | INFO | fairseq.tasks.translation | example hypothesis: I said, “No, I can’t eat it.”
2023-05-25 20:24:47 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-25 20:24:48 | INFO | fairseq.tasks.translation | example hypothesis: Wang Wen Hao’s he didn’t believe it at first, but Wang Wen Hao insisted on Wang Wen Hao’s words.
2023-05-25 20:24:48 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-25 20:24:49 | INFO | fairseq.tasks.translation | example hypothesis: With his status, even if Baili Hongzhuang didn’t treat him, he still had to treat him!
2023-05-25 20:24:49 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-25 20:24:50 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian: “Mr. Shen, I’ve left too much blood, my brain is lacking in oxygen, so I can’t think of it. Or you can give me a reminder, right?”
2023-05-25 20:24:50 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-25 20:24:51 | INFO | fairseq.tasks.translation | example hypothesis: He did not know why this matter had spread to so many people. Since he could not conceal it, he decided to just say it out loud.
2023-05-25 20:24:51 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-25 20:24:52 | INFO | fairseq.tasks.translation | example hypothesis: She deliberately lowered her voice, but she could not conceal the viciousness and cruelty in her tone.
2023-05-25 20:24:52 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-25 20:24:52 | INFO | fairseq.tasks.translation | example hypothesis: Different levels of beast pets had the same strength, but beast pets were precious and rare. It was impossible for ordinary people to possess them. Even the officials could not possess them.
2023-05-25 20:24:52 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-25 20:24:53 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chixia gritted her teeth and cursed.
2023-05-25 20:24:53 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-25 20:24:54 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang was well-hidden, Di Beichen could still see the ripple in her eyes, and a trace of warmth appeared in his eyes.
2023-05-25 20:24:54 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-25 20:24:55 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia walked in, not to mention the guests who had entered, not even the waiters could be seen.
2023-05-25 20:24:55 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-25 20:24:57 | INFO | fairseq.tasks.translation | example hypothesis: This person was the Fourth Miss of the Ye Family, Ye Qingling.
2023-05-25 20:24:57 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-25 20:24:58 | INFO | fairseq.tasks.translation | example hypothesis: This was because at this moment, she felt that her chin was about to break.
2023-05-25 20:24:58 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-25 20:24:59 | INFO | fairseq.tasks.translation | example hypothesis: “Good Mu Zi, help me. If it wasn't for you, that old fellow wouldn't have targeted me.”
2023-05-25 20:24:59 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-25 20:25:00 | INFO | fairseq.tasks.translation | example hypothesis: Bai Li Yu Yan was even more excited. This matter was completely caused by her director. Bai Li Hong Zhuang had treated her like before, and this time, she would definitely make Bai Li Hong Zhuang uncomfortable.
2023-05-25 20:25:00 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-25 20:25:01 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How could that be? The other side is also four Magic Masters, so it’s not easy to submit so easily. After arguing for a long time, I finally decided to use the method of the competition to get control over the Kingdom of E Xia.”
2023-05-25 20:25:01 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-25 20:25:03 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a little. Originally, he had been searching for reasons for Li Yuyue to not participate in the Imperial Hunting Competition.
2023-05-25 20:25:03 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-25 20:25:04 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my standard alright? We’re all the most outstanding talents in the country. My magic is so weak?”
2023-05-25 20:25:04 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-25 20:25:06 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yibei’s words meant that if Fang Chixia didn’t want to go, there was no need to go.
2023-05-25 20:25:06 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-25 20:25:07 | INFO | fairseq.tasks.translation | example hypothesis: She tilted her head and saw that the five palm marks on her face were extremely eye-catching. It was so swollen that it could be seen at a speed visible to the naked eye. She reached out and touched it. Immediately, she couldn’t help but let out a hissing sound. It really hurt.
2023-05-25 20:25:07 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-25 20:25:09 | INFO | fairseq.tasks.translation | example hypothesis: This... How could this be the charm that a piece of trash could emit?
2023-05-25 20:25:09 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-25 20:25:10 | INFO | fairseq.tasks.translation | example hypothesis: How could Wang Wenhao find the newspaper agency? The chief editor should have called her not to come to the newspaper, but these three people... had schemed against her!
2023-05-25 20:25:10 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-25 20:25:12 | INFO | fairseq.tasks.translation | example hypothesis: Hearing Teacher Di’s compliment, I was delighted. I took back the energy ball with my left hand and sent out a light sword towards Teacher Zhen with his right hand. The light sword was actually able to hit it smoothly. I was shocked and only then did I realize that it was just an afterimage. Teacher Zhen had already moved to my back and shouted, “Explosive space.”
2023-05-25 20:25:12 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-25 20:25:15 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Originally, we proposed a competition between the three teams, but it’s not fair on their side because we have Teacher Di and Teacher Zhen. They are ranked in the top five teams, and they suggested that they would win five rounds. Due to the competition, we brought it up, so we can only listen to them in the end. Three days from now on, we will have a secret competition in the Royal Fighting Grounds. If Teacher Di and Teacher
2023-05-25 20:25:15 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-25 20:25:17 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Di used 7th Rank of Light and Lightning, and I rarely used this spell because I didn’t have a good control of it. Teacher Di released 9 Light and Lightning to surround me, forming a simple formation that made me unable to escape through a short distance. Then, all of the Light and Lightning exploded into a powerful attack.
2023-05-25 20:25:17 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-25 20:25:20 | INFO | fairseq.tasks.translation | example hypothesis: As soon as Ma Ke and the two teachers walked to the other side, Teacher Zhen sent a small Dimensional Slash to me. As expected of the number one magician in the continent, he released a powerful suction force that was much stronger than mine. A small spatial crack appeared beside me, and a powerful suction force swept over.
2023-05-25 20:25:20 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-25 20:25:20 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.589 | nll_loss 2.956 | ppl 7.76 | bleu 19.02 | wps 1976.5 | wpb 2420.8 | bsz 84.5 | num_updates 6672
2023-05-25 20:25:20 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-25 20:25:24 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/concat-1-1-0.2-sf[zh-en]/checkpoint1.pt (epoch 1 @ 6672 updates, score 19.02) (writing took 4.026191944256425 seconds)
2023-05-25 20:25:24 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-05-25 20:25:24 | INFO | train | epoch 001 | loss 6.29 | nll_loss 4.928 | ppl 30.44 | wps 52255.4 | ups 0.91 | wpb 57189.8 | bsz 1477.5 | num_updates 6672 | lr 0.000774287 | gnorm 0.658 | clip 100 | loss_scale 27 | train_wall 7013 | wall 7519
2023-05-25 20:25:24 | INFO | fairseq.trainer | begin training epoch 2
2023-05-25 20:26:03 | INFO | train_inner | epoch 002:     28 / 6686 loss=4.833, nll_loss=3.274, ppl=9.67, wps=35118.7, ups=0.62, wpb=56682.4, bsz=1457.1, num_updates=6700, lr=0.000772667, gnorm=0.345, clip=100, loss_scale=32, train_wall=106, wall=7557
2023-05-25 20:27:56 | INFO | train_inner | epoch 002:    128 / 6686 loss=4.806, nll_loss=3.243, ppl=9.47, wps=50275.5, ups=0.88, wpb=57171.5, bsz=1457.7, num_updates=6800, lr=0.000766965, gnorm=0.347, clip=100, loss_scale=32, train_wall=108, wall=7670
2023-05-25 20:29:48 | INFO | train_inner | epoch 002:    228 / 6686 loss=4.805, nll_loss=3.242, ppl=9.46, wps=51258.9, ups=0.9, wpb=57010.8, bsz=1467.4, num_updates=6900, lr=0.000761387, gnorm=0.341, clip=100, loss_scale=32, train_wall=106, wall=7782
2023-05-25 20:31:36 | INFO | train_inner | epoch 002:    328 / 6686 loss=4.788, nll_loss=3.224, ppl=9.34, wps=52556.5, ups=0.92, wpb=57258.9, bsz=1476.9, num_updates=7000, lr=0.000755929, gnorm=0.341, clip=100, loss_scale=32, train_wall=105, wall=7891
2023-05-25 20:33:25 | INFO | train_inner | epoch 002:    428 / 6686 loss=4.799, nll_loss=3.237, ppl=9.43, wps=52755.1, ups=0.92, wpb=57363.5, bsz=1481.5, num_updates=7100, lr=0.000750587, gnorm=0.34, clip=100, loss_scale=39, train_wall=105, wall=7999
2023-05-25 20:33:38 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-25 20:35:15 | INFO | train_inner | epoch 002:    529 / 6686 loss=4.79, nll_loss=3.227, ppl=9.36, wps=52260.7, ups=0.91, wpb=57368, bsz=1468.1, num_updates=7200, lr=0.000745356, gnorm=0.334, clip=100, loss_scale=35, train_wall=106, wall=8109
2023-05-25 20:37:04 | INFO | train_inner | epoch 002:    629 / 6686 loss=4.778, nll_loss=3.213, ppl=9.27, wps=52730.9, ups=0.92, wpb=57253.3, bsz=1470.2, num_updates=7300, lr=0.000740233, gnorm=0.333, clip=100, loss_scale=32, train_wall=105, wall=8218
2023-05-25 20:38:52 | INFO | train_inner | epoch 002:    729 / 6686 loss=4.759, nll_loss=3.192, ppl=9.14, wps=52734.3, ups=0.92, wpb=57277.3, bsz=1481.3, num_updates=7400, lr=0.000735215, gnorm=0.333, clip=100, loss_scale=32, train_wall=105, wall=8326
2023-05-25 20:40:40 | INFO | train_inner | epoch 002:    829 / 6686 loss=4.77, nll_loss=3.205, ppl=9.22, wps=52844.8, ups=0.92, wpb=57138.1, bsz=1473, num_updates=7500, lr=0.000730297, gnorm=0.331, clip=100, loss_scale=32, train_wall=104, wall=8434
2023-05-25 20:42:29 | INFO | train_inner | epoch 002:    929 / 6686 loss=4.765, nll_loss=3.2, ppl=9.19, wps=52684.4, ups=0.92, wpb=57123.5, bsz=1474.2, num_updates=7600, lr=0.000725476, gnorm=0.329, clip=100, loss_scale=32, train_wall=105, wall=8543
2023-05-25 20:43:15 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-25 20:44:18 | INFO | train_inner | epoch 002:   1030 / 6686 loss=4.752, nll_loss=3.185, ppl=9.09, wps=52052.3, ups=0.91, wpb=57032.7, bsz=1463.4, num_updates=7700, lr=0.00072075, gnorm=0.331, clip=100, loss_scale=38, train_wall=106, wall=8652
2023-05-25 20:46:07 | INFO | train_inner | epoch 002:   1130 / 6686 loss=4.749, nll_loss=3.182, ppl=9.07, wps=52646.9, ups=0.92, wpb=57098.5, bsz=1480.1, num_updates=7800, lr=0.000716115, gnorm=0.325, clip=100, loss_scale=32, train_wall=105, wall=8761
2023-05-25 20:47:55 | INFO | train_inner | epoch 002:   1230 / 6686 loss=4.734, nll_loss=3.166, ppl=8.97, wps=52753.9, ups=0.92, wpb=57302.1, bsz=1486.4, num_updates=7900, lr=0.000711568, gnorm=0.337, clip=100, loss_scale=32, train_wall=105, wall=8870
2023-05-25 20:49:44 | INFO | train_inner | epoch 002:   1330 / 6686 loss=4.734, nll_loss=3.166, ppl=8.97, wps=52804.9, ups=0.92, wpb=57192.6, bsz=1473.1, num_updates=8000, lr=0.000707107, gnorm=0.32, clip=100, loss_scale=32, train_wall=105, wall=8978
2023-05-25 20:51:32 | INFO | train_inner | epoch 002:   1430 / 6686 loss=4.73, nll_loss=3.161, ppl=8.95, wps=52813.4, ups=0.92, wpb=57228.9, bsz=1469.1, num_updates=8100, lr=0.000702728, gnorm=0.32, clip=100, loss_scale=32, train_wall=105, wall=9086
2023-05-25 20:53:20 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-25 20:53:22 | INFO | train_inner | epoch 002:   1531 / 6686 loss=4.722, nll_loss=3.152, ppl=8.89, wps=52068, ups=0.91, wpb=57146.8, bsz=1462, num_updates=8200, lr=0.00069843, gnorm=0.326, clip=100, loss_scale=46, train_wall=106, wall=9196
2023-05-25 20:55:11 | INFO | train_inner | epoch 002:   1631 / 6686 loss=4.72, nll_loss=3.15, ppl=8.88, wps=52514.7, ups=0.92, wpb=57145.8, bsz=1482.1, num_updates=8300, lr=0.00069421, gnorm=0.324, clip=100, loss_scale=32, train_wall=105, wall=9305
2023-05-25 20:56:59 | INFO | train_inner | epoch 002:   1731 / 6686 loss=4.714, nll_loss=3.144, ppl=8.84, wps=52893.6, ups=0.92, wpb=57208.1, bsz=1491, num_updates=8400, lr=0.000690066, gnorm=0.316, clip=100, loss_scale=32, train_wall=105, wall=9413
2023-05-25 20:58:47 | INFO | train_inner | epoch 002:   1831 / 6686 loss=4.716, nll_loss=3.147, ppl=8.86, wps=52730.4, ups=0.92, wpb=57126, bsz=1467.2, num_updates=8500, lr=0.000685994, gnorm=0.32, clip=100, loss_scale=32, train_wall=105, wall=9521
2023-05-25 21:00:36 | INFO | train_inner | epoch 002:   1931 / 6686 loss=4.718, nll_loss=3.149, ppl=8.87, wps=52664.2, ups=0.92, wpb=57040.4, bsz=1458, num_updates=8600, lr=0.000681994, gnorm=0.315, clip=100, loss_scale=32, train_wall=105, wall=9630
2023-05-25 21:02:24 | INFO | train_inner | epoch 002:   2031 / 6686 loss=4.695, nll_loss=3.123, ppl=8.71, wps=52949.9, ups=0.92, wpb=57260.2, bsz=1495.5, num_updates=8700, lr=0.000678064, gnorm=0.311, clip=100, loss_scale=32, train_wall=104, wall=9738
2023-05-25 21:02:40 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-25 21:04:13 | INFO | train_inner | epoch 002:   2132 / 6686 loss=4.698, nll_loss=3.127, ppl=8.74, wps=52304.2, ups=0.92, wpb=57153.2, bsz=1466.6, num_updates=8800, lr=0.0006742, gnorm=0.314, clip=100, loss_scale=34, train_wall=106, wall=9847
2023-05-25 21:06:01 | INFO | train_inner | epoch 002:   2232 / 6686 loss=4.686, nll_loss=3.114, ppl=8.66, wps=52719.1, ups=0.92, wpb=57212.5, bsz=1491.8, num_updates=8900, lr=0.000670402, gnorm=0.321, clip=100, loss_scale=32, train_wall=105, wall=9956
2023-05-25 21:07:50 | INFO | train_inner | epoch 002:   2332 / 6686 loss=4.68, nll_loss=3.107, ppl=8.62, wps=52869.4, ups=0.92, wpb=57330.7, bsz=1479.8, num_updates=9000, lr=0.000666667, gnorm=0.315, clip=100, loss_scale=32, train_wall=105, wall=10064
2023-05-25 21:09:38 | INFO | train_inner | epoch 002:   2432 / 6686 loss=4.677, nll_loss=3.104, ppl=8.6, wps=52809.5, ups=0.92, wpb=57347.8, bsz=1478.5, num_updates=9100, lr=0.000662994, gnorm=0.311, clip=100, loss_scale=32, train_wall=105, wall=10173
2023-05-25 21:11:27 | INFO | train_inner | epoch 002:   2532 / 6686 loss=4.67, nll_loss=3.096, ppl=8.55, wps=52517.1, ups=0.92, wpb=57098.7, bsz=1474.1, num_updates=9200, lr=0.00065938, gnorm=0.313, clip=100, loss_scale=32, train_wall=105, wall=10281
2023-05-25 21:12:01 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-25 21:13:17 | INFO | train_inner | epoch 002:   2633 / 6686 loss=4.67, nll_loss=3.096, ppl=8.55, wps=52224.4, ups=0.91, wpb=57305.8, bsz=1483, num_updates=9300, lr=0.000655826, gnorm=0.318, clip=100, loss_scale=34, train_wall=106, wall=10391
2023-05-25 21:15:05 | INFO | train_inner | epoch 002:   2733 / 6686 loss=4.668, nll_loss=3.094, ppl=8.54, wps=52983.1, ups=0.92, wpb=57348, bsz=1499.1, num_updates=9400, lr=0.000652328, gnorm=0.311, clip=100, loss_scale=32, train_wall=105, wall=10499
2023-05-25 21:16:53 | INFO | train_inner | epoch 002:   2833 / 6686 loss=4.664, nll_loss=3.09, ppl=8.51, wps=52953, ups=0.93, wpb=57193.8, bsz=1475.1, num_updates=9500, lr=0.000648886, gnorm=0.304, clip=100, loss_scale=32, train_wall=104, wall=10607
2023-05-25 21:18:41 | INFO | train_inner | epoch 002:   2933 / 6686 loss=4.657, nll_loss=3.082, ppl=8.47, wps=52714, ups=0.92, wpb=56998.3, bsz=1475.2, num_updates=9600, lr=0.000645497, gnorm=0.308, clip=100, loss_scale=32, train_wall=104, wall=10715
2023-05-25 21:20:30 | INFO | train_inner | epoch 002:   3033 / 6686 loss=4.667, nll_loss=3.094, ppl=8.54, wps=52787.5, ups=0.92, wpb=57174.4, bsz=1483.4, num_updates=9700, lr=0.000642161, gnorm=0.311, clip=100, loss_scale=32, train_wall=105, wall=10824
2023-05-25 21:21:16 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-25 21:22:19 | INFO | train_inner | epoch 002:   3134 / 6686 loss=4.667, nll_loss=3.094, ppl=8.54, wps=52195.8, ups=0.91, wpb=57110.8, bsz=1460.6, num_updates=9800, lr=0.000638877, gnorm=0.305, clip=100, loss_scale=32, train_wall=106, wall=10933
2023-05-25 21:23:14 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-25 21:24:09 | INFO | train_inner | epoch 002:   3235 / 6686 loss=4.652, nll_loss=3.076, ppl=8.44, wps=52215.1, ups=0.91, wpb=57186.3, bsz=1472, num_updates=9900, lr=0.000635642, gnorm=0.305, clip=100, loss_scale=24, train_wall=106, wall=11043
2023-05-25 21:25:57 | INFO | train_inner | epoch 002:   3335 / 6686 loss=4.644, nll_loss=3.068, ppl=8.39, wps=52936.9, ups=0.93, wpb=57132.9, bsz=1464.3, num_updates=10000, lr=0.000632456, gnorm=0.301, clip=100, loss_scale=16, train_wall=104, wall=11151
2023-05-25 21:27:45 | INFO | train_inner | epoch 002:   3435 / 6686 loss=4.652, nll_loss=3.078, ppl=8.44, wps=52832.4, ups=0.92, wpb=57238.8, bsz=1480.1, num_updates=10100, lr=0.000629317, gnorm=0.305, clip=100, loss_scale=16, train_wall=105, wall=11259
2023-05-25 21:29:33 | INFO | train_inner | epoch 002:   3535 / 6686 loss=4.634, nll_loss=3.057, ppl=8.32, wps=52853.8, ups=0.92, wpb=57367.5, bsz=1489.8, num_updates=10200, lr=0.000626224, gnorm=0.3, clip=100, loss_scale=16, train_wall=105, wall=11368
2023-05-25 21:31:22 | INFO | train_inner | epoch 002:   3635 / 6686 loss=4.63, nll_loss=3.053, ppl=8.3, wps=52845.9, ups=0.92, wpb=57294.5, bsz=1485.5, num_updates=10300, lr=0.000623177, gnorm=0.298, clip=100, loss_scale=16, train_wall=105, wall=11476
2023-05-25 21:33:10 | INFO | train_inner | epoch 002:   3735 / 6686 loss=4.644, nll_loss=3.069, ppl=8.39, wps=52633.1, ups=0.92, wpb=57102.6, bsz=1491.4, num_updates=10400, lr=0.000620174, gnorm=0.301, clip=100, loss_scale=22, train_wall=105, wall=11584
2023-05-25 21:34:59 | INFO | train_inner | epoch 002:   3835 / 6686 loss=4.637, nll_loss=3.061, ppl=8.34, wps=52864.1, ups=0.92, wpb=57222.6, bsz=1478.1, num_updates=10500, lr=0.000617213, gnorm=0.301, clip=100, loss_scale=32, train_wall=105, wall=11693
2023-05-25 21:36:14 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-25 21:36:48 | INFO | train_inner | epoch 002:   3936 / 6686 loss=4.632, nll_loss=3.056, ppl=8.32, wps=52167.1, ups=0.91, wpb=57103.2, bsz=1465, num_updates=10600, lr=0.000614295, gnorm=0.307, clip=100, loss_scale=27, train_wall=106, wall=11802
2023-05-25 21:38:36 | INFO | train_inner | epoch 002:   4036 / 6686 loss=4.612, nll_loss=3.033, ppl=8.19, wps=52748.3, ups=0.92, wpb=57165.4, bsz=1476.8, num_updates=10700, lr=0.000611418, gnorm=0.3, clip=100, loss_scale=16, train_wall=105, wall=11911
2023-05-25 21:40:25 | INFO | train_inner | epoch 002:   4136 / 6686 loss=4.619, nll_loss=3.041, ppl=8.23, wps=52761, ups=0.92, wpb=57200.7, bsz=1493.8, num_updates=10800, lr=0.000608581, gnorm=0.295, clip=100, loss_scale=16, train_wall=105, wall=12019
2023-05-25 21:42:13 | INFO | train_inner | epoch 002:   4236 / 6686 loss=4.619, nll_loss=3.041, ppl=8.23, wps=52803.9, ups=0.92, wpb=57286.1, bsz=1463.5, num_updates=10900, lr=0.000605783, gnorm=0.3, clip=100, loss_scale=16, train_wall=105, wall=12128
2023-05-25 21:44:02 | INFO | train_inner | epoch 002:   4336 / 6686 loss=4.616, nll_loss=3.038, ppl=8.21, wps=52759.8, ups=0.92, wpb=57110.4, bsz=1483.4, num_updates=11000, lr=0.000603023, gnorm=0.295, clip=100, loss_scale=16, train_wall=105, wall=12236
2023-05-25 21:45:50 | INFO | train_inner | epoch 002:   4436 / 6686 loss=4.62, nll_loss=3.043, ppl=8.24, wps=52782.7, ups=0.92, wpb=57230.7, bsz=1466.7, num_updates=11100, lr=0.0006003, gnorm=0.301, clip=100, loss_scale=19, train_wall=105, wall=12344
2023-05-25 21:46:03 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-25 21:47:40 | INFO | train_inner | epoch 002:   4537 / 6686 loss=4.607, nll_loss=3.029, ppl=8.16, wps=52066.5, ups=0.91, wpb=57106.8, bsz=1493.9, num_updates=11200, lr=0.000597614, gnorm=0.301, clip=100, loss_scale=18, train_wall=106, wall=12454
2023-05-25 21:49:28 | INFO | train_inner | epoch 002:   4637 / 6686 loss=4.598, nll_loss=3.018, ppl=8.1, wps=52743.8, ups=0.92, wpb=57258.2, bsz=1474, num_updates=11300, lr=0.000594964, gnorm=0.303, clip=100, loss_scale=16, train_wall=105, wall=12562
2023-05-25 21:51:16 | INFO | train_inner | epoch 002:   4737 / 6686 loss=4.603, nll_loss=3.023, ppl=8.13, wps=52780.2, ups=0.92, wpb=57062.5, bsz=1474.7, num_updates=11400, lr=0.000592349, gnorm=0.298, clip=100, loss_scale=16, train_wall=104, wall=12671
2023-05-25 21:53:05 | INFO | train_inner | epoch 002:   4837 / 6686 loss=4.596, nll_loss=3.017, ppl=8.09, wps=52593.7, ups=0.92, wpb=57146.8, bsz=1503.5, num_updates=11500, lr=0.000589768, gnorm=0.292, clip=100, loss_scale=16, train_wall=105, wall=12779
2023-05-25 21:54:53 | INFO | train_inner | epoch 002:   4937 / 6686 loss=4.601, nll_loss=3.021, ppl=8.12, wps=52732.2, ups=0.92, wpb=57125, bsz=1461.4, num_updates=11600, lr=0.00058722, gnorm=0.299, clip=100, loss_scale=16, train_wall=105, wall=12888
2023-05-25 21:56:42 | INFO | train_inner | epoch 002:   5037 / 6686 loss=4.588, nll_loss=3.007, ppl=8.04, wps=52786.3, ups=0.92, wpb=57249.2, bsz=1504.8, num_updates=11700, lr=0.000584705, gnorm=0.29, clip=100, loss_scale=28, train_wall=105, wall=12996
2023-05-25 21:58:30 | INFO | train_inner | epoch 002:   5137 / 6686 loss=4.59, nll_loss=3.01, ppl=8.05, wps=52779, ups=0.92, wpb=57206.5, bsz=1473.5, num_updates=11800, lr=0.000582223, gnorm=0.299, clip=100, loss_scale=32, train_wall=105, wall=13104
2023-05-25 21:58:36 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-25 22:00:20 | INFO | train_inner | epoch 002:   5238 / 6686 loss=4.59, nll_loss=3.009, ppl=8.05, wps=52225.7, ups=0.91, wpb=57253.2, bsz=1485.6, num_updates=11900, lr=0.000579771, gnorm=0.289, clip=100, loss_scale=17, train_wall=106, wall=13214
2023-05-25 22:02:08 | INFO | train_inner | epoch 002:   5338 / 6686 loss=4.581, nll_loss=2.999, ppl=8, wps=52759.7, ups=0.92, wpb=57283.6, bsz=1479.9, num_updates=12000, lr=0.00057735, gnorm=0.294, clip=100, loss_scale=16, train_wall=105, wall=13323
2023-05-25 22:03:57 | INFO | train_inner | epoch 002:   5438 / 6686 loss=4.585, nll_loss=3.004, ppl=8.02, wps=52657.2, ups=0.92, wpb=57062.1, bsz=1463.4, num_updates=12100, lr=0.00057496, gnorm=0.297, clip=100, loss_scale=16, train_wall=105, wall=13431
2023-05-25 22:05:46 | INFO | train_inner | epoch 002:   5538 / 6686 loss=4.578, nll_loss=2.997, ppl=7.98, wps=52788.9, ups=0.92, wpb=57430.4, bsz=1497.2, num_updates=12200, lr=0.000572598, gnorm=0.291, clip=100, loss_scale=16, train_wall=105, wall=13540
2023-05-25 22:07:34 | INFO | train_inner | epoch 002:   5638 / 6686 loss=4.576, nll_loss=2.995, ppl=7.97, wps=52811.3, ups=0.92, wpb=57285.1, bsz=1464.3, num_updates=12300, lr=0.000570266, gnorm=0.301, clip=100, loss_scale=16, train_wall=105, wall=13648
2023-05-25 22:08:23 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-25 22:09:24 | INFO | train_inner | epoch 002:   5739 / 6686 loss=4.576, nll_loss=2.995, ppl=7.97, wps=52189.9, ups=0.91, wpb=57151.6, bsz=1473.4, num_updates=12400, lr=0.000567962, gnorm=0.287, clip=100, loss_scale=21, train_wall=106, wall=13758
2023-05-25 22:11:12 | INFO | train_inner | epoch 002:   5839 / 6686 loss=4.578, nll_loss=2.997, ppl=7.98, wps=52803.1, ups=0.93, wpb=57066.8, bsz=1473.7, num_updates=12500, lr=0.000565685, gnorm=0.285, clip=100, loss_scale=16, train_wall=105, wall=13866
2023-05-25 22:13:00 | INFO | train_inner | epoch 002:   5939 / 6686 loss=4.569, nll_loss=2.987, ppl=7.93, wps=52903.9, ups=0.92, wpb=57406.5, bsz=1509.2, num_updates=12600, lr=0.000563436, gnorm=0.286, clip=100, loss_scale=16, train_wall=105, wall=13974
2023-05-25 22:14:49 | INFO | train_inner | epoch 002:   6039 / 6686 loss=4.564, nll_loss=2.982, ppl=7.9, wps=52671, ups=0.92, wpb=57214.4, bsz=1475.8, num_updates=12700, lr=0.000561214, gnorm=0.293, clip=100, loss_scale=16, train_wall=105, wall=14083
2023-05-25 22:16:37 | INFO | train_inner | epoch 002:   6139 / 6686 loss=4.573, nll_loss=2.992, ppl=7.95, wps=52616.8, ups=0.92, wpb=57056, bsz=1469.4, num_updates=12800, lr=0.000559017, gnorm=0.288, clip=100, loss_scale=16, train_wall=105, wall=14191
2023-05-25 22:18:26 | INFO | train_inner | epoch 002:   6239 / 6686 loss=4.566, nll_loss=2.984, ppl=7.91, wps=52656.4, ups=0.92, wpb=57135.3, bsz=1465.4, num_updates=12900, lr=0.000556846, gnorm=0.284, clip=100, loss_scale=23, train_wall=105, wall=14300
2023-05-25 22:20:14 | INFO | train_inner | epoch 002:   6339 / 6686 loss=4.562, nll_loss=2.979, ppl=7.89, wps=52630.4, ups=0.92, wpb=57191.1, bsz=1489.3, num_updates=13000, lr=0.0005547, gnorm=0.282, clip=100, loss_scale=32, train_wall=105, wall=14409
2023-05-25 22:20:51 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-25 22:22:04 | INFO | train_inner | epoch 002:   6440 / 6686 loss=4.553, nll_loss=2.969, ppl=7.83, wps=52169.5, ups=0.91, wpb=57207.2, bsz=1480.4, num_updates=13100, lr=0.000552579, gnorm=0.289, clip=100, loss_scale=21, train_wall=106, wall=14518
2023-05-25 22:23:53 | INFO | train_inner | epoch 002:   6540 / 6686 loss=4.552, nll_loss=2.968, ppl=7.83, wps=52685.6, ups=0.92, wpb=57156.7, bsz=1480.1, num_updates=13200, lr=0.000550482, gnorm=0.293, clip=100, loss_scale=16, train_wall=105, wall=14627
2023-05-25 22:25:41 | INFO | train_inner | epoch 002:   6640 / 6686 loss=4.555, nll_loss=2.972, ppl=7.84, wps=52832, ups=0.92, wpb=57228.4, bsz=1474.2, num_updates=13300, lr=0.000548408, gnorm=0.284, clip=100, loss_scale=16, train_wall=105, wall=14735
2023-05-25 22:26:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-25 22:26:35 | INFO | fairseq.tasks.translation | example hypothesis: Why?
2023-05-25 22:26:35 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-25 22:26:35 | INFO | fairseq.tasks.translation | example hypothesis: I’ll make you lose so badly that you don’t even have your pants left!
2023-05-25 22:26:35 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-25 22:26:36 | INFO | fairseq.tasks.translation | example hypothesis: Just as Shen Liangchuan heaved a sigh of relief, he heard her say, “I’m calling you in the same room!”
2023-05-25 22:26:36 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-25 22:26:36 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved her hand and entered the elevator.
2023-05-25 22:26:36 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-25 22:26:37 | INFO | fairseq.tasks.translation | example hypothesis: When she raised her head, she saw Song Cheng standing in the distance!
2023-05-25 22:26:37 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-25 22:26:38 | INFO | fairseq.tasks.translation | example hypothesis: Song Cheng patted his chest. “You scared me to death! Where’s Wang Chuan?”
2023-05-25 22:26:38 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-25 22:26:38 | INFO | fairseq.tasks.translation | example hypothesis: I said, “I’m not going. I can’t eat.”
2023-05-25 22:26:38 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-25 22:26:39 | INFO | fairseq.tasks.translation | example hypothesis: No one believed it at first, but Wang Wen Hao insisted on him and made the public opinion lean towards Wang Wen Hao.
2023-05-25 22:26:39 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-25 22:26:40 | INFO | fairseq.tasks.translation | example hypothesis: With his identity, Baili Hongzhuang had to be treated even if he didn’t treat her!
2023-05-25 22:26:40 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-25 22:26:41 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian: “Mr. Shen, I, I’ve left too much blood and my brain is short of oxygen. I can’t figure it out. You can either give me a reminder or I’ll
2023-05-25 22:26:41 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-25 22:26:42 | INFO | fairseq.tasks.translation | example hypothesis: He didn’t know why so many people heard this. Since he couldn’t hide it, he might as well tell them.
2023-05-25 22:26:42 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-25 22:26:43 | INFO | fairseq.tasks.translation | example hypothesis: She deliberately lowered her voice, but it could not hide the viciousness and viciousness in her tone.
2023-05-25 22:26:43 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-25 22:26:44 | INFO | fairseq.tasks.translation | example hypothesis: Different levels of beast pets were different. However, beast pets were precious and rare. Ordinary people would not be able to possess them. Even official disciples would not be able to possess them.
2023-05-25 22:26:44 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-25 22:26:45 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chixia gritted his teeth and cursed.
2023-05-25 22:26:45 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-25 22:26:46 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang’s disguise was very good, Di Beichen still saw the ripple in her eyes, and a trace of warmth appeared in her eyes.
2023-05-25 22:26:46 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-25 22:26:47 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia walked in, not to mention the guests, not even a few waiters could be seen.
2023-05-25 22:26:47 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-25 22:26:48 | INFO | fairseq.tasks.translation | example hypothesis: This person was none other than the Fourth Young Lady of the Ye family, Ye Qing Ling.
2023-05-25 22:26:48 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-25 22:26:49 | INFO | fairseq.tasks.translation | example hypothesis: Because at this moment, she felt that her chin was about to shatter.
2023-05-25 22:26:49 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-25 22:26:50 | INFO | fairseq.tasks.translation | example hypothesis: “Alright Mu Zi, help me. If it wasn't for you, that old fellow wouldn't have targeted me.”
2023-05-25 22:26:50 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-25 22:26:51 | INFO | fairseq.tasks.translation | example hypothesis: Baili Yuyan was even more excited. She was the director of this matter. She would definitely make Baili Hongzhuang feel bad this time around.
2023-05-25 22:26:51 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-25 22:26:52 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How could that be? They also have four mages, so they naturally won’t surrender so easily. After arguing for a long time, they finally decided to use a method to get control of the Kingdom of Summer in the future.”
2023-05-25 22:26:52 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-25 22:26:54 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a bit. He had been looking for a reason for Li Yuyue to not participate in the Imperial Family’s hunting competition.
2023-05-25 22:26:54 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-25 22:26:55 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my standard okay? I’m the most outstanding talent in the country. Is my magic so weak?”
2023-05-25 22:26:55 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-25 22:26:57 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yibei’s words meant that if Fang Chixia didn’t want to go, then there was no need to go.
2023-05-25 22:26:57 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-25 22:26:58 | INFO | fairseq.tasks.translation | example hypothesis: She tilted her head and saw that the five palm marks on her face were very eye-catching. They were swelling up at a visible speed. She touched them with her hand, and she couldn’t help but hiss.
2023-05-25 22:26:58 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-25 22:27:00 | INFO | fairseq.tasks.translation | example hypothesis: How... How could this be the charm that that trash could emit?
2023-05-25 22:27:00 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-25 22:27:01 | INFO | fairseq.tasks.translation | example hypothesis: How could Wang Wenhao find the newspaper agency? The chief editor should have called her to tell her not to come to the newspaper agency, but these three people... had schemed against her!
2023-05-25 22:27:01 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-25 22:27:03 | INFO | fairseq.tasks.translation | example hypothesis: I was shocked when I heard Teacher Di’s praise. After a closer look, I realized that it was just an afterimage. Teacher Zhen had already moved to my back and shouted, “Berserk Space!”
2023-05-25 22:27:03 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-25 22:27:06 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Originally, our side proposed a competition of two or three rounds, but they said that it was unfair because we have Teacher Di and Teacher Zhen. They said that they wanted to win three rounds, but because we were the ones who suggested the competition, we could only listen to them in the end. Three days from now, we will have a secret competition in the Royal Martial Arts Arena. If we can’t win three rounds, then we can’t
2023-05-25 22:27:06 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-25 22:27:08 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Di used light-type rank 7 Light-Thunder Blast. I didn’t use much of this spell, because it wasn’t very good at controlling it. Teacher Di released nine light-Thunderbolts to surround me, forming a simple spell formation, preventing me from escaping through a short distance. Then, all the light-bolts exploded and formed a powerful attack power.
2023-05-25 22:27:08 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-25 22:27:12 | INFO | fairseq.tasks.translation | example hypothesis: Just as Ma Ke and the two teachers walked to the other end, Teacher Zhen sent a small Dimensional Slash at me. As expected of the number one Magician on the continent, the suction force he released was actually much stronger than mine. A small spatial crack appeared beside me, and a powerful suction force swept over.
2023-05-25 22:27:12 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-25 22:27:12 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.372 | nll_loss 2.734 | ppl 6.65 | bleu 20.73 | wps 1965.6 | wpb 2420.8 | bsz 84.5 | num_updates 13346 | best_bleu 20.73
2023-05-25 22:27:12 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-25 22:27:16 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/concat-1-1-0.2-sf[zh-en]/checkpoint2.pt (epoch 2 @ 13346 updates, score 20.73) (writing took 4.2121429443359375 seconds)
2023-05-25 22:27:16 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-05-25 22:27:16 | INFO | train | epoch 002 | loss 4.658 | nll_loss 3.083 | ppl 8.47 | wps 52201.8 | ups 0.91 | wpb 57189.1 | bsz 1477.5 | num_updates 13346 | lr 0.000547463 | gnorm 0.308 | clip 100 | loss_scale 26 | train_wall 7009 | wall 14830
2023-05-25 22:27:16 | INFO | fairseq.trainer | begin training epoch 3
2023-05-25 22:28:24 | INFO | train_inner | epoch 003:     54 / 6686 loss=4.537, nll_loss=2.951, ppl=7.73, wps=34726.1, ups=0.61, wpb=56691.1, bsz=1467.4, num_updates=13400, lr=0.000546358, gnorm=0.289, clip=100, loss_scale=16, train_wall=107, wall=14898
2023-05-25 22:30:17 | INFO | train_inner | epoch 003:    154 / 6686 loss=4.526, nll_loss=2.939, ppl=7.67, wps=50775.4, ups=0.89, wpb=57209.9, bsz=1475.2, num_updates=13500, lr=0.000544331, gnorm=0.283, clip=100, loss_scale=16, train_wall=107, wall=15011
2023-05-25 22:31:08 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-25 22:32:09 | INFO | train_inner | epoch 003:    255 / 6686 loss=4.525, nll_loss=2.937, ppl=7.66, wps=51243.8, ups=0.89, wpb=57275.9, bsz=1473.4, num_updates=13600, lr=0.000542326, gnorm=0.291, clip=100, loss_scale=16, train_wall=107, wall=15123
2023-05-25 22:33:58 | INFO | train_inner | epoch 003:    355 / 6686 loss=4.51, nll_loss=2.921, ppl=7.57, wps=52316.4, ups=0.91, wpb=57221.5, bsz=1496.3, num_updates=13700, lr=0.000540343, gnorm=0.284, clip=100, loss_scale=16, train_wall=105, wall=15232
2023-05-25 22:35:47 | INFO | train_inner | epoch 003:    455 / 6686 loss=4.526, nll_loss=2.939, ppl=7.67, wps=52500, ups=0.92, wpb=57166.4, bsz=1467.6, num_updates=13800, lr=0.000538382, gnorm=0.284, clip=100, loss_scale=16, train_wall=105, wall=15341
2023-05-25 22:37:36 | INFO | train_inner | epoch 003:    555 / 6686 loss=4.529, nll_loss=2.942, ppl=7.68, wps=52586.1, ups=0.92, wpb=57202.5, bsz=1469, num_updates=13900, lr=0.000536442, gnorm=0.288, clip=100, loss_scale=16, train_wall=105, wall=15450
2023-05-25 22:39:25 | INFO | train_inner | epoch 003:    655 / 6686 loss=4.52, nll_loss=2.932, ppl=7.63, wps=52670.7, ups=0.92, wpb=57283.2, bsz=1456.6, num_updates=14000, lr=0.000534522, gnorm=0.291, clip=100, loss_scale=16, train_wall=105, wall=15559
2023-05-25 22:41:13 | INFO | train_inner | epoch 003:    755 / 6686 loss=4.524, nll_loss=2.937, ppl=7.66, wps=52513.9, ups=0.92, wpb=57134.2, bsz=1474.3, num_updates=14100, lr=0.000532624, gnorm=0.289, clip=100, loss_scale=23, train_wall=105, wall=15667
2023-05-25 22:42:57 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-25 22:43:03 | INFO | train_inner | epoch 003:    856 / 6686 loss=4.517, nll_loss=2.929, ppl=7.61, wps=51998, ups=0.91, wpb=57117.9, bsz=1504.3, num_updates=14200, lr=0.000530745, gnorm=0.286, clip=100, loss_scale=31, train_wall=106, wall=15777
2023-05-25 22:44:52 | INFO | train_inner | epoch 003:    956 / 6686 loss=4.518, nll_loss=2.931, ppl=7.62, wps=52608.6, ups=0.92, wpb=57323.7, bsz=1493.4, num_updates=14300, lr=0.000528886, gnorm=0.283, clip=100, loss_scale=16, train_wall=105, wall=15886
2023-05-25 22:46:41 | INFO | train_inner | epoch 003:   1056 / 6686 loss=4.517, nll_loss=2.928, ppl=7.61, wps=52549.6, ups=0.92, wpb=57183.6, bsz=1487.7, num_updates=14400, lr=0.000527046, gnorm=0.275, clip=100, loss_scale=16, train_wall=105, wall=15995
2023-05-25 22:48:29 | INFO | train_inner | epoch 003:   1156 / 6686 loss=4.512, nll_loss=2.924, ppl=7.59, wps=52659.5, ups=0.92, wpb=57108.9, bsz=1472.9, num_updates=14500, lr=0.000525226, gnorm=0.281, clip=100, loss_scale=16, train_wall=105, wall=16104
2023-05-25 22:50:18 | INFO | train_inner | epoch 003:   1256 / 6686 loss=4.518, nll_loss=2.93, ppl=7.62, wps=52647.1, ups=0.92, wpb=57192.7, bsz=1460, num_updates=14600, lr=0.000523424, gnorm=0.283, clip=100, loss_scale=16, train_wall=105, wall=16212
2023-05-25 22:52:07 | INFO | train_inner | epoch 003:   1356 / 6686 loss=4.52, nll_loss=2.933, ppl=7.64, wps=52513, ups=0.92, wpb=57249.5, bsz=1467.9, num_updates=14700, lr=0.000521641, gnorm=0.279, clip=100, loss_scale=16, train_wall=105, wall=16321
2023-05-25 22:53:51 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-25 22:53:57 | INFO | train_inner | epoch 003:   1457 / 6686 loss=4.506, nll_loss=2.916, ppl=7.55, wps=52100, ups=0.91, wpb=57098.3, bsz=1470.7, num_updates=14800, lr=0.000519875, gnorm=0.279, clip=100, loss_scale=30, train_wall=106, wall=16431
2023-05-25 22:55:46 | INFO | train_inner | epoch 003:   1557 / 6686 loss=4.509, nll_loss=2.92, ppl=7.57, wps=52478.4, ups=0.92, wpb=57153.8, bsz=1476.2, num_updates=14900, lr=0.000518128, gnorm=0.284, clip=100, loss_scale=16, train_wall=105, wall=16540
2023-05-25 22:57:34 | INFO | train_inner | epoch 003:   1657 / 6686 loss=4.501, nll_loss=2.911, ppl=7.52, wps=52642, ups=0.92, wpb=57280.7, bsz=1485.8, num_updates=15000, lr=0.000516398, gnorm=0.284, clip=100, loss_scale=16, train_wall=105, wall=16649
2023-05-25 22:59:23 | INFO | train_inner | epoch 003:   1757 / 6686 loss=4.514, nll_loss=2.926, ppl=7.6, wps=52661.6, ups=0.92, wpb=57114.5, bsz=1459.4, num_updates=15100, lr=0.000514685, gnorm=0.277, clip=100, loss_scale=16, train_wall=105, wall=16757
2023-05-25 23:01:12 | INFO | train_inner | epoch 003:   1857 / 6686 loss=4.5, nll_loss=2.91, ppl=7.52, wps=52729.6, ups=0.92, wpb=57291.7, bsz=1480.6, num_updates=15200, lr=0.000512989, gnorm=0.275, clip=100, loss_scale=16, train_wall=105, wall=16866
2023-05-25 23:03:00 | INFO | train_inner | epoch 003:   1957 / 6686 loss=4.494, nll_loss=2.904, ppl=7.49, wps=52529.8, ups=0.92, wpb=57196, bsz=1503.5, num_updates=15300, lr=0.00051131, gnorm=0.285, clip=100, loss_scale=16, train_wall=105, wall=16975
2023-05-25 23:04:49 | INFO | train_inner | epoch 003:   2057 / 6686 loss=4.504, nll_loss=2.915, ppl=7.54, wps=52679.6, ups=0.92, wpb=57279.8, bsz=1460.8, num_updates=15400, lr=0.000509647, gnorm=0.276, clip=100, loss_scale=31, train_wall=105, wall=17083
2023-05-25 23:06:37 | INFO | train_inner | epoch 003:   2157 / 6686 loss=4.505, nll_loss=2.916, ppl=7.55, wps=52736.1, ups=0.92, wpb=57036.9, bsz=1463.6, num_updates=15500, lr=0.000508001, gnorm=0.277, clip=100, loss_scale=32, train_wall=104, wall=17191
2023-05-25 23:06:42 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-25 23:08:27 | INFO | train_inner | epoch 003:   2258 / 6686 loss=4.499, nll_loss=2.91, ppl=7.52, wps=52163.2, ups=0.91, wpb=57276.3, bsz=1485.4, num_updates=15600, lr=0.00050637, gnorm=0.284, clip=100, loss_scale=16, train_wall=106, wall=17301
2023-05-25 23:10:16 | INFO | train_inner | epoch 003:   2358 / 6686 loss=4.493, nll_loss=2.903, ppl=7.48, wps=52572.4, ups=0.92, wpb=57261, bsz=1486.6, num_updates=15700, lr=0.000504754, gnorm=0.279, clip=100, loss_scale=16, train_wall=105, wall=17410
2023-05-25 23:12:05 | INFO | train_inner | epoch 003:   2458 / 6686 loss=4.498, nll_loss=2.908, ppl=7.51, wps=52479.4, ups=0.92, wpb=57116.8, bsz=1468.4, num_updates=15800, lr=0.000503155, gnorm=0.277, clip=100, loss_scale=16, train_wall=105, wall=17519
2023-05-25 23:13:54 | INFO | train_inner | epoch 003:   2558 / 6686 loss=4.505, nll_loss=2.917, ppl=7.55, wps=52615.2, ups=0.92, wpb=57262.3, bsz=1475.3, num_updates=15900, lr=0.00050157, gnorm=0.279, clip=100, loss_scale=16, train_wall=105, wall=17628
2023-05-25 23:15:43 | INFO | train_inner | epoch 003:   2658 / 6686 loss=4.497, nll_loss=2.907, ppl=7.5, wps=52574.6, ups=0.92, wpb=57194.1, bsz=1480.1, num_updates=16000, lr=0.0005, gnorm=0.272, clip=100, loss_scale=16, train_wall=105, wall=17737
2023-05-25 23:17:31 | INFO | train_inner | epoch 003:   2758 / 6686 loss=4.495, nll_loss=2.906, ppl=7.49, wps=52654.6, ups=0.92, wpb=57072.1, bsz=1462.3, num_updates=16100, lr=0.000498445, gnorm=0.273, clip=100, loss_scale=30, train_wall=105, wall=17845
2023-05-25 23:19:18 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-25 23:19:21 | INFO | train_inner | epoch 003:   2859 / 6686 loss=4.502, nll_loss=2.914, ppl=7.54, wps=52153.8, ups=0.91, wpb=57303.3, bsz=1469.8, num_updates=16200, lr=0.000496904, gnorm=0.279, clip=100, loss_scale=31, train_wall=106, wall=17955
2023-05-25 23:21:10 | INFO | train_inner | epoch 003:   2959 / 6686 loss=4.489, nll_loss=2.898, ppl=7.46, wps=52654, ups=0.92, wpb=57362, bsz=1487.5, num_updates=16300, lr=0.000495377, gnorm=0.284, clip=100, loss_scale=16, train_wall=105, wall=18064
2023-05-25 23:22:58 | INFO | train_inner | epoch 003:   3059 / 6686 loss=4.493, nll_loss=2.904, ppl=7.48, wps=52662.9, ups=0.92, wpb=57112.9, bsz=1490.9, num_updates=16400, lr=0.000493865, gnorm=0.282, clip=100, loss_scale=16, train_wall=105, wall=18172
2023-05-25 23:24:47 | INFO | train_inner | epoch 003:   3159 / 6686 loss=4.477, nll_loss=2.885, ppl=7.39, wps=52533, ups=0.92, wpb=57147.2, bsz=1487.9, num_updates=16500, lr=0.000492366, gnorm=0.275, clip=100, loss_scale=16, train_wall=105, wall=18281
2023-05-25 23:26:36 | INFO | train_inner | epoch 003:   3259 / 6686 loss=4.495, nll_loss=2.906, ppl=7.49, wps=52710.5, ups=0.92, wpb=57233.3, bsz=1483.9, num_updates=16600, lr=0.000490881, gnorm=0.275, clip=100, loss_scale=16, train_wall=105, wall=18390
2023-05-25 23:28:24 | INFO | train_inner | epoch 003:   3359 / 6686 loss=4.493, nll_loss=2.904, ppl=7.48, wps=52460.1, ups=0.92, wpb=56945, bsz=1445.8, num_updates=16700, lr=0.000489409, gnorm=0.278, clip=100, loss_scale=16, train_wall=105, wall=18498
2023-05-25 23:29:44 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-25 23:30:14 | INFO | train_inner | epoch 003:   3460 / 6686 loss=4.499, nll_loss=2.91, ppl=7.52, wps=52181, ups=0.91, wpb=57148.1, bsz=1459, num_updates=16800, lr=0.00048795, gnorm=0.279, clip=100, loss_scale=26, train_wall=106, wall=18608
2023-05-25 23:32:03 | INFO | train_inner | epoch 003:   3560 / 6686 loss=4.486, nll_loss=2.895, ppl=7.44, wps=52596.8, ups=0.92, wpb=57399.5, bsz=1490.8, num_updates=16900, lr=0.000486504, gnorm=0.279, clip=100, loss_scale=16, train_wall=105, wall=18717
2023-05-25 23:33:51 | INFO | train_inner | epoch 003:   3660 / 6686 loss=4.479, nll_loss=2.888, ppl=7.4, wps=52653.8, ups=0.92, wpb=57196.5, bsz=1485.4, num_updates=17000, lr=0.000485071, gnorm=0.276, clip=100, loss_scale=16, train_wall=105, wall=18826
2023-05-25 23:35:40 | INFO | train_inner | epoch 003:   3760 / 6686 loss=4.483, nll_loss=2.892, ppl=7.42, wps=52494.4, ups=0.92, wpb=57213.6, bsz=1501.2, num_updates=17100, lr=0.000483651, gnorm=0.274, clip=100, loss_scale=16, train_wall=105, wall=18935
2023-05-25 23:37:29 | INFO | train_inner | epoch 003:   3860 / 6686 loss=4.479, nll_loss=2.889, ppl=7.41, wps=52607.6, ups=0.92, wpb=57044.3, bsz=1483.1, num_updates=17200, lr=0.000482243, gnorm=0.275, clip=100, loss_scale=16, train_wall=105, wall=19043
2023-05-25 23:39:02 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-25 23:39:19 | INFO | train_inner | epoch 003:   3961 / 6686 loss=4.487, nll_loss=2.897, ppl=7.45, wps=51990.8, ups=0.91, wpb=57077, bsz=1466.6, num_updates=17300, lr=0.000480847, gnorm=0.273, clip=100, loss_scale=16, train_wall=106, wall=19153
2023-05-25 23:41:07 | INFO | train_inner | epoch 003:   4061 / 6686 loss=4.49, nll_loss=2.901, ppl=7.47, wps=52659.8, ups=0.92, wpb=57080.7, bsz=1462.8, num_updates=17400, lr=0.000479463, gnorm=0.277, clip=100, loss_scale=16, train_wall=105, wall=19261
2023-05-25 23:42:56 | INFO | train_inner | epoch 003:   4161 / 6686 loss=4.48, nll_loss=2.889, ppl=7.41, wps=52744.3, ups=0.92, wpb=57254.4, bsz=1483.8, num_updates=17500, lr=0.000478091, gnorm=0.269, clip=100, loss_scale=16, train_wall=105, wall=19370
2023-05-25 23:44:44 | INFO | train_inner | epoch 003:   4261 / 6686 loss=4.468, nll_loss=2.876, ppl=7.34, wps=52631, ups=0.92, wpb=57266.6, bsz=1480.8, num_updates=17600, lr=0.000476731, gnorm=0.277, clip=100, loss_scale=16, train_wall=105, wall=19479
2023-05-25 23:46:33 | INFO | train_inner | epoch 003:   4361 / 6686 loss=4.472, nll_loss=2.881, ppl=7.37, wps=52707, ups=0.92, wpb=57298.9, bsz=1486, num_updates=17700, lr=0.000475383, gnorm=0.269, clip=100, loss_scale=16, train_wall=105, wall=19587
2023-05-25 23:48:22 | INFO | train_inner | epoch 003:   4461 / 6686 loss=4.458, nll_loss=2.866, ppl=7.29, wps=52661.2, ups=0.92, wpb=57267.5, bsz=1508.8, num_updates=17800, lr=0.000474045, gnorm=0.263, clip=100, loss_scale=17, train_wall=105, wall=19696
2023-05-25 23:48:40 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-25 23:50:12 | INFO | train_inner | epoch 003:   4562 / 6686 loss=4.469, nll_loss=2.877, ppl=7.35, wps=51909.9, ups=0.91, wpb=57201.7, bsz=1507.4, num_updates=17900, lr=0.000472719, gnorm=0.276, clip=100, loss_scale=19, train_wall=106, wall=19806
2023-05-25 23:52:01 | INFO | train_inner | epoch 003:   4662 / 6686 loss=4.47, nll_loss=2.878, ppl=7.35, wps=52522.3, ups=0.92, wpb=57156.6, bsz=1477.7, num_updates=18000, lr=0.000471405, gnorm=0.271, clip=100, loss_scale=16, train_wall=105, wall=19915
2023-05-25 23:53:49 | INFO | train_inner | epoch 003:   4762 / 6686 loss=4.458, nll_loss=2.865, ppl=7.28, wps=52736.5, ups=0.92, wpb=57217.7, bsz=1489.1, num_updates=18100, lr=0.0004701, gnorm=0.273, clip=100, loss_scale=16, train_wall=105, wall=20024
2023-05-25 23:55:38 | INFO | train_inner | epoch 003:   4862 / 6686 loss=4.474, nll_loss=2.884, ppl=7.38, wps=52534.4, ups=0.92, wpb=57004.6, bsz=1455.4, num_updates=18200, lr=0.000468807, gnorm=0.273, clip=100, loss_scale=16, train_wall=105, wall=20132
2023-05-25 23:57:27 | INFO | train_inner | epoch 003:   4962 / 6686 loss=4.469, nll_loss=2.878, ppl=7.35, wps=52584.1, ups=0.92, wpb=57241.9, bsz=1472.4, num_updates=18300, lr=0.000467525, gnorm=0.271, clip=100, loss_scale=16, train_wall=105, wall=20241
2023-05-25 23:58:11 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-25 23:59:16 | INFO | train_inner | epoch 003:   5063 / 6686 loss=4.475, nll_loss=2.885, ppl=7.38, wps=52185.2, ups=0.91, wpb=57056, bsz=1468.8, num_updates=18400, lr=0.000466252, gnorm=0.269, clip=100, loss_scale=18, train_wall=105, wall=20350
2023-05-26 00:01:05 | INFO | train_inner | epoch 003:   5163 / 6686 loss=4.46, nll_loss=2.868, ppl=7.3, wps=52682.9, ups=0.92, wpb=57313.7, bsz=1501.8, num_updates=18500, lr=0.000464991, gnorm=0.271, clip=100, loss_scale=16, train_wall=105, wall=20459
2023-05-26 00:02:54 | INFO | train_inner | epoch 003:   5263 / 6686 loss=4.474, nll_loss=2.883, ppl=7.38, wps=52581.7, ups=0.92, wpb=57147.2, bsz=1457.1, num_updates=18600, lr=0.000463739, gnorm=0.272, clip=100, loss_scale=16, train_wall=105, wall=20568
2023-05-26 00:03:48 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 00:04:43 | INFO | train_inner | epoch 003:   5364 / 6686 loss=4.461, nll_loss=2.869, ppl=7.3, wps=52056.1, ups=0.91, wpb=56984.4, bsz=1479.3, num_updates=18700, lr=0.000462497, gnorm=0.27, clip=100, loss_scale=12, train_wall=106, wall=20677
2023-05-26 00:06:32 | INFO | train_inner | epoch 003:   5464 / 6686 loss=4.449, nll_loss=2.856, ppl=7.24, wps=52620.7, ups=0.92, wpb=57409.8, bsz=1501.5, num_updates=18800, lr=0.000461266, gnorm=0.269, clip=100, loss_scale=8, train_wall=105, wall=20786
2023-05-26 00:08:21 | INFO | train_inner | epoch 003:   5564 / 6686 loss=4.463, nll_loss=2.871, ppl=7.32, wps=52555.3, ups=0.92, wpb=57197.7, bsz=1474.8, num_updates=18900, lr=0.000460044, gnorm=0.274, clip=100, loss_scale=8, train_wall=105, wall=20895
2023-05-26 00:10:09 | INFO | train_inner | epoch 003:   5664 / 6686 loss=4.454, nll_loss=2.862, ppl=7.27, wps=52861.2, ups=0.92, wpb=57235.2, bsz=1495, num_updates=19000, lr=0.000458831, gnorm=0.269, clip=100, loss_scale=8, train_wall=104, wall=21003
2023-05-26 00:11:58 | INFO | train_inner | epoch 003:   5764 / 6686 loss=4.46, nll_loss=2.868, ppl=7.3, wps=52502.2, ups=0.92, wpb=57238.7, bsz=1464.6, num_updates=19100, lr=0.000457629, gnorm=0.265, clip=100, loss_scale=8, train_wall=105, wall=21112
2023-05-26 00:13:47 | INFO | train_inner | epoch 003:   5864 / 6686 loss=4.456, nll_loss=2.864, ppl=7.28, wps=52599.8, ups=0.92, wpb=57344.5, bsz=1472.6, num_updates=19200, lr=0.000456435, gnorm=0.261, clip=100, loss_scale=11, train_wall=105, wall=21221
2023-05-26 00:15:36 | INFO | train_inner | epoch 003:   5964 / 6686 loss=4.452, nll_loss=2.86, ppl=7.26, wps=52565.2, ups=0.92, wpb=57152.9, bsz=1501.4, num_updates=19300, lr=0.000455251, gnorm=0.273, clip=100, loss_scale=16, train_wall=105, wall=21330
2023-05-26 00:17:25 | INFO | train_inner | epoch 003:   6064 / 6686 loss=4.456, nll_loss=2.864, ppl=7.28, wps=52677.8, ups=0.92, wpb=57319.6, bsz=1487.4, num_updates=19400, lr=0.000454077, gnorm=0.27, clip=100, loss_scale=16, train_wall=105, wall=21439
2023-05-26 00:19:14 | INFO | train_inner | epoch 003:   6164 / 6686 loss=4.456, nll_loss=2.863, ppl=7.28, wps=52446.8, ups=0.92, wpb=57055.6, bsz=1467.4, num_updates=19500, lr=0.000452911, gnorm=0.272, clip=100, loss_scale=16, train_wall=105, wall=21548
2023-05-26 00:21:03 | INFO | train_inner | epoch 003:   6264 / 6686 loss=4.451, nll_loss=2.858, ppl=7.25, wps=52466.1, ups=0.92, wpb=57296.1, bsz=1488, num_updates=19600, lr=0.000451754, gnorm=0.266, clip=100, loss_scale=16, train_wall=105, wall=21657
2023-05-26 00:22:46 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 00:22:53 | INFO | train_inner | epoch 003:   6365 / 6686 loss=4.45, nll_loss=2.857, ppl=7.25, wps=52174.6, ups=0.91, wpb=57454.1, bsz=1450.2, num_updates=19700, lr=0.000450606, gnorm=0.266, clip=100, loss_scale=19, train_wall=106, wall=21767
2023-05-26 00:24:42 | INFO | train_inner | epoch 003:   6465 / 6686 loss=4.445, nll_loss=2.851, ppl=7.22, wps=52702.1, ups=0.92, wpb=57236.8, bsz=1489.1, num_updates=19800, lr=0.000449467, gnorm=0.271, clip=100, loss_scale=16, train_wall=105, wall=21876
2023-05-26 00:26:30 | INFO | train_inner | epoch 003:   6565 / 6686 loss=4.461, nll_loss=2.87, ppl=7.31, wps=52358.8, ups=0.92, wpb=56990.8, bsz=1448.6, num_updates=19900, lr=0.000448336, gnorm=0.27, clip=100, loss_scale=16, train_wall=105, wall=21985
2023-05-26 00:28:19 | INFO | train_inner | epoch 003:   6665 / 6686 loss=4.454, nll_loss=2.861, ppl=7.27, wps=52585.9, ups=0.92, wpb=57208.6, bsz=1469.9, num_updates=20000, lr=0.000447214, gnorm=0.268, clip=100, loss_scale=16, train_wall=105, wall=22093
2023-05-26 00:28:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-26 00:28:46 | INFO | fairseq.tasks.translation | example hypothesis: Why? Why?
2023-05-26 00:28:46 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-26 00:28:47 | INFO | fairseq.tasks.translation | example hypothesis: You’ll lose so much that you don’t even have any pants left!
2023-05-26 00:28:47 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-26 00:28:47 | INFO | fairseq.tasks.translation | example hypothesis: Shen Liangchuan heaved a sigh of relief when he heard her say, “I’ll call you to the same room!”
2023-05-26 00:28:47 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-26 00:28:48 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved her hand and entered the elevator.
2023-05-26 00:28:48 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-26 00:28:49 | INFO | fairseq.tasks.translation | example hypothesis: She raised her head and saw Song Cheng standing in the distance!
2023-05-26 00:28:49 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-26 00:28:49 | INFO | fairseq.tasks.translation | example hypothesis: Song Cheng then patted his chest. “You scared me to death! Where’s Wang Chuan?”
2023-05-26 00:28:49 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-26 00:28:50 | INFO | fairseq.tasks.translation | example hypothesis: I said, “No, I can’t eat it.”
2023-05-26 00:28:50 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-26 00:28:50 | INFO | fairseq.tasks.translation | example hypothesis: Hao Wang insisted on him first, but Wang Wen Hao insisted on making the public opinion of him lean towards Wang Wen Hao.
2023-05-26 00:28:50 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-26 00:28:51 | INFO | fairseq.tasks.translation | example hypothesis: With his status, Baili Hongzhuang had to treat him even if he didn’t treat him!
2023-05-26 00:28:51 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-26 00:28:52 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian said, “Mr. Shen, I... I’ve lost too much blood and my brain is out of oxygen. I can’t figure it out. Why don’t you give me a notification?”
2023-05-26 00:28:52 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-26 00:28:53 | INFO | fairseq.tasks.translation | example hypothesis: He didn’t know why so many people heard about it. Since he couldn’t cover it up, he might as well tell them.
2023-05-26 00:28:53 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-26 00:28:54 | INFO | fairseq.tasks.translation | example hypothesis: She deliberately lowered her voice, but it could not conceal the viciousness and viciousness in her tone.
2023-05-26 00:28:54 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-26 00:28:55 | INFO | fairseq.tasks.translation | example hypothesis: Different levels of beast pets had different strengths, but beast pets were precious and rare. It was impossible for ordinary people to possess them, and even official descendants could not possess them.
2023-05-26 00:28:55 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-26 00:28:56 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chixia gritted his teeth and cursed.
2023-05-26 00:28:56 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-26 00:28:57 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang’s disguise was very good, Di Bei Chen still saw the flash of emotion in her eyes, and his eyes were filled with warmth.
2023-05-26 00:28:57 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-26 00:28:58 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia walked in, he didn't even see a few waiters, let alone the guests.
2023-05-26 00:28:58 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-26 00:28:59 | INFO | fairseq.tasks.translation | example hypothesis: This person was the Fourth Miss of the Ye Family, Ye Qingling.
2023-05-26 00:28:59 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-26 00:29:00 | INFO | fairseq.tasks.translation | example hypothesis: At this moment, she felt as though her chin was about to shatter.
2023-05-26 00:29:00 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-26 00:29:02 | INFO | fairseq.tasks.translation | example hypothesis: “Mu Zi, help me. If it wasn't for you, that old man wouldn't have set his eyes on me.”
2023-05-26 00:29:02 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-26 00:29:03 | INFO | fairseq.tasks.translation | example hypothesis: Baili Yuyan was even more excited. She was the one responsible for this matter. Earlier, Baili Hongzhuang had treated her like that. This time around, she would definitely make things difficult for Baili Hongzhuang.
2023-05-26 00:29:03 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-26 00:29:04 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How could that be? They also have four Magic Magisters on their side, so of course they won’t surrender so easily. After arguing for a long time, they finally decided to use the method to get control of the Summer Kingdom in the future.”
2023-05-26 00:29:04 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-26 00:29:06 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a little. He had always been looking for an excuse for Li Yuyue’s inability to participate in the royal hunting competition.
2023-05-26 00:29:06 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-26 00:29:07 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my standard good? I’m all the most outstanding talents in the country. Is my magic that weak?”
2023-05-26 00:29:07 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-26 00:29:09 | INFO | fairseq.tasks.translation | example hypothesis: What Luo Yi Bei meant was that if Fang Chi Xia didn’t want to go, he didn’t need to go.
2023-05-26 00:29:09 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-26 00:29:10 | INFO | fairseq.tasks.translation | example hypothesis: She tilted her head and saw that the five palm marks on her cheeks were extremely eye-catching. They were swollen at a speed visible to the naked eye. When she reached out and touched them, she couldn’t help but let out a hiss.
2023-05-26 00:29:10 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-26 00:29:12 | INFO | fairseq.tasks.translation | example hypothesis: This... how could this be the charm that that trash could give off?
2023-05-26 00:29:12 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-26 00:29:13 | INFO | fairseq.tasks.translation | example hypothesis: How could Wang Wenhao find the newspaper? The chief editor should have called her to tell her not to come to the newspaper, but these three people... had plotted against her!
2023-05-26 00:29:13 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-26 00:29:15 | INFO | fairseq.tasks.translation | example hypothesis: Hearing Teacher Di’s praise, I was delighted. I withdrew the energy ball with my left hand, and a beam of light shot out from my right hand towards Teacher Zhen. The light sword actually managed to hit me smoothly, and I was shocked. After a closer look, I realized that it was just an afterimage. Teacher Zhen had already moved to my back and shouted, “Berserk
2023-05-26 00:29:15 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-26 00:29:18 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Originally, we proposed three rounds of two wins, but they said that it was unfair because we had Teacher Dick and Teacher Zhen. Their rankings were even higher than theirs, and they proposed five rounds of three wins. Since we were the ones who proposed the competition, we could only listen to them in the end. Three days from now, we will have a secret competition in the Royal Martial Arts Arena. If we can’t compete, then we can
2023-05-26 00:29:18 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-26 00:29:20 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Di used light-type rank 7 spell, Light Lightning Burst. I didn’t use much of this spell, because I couldn’t control it very well. Teacher Di released nine light bolts and surrounded me, forming a simple spell formation, preventing me from escaping through short distance. Then, the light bolts exploded one after another and formed a powerful attack.
2023-05-26 00:29:20 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-26 00:29:23 | INFO | fairseq.tasks.translation | example hypothesis: As soon as Ma Ke and the two teachers reached the other side of the courtyard, Teacher Zhen shot a small Dimensional Slash at me. As expected of the continent’s number one Magician, the powerful suction force he released was much stronger than the one I released. A small spatial crack appeared beside me, and a powerful suction force immediately swept over.
2023-05-26 00:29:23 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-26 00:29:23 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.3 | nll_loss 2.661 | ppl 6.32 | bleu 20.85 | wps 1966.4 | wpb 2420.8 | bsz 84.5 | num_updates 20021 | best_bleu 20.85
2023-05-26 00:29:23 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-26 00:29:28 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/concat-1-1-0.2-sf[zh-en]/checkpoint3.pt (epoch 3 @ 20021 updates, score 20.85) (writing took 4.26903014909476 seconds)
2023-05-26 00:29:28 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-05-26 00:29:28 | INFO | train | epoch 003 | loss 4.487 | nll_loss 2.897 | ppl 7.45 | wps 52068.6 | ups 0.91 | wpb 57190.3 | bsz 1477.7 | num_updates 20021 | lr 0.000446979 | gnorm 0.276 | clip 100 | loss_scale 17 | train_wall 7020 | wall 22162
2023-05-26 00:29:28 | INFO | fairseq.trainer | begin training epoch 4
2023-05-26 00:31:04 | INFO | train_inner | epoch 004:     79 / 6686 loss=4.416, nll_loss=2.818, ppl=7.05, wps=34466.6, ups=0.61, wpb=56743.7, bsz=1475, num_updates=20100, lr=0.0004461, gnorm=0.272, clip=100, loss_scale=16, train_wall=107, wall=22258
2023-05-26 00:32:57 | INFO | train_inner | epoch 004:    179 / 6686 loss=4.431, nll_loss=2.835, ppl=7.13, wps=50660.5, ups=0.89, wpb=57176.7, bsz=1448.1, num_updates=20200, lr=0.000444994, gnorm=0.267, clip=100, loss_scale=16, train_wall=107, wall=22371
2023-05-26 00:34:47 | INFO | train_inner | epoch 004:    279 / 6686 loss=4.414, nll_loss=2.816, ppl=7.04, wps=51896.1, ups=0.9, wpb=57366.6, bsz=1488, num_updates=20300, lr=0.000443897, gnorm=0.261, clip=100, loss_scale=31, train_wall=106, wall=22481
2023-05-26 00:36:36 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 00:36:37 | INFO | train_inner | epoch 004:    380 / 6686 loss=4.425, nll_loss=2.828, ppl=7.1, wps=51875.4, ups=0.91, wpb=57042.8, bsz=1453, num_updates=20400, lr=0.000442807, gnorm=0.263, clip=100, loss_scale=32, train_wall=106, wall=22591
2023-05-26 00:38:26 | INFO | train_inner | epoch 004:    480 / 6686 loss=4.413, nll_loss=2.815, ppl=7.04, wps=52583.8, ups=0.92, wpb=57240.6, bsz=1493.3, num_updates=20500, lr=0.000441726, gnorm=0.267, clip=100, loss_scale=16, train_wall=105, wall=22700
2023-05-26 00:40:15 | INFO | train_inner | epoch 004:    580 / 6686 loss=4.428, nll_loss=2.831, ppl=7.12, wps=52553.7, ups=0.92, wpb=57277.3, bsz=1477.8, num_updates=20600, lr=0.000440653, gnorm=0.267, clip=100, loss_scale=16, train_wall=105, wall=22809
2023-05-26 00:42:04 | INFO | train_inner | epoch 004:    680 / 6686 loss=4.425, nll_loss=2.828, ppl=7.1, wps=52762.6, ups=0.92, wpb=57195.8, bsz=1467.3, num_updates=20700, lr=0.000439587, gnorm=0.27, clip=100, loss_scale=16, train_wall=105, wall=22918
2023-05-26 00:43:53 | INFO | train_inner | epoch 004:    780 / 6686 loss=4.424, nll_loss=2.827, ppl=7.1, wps=52554.2, ups=0.92, wpb=57424.2, bsz=1495.4, num_updates=20800, lr=0.000438529, gnorm=0.269, clip=100, loss_scale=16, train_wall=105, wall=23027
2023-05-26 00:45:41 | INFO | train_inner | epoch 004:    880 / 6686 loss=4.419, nll_loss=2.821, ppl=7.07, wps=52567, ups=0.92, wpb=57035.1, bsz=1462.9, num_updates=20900, lr=0.000437479, gnorm=0.266, clip=100, loss_scale=16, train_wall=105, wall=23135
2023-05-26 00:47:07 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 00:47:31 | INFO | train_inner | epoch 004:    981 / 6686 loss=4.422, nll_loss=2.825, ppl=7.09, wps=52214.2, ups=0.91, wpb=57239.2, bsz=1461.6, num_updates=21000, lr=0.000436436, gnorm=0.268, clip=100, loss_scale=27, train_wall=106, wall=23245
2023-05-26 00:49:20 | INFO | train_inner | epoch 004:   1081 / 6686 loss=4.426, nll_loss=2.83, ppl=7.11, wps=52544.3, ups=0.92, wpb=57071.5, bsz=1454.9, num_updates=21100, lr=0.0004354, gnorm=0.266, clip=100, loss_scale=16, train_wall=105, wall=23354
2023-05-26 00:51:08 | INFO | train_inner | epoch 004:   1181 / 6686 loss=4.411, nll_loss=2.813, ppl=7.03, wps=52687.1, ups=0.92, wpb=57295.4, bsz=1459.4, num_updates=21200, lr=0.000434372, gnorm=0.267, clip=100, loss_scale=16, train_wall=105, wall=23462
2023-05-26 00:52:57 | INFO | train_inner | epoch 004:   1281 / 6686 loss=4.427, nll_loss=2.831, ppl=7.11, wps=52618.2, ups=0.92, wpb=57152.8, bsz=1477.8, num_updates=21300, lr=0.000433351, gnorm=0.268, clip=100, loss_scale=16, train_wall=105, wall=23571
2023-05-26 00:54:46 | INFO | train_inner | epoch 004:   1381 / 6686 loss=4.428, nll_loss=2.832, ppl=7.12, wps=52637.7, ups=0.92, wpb=57284, bsz=1475.7, num_updates=21400, lr=0.000432338, gnorm=0.267, clip=100, loss_scale=16, train_wall=105, wall=23680
2023-05-26 00:56:34 | INFO | train_inner | epoch 004:   1481 / 6686 loss=4.412, nll_loss=2.814, ppl=7.03, wps=52601.5, ups=0.92, wpb=57110.1, bsz=1463.5, num_updates=21500, lr=0.000431331, gnorm=0.265, clip=100, loss_scale=18, train_wall=105, wall=23788
2023-05-26 00:57:14 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 00:58:24 | INFO | train_inner | epoch 004:   1582 / 6686 loss=4.417, nll_loss=2.82, ppl=7.06, wps=52066.8, ups=0.91, wpb=57082.8, bsz=1480.5, num_updates=21600, lr=0.000430331, gnorm=0.268, clip=100, loss_scale=22, train_wall=106, wall=23898
2023-05-26 01:00:12 | INFO | train_inner | epoch 004:   1682 / 6686 loss=4.412, nll_loss=2.814, ppl=7.03, wps=52782.4, ups=0.92, wpb=57198.6, bsz=1484.7, num_updates=21700, lr=0.000429339, gnorm=0.265, clip=100, loss_scale=16, train_wall=105, wall=24006
2023-05-26 01:02:00 | INFO | train_inner | epoch 004:   1782 / 6686 loss=4.415, nll_loss=2.818, ppl=7.05, wps=52918.5, ups=0.93, wpb=57062.8, bsz=1479.4, num_updates=21800, lr=0.000428353, gnorm=0.264, clip=100, loss_scale=16, train_wall=104, wall=24114
2023-05-26 01:03:48 | INFO | train_inner | epoch 004:   1882 / 6686 loss=4.414, nll_loss=2.817, ppl=7.05, wps=52875.1, ups=0.92, wpb=57217.4, bsz=1504.7, num_updates=21900, lr=0.000427374, gnorm=0.265, clip=100, loss_scale=16, train_wall=104, wall=24223
2023-05-26 01:05:37 | INFO | train_inner | epoch 004:   1982 / 6686 loss=4.411, nll_loss=2.814, ppl=7.03, wps=52783.3, ups=0.92, wpb=57251.8, bsz=1496, num_updates=22000, lr=0.000426401, gnorm=0.265, clip=100, loss_scale=16, train_wall=105, wall=24331
2023-05-26 01:06:45 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 01:07:27 | INFO | train_inner | epoch 004:   2083 / 6686 loss=4.411, nll_loss=2.813, ppl=7.03, wps=52064.9, ups=0.91, wpb=57141.8, bsz=1496.3, num_updates=22100, lr=0.000425436, gnorm=0.263, clip=100, loss_scale=19, train_wall=106, wall=24441
2023-05-26 01:09:15 | INFO | train_inner | epoch 004:   2183 / 6686 loss=4.409, nll_loss=2.811, ppl=7.02, wps=52640.2, ups=0.92, wpb=57083.1, bsz=1485, num_updates=22200, lr=0.000424476, gnorm=0.261, clip=100, loss_scale=16, train_wall=105, wall=24549
2023-05-26 01:11:03 | INFO | train_inner | epoch 004:   2283 / 6686 loss=4.423, nll_loss=2.826, ppl=7.09, wps=52845.9, ups=0.93, wpb=57091, bsz=1451.4, num_updates=22300, lr=0.000423524, gnorm=0.26, clip=100, loss_scale=16, train_wall=104, wall=24657
2023-05-26 01:12:52 | INFO | train_inner | epoch 004:   2383 / 6686 loss=4.414, nll_loss=2.816, ppl=7.04, wps=52698.6, ups=0.92, wpb=57186.3, bsz=1465, num_updates=22400, lr=0.000422577, gnorm=0.268, clip=100, loss_scale=16, train_wall=105, wall=24766
2023-05-26 01:14:40 | INFO | train_inner | epoch 004:   2483 / 6686 loss=4.399, nll_loss=2.8, ppl=6.96, wps=52617.2, ups=0.92, wpb=57267.7, bsz=1475.3, num_updates=22500, lr=0.000421637, gnorm=0.262, clip=100, loss_scale=16, train_wall=105, wall=24875
2023-05-26 01:16:29 | INFO | train_inner | epoch 004:   2583 / 6686 loss=4.415, nll_loss=2.818, ppl=7.05, wps=52578.6, ups=0.92, wpb=57143.8, bsz=1466.4, num_updates=22600, lr=0.000420703, gnorm=0.264, clip=100, loss_scale=20, train_wall=105, wall=24983
2023-05-26 01:17:27 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 01:18:19 | INFO | train_inner | epoch 004:   2684 / 6686 loss=4.416, nll_loss=2.819, ppl=7.06, wps=52235.3, ups=0.91, wpb=57277.8, bsz=1473.1, num_updates=22700, lr=0.000419775, gnorm=0.26, clip=100, loss_scale=24, train_wall=106, wall=25093
2023-05-26 01:20:08 | INFO | train_inner | epoch 004:   2784 / 6686 loss=4.411, nll_loss=2.813, ppl=7.03, wps=52643.9, ups=0.92, wpb=57294.1, bsz=1474, num_updates=22800, lr=0.000418854, gnorm=0.264, clip=100, loss_scale=16, train_wall=105, wall=25202
2023-05-26 01:21:56 | INFO | train_inner | epoch 004:   2884 / 6686 loss=4.403, nll_loss=2.805, ppl=6.99, wps=52703.1, ups=0.92, wpb=57141.6, bsz=1494.4, num_updates=22900, lr=0.000417938, gnorm=0.261, clip=100, loss_scale=16, train_wall=105, wall=25310
2023-05-26 01:23:45 | INFO | train_inner | epoch 004:   2984 / 6686 loss=4.403, nll_loss=2.805, ppl=6.99, wps=52753.1, ups=0.92, wpb=57316.1, bsz=1490.5, num_updates=23000, lr=0.000417029, gnorm=0.261, clip=100, loss_scale=16, train_wall=105, wall=25419
2023-05-26 01:25:34 | INFO | train_inner | epoch 004:   3084 / 6686 loss=4.411, nll_loss=2.814, ppl=7.03, wps=52709.7, ups=0.92, wpb=57368.7, bsz=1484.2, num_updates=23100, lr=0.000416125, gnorm=0.262, clip=100, loss_scale=16, train_wall=105, wall=25528
2023-05-26 01:27:22 | INFO | train_inner | epoch 004:   3184 / 6686 loss=4.417, nll_loss=2.821, ppl=7.07, wps=52500.4, ups=0.92, wpb=57181.4, bsz=1464.9, num_updates=23200, lr=0.000415227, gnorm=0.264, clip=100, loss_scale=22, train_wall=105, wall=25637
2023-05-26 01:28:19 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 01:29:12 | INFO | train_inner | epoch 004:   3285 / 6686 loss=4.396, nll_loss=2.797, ppl=6.95, wps=52278.5, ups=0.91, wpb=57351.3, bsz=1481.9, num_updates=23300, lr=0.000414335, gnorm=0.26, clip=100, loss_scale=24, train_wall=106, wall=25746
2023-05-26 01:31:00 | INFO | train_inner | epoch 004:   3385 / 6686 loss=4.416, nll_loss=2.82, ppl=7.06, wps=52730.1, ups=0.92, wpb=57042.4, bsz=1469.8, num_updates=23400, lr=0.000413449, gnorm=0.264, clip=100, loss_scale=16, train_wall=104, wall=25855
2023-05-26 01:32:49 | INFO | train_inner | epoch 004:   3485 / 6686 loss=4.403, nll_loss=2.806, ppl=6.99, wps=52604.1, ups=0.92, wpb=56977.5, bsz=1492.6, num_updates=23500, lr=0.000412568, gnorm=0.264, clip=100, loss_scale=16, train_wall=105, wall=25963
2023-05-26 01:34:37 | INFO | train_inner | epoch 004:   3585 / 6686 loss=4.403, nll_loss=2.805, ppl=6.99, wps=52693, ups=0.92, wpb=57137.1, bsz=1466, num_updates=23600, lr=0.000411693, gnorm=0.263, clip=100, loss_scale=16, train_wall=105, wall=26071
2023-05-26 01:36:25 | INFO | train_inner | epoch 004:   3685 / 6686 loss=4.416, nll_loss=2.819, ppl=7.06, wps=52700.8, ups=0.92, wpb=57058.4, bsz=1456.8, num_updates=23700, lr=0.000410824, gnorm=0.262, clip=100, loss_scale=16, train_wall=105, wall=26180
2023-05-26 01:37:58 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 01:38:15 | INFO | train_inner | epoch 004:   3786 / 6686 loss=4.405, nll_loss=2.807, ppl=7, wps=52138.1, ups=0.91, wpb=57182.1, bsz=1487.4, num_updates=23800, lr=0.00040996, gnorm=0.257, clip=100, loss_scale=19, train_wall=106, wall=26289
2023-05-26 01:40:04 | INFO | train_inner | epoch 004:   3886 / 6686 loss=4.402, nll_loss=2.804, ppl=6.98, wps=52697.9, ups=0.92, wpb=57151.3, bsz=1463.8, num_updates=23900, lr=0.000409101, gnorm=0.266, clip=100, loss_scale=16, train_wall=105, wall=26398
2023-05-26 01:41:52 | INFO | train_inner | epoch 004:   3986 / 6686 loss=4.393, nll_loss=2.794, ppl=6.94, wps=52692.6, ups=0.92, wpb=57280.2, bsz=1497.6, num_updates=24000, lr=0.000408248, gnorm=0.262, clip=100, loss_scale=16, train_wall=105, wall=26506
2023-05-26 01:43:41 | INFO | train_inner | epoch 004:   4086 / 6686 loss=4.39, nll_loss=2.79, ppl=6.92, wps=52694.4, ups=0.92, wpb=57073, bsz=1487.3, num_updates=24100, lr=0.0004074, gnorm=0.263, clip=100, loss_scale=16, train_wall=105, wall=26615
2023-05-26 01:45:29 | INFO | train_inner | epoch 004:   4186 / 6686 loss=4.409, nll_loss=2.812, ppl=7.02, wps=52573.3, ups=0.92, wpb=57108.4, bsz=1467.5, num_updates=24200, lr=0.000406558, gnorm=0.262, clip=100, loss_scale=16, train_wall=105, wall=26723
2023-05-26 01:47:14 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 01:47:19 | INFO | train_inner | epoch 004:   4287 / 6686 loss=4.396, nll_loss=2.797, ppl=6.95, wps=52171.3, ups=0.91, wpb=57170.8, bsz=1470, num_updates=24300, lr=0.00040572, gnorm=0.261, clip=100, loss_scale=16, train_wall=106, wall=26833
2023-05-26 01:49:08 | INFO | train_inner | epoch 004:   4387 / 6686 loss=4.422, nll_loss=2.827, ppl=7.1, wps=52734.6, ups=0.92, wpb=57408.3, bsz=1453.8, num_updates=24400, lr=0.000404888, gnorm=0.261, clip=100, loss_scale=16, train_wall=105, wall=26942
2023-05-26 01:50:56 | INFO | train_inner | epoch 004:   4487 / 6686 loss=4.402, nll_loss=2.804, ppl=6.99, wps=52852, ups=0.92, wpb=57310.9, bsz=1480.9, num_updates=24500, lr=0.000404061, gnorm=0.263, clip=100, loss_scale=16, train_wall=105, wall=27050
2023-05-26 01:52:44 | INFO | train_inner | epoch 004:   4587 / 6686 loss=4.406, nll_loss=2.809, ppl=7.01, wps=52803, ups=0.92, wpb=57200.8, bsz=1474.3, num_updates=24600, lr=0.000403239, gnorm=0.259, clip=100, loss_scale=16, train_wall=105, wall=27159
2023-05-26 01:54:33 | INFO | train_inner | epoch 004:   4687 / 6686 loss=4.399, nll_loss=2.801, ppl=6.97, wps=52795.8, ups=0.92, wpb=57283.5, bsz=1477.7, num_updates=24700, lr=0.000402422, gnorm=0.255, clip=100, loss_scale=16, train_wall=105, wall=27267
2023-05-26 01:56:22 | INFO | train_inner | epoch 004:   4787 / 6686 loss=4.4, nll_loss=2.802, ppl=6.97, wps=52613.5, ups=0.92, wpb=57208.7, bsz=1461.6, num_updates=24800, lr=0.00040161, gnorm=0.256, clip=100, loss_scale=16, train_wall=105, wall=27376
2023-05-26 01:58:11 | INFO | train_inner | epoch 004:   4887 / 6686 loss=4.393, nll_loss=2.794, ppl=6.94, wps=52501.6, ups=0.92, wpb=57172.7, bsz=1477.9, num_updates=24900, lr=0.000400802, gnorm=0.257, clip=100, loss_scale=31, train_wall=105, wall=27485
2023-05-26 01:59:59 | INFO | train_inner | epoch 004:   4987 / 6686 loss=4.394, nll_loss=2.796, ppl=6.94, wps=52707.3, ups=0.92, wpb=57283.1, bsz=1482, num_updates=25000, lr=0.0004, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=27593
2023-05-26 02:01:47 | INFO | train_inner | epoch 004:   5087 / 6686 loss=4.381, nll_loss=2.781, ppl=6.87, wps=52955.9, ups=0.92, wpb=57290.9, bsz=1503.9, num_updates=25100, lr=0.000399202, gnorm=0.26, clip=100, loss_scale=32, train_wall=104, wall=27702
2023-05-26 02:02:13 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 02:03:37 | INFO | train_inner | epoch 004:   5188 / 6686 loss=4.399, nll_loss=2.801, ppl=6.97, wps=52132.5, ups=0.91, wpb=57214.5, bsz=1477.4, num_updates=25200, lr=0.00039841, gnorm=0.264, clip=100, loss_scale=20, train_wall=106, wall=27811
2023-05-26 02:05:26 | INFO | train_inner | epoch 004:   5288 / 6686 loss=4.4, nll_loss=2.802, ppl=6.97, wps=52662.9, ups=0.92, wpb=57196.4, bsz=1471.5, num_updates=25300, lr=0.000397621, gnorm=0.265, clip=100, loss_scale=16, train_wall=105, wall=27920
2023-05-26 02:07:14 | INFO | train_inner | epoch 004:   5388 / 6686 loss=4.383, nll_loss=2.783, ppl=6.88, wps=52676, ups=0.92, wpb=57135.7, bsz=1480.2, num_updates=25400, lr=0.000396838, gnorm=0.264, clip=100, loss_scale=16, train_wall=105, wall=28028
2023-05-26 02:09:03 | INFO | train_inner | epoch 004:   5488 / 6686 loss=4.4, nll_loss=2.803, ppl=6.98, wps=52705.4, ups=0.92, wpb=57064.9, bsz=1468.7, num_updates=25500, lr=0.000396059, gnorm=0.258, clip=100, loss_scale=16, train_wall=105, wall=28137
2023-05-26 02:10:51 | INFO | train_inner | epoch 004:   5588 / 6686 loss=4.398, nll_loss=2.8, ppl=6.96, wps=52697.2, ups=0.92, wpb=57082.2, bsz=1471, num_updates=25600, lr=0.000395285, gnorm=0.258, clip=100, loss_scale=16, train_wall=105, wall=28245
2023-05-26 02:12:39 | INFO | train_inner | epoch 004:   5688 / 6686 loss=4.386, nll_loss=2.787, ppl=6.9, wps=52849.1, ups=0.92, wpb=57323.3, bsz=1495, num_updates=25700, lr=0.000394515, gnorm=0.259, clip=100, loss_scale=27, train_wall=105, wall=28353
2023-05-26 02:14:28 | INFO | train_inner | epoch 004:   5788 / 6686 loss=4.398, nll_loss=2.799, ppl=6.96, wps=52387.1, ups=0.92, wpb=57179.6, bsz=1471.4, num_updates=25800, lr=0.00039375, gnorm=0.26, clip=100, loss_scale=32, train_wall=105, wall=28463
2023-05-26 02:15:30 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 02:16:18 | INFO | train_inner | epoch 004:   5889 / 6686 loss=4.39, nll_loss=2.791, ppl=6.92, wps=52280.4, ups=0.91, wpb=57244.5, bsz=1474.7, num_updates=25900, lr=0.000392989, gnorm=0.256, clip=100, loss_scale=25, train_wall=106, wall=28572
2023-05-26 02:18:07 | INFO | train_inner | epoch 004:   5989 / 6686 loss=4.393, nll_loss=2.794, ppl=6.94, wps=52727.3, ups=0.92, wpb=57231, bsz=1479.8, num_updates=26000, lr=0.000392232, gnorm=0.259, clip=100, loss_scale=16, train_wall=105, wall=28681
2023-05-26 02:19:55 | INFO | train_inner | epoch 004:   6089 / 6686 loss=4.382, nll_loss=2.783, ppl=6.88, wps=52666.6, ups=0.92, wpb=57234.6, bsz=1499.8, num_updates=26100, lr=0.00039148, gnorm=0.261, clip=100, loss_scale=16, train_wall=105, wall=28789
2023-05-26 02:21:44 | INFO | train_inner | epoch 004:   6189 / 6686 loss=4.391, nll_loss=2.793, ppl=6.93, wps=52663.2, ups=0.92, wpb=57228.5, bsz=1498.8, num_updates=26200, lr=0.000390732, gnorm=0.265, clip=100, loss_scale=16, train_wall=105, wall=28898
2023-05-26 02:23:32 | INFO | train_inner | epoch 004:   6289 / 6686 loss=4.378, nll_loss=2.778, ppl=6.86, wps=52858, ups=0.92, wpb=57273.5, bsz=1512.2, num_updates=26300, lr=0.000389989, gnorm=0.257, clip=100, loss_scale=16, train_wall=105, wall=29006
2023-05-26 02:25:20 | INFO | train_inner | epoch 004:   6389 / 6686 loss=4.396, nll_loss=2.798, ppl=6.96, wps=52934.7, ups=0.93, wpb=57111.7, bsz=1474.9, num_updates=26400, lr=0.000389249, gnorm=0.258, clip=100, loss_scale=21, train_wall=104, wall=29114
2023-05-26 02:25:24 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 02:27:09 | INFO | train_inner | epoch 004:   6490 / 6686 loss=4.385, nll_loss=2.786, ppl=6.9, wps=52328.1, ups=0.91, wpb=57223.4, bsz=1484.7, num_updates=26500, lr=0.000388514, gnorm=0.256, clip=100, loss_scale=16, train_wall=106, wall=29224
2023-05-26 02:28:58 | INFO | train_inner | epoch 004:   6590 / 6686 loss=4.384, nll_loss=2.785, ppl=6.89, wps=52520.3, ups=0.92, wpb=57064, bsz=1472.9, num_updates=26600, lr=0.000387783, gnorm=0.257, clip=100, loss_scale=16, train_wall=105, wall=29332
2023-05-26 02:30:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-26 02:30:47 | INFO | fairseq.tasks.translation | example hypothesis: Why?
2023-05-26 02:30:47 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-26 02:30:47 | INFO | fairseq.tasks.translation | example hypothesis: You’ll lose so much that you won’t even have any pants left!
2023-05-26 02:30:47 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-26 02:30:48 | INFO | fairseq.tasks.translation | example hypothesis: Shen Liangchuan heaved a sigh of relief when she said, “I’ll call you to stay in the same room!”
2023-05-26 02:30:48 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-26 02:30:48 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved her hand and entered the elevator.
2023-05-26 02:30:48 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-26 02:30:49 | INFO | fairseq.tasks.translation | example hypothesis: She raised her head and saw Song Cheng standing in the distance!
2023-05-26 02:30:49 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-26 02:30:50 | INFO | fairseq.tasks.translation | example hypothesis: Song Cheng patted his chest. “You scared me to death! Where’s Wang Chuan?”
2023-05-26 02:30:50 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-26 02:30:51 | INFO | fairseq.tasks.translation | example hypothesis: “No, I can’t eat it,” I said.
2023-05-26 02:30:51 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-26 02:30:51 | INFO | fairseq.tasks.translation | example hypothesis: a while ago, everyone didn’t believe it, but Wang Wenhao insisted on making the public opinion lean towards Wang Wenhao.
2023-05-26 02:30:51 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-26 02:30:52 | INFO | fairseq.tasks.translation | example hypothesis: With his identity, coming here like this, Baili Hongzhuang had to be treated even if she didn’t treat him!
2023-05-26 02:30:52 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-26 02:30:53 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian said, "Mr. Shen, I... I've left too much blood and my brain lacks oxygen. I can't figure it out. Or, can you give me a reminder?"
2023-05-26 02:30:53 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-26 02:30:54 | INFO | fairseq.tasks.translation | example hypothesis: He didn’t know why so many people had heard about it. Since he couldn’t hide it, he might as well tell them.
2023-05-26 02:30:54 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-26 02:30:55 | INFO | fairseq.tasks.translation | example hypothesis: Her deliberately suppressed voice was unable to conceal the viciousness and ruthlessness in her tone.
2023-05-26 02:30:55 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-26 02:30:56 | INFO | fairseq.tasks.translation | example hypothesis: Different levels of beast pets had different strengths. However, beast pets were precious and rare. It was impossible for ordinary people to possess them. Even official disciples would not be able to possess them.
2023-05-26 02:30:56 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-26 02:30:57 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chixia gritted his teeth and cursed.
2023-05-26 02:30:57 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-26 02:30:58 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang had concealed it very well, Di Beichen could still see the ripple in her eyes. There was a hint of warmth in her eyes.
2023-05-26 02:30:58 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-26 02:30:59 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia walked in, he didn't even see a few guests or waiters.
2023-05-26 02:30:59 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-26 02:31:00 | INFO | fairseq.tasks.translation | example hypothesis: This person was the Ye Family’s fourth young miss, Ye Qing Ling.
2023-05-26 02:31:00 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-26 02:31:01 | INFO | fairseq.tasks.translation | example hypothesis: At this moment, she felt as though her chin was about to shatter.
2023-05-26 02:31:01 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-26 02:31:02 | INFO | fairseq.tasks.translation | example hypothesis: “Mu Zi, help me. If it wasn't for you, that old man wouldn't have targeted me.”
2023-05-26 02:31:02 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-26 02:31:04 | INFO | fairseq.tasks.translation | example hypothesis: Baili Yuyan was even more excited. She was the one in charge of this matter. For Baili Hongzhuang to treat her like this earlier, she would definitely make it difficult for Baili Hongzhuang.
2023-05-26 02:31:04 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-26 02:31:05 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How could that be? They’re also four mages, so of course they won’t surrender so easily. After arguing for a long time, they decided to use the method of the competition to obtain control over the Kingdom of Axia in the future.”
2023-05-26 02:31:05 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-26 02:31:06 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a few times. Originally, he had been looking for a reason for Li Yuyue not being able to participate in the Imperial Hunting Competition.
2023-05-26 02:31:06 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-26 02:31:07 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my standard good? I’m the country’s most outstanding talent. My magic is so weak?”
2023-05-26 02:31:07 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-26 02:31:09 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yibei’s words meant that if Fang Chixia didn’t want to go, she didn’t need to go.
2023-05-26 02:31:09 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-26 02:31:11 | INFO | fairseq.tasks.translation | example hypothesis: She tilted her head and saw that the five palm prints on her cheeks were very conspicuous. They swelled up at a speed visible to the naked eye. When she touched them, she couldn’t help but let out a hissing sound.
2023-05-26 02:31:11 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-26 02:31:12 | INFO | fairseq.tasks.translation | example hypothesis: How... how could this be the charm that that trash could give off?
2023-05-26 02:31:12 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-26 02:31:13 | INFO | fairseq.tasks.translation | example hypothesis: How could Wang Wenhao have found the newspaper? The chief editor should have called her to tell her not to come to the newspaper, but these three people... had schemed against her!
2023-05-26 02:31:13 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-26 02:31:16 | INFO | fairseq.tasks.translation | example hypothesis: When I heard Teacher Di’s praise, I was overjoyed. I withdrew the energy ball with my left hand and sent a beam of light sword towards Teacher Zhen. The beam of light sword actually managed to land smoothly. I was startled, but upon closer inspection, I realized that it was just an afterimage. Teacher Zhen had already moved to my back and shouted, “Berserk Space!”
2023-05-26 02:31:16 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-26 02:31:19 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Originally, we proposed a two-win draw, but their side said it was unfair because we have Teacher Dean and Teacher Zhen. They were ranked higher than them, and they proposed three-win draw. Since we were the ones who proposed the competition, the competition’s method could only be decided by them. Three days from now, we will have a secret competition in the Royal Family’s martial arts arena, and the competition will be held by the
2023-05-26 02:31:19 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-26 02:31:21 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Di used light-type class seven light-type spell, Light Thunder Burst. I didn’t use much of this spell, because it wasn’t ideal for me to control it. Teacher Di released nine light-type spells to surround me, forming a simple formation, preventing me from escaping in a short distance. The light-type spells then exploded one after another, forming a powerful offensive spell.
2023-05-26 02:31:21 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-26 02:31:24 | INFO | fairseq.tasks.translation | example hypothesis: As soon as Ma Ke and the two teachers reached the other side of the courtyard, Teacher Zhen shot a small Dimensional Slash at me. As expected of the continent’s number one mage. The suction force he released was actually much stronger than what I did. A small spatial rift appeared beside me, and a powerful suction force swept towards me.
2023-05-26 02:31:24 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-26 02:31:24 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.253 | nll_loss 2.608 | ppl 6.1 | bleu 21.44 | wps 1949.1 | wpb 2420.8 | bsz 84.5 | num_updates 26696 | best_bleu 21.44
2023-05-26 02:31:24 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-26 02:31:29 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/concat-1-1-0.2-sf[zh-en]/checkpoint4.pt (epoch 4 @ 26696 updates, score 21.44) (writing took 4.275273638777435 seconds)
2023-05-26 02:31:29 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-05-26 02:31:29 | INFO | train | epoch 004 | loss 4.406 | nll_loss 2.808 | ppl 7 | wps 52143.6 | ups 0.91 | wpb 57190 | bsz 1477.5 | num_updates 26696 | lr 0.000387085 | gnorm 0.262 | clip 100 | loss_scale 19 | train_wall 7012 | wall 29483
2023-05-26 02:31:29 | INFO | fairseq.trainer | begin training epoch 5
2023-05-26 02:31:38 | INFO | train_inner | epoch 005:      4 / 6686 loss=4.388, nll_loss=2.789, ppl=6.91, wps=35436.4, ups=0.62, wpb=56744.3, bsz=1478.3, num_updates=26700, lr=0.000387056, gnorm=0.261, clip=100, loss_scale=16, train_wall=105, wall=29492
2023-05-26 02:33:33 | INFO | train_inner | epoch 005:    104 / 6686 loss=4.352, nll_loss=2.747, ppl=6.71, wps=49792.8, ups=0.87, wpb=57333.9, bsz=1499.8, num_updates=26800, lr=0.000386334, gnorm=0.253, clip=100, loss_scale=16, train_wall=109, wall=29608
2023-05-26 02:35:25 | INFO | train_inner | epoch 005:    204 / 6686 loss=4.349, nll_loss=2.745, ppl=6.7, wps=51246.6, ups=0.89, wpb=57305.2, bsz=1487.5, num_updates=26900, lr=0.000385615, gnorm=0.252, clip=100, loss_scale=16, train_wall=106, wall=29719
2023-05-26 02:35:55 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 02:37:16 | INFO | train_inner | epoch 005:    305 / 6686 loss=4.368, nll_loss=2.766, ppl=6.8, wps=51671.8, ups=0.9, wpb=57099.1, bsz=1457.4, num_updates=27000, lr=0.0003849, gnorm=0.258, clip=100, loss_scale=18, train_wall=106, wall=29830
2023-05-26 02:39:05 | INFO | train_inner | epoch 005:    405 / 6686 loss=4.369, nll_loss=2.767, ppl=6.81, wps=52426.7, ups=0.92, wpb=57274.5, bsz=1477.8, num_updates=27100, lr=0.000384189, gnorm=0.258, clip=100, loss_scale=16, train_wall=105, wall=29939
2023-05-26 02:40:54 | INFO | train_inner | epoch 005:    505 / 6686 loss=4.358, nll_loss=2.755, ppl=6.75, wps=52760.2, ups=0.92, wpb=57396.6, bsz=1505.8, num_updates=27200, lr=0.000383482, gnorm=0.254, clip=100, loss_scale=16, train_wall=105, wall=30048
2023-05-26 02:42:42 | INFO | train_inner | epoch 005:    605 / 6686 loss=4.355, nll_loss=2.751, ppl=6.73, wps=52621.5, ups=0.92, wpb=57115.5, bsz=1472.2, num_updates=27300, lr=0.00038278, gnorm=0.261, clip=100, loss_scale=16, train_wall=105, wall=30156
2023-05-26 02:44:31 | INFO | train_inner | epoch 005:    705 / 6686 loss=4.376, nll_loss=2.775, ppl=6.84, wps=52642.7, ups=0.92, wpb=57199.5, bsz=1471.6, num_updates=27400, lr=0.00038208, gnorm=0.255, clip=100, loss_scale=16, train_wall=105, wall=30265
2023-05-26 02:46:20 | INFO | train_inner | epoch 005:    805 / 6686 loss=4.367, nll_loss=2.765, ppl=6.8, wps=52424.1, ups=0.92, wpb=57066.9, bsz=1442.6, num_updates=27500, lr=0.000381385, gnorm=0.258, clip=100, loss_scale=26, train_wall=105, wall=30374
2023-05-26 02:48:09 | INFO | train_inner | epoch 005:    905 / 6686 loss=4.369, nll_loss=2.767, ppl=6.81, wps=52529.5, ups=0.92, wpb=57307.3, bsz=1465.4, num_updates=27600, lr=0.000380693, gnorm=0.255, clip=100, loss_scale=32, train_wall=105, wall=30483
2023-05-26 02:49:57 | INFO | train_inner | epoch 005:   1005 / 6686 loss=4.36, nll_loss=2.757, ppl=6.76, wps=52839.9, ups=0.92, wpb=57261.1, bsz=1475.4, num_updates=27700, lr=0.000380006, gnorm=0.254, clip=100, loss_scale=32, train_wall=105, wall=30591
2023-05-26 02:50:55 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 02:51:47 | INFO | train_inner | epoch 005:   1106 / 6686 loss=4.362, nll_loss=2.759, ppl=6.77, wps=52095.3, ups=0.91, wpb=57107.2, bsz=1490.6, num_updates=27800, lr=0.000379322, gnorm=0.259, clip=100, loss_scale=24, train_wall=106, wall=30701
2023-05-26 02:53:36 | INFO | train_inner | epoch 005:   1206 / 6686 loss=4.368, nll_loss=2.766, ppl=6.8, wps=52659.5, ups=0.92, wpb=57307.9, bsz=1471.8, num_updates=27900, lr=0.000378641, gnorm=0.259, clip=100, loss_scale=16, train_wall=105, wall=30810
2023-05-26 02:55:25 | INFO | train_inner | epoch 005:   1306 / 6686 loss=4.364, nll_loss=2.762, ppl=6.78, wps=52407.7, ups=0.92, wpb=57171.5, bsz=1458.7, num_updates=28000, lr=0.000377964, gnorm=0.257, clip=100, loss_scale=16, train_wall=105, wall=30919
2023-05-26 02:57:13 | INFO | train_inner | epoch 005:   1406 / 6686 loss=4.372, nll_loss=2.771, ppl=6.83, wps=52596.9, ups=0.92, wpb=57099.2, bsz=1447.4, num_updates=28100, lr=0.000377291, gnorm=0.262, clip=100, loss_scale=16, train_wall=105, wall=31028
2023-05-26 02:59:02 | INFO | train_inner | epoch 005:   1506 / 6686 loss=4.369, nll_loss=2.767, ppl=6.81, wps=52781.7, ups=0.92, wpb=57248.9, bsz=1468.5, num_updates=28200, lr=0.000376622, gnorm=0.253, clip=100, loss_scale=16, train_wall=105, wall=31136
2023-05-26 03:00:13 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 03:00:52 | INFO | train_inner | epoch 005:   1607 / 6686 loss=4.366, nll_loss=2.765, ppl=6.8, wps=52062.4, ups=0.91, wpb=57175, bsz=1472.2, num_updates=28300, lr=0.000375956, gnorm=0.262, clip=100, loss_scale=16, train_wall=106, wall=31246
2023-05-26 03:02:40 | INFO | train_inner | epoch 005:   1707 / 6686 loss=4.356, nll_loss=2.752, ppl=6.74, wps=52555.8, ups=0.92, wpb=57129.9, bsz=1480.3, num_updates=28400, lr=0.000375293, gnorm=0.261, clip=100, loss_scale=16, train_wall=105, wall=31355
2023-05-26 03:04:29 | INFO | train_inner | epoch 005:   1807 / 6686 loss=4.356, nll_loss=2.753, ppl=6.74, wps=52707.1, ups=0.92, wpb=57278.8, bsz=1502.2, num_updates=28500, lr=0.000374634, gnorm=0.255, clip=100, loss_scale=16, train_wall=105, wall=31463
2023-05-26 03:06:18 | INFO | train_inner | epoch 005:   1907 / 6686 loss=4.357, nll_loss=2.755, ppl=6.75, wps=52577, ups=0.92, wpb=57072.1, bsz=1482.6, num_updates=28600, lr=0.000373979, gnorm=0.258, clip=100, loss_scale=16, train_wall=105, wall=31572
2023-05-26 03:08:06 | INFO | train_inner | epoch 005:   2007 / 6686 loss=4.36, nll_loss=2.758, ppl=6.77, wps=52803.1, ups=0.92, wpb=57259.8, bsz=1491.4, num_updates=28700, lr=0.000373327, gnorm=0.258, clip=100, loss_scale=16, train_wall=105, wall=31680
2023-05-26 03:09:55 | INFO | train_inner | epoch 005:   2107 / 6686 loss=4.367, nll_loss=2.765, ppl=6.8, wps=52731.8, ups=0.92, wpb=57287.3, bsz=1462.9, num_updates=28800, lr=0.000372678, gnorm=0.257, clip=100, loss_scale=20, train_wall=105, wall=31789
2023-05-26 03:11:31 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 03:11:45 | INFO | train_inner | epoch 005:   2208 / 6686 loss=4.366, nll_loss=2.765, ppl=6.8, wps=51821.9, ups=0.91, wpb=56896, bsz=1461.4, num_updates=28900, lr=0.000372033, gnorm=0.259, clip=100, loss_scale=30, train_wall=106, wall=31899
2023-05-26 03:13:33 | INFO | train_inner | epoch 005:   2308 / 6686 loss=4.364, nll_loss=2.762, ppl=6.78, wps=52511.9, ups=0.92, wpb=56979.3, bsz=1444, num_updates=29000, lr=0.000371391, gnorm=0.255, clip=100, loss_scale=16, train_wall=105, wall=32007
2023-05-26 03:15:22 | INFO | train_inner | epoch 005:   2408 / 6686 loss=4.36, nll_loss=2.758, ppl=6.76, wps=52648.9, ups=0.92, wpb=57231.8, bsz=1489.8, num_updates=29100, lr=0.000370752, gnorm=0.257, clip=100, loss_scale=16, train_wall=105, wall=32116
2023-05-26 03:17:11 | INFO | train_inner | epoch 005:   2508 / 6686 loss=4.357, nll_loss=2.754, ppl=6.75, wps=52674.5, ups=0.92, wpb=57394.9, bsz=1488.8, num_updates=29200, lr=0.000370117, gnorm=0.254, clip=100, loss_scale=16, train_wall=105, wall=32225
2023-05-26 03:19:00 | INFO | train_inner | epoch 005:   2608 / 6686 loss=4.356, nll_loss=2.753, ppl=6.74, wps=52379.4, ups=0.92, wpb=57055.6, bsz=1455.4, num_updates=29300, lr=0.000369484, gnorm=0.255, clip=100, loss_scale=16, train_wall=105, wall=32334
2023-05-26 03:20:48 | INFO | train_inner | epoch 005:   2708 / 6686 loss=4.351, nll_loss=2.748, ppl=6.72, wps=52669.8, ups=0.92, wpb=57296.2, bsz=1495.8, num_updates=29400, lr=0.000368856, gnorm=0.26, clip=100, loss_scale=16, train_wall=105, wall=32443
2023-05-26 03:20:50 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 03:20:50 | INFO | train_inner | epoch 005:   2709 / 6686 loss=None, nll_loss=None, ppl=0, wps=0, ups=0, wpb=None, bsz=None, num_updates=None, lr=None, gnorm=None, clip=None, loss_scale=16, train_wall=1, wall=32444
2023-05-26 03:22:38 | INFO | train_inner | epoch 005:   2809 / 6686 loss=4.36, nll_loss=2.758, ppl=6.76, wps=52726, ups=0.92, wpb=57192.2, bsz=1477.6, num_updates=29500, lr=0.00036823, gnorm=0.261, clip=100, loss_scale=16, train_wall=105, wall=32552
2023-05-26 03:24:26 | INFO | train_inner | epoch 005:   2909 / 6686 loss=4.36, nll_loss=2.758, ppl=6.76, wps=52688.6, ups=0.92, wpb=57040.3, bsz=1477.6, num_updates=29600, lr=0.000367607, gnorm=0.259, clip=100, loss_scale=16, train_wall=105, wall=32660
2023-05-26 03:26:15 | INFO | train_inner | epoch 005:   3009 / 6686 loss=4.358, nll_loss=2.756, ppl=6.75, wps=52810.1, ups=0.92, wpb=57164.6, bsz=1483.4, num_updates=29700, lr=0.000366988, gnorm=0.252, clip=100, loss_scale=16, train_wall=104, wall=32769
2023-05-26 03:28:03 | INFO | train_inner | epoch 005:   3109 / 6686 loss=4.356, nll_loss=2.754, ppl=6.75, wps=52570.5, ups=0.92, wpb=57106, bsz=1490.7, num_updates=29800, lr=0.000366372, gnorm=0.258, clip=100, loss_scale=16, train_wall=105, wall=32877
2023-05-26 03:29:52 | INFO | train_inner | epoch 005:   3209 / 6686 loss=4.343, nll_loss=2.739, ppl=6.68, wps=52533, ups=0.92, wpb=57220.9, bsz=1487.6, num_updates=29900, lr=0.000365758, gnorm=0.254, clip=100, loss_scale=16, train_wall=105, wall=32986
2023-05-26 03:30:08 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 03:31:42 | INFO | train_inner | epoch 005:   3310 / 6686 loss=4.353, nll_loss=2.75, ppl=6.73, wps=52173.3, ups=0.91, wpb=57233.2, bsz=1472.8, num_updates=30000, lr=0.000365148, gnorm=0.253, clip=100, loss_scale=16, train_wall=106, wall=33096
2023-05-26 03:33:31 | INFO | train_inner | epoch 005:   3410 / 6686 loss=4.357, nll_loss=2.755, ppl=6.75, wps=52519, ups=0.92, wpb=57211, bsz=1513.8, num_updates=30100, lr=0.000364541, gnorm=0.251, clip=100, loss_scale=16, train_wall=105, wall=33205
2023-05-26 03:35:19 | INFO | train_inner | epoch 005:   3510 / 6686 loss=4.351, nll_loss=2.748, ppl=6.72, wps=52529.1, ups=0.92, wpb=57139.8, bsz=1467.7, num_updates=30200, lr=0.000363937, gnorm=0.259, clip=100, loss_scale=16, train_wall=105, wall=33314
2023-05-26 03:37:08 | INFO | train_inner | epoch 005:   3610 / 6686 loss=4.351, nll_loss=2.749, ppl=6.72, wps=52642.3, ups=0.92, wpb=57200, bsz=1482.6, num_updates=30300, lr=0.000363336, gnorm=0.26, clip=100, loss_scale=16, train_wall=105, wall=33422
2023-05-26 03:38:57 | INFO | train_inner | epoch 005:   3710 / 6686 loss=4.352, nll_loss=2.75, ppl=6.73, wps=52675.4, ups=0.92, wpb=57154.7, bsz=1497.8, num_updates=30400, lr=0.000362738, gnorm=0.251, clip=100, loss_scale=16, train_wall=105, wall=33531
2023-05-26 03:40:45 | INFO | train_inner | epoch 005:   3810 / 6686 loss=4.361, nll_loss=2.76, ppl=6.77, wps=52757.3, ups=0.92, wpb=57124.2, bsz=1463.7, num_updates=30500, lr=0.000362143, gnorm=0.257, clip=100, loss_scale=28, train_wall=105, wall=33639
2023-05-26 03:41:37 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 03:42:35 | INFO | train_inner | epoch 005:   3911 / 6686 loss=4.356, nll_loss=2.753, ppl=6.74, wps=52076.6, ups=0.91, wpb=57234.6, bsz=1475.9, num_updates=30600, lr=0.000361551, gnorm=0.257, clip=100, loss_scale=23, train_wall=106, wall=33749
2023-05-26 03:44:23 | INFO | train_inner | epoch 005:   4011 / 6686 loss=4.347, nll_loss=2.743, ppl=6.7, wps=52813.4, ups=0.92, wpb=57362.8, bsz=1491.9, num_updates=30700, lr=0.000360961, gnorm=0.255, clip=100, loss_scale=16, train_wall=105, wall=33858
2023-05-26 03:46:12 | INFO | train_inner | epoch 005:   4111 / 6686 loss=4.349, nll_loss=2.745, ppl=6.71, wps=52654.8, ups=0.92, wpb=57182, bsz=1479.8, num_updates=30800, lr=0.000360375, gnorm=0.252, clip=100, loss_scale=16, train_wall=105, wall=33966
2023-05-26 03:48:00 | INFO | train_inner | epoch 005:   4211 / 6686 loss=4.346, nll_loss=2.742, ppl=6.69, wps=52929.5, ups=0.92, wpb=57339.6, bsz=1476.6, num_updates=30900, lr=0.000359791, gnorm=0.259, clip=100, loss_scale=16, train_wall=104, wall=34075
2023-05-26 03:49:49 | INFO | train_inner | epoch 005:   4311 / 6686 loss=4.359, nll_loss=2.757, ppl=6.76, wps=52484.9, ups=0.92, wpb=56976.7, bsz=1466.6, num_updates=31000, lr=0.000359211, gnorm=0.254, clip=100, loss_scale=16, train_wall=105, wall=34183
2023-05-26 03:51:38 | INFO | train_inner | epoch 005:   4411 / 6686 loss=4.35, nll_loss=2.748, ppl=6.72, wps=52622, ups=0.92, wpb=57210.3, bsz=1477.6, num_updates=31100, lr=0.000358633, gnorm=0.253, clip=100, loss_scale=23, train_wall=105, wall=34292
2023-05-26 03:53:27 | INFO | train_inner | epoch 005:   4511 / 6686 loss=4.343, nll_loss=2.739, ppl=6.68, wps=52763.1, ups=0.92, wpb=57449.3, bsz=1490.3, num_updates=31200, lr=0.000358057, gnorm=0.252, clip=100, loss_scale=32, train_wall=105, wall=34401
2023-05-26 03:54:46 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 03:55:17 | INFO | train_inner | epoch 005:   4612 / 6686 loss=4.352, nll_loss=2.749, ppl=6.72, wps=52031.8, ups=0.91, wpb=57204.1, bsz=1465.7, num_updates=31300, lr=0.000357485, gnorm=0.25, clip=100, loss_scale=27, train_wall=106, wall=34511
2023-05-26 03:57:06 | INFO | train_inner | epoch 005:   4712 / 6686 loss=4.356, nll_loss=2.755, ppl=6.75, wps=52472.9, ups=0.92, wpb=57283.4, bsz=1481.4, num_updates=31400, lr=0.000356915, gnorm=0.251, clip=100, loss_scale=16, train_wall=105, wall=34620
2023-05-26 03:58:54 | INFO | train_inner | epoch 005:   4812 / 6686 loss=4.357, nll_loss=2.755, ppl=6.75, wps=52699, ups=0.92, wpb=57205.9, bsz=1479.7, num_updates=31500, lr=0.000356348, gnorm=0.252, clip=100, loss_scale=16, train_wall=105, wall=34728
2023-05-26 04:00:43 | INFO | train_inner | epoch 005:   4912 / 6686 loss=4.346, nll_loss=2.742, ppl=6.69, wps=52547.6, ups=0.92, wpb=57189.9, bsz=1477.4, num_updates=31600, lr=0.000355784, gnorm=0.252, clip=100, loss_scale=16, train_wall=105, wall=34837
2023-05-26 04:02:32 | INFO | train_inner | epoch 005:   5012 / 6686 loss=4.358, nll_loss=2.757, ppl=6.76, wps=52613.8, ups=0.92, wpb=57025.9, bsz=1464.4, num_updates=31700, lr=0.000355222, gnorm=0.255, clip=100, loss_scale=16, train_wall=105, wall=34946
2023-05-26 04:04:20 | INFO | train_inner | epoch 005:   5112 / 6686 loss=4.355, nll_loss=2.753, ppl=6.74, wps=52845.3, ups=0.92, wpb=57329.4, bsz=1480.6, num_updates=31800, lr=0.000354663, gnorm=0.256, clip=100, loss_scale=19, train_wall=105, wall=35054
2023-05-26 04:06:09 | INFO | train_inner | epoch 005:   5212 / 6686 loss=4.337, nll_loss=2.733, ppl=6.65, wps=52724.7, ups=0.92, wpb=57351.2, bsz=1484.3, num_updates=31900, lr=0.000354107, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=35163
2023-05-26 04:07:57 | INFO | train_inner | epoch 005:   5312 / 6686 loss=4.355, nll_loss=2.753, ppl=6.74, wps=52589.4, ups=0.92, wpb=57061.3, bsz=1452.9, num_updates=32000, lr=0.000353553, gnorm=0.253, clip=100, loss_scale=32, train_wall=105, wall=35271
2023-05-26 04:08:39 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 04:09:47 | INFO | train_inner | epoch 005:   5413 / 6686 loss=4.362, nll_loss=2.761, ppl=6.78, wps=51983.8, ups=0.91, wpb=57116.3, bsz=1453.2, num_updates=32100, lr=0.000353002, gnorm=0.253, clip=100, loss_scale=22, train_wall=106, wall=35381
2023-05-26 04:11:36 | INFO | train_inner | epoch 005:   5513 / 6686 loss=4.355, nll_loss=2.753, ppl=6.74, wps=52821.9, ups=0.92, wpb=57279.9, bsz=1472.6, num_updates=32200, lr=0.000352454, gnorm=0.252, clip=100, loss_scale=16, train_wall=105, wall=35490
2023-05-26 04:13:24 | INFO | train_inner | epoch 005:   5613 / 6686 loss=4.356, nll_loss=2.754, ppl=6.75, wps=52664.2, ups=0.92, wpb=57210.9, bsz=1466.7, num_updates=32300, lr=0.000351908, gnorm=0.251, clip=100, loss_scale=16, train_wall=105, wall=35598
2023-05-26 04:15:13 | INFO | train_inner | epoch 005:   5713 / 6686 loss=4.35, nll_loss=2.747, ppl=6.72, wps=52690.1, ups=0.92, wpb=57180.6, bsz=1483.7, num_updates=32400, lr=0.000351364, gnorm=0.25, clip=100, loss_scale=16, train_wall=105, wall=35707
2023-05-26 04:17:02 | INFO | train_inner | epoch 005:   5813 / 6686 loss=4.351, nll_loss=2.748, ppl=6.72, wps=52619.8, ups=0.92, wpb=57246.6, bsz=1474, num_updates=32500, lr=0.000350823, gnorm=0.251, clip=100, loss_scale=16, train_wall=105, wall=35816
2023-05-26 04:18:32 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 04:18:52 | INFO | train_inner | epoch 005:   5914 / 6686 loss=4.334, nll_loss=2.73, ppl=6.63, wps=52030.3, ups=0.91, wpb=57347.7, bsz=1491, num_updates=32600, lr=0.000350285, gnorm=0.259, clip=100, loss_scale=21, train_wall=106, wall=35926
2023-05-26 04:20:40 | INFO | train_inner | epoch 005:   6014 / 6686 loss=4.35, nll_loss=2.747, ppl=6.71, wps=52668.7, ups=0.92, wpb=57134.9, bsz=1459.9, num_updates=32700, lr=0.000349749, gnorm=0.25, clip=100, loss_scale=16, train_wall=105, wall=36034
2023-05-26 04:22:29 | INFO | train_inner | epoch 005:   6114 / 6686 loss=4.337, nll_loss=2.733, ppl=6.65, wps=52588.6, ups=0.92, wpb=57147.6, bsz=1482.2, num_updates=32800, lr=0.000349215, gnorm=0.254, clip=100, loss_scale=16, train_wall=105, wall=36143
2023-05-26 04:24:18 | INFO | train_inner | epoch 005:   6214 / 6686 loss=4.35, nll_loss=2.748, ppl=6.72, wps=52661.4, ups=0.92, wpb=57248, bsz=1479.1, num_updates=32900, lr=0.000348684, gnorm=0.251, clip=100, loss_scale=16, train_wall=105, wall=36252
2023-05-26 04:26:06 | INFO | train_inner | epoch 005:   6314 / 6686 loss=4.34, nll_loss=2.736, ppl=6.66, wps=52517.3, ups=0.92, wpb=57088.2, bsz=1487, num_updates=33000, lr=0.000348155, gnorm=0.253, clip=100, loss_scale=16, train_wall=105, wall=36361
2023-05-26 04:27:55 | INFO | train_inner | epoch 005:   6414 / 6686 loss=4.335, nll_loss=2.731, ppl=6.64, wps=52665.4, ups=0.92, wpb=57173.8, bsz=1505.2, num_updates=33100, lr=0.000347629, gnorm=0.253, clip=100, loss_scale=17, train_wall=105, wall=36469
2023-05-26 04:29:44 | INFO | train_inner | epoch 005:   6514 / 6686 loss=4.337, nll_loss=2.733, ppl=6.65, wps=52618.7, ups=0.92, wpb=57206.9, bsz=1500.4, num_updates=33200, lr=0.000347105, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=36578
2023-05-26 04:29:48 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 04:31:34 | INFO | train_inner | epoch 005:   6615 / 6686 loss=4.34, nll_loss=2.737, ppl=6.67, wps=52047.9, ups=0.91, wpb=57181.2, bsz=1487.6, num_updates=33300, lr=0.000346583, gnorm=0.251, clip=100, loss_scale=16, train_wall=106, wall=36688
2023-05-26 04:32:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-26 04:32:55 | INFO | fairseq.tasks.translation | example hypothesis: Why?
2023-05-26 04:32:55 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-26 04:32:55 | INFO | fairseq.tasks.translation | example hypothesis: I’ll make you lose so much that you don’t even have any pants left!
2023-05-26 04:32:55 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-26 04:32:56 | INFO | fairseq.tasks.translation | example hypothesis: Just as Shen Liangchuan heaved a sigh of relief, she said, “I’ll call you in the same room!”
2023-05-26 04:32:56 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-26 04:32:57 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved her hand and entered the elevator.
2023-05-26 04:32:57 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-26 04:32:57 | INFO | fairseq.tasks.translation | example hypothesis: She raised her head and saw Song Cheng standing in the distance!
2023-05-26 04:32:57 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-26 04:32:58 | INFO | fairseq.tasks.translation | example hypothesis: Song Cheng patted his chest. “You scared me to death! Where’s Wang Chuan?”
2023-05-26 04:32:58 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-26 04:32:59 | INFO | fairseq.tasks.translation | example hypothesis: I said, “No, I can’t eat it.”
2023-05-26 04:32:59 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-26 04:32:59 | INFO | fairseq.tasks.translation | example hypothesis: Hao Wang insisted on him and made the public opinion lean towards him.
2023-05-26 04:32:59 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-26 04:33:00 | INFO | fairseq.tasks.translation | example hypothesis: With his status, even if Baili Hongzhuang did not treat him, he had to treat him!
2023-05-26 04:33:00 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-26 04:33:01 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my brain is lacking oxygen. I can’t think of anything. Why don’t you give me a hint?”
2023-05-26 04:33:01 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-26 04:33:02 | INFO | fairseq.tasks.translation | example hypothesis: He didn’t know why so many people heard about this. Since he couldn’t hide it, he might as well tell them.
2023-05-26 04:33:02 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-26 04:33:03 | INFO | fairseq.tasks.translation | example hypothesis: She deliberately lowered her voice, but it could not conceal the viciousness and viciousness in her tone.
2023-05-26 04:33:03 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-26 04:33:04 | INFO | fairseq.tasks.translation | example hypothesis: Different levels of beast pets had different strengths, but beast pets were precious and rare. Ordinary people simply couldn’t have them. Even the descendants of officials couldn’t have them.
2023-05-26 04:33:04 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-26 04:33:05 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chixia gritted her teeth and cursed.
2023-05-26 04:33:05 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-26 04:33:06 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang’s disguise was very good, Di Beichen still saw a flash of emotion in her eyes, and a tinge of warmth filled his eyes.
2023-05-26 04:33:06 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-26 04:33:07 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia walked in, he didn't even see a few waitresses, not to mention the guests.
2023-05-26 04:33:07 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-26 04:33:08 | INFO | fairseq.tasks.translation | example hypothesis: This person was none other than the Fourth Young Miss of the Ye Family, Ye Qingling.
2023-05-26 04:33:08 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-26 04:33:09 | INFO | fairseq.tasks.translation | example hypothesis: At this moment, she felt as though her chin was about to shatter.
2023-05-26 04:33:09 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-26 04:33:11 | INFO | fairseq.tasks.translation | example hypothesis: “Good Mu Zi, help me. If it wasn't for you, that old man wouldn't have targeted me.”
2023-05-26 04:33:11 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-26 04:33:12 | INFO | fairseq.tasks.translation | example hypothesis: Baili Yuyan was even more excited. This matter was completely handled by her. Earlier, Baili Hongzhuang had treated her like this. This time around, she would definitely make Baili Hongzhuang feel bad.
2023-05-26 04:33:12 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-26 04:33:13 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How is that possible? They are also four mages, so of course they won’t surrender so easily. After arguing for a long time, they finally decided to use the method of the competition to obtain the right to control the Kingdom of Summer.”
2023-05-26 04:33:13 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-26 04:33:14 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a little. He had always been looking for a reason for Li Yuyue not being able to participate in the royal family’s hunting competition.
2023-05-26 04:33:14 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-26 04:33:16 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my standard good? They’re all the best in the country. Is my magic that weak?”
2023-05-26 04:33:16 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-26 04:33:18 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yibei meant that if Fang Chixia didn’t want to go, there was no need to go.
2023-05-26 04:33:18 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-26 04:33:19 | INFO | fairseq.tasks.translation | example hypothesis: She tilted her head and saw that the five palm marks on her face were very eye-catching. They were swelling at a visible speed. She reached out to touch them and could not help but let out a hiss.
2023-05-26 04:33:19 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-26 04:33:20 | INFO | fairseq.tasks.translation | example hypothesis: This... How could this be the charm that that trash could emit?
2023-05-26 04:33:20 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-26 04:33:21 | INFO | fairseq.tasks.translation | example hypothesis: How could Wang Wenhao have found a newspaper agency? The chief editor should have called her to tell her not to come to the newspaper agency, which was the best choice. However, the three of them... had plotted against her!
2023-05-26 04:33:21 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-26 04:33:24 | INFO | fairseq.tasks.translation | example hypothesis: Hearing Teacher Di’s praise, I was delighted. I put away the energy ball with my left hand and shot a beam of light at Teacher Zhen with my right hand. The beam of light actually managed to hit Teacher Zhen. I jumped in fright. Upon closer inspection, I realized that it was just an afterimage. Teacher Zhen had already moved behind me and shouted, “Berserk Space!”
2023-05-26 04:33:24 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-26 04:33:27 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Originally, our side proposed a competition of three rounds and two victories, but their side said that it was unfair because we had Teacher Di and Teacher Zhen. Their rankings were even higher than theirs, and they proposed five rounds and three victories. Since we proposed the competition, the competition would be decided by them in the end. Three days from now, we will have a secret competition in the Royal Clan’s martial arts arena.
2023-05-26 04:33:27 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-26 04:33:29 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Zhen had used a light-style seventh-level spell, Light Lightning Burst. I didn’t use much of this spell because it wasn’t ideal for me to control it. Teacher Di had cast nine Light Lightning Bursts to surround me, forming a simple spell formation, preventing me from escaping in a short distance. Then, each of the Light Lightning Bursts exploded to form a powerful attack power.
2023-05-26 04:33:29 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-26 04:33:32 | INFO | fairseq.tasks.translation | example hypothesis: As soon as Ma Ke and the two teachers reached the other side of the courtyard, Teacher Zhen sent me a Small Dimension Slash. As expected of the number one Magician in the continent. The Small Dimension Slash’s attractive force was actually much stronger than the one I sent out. A small spatial crack appeared beside me, and a powerful attractive force swept towards me.
2023-05-26 04:33:32 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-26 04:33:32 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.239 | nll_loss 2.594 | ppl 6.04 | bleu 21.42 | wps 1961.1 | wpb 2420.8 | bsz 84.5 | num_updates 33371 | best_bleu 21.44
2023-05-26 04:33:32 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-26 04:33:35 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/concat-1-1-0.2-sf[zh-en]/checkpoint5.pt (epoch 5 @ 33371 updates, score 21.42) (writing took 2.9354983055964112 seconds)
2023-05-26 04:33:35 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-05-26 04:33:35 | INFO | train | epoch 005 | loss 4.355 | nll_loss 2.752 | ppl 6.74 | wps 52104 | ups 0.91 | wpb 57190.3 | bsz 1477.5 | num_updates 33371 | lr 0.000346215 | gnorm 0.255 | clip 100 | loss_scale 19 | train_wall 7016 | wall 36809
2023-05-26 04:33:35 | INFO | fairseq.trainer | begin training epoch 6
2023-05-26 04:34:15 | INFO | train_inner | epoch 006:     29 / 6686 loss=4.33, nll_loss=2.725, ppl=6.61, wps=35192, ups=0.62, wpb=56749.6, bsz=1483.8, num_updates=33400, lr=0.000346064, gnorm=0.26, clip=100, loss_scale=16, train_wall=106, wall=36849
2023-05-26 04:36:08 | INFO | train_inner | epoch 006:    129 / 6686 loss=4.317, nll_loss=2.709, ppl=6.54, wps=50751.6, ups=0.89, wpb=57307, bsz=1483.1, num_updates=33500, lr=0.000345547, gnorm=0.252, clip=100, loss_scale=16, train_wall=107, wall=36962
2023-05-26 04:37:59 | INFO | train_inner | epoch 006:    229 / 6686 loss=4.316, nll_loss=2.709, ppl=6.54, wps=51426.7, ups=0.9, wpb=57093.8, bsz=1484, num_updates=33600, lr=0.000345033, gnorm=0.248, clip=100, loss_scale=16, train_wall=106, wall=37073
2023-05-26 04:39:48 | INFO | train_inner | epoch 006:    329 / 6686 loss=4.321, nll_loss=2.714, ppl=6.56, wps=52419.6, ups=0.91, wpb=57407.8, bsz=1463.9, num_updates=33700, lr=0.00034452, gnorm=0.255, clip=100, loss_scale=16, train_wall=105, wall=37182
2023-05-26 04:41:37 | INFO | train_inner | epoch 006:    429 / 6686 loss=4.321, nll_loss=2.714, ppl=6.56, wps=52671.4, ups=0.92, wpb=57078.4, bsz=1472.6, num_updates=33800, lr=0.00034401, gnorm=0.254, clip=100, loss_scale=30, train_wall=105, wall=37291
2023-05-26 04:43:25 | INFO | train_inner | epoch 006:    529 / 6686 loss=4.309, nll_loss=2.701, ppl=6.5, wps=52735.3, ups=0.92, wpb=57326, bsz=1491.2, num_updates=33900, lr=0.000343503, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=37399
2023-05-26 04:45:14 | INFO | train_inner | epoch 006:    629 / 6686 loss=4.328, nll_loss=2.723, ppl=6.6, wps=52605.2, ups=0.92, wpb=57124.5, bsz=1464.7, num_updates=34000, lr=0.000342997, gnorm=0.255, clip=100, loss_scale=32, train_wall=105, wall=37508
2023-05-26 04:46:26 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 04:47:03 | INFO | train_inner | epoch 006:    730 / 6686 loss=4.317, nll_loss=2.71, ppl=6.54, wps=52121.2, ups=0.92, wpb=56948.1, bsz=1473.7, num_updates=34100, lr=0.000342494, gnorm=0.249, clip=100, loss_scale=26, train_wall=105, wall=37617
2023-05-26 04:48:52 | INFO | train_inner | epoch 006:    830 / 6686 loss=4.326, nll_loss=2.72, ppl=6.59, wps=52707.1, ups=0.92, wpb=57095.1, bsz=1467.7, num_updates=34200, lr=0.000341993, gnorm=0.249, clip=100, loss_scale=16, train_wall=104, wall=37726
2023-05-26 04:50:40 | INFO | train_inner | epoch 006:    930 / 6686 loss=4.327, nll_loss=2.722, ppl=6.6, wps=52452, ups=0.92, wpb=56963.7, bsz=1463.8, num_updates=34300, lr=0.000341494, gnorm=0.252, clip=100, loss_scale=16, train_wall=105, wall=37834
2023-05-26 04:52:29 | INFO | train_inner | epoch 006:   1030 / 6686 loss=4.318, nll_loss=2.711, ppl=6.55, wps=52679.8, ups=0.92, wpb=57186.7, bsz=1497.8, num_updates=34400, lr=0.000340997, gnorm=0.251, clip=100, loss_scale=16, train_wall=105, wall=37943
2023-05-26 04:54:17 | INFO | train_inner | epoch 006:   1130 / 6686 loss=4.324, nll_loss=2.718, ppl=6.58, wps=52607.4, ups=0.92, wpb=57154.5, bsz=1488.9, num_updates=34500, lr=0.000340503, gnorm=0.252, clip=100, loss_scale=16, train_wall=105, wall=38052
2023-05-26 04:56:06 | INFO | train_inner | epoch 006:   1230 / 6686 loss=4.324, nll_loss=2.718, ppl=6.58, wps=52625.2, ups=0.92, wpb=57098.8, bsz=1471.7, num_updates=34600, lr=0.00034001, gnorm=0.252, clip=100, loss_scale=20, train_wall=105, wall=38160
2023-05-26 04:56:17 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 04:57:56 | INFO | train_inner | epoch 006:   1331 / 6686 loss=4.324, nll_loss=2.718, ppl=6.58, wps=52077.1, ups=0.91, wpb=57444.2, bsz=1493.6, num_updates=34700, lr=0.00033952, gnorm=0.25, clip=100, loss_scale=17, train_wall=106, wall=38270
2023-05-26 04:59:45 | INFO | train_inner | epoch 006:   1431 / 6686 loss=4.332, nll_loss=2.727, ppl=6.62, wps=52805, ups=0.92, wpb=57303, bsz=1462.1, num_updates=34800, lr=0.000339032, gnorm=0.251, clip=100, loss_scale=16, train_wall=105, wall=38379
2023-05-26 05:01:34 | INFO | train_inner | epoch 006:   1531 / 6686 loss=4.324, nll_loss=2.718, ppl=6.58, wps=52501.8, ups=0.92, wpb=57267.3, bsz=1473.2, num_updates=34900, lr=0.000338546, gnorm=0.254, clip=100, loss_scale=16, train_wall=105, wall=38488
2023-05-26 05:03:22 | INFO | train_inner | epoch 006:   1631 / 6686 loss=4.324, nll_loss=2.718, ppl=6.58, wps=52654.1, ups=0.92, wpb=57233.5, bsz=1462.2, num_updates=35000, lr=0.000338062, gnorm=0.254, clip=100, loss_scale=16, train_wall=105, wall=38597
2023-05-26 05:05:12 | INFO | train_inner | epoch 006:   1731 / 6686 loss=4.326, nll_loss=2.72, ppl=6.59, wps=52559.7, ups=0.92, wpb=57334.1, bsz=1478.4, num_updates=35100, lr=0.00033758, gnorm=0.252, clip=100, loss_scale=16, train_wall=105, wall=38706
2023-05-26 05:07:00 | INFO | train_inner | epoch 006:   1831 / 6686 loss=4.321, nll_loss=2.714, ppl=6.56, wps=52774.9, ups=0.92, wpb=57347.6, bsz=1482.8, num_updates=35200, lr=0.0003371, gnorm=0.255, clip=100, loss_scale=29, train_wall=105, wall=38814
2023-05-26 05:08:49 | INFO | train_inner | epoch 006:   1931 / 6686 loss=4.323, nll_loss=2.717, ppl=6.58, wps=52723.3, ups=0.92, wpb=57404.4, bsz=1496.8, num_updates=35300, lr=0.000336622, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=38923
2023-05-26 05:09:58 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 05:10:39 | INFO | train_inner | epoch 006:   2032 / 6686 loss=4.318, nll_loss=2.711, ppl=6.55, wps=52038.2, ups=0.91, wpb=57270.6, bsz=1485.5, num_updates=35400, lr=0.000336146, gnorm=0.248, clip=100, loss_scale=26, train_wall=106, wall=39033
2023-05-26 05:12:28 | INFO | train_inner | epoch 006:   2132 / 6686 loss=4.327, nll_loss=2.721, ppl=6.59, wps=52670.2, ups=0.92, wpb=57211, bsz=1471.8, num_updates=35500, lr=0.000335673, gnorm=0.25, clip=100, loss_scale=16, train_wall=105, wall=39142
2023-05-26 05:14:16 | INFO | train_inner | epoch 006:   2232 / 6686 loss=4.32, nll_loss=2.714, ppl=6.56, wps=52789.6, ups=0.92, wpb=57157.4, bsz=1480.7, num_updates=35600, lr=0.000335201, gnorm=0.252, clip=100, loss_scale=16, train_wall=104, wall=39250
2023-05-26 05:16:05 | INFO | train_inner | epoch 006:   2332 / 6686 loss=4.326, nll_loss=2.721, ppl=6.59, wps=52412.8, ups=0.92, wpb=56946.3, bsz=1464.8, num_updates=35700, lr=0.000334731, gnorm=0.248, clip=100, loss_scale=16, train_wall=105, wall=39359
2023-05-26 05:17:53 | INFO | train_inner | epoch 006:   2432 / 6686 loss=4.324, nll_loss=2.718, ppl=6.58, wps=52624.6, ups=0.92, wpb=57064.9, bsz=1444.6, num_updates=35800, lr=0.000334263, gnorm=0.253, clip=100, loss_scale=16, train_wall=105, wall=39467
2023-05-26 05:19:42 | INFO | train_inner | epoch 006:   2532 / 6686 loss=4.323, nll_loss=2.717, ppl=6.57, wps=52581.9, ups=0.92, wpb=57168, bsz=1476.5, num_updates=35900, lr=0.000333797, gnorm=0.249, clip=100, loss_scale=20, train_wall=105, wall=39576
2023-05-26 05:21:30 | INFO | train_inner | epoch 006:   2632 / 6686 loss=4.325, nll_loss=2.719, ppl=6.58, wps=52690.1, ups=0.92, wpb=57131.9, bsz=1471, num_updates=36000, lr=0.000333333, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=39684
2023-05-26 05:22:37 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 05:23:20 | INFO | train_inner | epoch 006:   2733 / 6686 loss=4.326, nll_loss=2.721, ppl=6.59, wps=52206.8, ups=0.91, wpb=57334.4, bsz=1505.4, num_updates=36100, lr=0.000332871, gnorm=0.253, clip=100, loss_scale=26, train_wall=106, wall=39794
2023-05-26 05:25:09 | INFO | train_inner | epoch 006:   2833 / 6686 loss=4.314, nll_loss=2.707, ppl=6.53, wps=52615.9, ups=0.92, wpb=57262, bsz=1469, num_updates=36200, lr=0.000332411, gnorm=0.253, clip=100, loss_scale=16, train_wall=105, wall=39903
2023-05-26 05:26:58 | INFO | train_inner | epoch 006:   2933 / 6686 loss=4.323, nll_loss=2.718, ppl=6.58, wps=52693.2, ups=0.92, wpb=57205.4, bsz=1482.4, num_updates=36300, lr=0.000331953, gnorm=0.25, clip=100, loss_scale=16, train_wall=105, wall=40012
2023-05-26 05:28:46 | INFO | train_inner | epoch 006:   3033 / 6686 loss=4.328, nll_loss=2.723, ppl=6.6, wps=52657.3, ups=0.92, wpb=57072.3, bsz=1478.6, num_updates=36400, lr=0.000331497, gnorm=0.25, clip=100, loss_scale=16, train_wall=105, wall=40120
2023-05-26 05:30:35 | INFO | train_inner | epoch 006:   3133 / 6686 loss=4.31, nll_loss=2.703, ppl=6.51, wps=52717.2, ups=0.92, wpb=57237.9, bsz=1513.9, num_updates=36500, lr=0.000331042, gnorm=0.248, clip=100, loss_scale=16, train_wall=105, wall=40229
2023-05-26 05:32:23 | INFO | train_inner | epoch 006:   3233 / 6686 loss=4.32, nll_loss=2.715, ppl=6.56, wps=52813.6, ups=0.92, wpb=57135.8, bsz=1484.6, num_updates=36600, lr=0.00033059, gnorm=0.25, clip=100, loss_scale=21, train_wall=104, wall=40337
2023-05-26 05:33:28 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 05:34:12 | INFO | train_inner | epoch 006:   3334 / 6686 loss=4.325, nll_loss=2.719, ppl=6.59, wps=52033.7, ups=0.91, wpb=56882.8, bsz=1460.2, num_updates=36700, lr=0.000330139, gnorm=0.252, clip=100, loss_scale=25, train_wall=105, wall=40446
2023-05-26 05:36:01 | INFO | train_inner | epoch 006:   3434 / 6686 loss=4.329, nll_loss=2.724, ppl=6.61, wps=52694.2, ups=0.92, wpb=57228.7, bsz=1479.8, num_updates=36800, lr=0.00032969, gnorm=0.252, clip=100, loss_scale=16, train_wall=105, wall=40555
2023-05-26 05:37:49 | INFO | train_inner | epoch 006:   3534 / 6686 loss=4.318, nll_loss=2.712, ppl=6.55, wps=52703.9, ups=0.92, wpb=57173.3, bsz=1483.2, num_updates=36900, lr=0.000329243, gnorm=0.249, clip=100, loss_scale=16, train_wall=105, wall=40663
2023-05-26 05:39:38 | INFO | train_inner | epoch 006:   3634 / 6686 loss=4.322, nll_loss=2.716, ppl=6.57, wps=52482.7, ups=0.92, wpb=57052.7, bsz=1490.6, num_updates=37000, lr=0.000328798, gnorm=0.246, clip=100, loss_scale=16, train_wall=105, wall=40772
2023-05-26 05:41:26 | INFO | train_inner | epoch 006:   3734 / 6686 loss=4.342, nll_loss=2.739, ppl=6.68, wps=52615.9, ups=0.92, wpb=57032.2, bsz=1445.7, num_updates=37100, lr=0.000328355, gnorm=0.253, clip=100, loss_scale=16, train_wall=105, wall=40880
2023-05-26 05:43:15 | INFO | train_inner | epoch 006:   3834 / 6686 loss=4.322, nll_loss=2.716, ppl=6.57, wps=52849.9, ups=0.92, wpb=57247.2, bsz=1462, num_updates=37200, lr=0.000327913, gnorm=0.253, clip=100, loss_scale=21, train_wall=104, wall=40989
2023-05-26 05:44:36 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 05:45:04 | INFO | train_inner | epoch 006:   3935 / 6686 loss=4.325, nll_loss=2.72, ppl=6.59, wps=52180.5, ups=0.91, wpb=57183.2, bsz=1439.7, num_updates=37300, lr=0.000327473, gnorm=0.253, clip=100, loss_scale=28, train_wall=106, wall=41098
2023-05-26 05:46:53 | INFO | train_inner | epoch 006:   4035 / 6686 loss=4.32, nll_loss=2.715, ppl=6.56, wps=52726.1, ups=0.92, wpb=57204.9, bsz=1500.6, num_updates=37400, lr=0.000327035, gnorm=0.249, clip=100, loss_scale=16, train_wall=105, wall=41207
2023-05-26 05:48:41 | INFO | train_inner | epoch 006:   4135 / 6686 loss=4.307, nll_loss=2.7, ppl=6.5, wps=52736.9, ups=0.92, wpb=57199.2, bsz=1475, num_updates=37500, lr=0.000326599, gnorm=0.253, clip=100, loss_scale=16, train_wall=105, wall=41315
2023-05-26 05:50:30 | INFO | train_inner | epoch 006:   4235 / 6686 loss=4.328, nll_loss=2.723, ppl=6.6, wps=52488.3, ups=0.92, wpb=56993.9, bsz=1462.2, num_updates=37600, lr=0.000326164, gnorm=0.253, clip=100, loss_scale=16, train_wall=105, wall=41424
2023-05-26 05:52:18 | INFO | train_inner | epoch 006:   4335 / 6686 loss=4.319, nll_loss=2.713, ppl=6.56, wps=52699.4, ups=0.92, wpb=57197, bsz=1455.9, num_updates=37700, lr=0.000325731, gnorm=0.249, clip=100, loss_scale=16, train_wall=105, wall=41532
2023-05-26 05:53:41 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 05:54:08 | INFO | train_inner | epoch 006:   4436 / 6686 loss=4.319, nll_loss=2.713, ppl=6.56, wps=52160.1, ups=0.91, wpb=57113.9, bsz=1488.8, num_updates=37800, lr=0.0003253, gnorm=0.248, clip=100, loss_scale=14, train_wall=106, wall=41642
2023-05-26 05:55:56 | INFO | train_inner | epoch 006:   4536 / 6686 loss=4.323, nll_loss=2.717, ppl=6.58, wps=52636.7, ups=0.92, wpb=57127.7, bsz=1467.8, num_updates=37900, lr=0.000324871, gnorm=0.25, clip=100, loss_scale=8, train_wall=105, wall=41750
2023-05-26 05:57:45 | INFO | train_inner | epoch 006:   4636 / 6686 loss=4.322, nll_loss=2.717, ppl=6.57, wps=52601.3, ups=0.92, wpb=57157.5, bsz=1472, num_updates=38000, lr=0.000324443, gnorm=0.254, clip=100, loss_scale=8, train_wall=105, wall=41859
2023-05-26 05:59:34 | INFO | train_inner | epoch 006:   4736 / 6686 loss=4.315, nll_loss=2.709, ppl=6.54, wps=52643, ups=0.92, wpb=57294.4, bsz=1477, num_updates=38100, lr=0.000324017, gnorm=0.249, clip=100, loss_scale=8, train_wall=105, wall=41968
2023-05-26 06:01:23 | INFO | train_inner | epoch 006:   4836 / 6686 loss=4.311, nll_loss=2.704, ppl=6.52, wps=52649.5, ups=0.92, wpb=57323, bsz=1489.3, num_updates=38200, lr=0.000323592, gnorm=0.248, clip=100, loss_scale=8, train_wall=105, wall=42077
2023-05-26 06:03:12 | INFO | train_inner | epoch 006:   4936 / 6686 loss=4.321, nll_loss=2.715, ppl=6.57, wps=52787.2, ups=0.92, wpb=57483.9, bsz=1482.3, num_updates=38300, lr=0.00032317, gnorm=0.25, clip=100, loss_scale=9, train_wall=105, wall=42186
2023-05-26 06:05:01 | INFO | train_inner | epoch 006:   5036 / 6686 loss=4.301, nll_loss=2.693, ppl=6.47, wps=52553.5, ups=0.92, wpb=57308.7, bsz=1476.1, num_updates=38400, lr=0.000322749, gnorm=0.251, clip=100, loss_scale=16, train_wall=105, wall=42295
2023-05-26 06:06:49 | INFO | train_inner | epoch 006:   5136 / 6686 loss=4.309, nll_loss=2.702, ppl=6.51, wps=52711, ups=0.92, wpb=57108.1, bsz=1490.6, num_updates=38500, lr=0.000322329, gnorm=0.253, clip=100, loss_scale=16, train_wall=105, wall=42403
2023-05-26 06:08:38 | INFO | train_inner | epoch 006:   5236 / 6686 loss=4.318, nll_loss=2.712, ppl=6.55, wps=52705, ups=0.92, wpb=57322.2, bsz=1464.4, num_updates=38600, lr=0.000321911, gnorm=0.246, clip=100, loss_scale=16, train_wall=105, wall=42512
2023-05-26 06:10:26 | INFO | train_inner | epoch 006:   5336 / 6686 loss=4.31, nll_loss=2.703, ppl=6.51, wps=52834.6, ups=0.92, wpb=57277.8, bsz=1491.2, num_updates=38700, lr=0.000321495, gnorm=0.247, clip=100, loss_scale=16, train_wall=105, wall=42620
2023-05-26 06:12:15 | INFO | train_inner | epoch 006:   5436 / 6686 loss=4.313, nll_loss=2.707, ppl=6.53, wps=52788.6, ups=0.92, wpb=57305.5, bsz=1489.4, num_updates=38800, lr=0.000321081, gnorm=0.249, clip=100, loss_scale=16, train_wall=105, wall=42729
2023-05-26 06:14:03 | INFO | train_inner | epoch 006:   5536 / 6686 loss=4.311, nll_loss=2.705, ppl=6.52, wps=52830.7, ups=0.92, wpb=57123.3, bsz=1483.2, num_updates=38900, lr=0.000320668, gnorm=0.246, clip=100, loss_scale=32, train_wall=104, wall=42837
2023-05-26 06:14:21 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 06:15:53 | INFO | train_inner | epoch 006:   5637 / 6686 loss=4.314, nll_loss=2.707, ppl=6.53, wps=52211.1, ups=0.91, wpb=57306.4, bsz=1485.1, num_updates=39000, lr=0.000320256, gnorm=0.25, clip=100, loss_scale=19, train_wall=106, wall=42947
2023-05-26 06:17:41 | INFO | train_inner | epoch 006:   5737 / 6686 loss=4.303, nll_loss=2.695, ppl=6.48, wps=52795.1, ups=0.92, wpb=57274.9, bsz=1482, num_updates=39100, lr=0.000319847, gnorm=0.247, clip=100, loss_scale=16, train_wall=105, wall=43055
2023-05-26 06:19:30 | INFO | train_inner | epoch 006:   5837 / 6686 loss=4.315, nll_loss=2.709, ppl=6.54, wps=52768.5, ups=0.92, wpb=57273.3, bsz=1489.4, num_updates=39200, lr=0.000319438, gnorm=0.25, clip=100, loss_scale=16, train_wall=105, wall=43164
2023-05-26 06:21:18 | INFO | train_inner | epoch 006:   5937 / 6686 loss=4.318, nll_loss=2.713, ppl=6.56, wps=52627.1, ups=0.92, wpb=57264.4, bsz=1466.7, num_updates=39300, lr=0.000319032, gnorm=0.255, clip=100, loss_scale=16, train_wall=105, wall=43273
2023-05-26 06:23:07 | INFO | train_inner | epoch 006:   6037 / 6686 loss=4.308, nll_loss=2.701, ppl=6.5, wps=52881.9, ups=0.92, wpb=57398.2, bsz=1487.4, num_updates=39400, lr=0.000318626, gnorm=0.244, clip=100, loss_scale=16, train_wall=105, wall=43381
2023-05-26 06:24:55 | INFO | train_inner | epoch 006:   6137 / 6686 loss=4.306, nll_loss=2.699, ppl=6.49, wps=52796.8, ups=0.92, wpb=57230.1, bsz=1487, num_updates=39500, lr=0.000318223, gnorm=0.249, clip=100, loss_scale=28, train_wall=105, wall=43489
2023-05-26 06:26:44 | INFO | train_inner | epoch 006:   6237 / 6686 loss=4.312, nll_loss=2.706, ppl=6.52, wps=52503.4, ups=0.92, wpb=56895.6, bsz=1473, num_updates=39600, lr=0.000317821, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=43598
2023-05-26 06:28:32 | INFO | train_inner | epoch 006:   6337 / 6686 loss=4.313, nll_loss=2.707, ppl=6.53, wps=52614.9, ups=0.92, wpb=57068.6, bsz=1477.4, num_updates=39700, lr=0.00031742, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=43706
2023-05-26 06:29:49 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 06:30:21 | INFO | train_inner | epoch 006:   6438 / 6686 loss=4.322, nll_loss=2.718, ppl=6.58, wps=52350.6, ups=0.92, wpb=57146.1, bsz=1476.3, num_updates=39800, lr=0.000317021, gnorm=0.248, clip=100, loss_scale=27, train_wall=105, wall=43815
2023-05-26 06:32:10 | INFO | train_inner | epoch 006:   6538 / 6686 loss=4.307, nll_loss=2.7, ppl=6.5, wps=52763.6, ups=0.92, wpb=57308.1, bsz=1495.5, num_updates=39900, lr=0.000316624, gnorm=0.248, clip=100, loss_scale=16, train_wall=105, wall=43924
2023-05-26 06:33:58 | INFO | train_inner | epoch 006:   6638 / 6686 loss=4.327, nll_loss=2.723, ppl=6.6, wps=52736.3, ups=0.93, wpb=56980.1, bsz=1451, num_updates=40000, lr=0.000316228, gnorm=0.249, clip=100, loss_scale=16, train_wall=104, wall=44032
2023-05-26 06:34:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-26 06:34:54 | INFO | fairseq.tasks.translation | example hypothesis: Why was that?
2023-05-26 06:34:54 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-26 06:34:55 | INFO | fairseq.tasks.translation | example hypothesis: I’ll make you lose so much that not even your pants are left!
2023-05-26 06:34:55 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-26 06:34:55 | INFO | fairseq.tasks.translation | example hypothesis: Just as Shen Liangchuan heaved a sigh of relief, he heard her say, “I’ll call you to stay in the same room!”
2023-05-26 06:34:55 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-26 06:34:56 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved her hand and entered the elevator.
2023-05-26 06:34:56 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-26 06:34:57 | INFO | fairseq.tasks.translation | example hypothesis: She raised her head and saw Song Cheng standing in the distance!
2023-05-26 06:34:57 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-26 06:34:57 | INFO | fairseq.tasks.translation | example hypothesis: Then, Song Cheng patted his chest, “I was scared to death! Where’s Wang Chuan?”
2023-05-26 06:34:57 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-26 06:34:58 | INFO | fairseq.tasks.translation | example hypothesis: I said, “I’m not going, I can’t eat it.”
2023-05-26 06:34:58 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-26 06:34:58 | INFO | fairseq.tasks.translation | example hypothesis: Hao Wang insisted on him, causing the public to lean towards Wang Wen Hao.
2023-05-26 06:34:58 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-26 06:35:00 | INFO | fairseq.tasks.translation | example hypothesis: With his identity, coming here like this, Baili Hongzhuang had to treat him even if she did not treat him!
2023-05-26 06:35:00 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-26 06:35:01 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian: “Mr. Shen, I... I’ve left too much blood and my brain is lacking oxygen. I can’t think of anything. Why don’t you give me a hint?”
2023-05-26 06:35:01 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-26 06:35:02 | INFO | fairseq.tasks.translation | example hypothesis: He didn’t know why so many people had heard of this. Since he couldn’t hide it anymore, he might as well tell them.
2023-05-26 06:35:02 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-26 06:35:02 | INFO | fairseq.tasks.translation | example hypothesis: She deliberately lowered her voice, but it could not hide the viciousness and viciousness in her tone.
2023-05-26 06:35:02 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-26 06:35:03 | INFO | fairseq.tasks.translation | example hypothesis: The strength of a beast pet of different levels was different, but a beast pet was precious and rare. It was impossible for an ordinary person to have it, and even an official’s disciple would not be able to have it.
2023-05-26 06:35:03 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-26 06:35:04 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chixia gritted her teeth and cursed in a low voice.
2023-05-26 06:35:04 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-26 06:35:05 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang was well-hidden, Di Bei Chen could still see the waves flashing in her eyes, and a hint of warmth filled his eyes.
2023-05-26 06:35:05 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-26 06:35:06 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia walked in, not to mention the guests, not even a few waiters could be seen.
2023-05-26 06:35:06 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-26 06:35:07 | INFO | fairseq.tasks.translation | example hypothesis: This person was none other than the Ye Family's Fourth Young Miss, Ye Qingling.
2023-05-26 06:35:07 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-26 06:35:09 | INFO | fairseq.tasks.translation | example hypothesis: Because at this moment, she felt as though her chin was about to shatter.
2023-05-26 06:35:09 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-26 06:35:10 | INFO | fairseq.tasks.translation | example hypothesis: “Alright Mu Zi, help me. If it wasn't for you, that old man wouldn't have set his eyes on me.”
2023-05-26 06:35:10 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-26 06:35:11 | INFO | fairseq.tasks.translation | example hypothesis: Baili Yuyan was even more excited. This matter was completely under her control. Earlier, Bai Li Hongzhuang had treated her like this. This time around, she would definitely make Bai Li Hongzhuang feel bad.
2023-05-26 06:35:11 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-26 06:35:12 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How could that be? They are also four grand mages, so of course they won’t surrender so easily. After arguing for a long time, they finally decided to use the method of the competition to obtain control over the Kingdom of Axia.”
2023-05-26 06:35:12 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-26 06:35:14 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a little. Originally, he had been looking for a reason for Li Yuyue not being able to participate in the royal family’s hunting competition.
2023-05-26 06:35:14 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-26 06:35:15 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my level good? They’re all the best talents in the country, my magic is so weak?”
2023-05-26 06:35:15 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-26 06:35:17 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yibei’s words meant that if Fang Chixia didn’t want to go, she didn’t need to go.
2023-05-26 06:35:17 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-26 06:35:19 | INFO | fairseq.tasks.translation | example hypothesis: She turned her head and saw that the five palm marks on her cheeks were very eye-catching. They were swelling at a speed visible to the naked eye. When she reached out to touch them, she couldn’t help but let out a hissing sound.
2023-05-26 06:35:19 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-26 06:35:20 | INFO | fairseq.tasks.translation | example hypothesis: This... how could this be the charm that that trash could emit?
2023-05-26 06:35:20 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-26 06:35:21 | INFO | fairseq.tasks.translation | example hypothesis: How could Wang Wenhao have found a newspaper agency? The chief editor should have called to inform her not to come to the newspaper agency, but these three people... had plotted against her!
2023-05-26 06:35:21 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-26 06:35:24 | INFO | fairseq.tasks.translation | example hypothesis: I was delighted when I heard Teacher Di’s praise. I put away the energy ball with my left hand and shot out a beam of light towards Teacher Zhen with my right hand. The beam of light actually managed to hit Teacher Zhen smoothly. I was shocked, and upon closer inspection, I realized that it was just an afterimage.
2023-05-26 06:35:24 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-26 06:35:27 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Originally, we proposed a three-on-one competition, but they said that it was unfair, because we have Teacher Di and Teacher Zhen, their rankings are higher than them, and they proposed five-on-three wins, since we proposed the competition, so we can only listen to them in the end. Three days later, we’ll have a secret competition in the Royal Colosseum, and we’ll be able to compete with them.”
2023-05-26 06:35:27 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-26 06:35:29 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Zhen used a seventh-level spell, Light Thunder Chain, which I rarely used, because I was not very good at controlling it. Teacher Zhen cast nine lightning bolts to surround me, forming a simple spell formation that prevented me from escaping through a short distance. Then, the lightning bolts exploded one after another to form a powerful offensive power.
2023-05-26 06:35:29 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-26 06:35:32 | INFO | fairseq.tasks.translation | example hypothesis: As soon as Mark and the two teachers reached the other side, Teacher Zhen sent out a Lesser Dimensional Slash at me. As expected of the continent’s number one mage, the powerful suction force from the Lesser Dimensional Slash was actually much stronger than the one I sent out. A small spatial crack appeared beside me, and a powerful suction force swept towards me.
2023-05-26 06:35:32 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-26 06:35:32 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 4.222 | nll_loss 2.582 | ppl 5.99 | bleu 21.31 | wps 1921.3 | wpb 2420.8 | bsz 84.5 | num_updates 40048 | best_bleu 21.44
2023-05-26 06:35:32 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-26 06:35:35 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/concat-1-1-0.2-sf[zh-en]/checkpoint6.pt (epoch 6 @ 40048 updates, score 21.31) (writing took 2.7817056449130177 seconds)
2023-05-26 06:35:35 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-05-26 06:35:35 | INFO | train | epoch 006 | loss 4.319 | nll_loss 2.713 | ppl 6.56 | wps 52166.5 | ups 0.91 | wpb 57189.1 | bsz 1477.5 | num_updates 40048 | lr 0.000316038 | gnorm 0.25 | clip 100 | loss_scale 19 | train_wall 7010 | wall 44129
2023-05-26 06:35:35 | INFO | fairseq.trainer | begin training epoch 7
2023-05-26 06:35:56 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-26 06:36:42 | INFO | train_inner | epoch 007:     53 / 6686 loss=4.289, nll_loss=2.679, ppl=6.41, wps=34667, ups=0.61, wpb=56771.9, bsz=1491.2, num_updates=40100, lr=0.000315833, gnorm=0.256, clip=100, loss_scale=13, train_wall=108, wall=44196
2023-05-26 06:38:35 | INFO | train_inner | epoch 007:    153 / 6686 loss=4.283, nll_loss=2.673, ppl=6.38, wps=50737, ups=0.89, wpb=57217.5, bsz=1478.4, num_updates=40200, lr=0.00031544, gnorm=0.248, clip=100, loss_scale=8, train_wall=107, wall=44309
2023-05-26 06:40:25 | INFO | train_inner | epoch 007:    253 / 6686 loss=4.295, nll_loss=2.686, ppl=6.44, wps=51698.6, ups=0.91, wpb=57006.8, bsz=1474.7, num_updates=40300, lr=0.000315049, gnorm=0.258, clip=100, loss_scale=8, train_wall=106, wall=44419
2023-05-26 06:42:14 | INFO | train_inner | epoch 007:    353 / 6686 loss=4.288, nll_loss=2.678, ppl=6.4, wps=52292.1, ups=0.92, wpb=57132.4, bsz=1493, num_updates=40400, lr=0.000314658, gnorm=0.248, clip=100, loss_scale=8, train_wall=105, wall=44528
2023-05-26 06:44:03 | INFO | train_inner | epoch 007:    453 / 6686 loss=4.289, nll_loss=2.679, ppl=6.4, wps=52493.8, ups=0.92, wpb=57184.2, bsz=1473.3, num_updates=40500, lr=0.00031427, gnorm=0.249, clip=100, loss_scale=8, train_wall=105, wall=44637
2023-05-26 06:45:52 | INFO | train_inner | epoch 007:    553 / 6686 loss=4.292, nll_loss=2.683, ppl=6.42, wps=52636.1, ups=0.92, wpb=57198.8, bsz=1480.6, num_updates=40600, lr=0.000313882, gnorm=0.252, clip=100, loss_scale=10, train_wall=105, wall=44746
2023-05-26 06:47:41 | INFO | train_inner | epoch 007:    653 / 6686 loss=4.276, nll_loss=2.665, ppl=6.34, wps=52802.2, ups=0.92, wpb=57466.5, bsz=1492.8, num_updates=40700, lr=0.000313497, gnorm=0.248, clip=100, loss_scale=16, train_wall=105, wall=44855
2023-05-26 06:49:29 | INFO | train_inner | epoch 007:    753 / 6686 loss=4.284, nll_loss=2.674, ppl=6.38, wps=52637.8, ups=0.92, wpb=57134.1, bsz=1468.3, num_updates=40800, lr=0.000313112, gnorm=0.25, clip=100, loss_scale=16, train_wall=105, wall=44963
2023-05-26 06:51:18 | INFO | train_inner | epoch 007:    853 / 6686 loss=4.293, nll_loss=2.684, ppl=6.43, wps=52607.3, ups=0.92, wpb=57090, bsz=1478.8, num_updates=40900, lr=0.000312729, gnorm=0.247, clip=100, loss_scale=16, train_wall=105, wall=45072
2023-05-26 06:53:07 | INFO | train_inner | epoch 007:    953 / 6686 loss=4.291, nll_loss=2.682, ppl=6.42, wps=52615.8, ups=0.92, wpb=57300.2, bsz=1471, num_updates=41000, lr=0.000312348, gnorm=0.252, clip=100, loss_scale=16, train_wall=105, wall=45181
2023-05-26 06:54:55 | INFO | train_inner | epoch 007:   1053 / 6686 loss=4.301, nll_loss=2.693, ppl=6.46, wps=52731.4, ups=0.92, wpb=57422.8, bsz=1456.8, num_updates=41100, lr=0.000311967, gnorm=0.248, clip=100, loss_scale=19, train_wall=105, wall=45290
2023-05-26 06:56:44 | INFO | train_inner | epoch 007:   1153 / 6686 loss=4.288, nll_loss=2.678, ppl=6.4, wps=52672.5, ups=0.92, wpb=57237.1, bsz=1485.7, num_updates=41200, lr=0.000311588, gnorm=0.251, clip=100, loss_scale=32, train_wall=105, wall=45398
2023-05-26 06:57:58 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 06:58:34 | INFO | train_inner | epoch 007:   1254 / 6686 loss=4.302, nll_loss=2.694, ppl=6.47, wps=51959.7, ups=0.91, wpb=57115.3, bsz=1464.5, num_updates=41300, lr=0.000311211, gnorm=0.252, clip=100, loss_scale=27, train_wall=106, wall=45508
2023-05-26 07:00:23 | INFO | train_inner | epoch 007:   1354 / 6686 loss=4.29, nll_loss=2.681, ppl=6.41, wps=52766.1, ups=0.92, wpb=57441.9, bsz=1513.3, num_updates=41400, lr=0.000310835, gnorm=0.246, clip=100, loss_scale=16, train_wall=105, wall=45617
2023-05-26 07:02:11 | INFO | train_inner | epoch 007:   1454 / 6686 loss=4.295, nll_loss=2.686, ppl=6.44, wps=52553.7, ups=0.92, wpb=56973.8, bsz=1455.4, num_updates=41500, lr=0.00031046, gnorm=0.252, clip=100, loss_scale=16, train_wall=105, wall=45725
2023-05-26 07:04:00 | INFO | train_inner | epoch 007:   1554 / 6686 loss=4.294, nll_loss=2.685, ppl=6.43, wps=52492.5, ups=0.92, wpb=57199.5, bsz=1481.5, num_updates=41600, lr=0.000310087, gnorm=0.25, clip=100, loss_scale=16, train_wall=105, wall=45834
2023-05-26 07:05:49 | INFO | train_inner | epoch 007:   1654 / 6686 loss=4.297, nll_loss=2.688, ppl=6.45, wps=52454.8, ups=0.92, wpb=57060.1, bsz=1455.5, num_updates=41700, lr=0.000309715, gnorm=0.253, clip=100, loss_scale=16, train_wall=105, wall=45943
2023-05-26 07:07:22 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 07:07:39 | INFO | train_inner | epoch 007:   1755 / 6686 loss=4.302, nll_loss=2.694, ppl=6.47, wps=52067.9, ups=0.91, wpb=57360.9, bsz=1474.3, num_updates=41800, lr=0.000309344, gnorm=0.253, clip=100, loss_scale=17, train_wall=106, wall=46053
2023-05-26 07:09:28 | INFO | train_inner | epoch 007:   1855 / 6686 loss=4.306, nll_loss=2.698, ppl=6.49, wps=52437.5, ups=0.92, wpb=57014.3, bsz=1445.9, num_updates=41900, lr=0.000308975, gnorm=0.251, clip=100, loss_scale=16, train_wall=105, wall=46162
2023-05-26 07:11:17 | INFO | train_inner | epoch 007:   1955 / 6686 loss=4.289, nll_loss=2.679, ppl=6.41, wps=52542.6, ups=0.92, wpb=57332.5, bsz=1473.5, num_updates=42000, lr=0.000308607, gnorm=0.247, clip=100, loss_scale=16, train_wall=105, wall=46271
2023-05-26 07:13:06 | INFO | train_inner | epoch 007:   2055 / 6686 loss=4.302, nll_loss=2.694, ppl=6.47, wps=52526.9, ups=0.92, wpb=57148.4, bsz=1470.8, num_updates=42100, lr=0.00030824, gnorm=0.252, clip=100, loss_scale=16, train_wall=105, wall=46380
2023-05-26 07:14:55 | INFO | train_inner | epoch 007:   2155 / 6686 loss=4.3, nll_loss=2.692, ppl=6.46, wps=52705.1, ups=0.92, wpb=57394, bsz=1476.6, num_updates=42200, lr=0.000307875, gnorm=0.247, clip=100, loss_scale=16, train_wall=105, wall=46489
2023-05-26 07:16:44 | INFO | train_inner | epoch 007:   2255 / 6686 loss=4.294, nll_loss=2.685, ppl=6.43, wps=52454.5, ups=0.92, wpb=57111.9, bsz=1468.9, num_updates=42300, lr=0.00030751, gnorm=0.251, clip=100, loss_scale=17, train_wall=105, wall=46598
2023-05-26 07:18:32 | INFO | train_inner | epoch 007:   2355 / 6686 loss=4.304, nll_loss=2.697, ppl=6.48, wps=52558.2, ups=0.92, wpb=57156.4, bsz=1470.9, num_updates=42400, lr=0.000307148, gnorm=0.245, clip=100, loss_scale=32, train_wall=105, wall=46707
2023-05-26 07:20:21 | INFO | train_inner | epoch 007:   2455 / 6686 loss=4.304, nll_loss=2.697, ppl=6.48, wps=52469.8, ups=0.92, wpb=57011.8, bsz=1458.6, num_updates=42500, lr=0.000306786, gnorm=0.251, clip=100, loss_scale=32, train_wall=105, wall=46815
2023-05-26 07:21:00 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 07:22:10 | INFO | train_inner | epoch 007:   2556 / 6686 loss=4.289, nll_loss=2.68, ppl=6.41, wps=52227.7, ups=0.92, wpb=56881.4, bsz=1473, num_updates=42600, lr=0.000306426, gnorm=0.248, clip=100, loss_scale=22, train_wall=105, wall=46924
2023-05-26 07:23:59 | INFO | train_inner | epoch 007:   2656 / 6686 loss=4.294, nll_loss=2.685, ppl=6.43, wps=52568.6, ups=0.92, wpb=57305.4, bsz=1460.2, num_updates=42700, lr=0.000306067, gnorm=0.245, clip=100, loss_scale=16, train_wall=105, wall=47033
2023-05-26 07:25:48 | INFO | train_inner | epoch 007:   2756 / 6686 loss=4.284, nll_loss=2.674, ppl=6.38, wps=52604.3, ups=0.92, wpb=57286.2, bsz=1484.5, num_updates=42800, lr=0.000305709, gnorm=0.249, clip=100, loss_scale=16, train_wall=105, wall=47142
2023-05-26 07:27:36 | INFO | train_inner | epoch 007:   2856 / 6686 loss=4.296, nll_loss=2.687, ppl=6.44, wps=52720.6, ups=0.92, wpb=57052.6, bsz=1473.2, num_updates=42900, lr=0.000305352, gnorm=0.251, clip=100, loss_scale=16, train_wall=105, wall=47250
2023-05-26 07:29:25 | INFO | train_inner | epoch 007:   2956 / 6686 loss=4.294, nll_loss=2.686, ppl=6.43, wps=52720, ups=0.92, wpb=57236.8, bsz=1456.4, num_updates=43000, lr=0.000304997, gnorm=0.248, clip=100, loss_scale=16, train_wall=105, wall=47359
2023-05-26 07:31:13 | INFO | train_inner | epoch 007:   3056 / 6686 loss=4.305, nll_loss=2.698, ppl=6.49, wps=52757.8, ups=0.92, wpb=57292.2, bsz=1466, num_updates=43100, lr=0.000304643, gnorm=0.248, clip=100, loss_scale=25, train_wall=105, wall=47467
2023-05-26 07:33:02 | INFO | train_inner | epoch 007:   3156 / 6686 loss=4.292, nll_loss=2.683, ppl=6.42, wps=52534.4, ups=0.92, wpb=57003.1, bsz=1471.2, num_updates=43200, lr=0.00030429, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=47576
2023-05-26 07:34:50 | INFO | train_inner | epoch 007:   3256 / 6686 loss=4.283, nll_loss=2.673, ppl=6.38, wps=52802.2, ups=0.92, wpb=57181.3, bsz=1498.7, num_updates=43300, lr=0.000303939, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=47684
2023-05-26 07:36:39 | INFO | train_inner | epoch 007:   3356 / 6686 loss=4.291, nll_loss=2.682, ppl=6.42, wps=52791.2, ups=0.92, wpb=57214.8, bsz=1483.6, num_updates=43400, lr=0.000303588, gnorm=0.251, clip=100, loss_scale=32, train_wall=104, wall=47793
2023-05-26 07:38:27 | INFO | train_inner | epoch 007:   3456 / 6686 loss=4.29, nll_loss=2.681, ppl=6.41, wps=52906.2, ups=0.93, wpb=57184.2, bsz=1458.4, num_updates=43500, lr=0.000303239, gnorm=0.251, clip=100, loss_scale=32, train_wall=104, wall=47901
2023-05-26 07:39:32 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 07:39:55 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 07:40:18 | INFO | train_inner | epoch 007:   3558 / 6686 loss=4.289, nll_loss=2.681, ppl=6.41, wps=51340.9, ups=0.9, wpb=57187.2, bsz=1495.3, num_updates=43600, lr=0.000302891, gnorm=0.249, clip=100, loss_scale=29, train_wall=107, wall=48012
2023-05-26 07:42:07 | INFO | train_inner | epoch 007:   3658 / 6686 loss=4.297, nll_loss=2.689, ppl=6.45, wps=52577.3, ups=0.92, wpb=57148.1, bsz=1474, num_updates=43700, lr=0.000302545, gnorm=0.244, clip=100, loss_scale=16, train_wall=105, wall=48121
2023-05-26 07:43:55 | INFO | train_inner | epoch 007:   3758 / 6686 loss=4.287, nll_loss=2.678, ppl=6.4, wps=52609.3, ups=0.92, wpb=57176.4, bsz=1477.7, num_updates=43800, lr=0.000302199, gnorm=0.253, clip=100, loss_scale=16, train_wall=105, wall=48230
2023-05-26 07:45:44 | INFO | train_inner | epoch 007:   3858 / 6686 loss=4.288, nll_loss=2.68, ppl=6.41, wps=52770.4, ups=0.92, wpb=57457.6, bsz=1490.7, num_updates=43900, lr=0.000301855, gnorm=0.247, clip=100, loss_scale=16, train_wall=105, wall=48338
2023-05-26 07:47:33 | INFO | train_inner | epoch 007:   3958 / 6686 loss=4.297, nll_loss=2.689, ppl=6.45, wps=52857.9, ups=0.92, wpb=57292.4, bsz=1475.2, num_updates=44000, lr=0.000301511, gnorm=0.246, clip=100, loss_scale=16, train_wall=105, wall=48447
2023-05-26 07:49:21 | INFO | train_inner | epoch 007:   4058 / 6686 loss=4.287, nll_loss=2.678, ppl=6.4, wps=52874, ups=0.92, wpb=57335.3, bsz=1509.9, num_updates=44100, lr=0.000301169, gnorm=0.246, clip=100, loss_scale=18, train_wall=105, wall=48555
2023-05-26 07:51:10 | INFO | train_inner | epoch 007:   4158 / 6686 loss=4.305, nll_loss=2.699, ppl=6.49, wps=52724.2, ups=0.92, wpb=57299.6, bsz=1484.3, num_updates=44200, lr=0.000300828, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=48664
2023-05-26 07:52:59 | INFO | train_inner | epoch 007:   4258 / 6686 loss=4.276, nll_loss=2.666, ppl=6.34, wps=52592.6, ups=0.92, wpb=57334.5, bsz=1523.8, num_updates=44300, lr=0.000300489, gnorm=0.246, clip=100, loss_scale=32, train_wall=105, wall=48773
2023-05-26 07:54:47 | INFO | train_inner | epoch 007:   4358 / 6686 loss=4.295, nll_loss=2.686, ppl=6.44, wps=52704.8, ups=0.92, wpb=57233.3, bsz=1480.7, num_updates=44400, lr=0.00030015, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=48882
2023-05-26 07:56:36 | INFO | train_inner | epoch 007:   4458 / 6686 loss=4.289, nll_loss=2.681, ppl=6.41, wps=52643.2, ups=0.92, wpb=57339.5, bsz=1499.1, num_updates=44500, lr=0.000299813, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=48990
2023-05-26 07:58:25 | INFO | train_inner | epoch 007:   4558 / 6686 loss=4.289, nll_loss=2.68, ppl=6.41, wps=52751.4, ups=0.92, wpb=57304.4, bsz=1484.4, num_updates=44600, lr=0.000299476, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=49099
2023-05-26 07:58:47 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 08:00:14 | INFO | train_inner | epoch 007:   4659 / 6686 loss=4.293, nll_loss=2.684, ppl=6.43, wps=52114.6, ups=0.91, wpb=57036.2, bsz=1474.1, num_updates=44700, lr=0.000299141, gnorm=0.248, clip=100, loss_scale=37, train_wall=106, wall=49209
2023-05-26 08:01:53 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 08:02:04 | INFO | train_inner | epoch 007:   4760 / 6686 loss=4.288, nll_loss=2.679, ppl=6.4, wps=52180.3, ups=0.91, wpb=57241, bsz=1484.5, num_updates=44800, lr=0.000298807, gnorm=0.249, clip=100, loss_scale=30, train_wall=106, wall=49318
2023-05-26 08:03:53 | INFO | train_inner | epoch 007:   4860 / 6686 loss=4.285, nll_loss=2.676, ppl=6.39, wps=52569.6, ups=0.92, wpb=57062.8, bsz=1470.6, num_updates=44900, lr=0.000298474, gnorm=0.249, clip=100, loss_scale=16, train_wall=105, wall=49427
2023-05-26 08:05:41 | INFO | train_inner | epoch 007:   4960 / 6686 loss=4.299, nll_loss=2.692, ppl=6.46, wps=52710.7, ups=0.92, wpb=57188.9, bsz=1460.2, num_updates=45000, lr=0.000298142, gnorm=0.249, clip=100, loss_scale=16, train_wall=105, wall=49535
2023-05-26 08:07:30 | INFO | train_inner | epoch 007:   5060 / 6686 loss=4.298, nll_loss=2.691, ppl=6.46, wps=52497.7, ups=0.92, wpb=57104, bsz=1439.7, num_updates=45100, lr=0.000297812, gnorm=0.247, clip=100, loss_scale=16, train_wall=105, wall=49644
2023-05-26 08:09:18 | INFO | train_inner | epoch 007:   5160 / 6686 loss=4.294, nll_loss=2.686, ppl=6.44, wps=52871.8, ups=0.92, wpb=57366.3, bsz=1482.1, num_updates=45200, lr=0.000297482, gnorm=0.245, clip=100, loss_scale=16, train_wall=105, wall=49753
2023-05-26 08:11:07 | INFO | train_inner | epoch 007:   5260 / 6686 loss=4.293, nll_loss=2.685, ppl=6.43, wps=52825.2, ups=0.92, wpb=57247.4, bsz=1471.5, num_updates=45300, lr=0.000297154, gnorm=0.247, clip=100, loss_scale=16, train_wall=105, wall=49861
2023-05-26 08:12:56 | INFO | train_inner | epoch 007:   5360 / 6686 loss=4.284, nll_loss=2.675, ppl=6.39, wps=52594.7, ups=0.92, wpb=57251, bsz=1484, num_updates=45400, lr=0.000296826, gnorm=0.244, clip=100, loss_scale=32, train_wall=105, wall=49970
2023-05-26 08:14:44 | INFO | train_inner | epoch 007:   5460 / 6686 loss=4.281, nll_loss=2.671, ppl=6.37, wps=52755.1, ups=0.92, wpb=57275.6, bsz=1504.6, num_updates=45500, lr=0.0002965, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=50078
2023-05-26 08:16:33 | INFO | train_inner | epoch 007:   5560 / 6686 loss=4.299, nll_loss=2.692, ppl=6.46, wps=52536, ups=0.92, wpb=57033.1, bsz=1474.8, num_updates=45600, lr=0.000296174, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=50187
2023-05-26 08:18:21 | INFO | train_inner | epoch 007:   5660 / 6686 loss=4.282, nll_loss=2.672, ppl=6.37, wps=52629.6, ups=0.92, wpb=57175.5, bsz=1498.1, num_updates=45700, lr=0.00029585, gnorm=0.252, clip=100, loss_scale=32, train_wall=105, wall=50296
2023-05-26 08:20:10 | INFO | train_inner | epoch 007:   5760 / 6686 loss=4.3, nll_loss=2.693, ppl=6.47, wps=52530.9, ups=0.92, wpb=57030, bsz=1454.8, num_updates=45800, lr=0.000295527, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=50404
2023-05-26 08:20:29 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 08:20:48 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 08:22:01 | INFO | train_inner | epoch 007:   5862 / 6686 loss=4.28, nll_loss=2.67, ppl=6.37, wps=51542.8, ups=0.9, wpb=57126.1, bsz=1489.8, num_updates=45900, lr=0.000295205, gnorm=0.249, clip=100, loss_scale=23, train_wall=107, wall=50515
2023-05-26 08:23:49 | INFO | train_inner | epoch 007:   5962 / 6686 loss=4.3, nll_loss=2.693, ppl=6.46, wps=52580.3, ups=0.92, wpb=57038.1, bsz=1446.2, num_updates=46000, lr=0.000294884, gnorm=0.247, clip=100, loss_scale=16, train_wall=105, wall=50623
2023-05-26 08:25:39 | INFO | train_inner | epoch 007:   6062 / 6686 loss=4.291, nll_loss=2.683, ppl=6.42, wps=52389.5, ups=0.92, wpb=57190.8, bsz=1480.6, num_updates=46100, lr=0.000294564, gnorm=0.249, clip=100, loss_scale=16, train_wall=105, wall=50733
2023-05-26 08:27:27 | INFO | train_inner | epoch 007:   6162 / 6686 loss=4.275, nll_loss=2.665, ppl=6.34, wps=52652.8, ups=0.92, wpb=57249, bsz=1512.5, num_updates=46200, lr=0.000294245, gnorm=0.246, clip=100, loss_scale=16, train_wall=105, wall=50841
2023-05-26 08:29:15 | INFO | train_inner | epoch 007:   6262 / 6686 loss=4.29, nll_loss=2.682, ppl=6.42, wps=52868.8, ups=0.92, wpb=57188.6, bsz=1489.1, num_updates=46300, lr=0.000293927, gnorm=0.252, clip=100, loss_scale=16, train_wall=104, wall=50950
2023-05-26 08:31:04 | INFO | train_inner | epoch 007:   6362 / 6686 loss=4.295, nll_loss=2.687, ppl=6.44, wps=52646.8, ups=0.92, wpb=57002.3, bsz=1489.4, num_updates=46400, lr=0.00029361, gnorm=0.25, clip=100, loss_scale=25, train_wall=104, wall=51058
2023-05-26 08:32:53 | INFO | train_inner | epoch 007:   6462 / 6686 loss=4.292, nll_loss=2.684, ppl=6.43, wps=52610.3, ups=0.92, wpb=57328.2, bsz=1477.3, num_updates=46500, lr=0.000293294, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=51167
2023-05-26 08:34:41 | INFO | train_inner | epoch 007:   6562 / 6686 loss=4.285, nll_loss=2.675, ppl=6.39, wps=52630, ups=0.92, wpb=57149.3, bsz=1457, num_updates=46600, lr=0.000292979, gnorm=0.245, clip=100, loss_scale=32, train_wall=105, wall=51275
2023-05-26 08:36:30 | INFO | train_inner | epoch 007:   6662 / 6686 loss=4.288, nll_loss=2.68, ppl=6.41, wps=52466.2, ups=0.92, wpb=57287, bsz=1491.4, num_updates=46700, lr=0.000292666, gnorm=0.252, clip=100, loss_scale=32, train_wall=105, wall=51385
2023-05-26 08:36:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-26 08:37:00 | INFO | fairseq.tasks.translation | example hypothesis: Why was that?
2023-05-26 08:37:00 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-26 08:37:01 | INFO | fairseq.tasks.translation | example hypothesis: I’ll make you lose so much that you don’t even have your pants left!
2023-05-26 08:37:01 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-26 08:37:02 | INFO | fairseq.tasks.translation | example hypothesis: Just as Shen Liangchuan heaved a sigh of relief, he heard her say, “I’ll call you to stay in the same room!”
2023-05-26 08:37:02 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-26 08:37:02 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved her hand and entered the elevator.
2023-05-26 08:37:02 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-26 08:37:03 | INFO | fairseq.tasks.translation | example hypothesis: She looked up and saw Song Cheng standing in the distance!
2023-05-26 08:37:03 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-26 08:37:04 | INFO | fairseq.tasks.translation | example hypothesis: Then, Song Cheng patted his chest. “You scared me to death! Where’s Wang Chuan?”
2023-05-26 08:37:04 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-26 08:37:04 | INFO | fairseq.tasks.translation | example hypothesis: I said, “I’m not going, I can’t eat it.”
2023-05-26 08:37:04 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-26 08:37:05 | INFO | fairseq.tasks.translation | example hypothesis: Voices were first in disbelief, but Wang Wenhao insisted that he was biased towards Wang Wenhao.
2023-05-26 08:37:05 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-26 08:37:06 | INFO | fairseq.tasks.translation | example hypothesis: With his identity coming here like this, Baili Hongzhuang had to be treated even if she did not want to!
2023-05-26 08:37:06 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-26 08:37:07 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian said, “Mr. Shen, I-I’ve left too much blood and my brain is short of oxygen. I can’t figure it out. Why don’t you give me a hint?”
2023-05-26 08:37:07 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-26 08:37:08 | INFO | fairseq.tasks.translation | example hypothesis: He didn’t know why so many people would hear about this. Since he couldn’t hide it anymore, he might as well tell them.
2023-05-26 08:37:08 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-26 08:37:09 | INFO | fairseq.tasks.translation | example hypothesis: She deliberately lowered her voice, but it was unable to conceal the viciousness and ruthlessness in her tone.
2023-05-26 08:37:09 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-26 08:37:10 | INFO | fairseq.tasks.translation | example hypothesis: Different ranks of beast pets had different strengths, but beast pets were precious and rare. It was impossible for ordinary people to have one, not even for the descendants of officials.
2023-05-26 08:37:10 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-26 08:37:11 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chixia gritted her teeth and cursed under her breath.
2023-05-26 08:37:11 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-26 08:37:12 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang was well-hidden, Di Bei Cheng still saw the ripple in her eyes and felt a little warm.
2023-05-26 08:37:12 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-26 08:37:13 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia walked in, she didn't even see a few waiters, let alone guests.
2023-05-26 08:37:13 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-26 08:37:14 | INFO | fairseq.tasks.translation | example hypothesis: This person was the Ye Family’s fourth young miss, Ye Qing Ling.
2023-05-26 08:37:14 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-26 08:37:15 | INFO | fairseq.tasks.translation | example hypothesis: Because at this moment, she felt as though her chin was about to shatter.
2023-05-26 08:37:15 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-26 08:37:16 | INFO | fairseq.tasks.translation | example hypothesis: “Good Mu Zi, help me. If it wasn't for you, that old man wouldn't have targeted me.”
2023-05-26 08:37:16 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-26 08:37:17 | INFO | fairseq.tasks.translation | example hypothesis: Baili Yuyan was even more excited. This matter was completely directed by her. Earlier, when Baili Hongzhuang treated her like that, this time around, she would definitely make it difficult for Baili Hongzhuang.
2023-05-26 08:37:17 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-26 08:37:18 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How could that be? They also have four mages on their side, so of course they won’t surrender so easily. After arguing for a long time, they finally decided what method to use to obtain control over the Kingdom of Summer in the future.”
2023-05-26 08:37:18 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-26 08:37:20 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a little. He had always been looking for a reason for Li Yuyue not being able to participate in the Royal Family’s hunting competition.
2023-05-26 08:37:20 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-26 08:37:21 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my standard good? They’re all the most outstanding people in the country, how can my magic be so weak?”
2023-05-26 08:37:21 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-26 08:37:23 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yibei’s words meant that if Fang Chixia didn’t want to go, she didn’t need to go.
2023-05-26 08:37:23 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-26 08:37:25 | INFO | fairseq.tasks.translation | example hypothesis: She tilted her head and saw that the five palm prints on her cheeks were very eye-catching. They swelled up at a speed visible to the naked eye. She reached out to touch them, and she couldn’t help but let out a hiss.
2023-05-26 08:37:25 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-26 08:37:26 | INFO | fairseq.tasks.translation | example hypothesis: This... how could this be the charm that that trash could emit?
2023-05-26 08:37:26 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-26 08:37:27 | INFO | fairseq.tasks.translation | example hypothesis: How could Wang Wenhao have found the newspaper? The chief editor should have called her to tell her not to come to the newspaper, but these three people... had schemed against her!
2023-05-26 08:37:27 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-26 08:37:30 | INFO | fairseq.tasks.translation | example hypothesis: Hearing Teacher Di’s praise, I was delighted. I put the energy ball away with my left hand, and a beam of light shot out from my right hand towards Teacher Zhen. The beam of light actually managed to hit me smoothly. I was startled, and upon closer inspection, I realized that it was just an afterimage.
2023-05-26 08:37:30 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-26 08:37:33 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Originally, we proposed a two-on-three competition, but they said that it was unfair because we have Teacher Di and Teacher Zhen, and their rankings are higher than theirs. They proposed five-on-three matches, and because we proposed the competition, we can only listen to them in the end. Three days from now, we’ll have a secret competition in the Royal Coliseum. The competition will be held three days from now, and the competition
2023-05-26 08:37:33 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-26 08:37:35 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Di used light-type level 7 spell, Light Bolts. I rarely used this spell because I didn’t have a good control over it. Teacher Di released nine lightning bolts and surrounded me, forming a simple formation that prevented me from escaping in a short distance. Then, each of the lightning bolts exploded to form a powerful attack.
2023-05-26 08:37:35 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-26 08:37:38 | INFO | fairseq.tasks.translation | example hypothesis: As soon as Ma Ke and the two teachers walked to the other side, Teacher Zhen sent out a Small Dimensional Slash at me. As expected of the continent’s number one mage, the suction force of the Small Dimensional Slash was much stronger than mine. A small spatial crack appeared beside me, and a powerful suction force swept towards me.
2023-05-26 08:37:38 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-26 08:37:38 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 4.221 | nll_loss 2.582 | ppl 5.99 | bleu 21.33 | wps 1938.5 | wpb 2420.8 | bsz 84.5 | num_updates 46724 | best_bleu 21.44
2023-05-26 08:37:38 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-26 08:37:41 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/concat-1-1-0.2-sf[zh-en]/checkpoint7.pt (epoch 7 @ 46724 updates, score 21.33) (writing took 2.91538561694324 seconds)
2023-05-26 08:37:41 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-05-26 08:37:41 | INFO | train | epoch 007 | loss 4.292 | nll_loss 2.683 | ppl 6.42 | wps 52114.9 | ups 0.91 | wpb 57189.9 | bsz 1477.5 | num_updates 46724 | lr 0.00029259 | gnorm 0.249 | clip 100 | loss_scale 22 | train_wall 7019 | wall 51455
2023-05-26 08:37:41 | INFO | fairseq.trainer | begin training epoch 8
2023-05-26 08:39:14 | INFO | train_inner | epoch 008:     76 / 6686 loss=4.278, nll_loss=2.668, ppl=6.36, wps=34715.4, ups=0.61, wpb=56598.2, bsz=1446.4, num_updates=46800, lr=0.000292353, gnorm=0.251, clip=100, loss_scale=32, train_wall=107, wall=51548
2023-05-26 08:40:25 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 08:41:07 | INFO | train_inner | epoch 008:    177 / 6686 loss=4.259, nll_loss=2.645, ppl=6.26, wps=50444.1, ups=0.88, wpb=57152, bsz=1474.2, num_updates=46900, lr=0.000292041, gnorm=0.246, clip=100, loss_scale=34, train_wall=108, wall=51661
2023-05-26 08:42:57 | INFO | train_inner | epoch 008:    277 / 6686 loss=4.262, nll_loss=2.65, ppl=6.28, wps=51925.6, ups=0.91, wpb=57257.3, bsz=1459.7, num_updates=47000, lr=0.00029173, gnorm=0.247, clip=100, loss_scale=32, train_wall=106, wall=51771
2023-05-26 08:44:46 | INFO | train_inner | epoch 008:    377 / 6686 loss=4.258, nll_loss=2.645, ppl=6.25, wps=52418.8, ups=0.92, wpb=57196.8, bsz=1485.7, num_updates=47100, lr=0.00029142, gnorm=0.246, clip=100, loss_scale=32, train_wall=105, wall=51880
2023-05-26 08:46:35 | INFO | train_inner | epoch 008:    477 / 6686 loss=4.261, nll_loss=2.648, ppl=6.27, wps=52729.9, ups=0.92, wpb=57325.1, bsz=1483, num_updates=47200, lr=0.000291111, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=51989
2023-05-26 08:48:23 | INFO | train_inner | epoch 008:    577 / 6686 loss=4.27, nll_loss=2.659, ppl=6.31, wps=52734.5, ups=0.92, wpb=57154.6, bsz=1474.6, num_updates=47300, lr=0.000290803, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=52097
2023-05-26 08:49:47 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 08:50:13 | INFO | train_inner | epoch 008:    678 / 6686 loss=4.259, nll_loss=2.646, ppl=6.26, wps=52140.4, ups=0.91, wpb=57107.2, bsz=1502.1, num_updates=47400, lr=0.000290496, gnorm=0.249, clip=100, loss_scale=33, train_wall=106, wall=52207
2023-05-26 08:50:31 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 08:52:03 | INFO | train_inner | epoch 008:    779 / 6686 loss=4.276, nll_loss=2.665, ppl=6.34, wps=52102, ups=0.91, wpb=57162.2, bsz=1462.2, num_updates=47500, lr=0.000290191, gnorm=0.247, clip=100, loss_scale=19, train_wall=106, wall=52317
2023-05-26 08:53:51 | INFO | train_inner | epoch 008:    879 / 6686 loss=4.276, nll_loss=2.665, ppl=6.34, wps=52681, ups=0.92, wpb=57256.6, bsz=1455.8, num_updates=47600, lr=0.000289886, gnorm=0.247, clip=100, loss_scale=16, train_wall=105, wall=52425
2023-05-26 08:55:40 | INFO | train_inner | epoch 008:    979 / 6686 loss=4.271, nll_loss=2.659, ppl=6.32, wps=52773, ups=0.92, wpb=57276.9, bsz=1463.4, num_updates=47700, lr=0.000289581, gnorm=0.247, clip=100, loss_scale=16, train_wall=105, wall=52534
2023-05-26 08:57:28 | INFO | train_inner | epoch 008:   1079 / 6686 loss=4.271, nll_loss=2.659, ppl=6.32, wps=52595.5, ups=0.92, wpb=57053.3, bsz=1466.2, num_updates=47800, lr=0.000289278, gnorm=0.252, clip=100, loss_scale=16, train_wall=105, wall=52642
2023-05-26 08:59:17 | INFO | train_inner | epoch 008:   1179 / 6686 loss=4.266, nll_loss=2.655, ppl=6.3, wps=52515.5, ups=0.92, wpb=57027.7, bsz=1497.7, num_updates=47900, lr=0.000288976, gnorm=0.246, clip=100, loss_scale=16, train_wall=105, wall=52751
2023-05-26 09:01:06 | INFO | train_inner | epoch 008:   1279 / 6686 loss=4.278, nll_loss=2.668, ppl=6.36, wps=52535.9, ups=0.92, wpb=57143, bsz=1468.2, num_updates=48000, lr=0.000288675, gnorm=0.25, clip=100, loss_scale=28, train_wall=105, wall=52860
2023-05-26 09:02:55 | INFO | train_inner | epoch 008:   1379 / 6686 loss=4.259, nll_loss=2.646, ppl=6.26, wps=52616.8, ups=0.92, wpb=57299, bsz=1490.2, num_updates=48100, lr=0.000288375, gnorm=0.25, clip=100, loss_scale=32, train_wall=105, wall=52969
2023-05-26 09:04:43 | INFO | train_inner | epoch 008:   1479 / 6686 loss=4.273, nll_loss=2.662, ppl=6.33, wps=52767.1, ups=0.92, wpb=57120.2, bsz=1479.9, num_updates=48200, lr=0.000288076, gnorm=0.248, clip=100, loss_scale=32, train_wall=104, wall=53077
2023-05-26 09:06:32 | INFO | train_inner | epoch 008:   1579 / 6686 loss=4.271, nll_loss=2.659, ppl=6.32, wps=52725.4, ups=0.92, wpb=57345.2, bsz=1441.9, num_updates=48300, lr=0.000287777, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=53186
2023-05-26 09:08:20 | INFO | train_inner | epoch 008:   1679 / 6686 loss=4.273, nll_loss=2.663, ppl=6.33, wps=52908.1, ups=0.92, wpb=57351, bsz=1509.4, num_updates=48400, lr=0.00028748, gnorm=0.245, clip=100, loss_scale=32, train_wall=105, wall=53294
2023-05-26 09:09:07 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 09:10:09 | INFO | train_inner | epoch 008:   1780 / 6686 loss=4.257, nll_loss=2.645, ppl=6.25, wps=52258.3, ups=0.91, wpb=57190.6, bsz=1487.3, num_updates=48500, lr=0.000287183, gnorm=0.244, clip=100, loss_scale=33, train_wall=106, wall=53404
2023-05-26 09:11:58 | INFO | train_inner | epoch 008:   1880 / 6686 loss=4.271, nll_loss=2.66, ppl=6.32, wps=52600.7, ups=0.92, wpb=57137.1, bsz=1470.5, num_updates=48600, lr=0.000286888, gnorm=0.251, clip=100, loss_scale=32, train_wall=105, wall=53512
2023-05-26 09:13:46 | INFO | train_inner | epoch 008:   1980 / 6686 loss=4.273, nll_loss=2.663, ppl=6.33, wps=52888, ups=0.92, wpb=57247.3, bsz=1479.8, num_updates=48700, lr=0.000286593, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=53620
2023-05-26 09:15:35 | INFO | train_inner | epoch 008:   2080 / 6686 loss=4.28, nll_loss=2.67, ppl=6.37, wps=52727.2, ups=0.92, wpb=57115.3, bsz=1481.2, num_updates=48800, lr=0.000286299, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=53729
2023-05-26 09:17:23 | INFO | train_inner | epoch 008:   2180 / 6686 loss=4.283, nll_loss=2.673, ppl=6.38, wps=52413.7, ups=0.92, wpb=57046.1, bsz=1466.2, num_updates=48900, lr=0.000286006, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=53838
2023-05-26 09:18:11 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 09:19:13 | INFO | train_inner | epoch 008:   2281 / 6686 loss=4.277, nll_loss=2.666, ppl=6.35, wps=52192, ups=0.91, wpb=57061.5, bsz=1472.3, num_updates=49000, lr=0.000285714, gnorm=0.252, clip=100, loss_scale=23, train_wall=106, wall=53947
2023-05-26 09:21:01 | INFO | train_inner | epoch 008:   2381 / 6686 loss=4.269, nll_loss=2.658, ppl=6.31, wps=52770.5, ups=0.92, wpb=57129, bsz=1493, num_updates=49100, lr=0.000285423, gnorm=0.253, clip=100, loss_scale=16, train_wall=105, wall=54055
2023-05-26 09:22:49 | INFO | train_inner | epoch 008:   2481 / 6686 loss=4.276, nll_loss=2.666, ppl=6.35, wps=52675.8, ups=0.92, wpb=56995.8, bsz=1486.3, num_updates=49200, lr=0.000285133, gnorm=0.245, clip=100, loss_scale=16, train_wall=105, wall=54163
2023-05-26 09:24:38 | INFO | train_inner | epoch 008:   2581 / 6686 loss=4.271, nll_loss=2.66, ppl=6.32, wps=52838.7, ups=0.92, wpb=57300, bsz=1464.2, num_updates=49300, lr=0.000284844, gnorm=0.246, clip=100, loss_scale=16, train_wall=105, wall=54272
2023-05-26 09:26:26 | INFO | train_inner | epoch 008:   2681 / 6686 loss=4.273, nll_loss=2.662, ppl=6.33, wps=52617.6, ups=0.92, wpb=57164.3, bsz=1484.9, num_updates=49400, lr=0.000284555, gnorm=0.249, clip=100, loss_scale=16, train_wall=105, wall=54380
2023-05-26 09:28:15 | INFO | train_inner | epoch 008:   2781 / 6686 loss=4.278, nll_loss=2.668, ppl=6.35, wps=52742.1, ups=0.92, wpb=57206.9, bsz=1479.2, num_updates=49500, lr=0.000284268, gnorm=0.249, clip=100, loss_scale=23, train_wall=105, wall=54489
2023-05-26 09:30:04 | INFO | train_inner | epoch 008:   2881 / 6686 loss=4.27, nll_loss=2.659, ppl=6.32, wps=52585.1, ups=0.92, wpb=57192, bsz=1475.5, num_updates=49600, lr=0.000283981, gnorm=0.246, clip=100, loss_scale=32, train_wall=105, wall=54598
2023-05-26 09:31:52 | INFO | train_inner | epoch 008:   2981 / 6686 loss=4.265, nll_loss=2.654, ppl=6.29, wps=52807.9, ups=0.92, wpb=57403.6, bsz=1474.8, num_updates=49700, lr=0.000283695, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=54706
2023-05-26 09:33:41 | INFO | train_inner | epoch 008:   3081 / 6686 loss=4.261, nll_loss=2.648, ppl=6.27, wps=52585.8, ups=0.92, wpb=57230.9, bsz=1478.2, num_updates=49800, lr=0.00028341, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=54815
2023-05-26 09:35:23 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 09:35:30 | INFO | train_inner | epoch 008:   3182 / 6686 loss=4.272, nll_loss=2.661, ppl=6.33, wps=52324.9, ups=0.92, wpb=57116.5, bsz=1470.2, num_updates=49900, lr=0.000283126, gnorm=0.245, clip=100, loss_scale=31, train_wall=105, wall=54924
2023-05-26 09:37:19 | INFO | train_inner | epoch 008:   3282 / 6686 loss=4.265, nll_loss=2.653, ppl=6.29, wps=52578, ups=0.92, wpb=57281.2, bsz=1466, num_updates=50000, lr=0.000282843, gnorm=0.249, clip=100, loss_scale=16, train_wall=105, wall=55033
2023-05-26 09:39:07 | INFO | train_inner | epoch 008:   3382 / 6686 loss=4.28, nll_loss=2.671, ppl=6.37, wps=52764.2, ups=0.92, wpb=57090.7, bsz=1463.7, num_updates=50100, lr=0.00028256, gnorm=0.248, clip=100, loss_scale=16, train_wall=105, wall=55142
2023-05-26 09:40:56 | INFO | train_inner | epoch 008:   3482 / 6686 loss=4.274, nll_loss=2.663, ppl=6.33, wps=52711.2, ups=0.92, wpb=57378.1, bsz=1493.2, num_updates=50200, lr=0.000282279, gnorm=0.249, clip=100, loss_scale=16, train_wall=105, wall=55250
2023-05-26 09:42:45 | INFO | train_inner | epoch 008:   3582 / 6686 loss=4.272, nll_loss=2.661, ppl=6.33, wps=52785.5, ups=0.92, wpb=57240.8, bsz=1496.6, num_updates=50300, lr=0.000281998, gnorm=0.244, clip=100, loss_scale=16, train_wall=105, wall=55359
2023-05-26 09:44:33 | INFO | train_inner | epoch 008:   3682 / 6686 loss=4.264, nll_loss=2.652, ppl=6.28, wps=52903.6, ups=0.92, wpb=57444, bsz=1476.6, num_updates=50400, lr=0.000281718, gnorm=0.244, clip=100, loss_scale=16, train_wall=105, wall=55467
2023-05-26 09:46:22 | INFO | train_inner | epoch 008:   3782 / 6686 loss=4.279, nll_loss=2.669, ppl=6.36, wps=52773.7, ups=0.92, wpb=57350.1, bsz=1482.6, num_updates=50500, lr=0.000281439, gnorm=0.249, clip=100, loss_scale=31, train_wall=105, wall=55576
2023-05-26 09:48:10 | INFO | train_inner | epoch 008:   3882 / 6686 loss=4.267, nll_loss=2.655, ppl=6.3, wps=52763.1, ups=0.92, wpb=57103.6, bsz=1484, num_updates=50600, lr=0.000281161, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=55684
2023-05-26 09:49:59 | INFO | train_inner | epoch 008:   3982 / 6686 loss=4.26, nll_loss=2.648, ppl=6.27, wps=52926, ups=0.92, wpb=57386.7, bsz=1504.2, num_updates=50700, lr=0.000280883, gnorm=0.246, clip=100, loss_scale=32, train_wall=105, wall=55793
2023-05-26 09:51:47 | INFO | train_inner | epoch 008:   4082 / 6686 loss=4.271, nll_loss=2.661, ppl=6.32, wps=52759.3, ups=0.92, wpb=57124.3, bsz=1474.5, num_updates=50800, lr=0.000280607, gnorm=0.246, clip=100, loss_scale=32, train_wall=105, wall=55901
2023-05-26 09:52:05 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 09:53:36 | INFO | train_inner | epoch 008:   4183 / 6686 loss=4.273, nll_loss=2.662, ppl=6.33, wps=52343.3, ups=0.92, wpb=57049.2, bsz=1480.3, num_updates=50900, lr=0.000280331, gnorm=0.249, clip=100, loss_scale=19, train_wall=105, wall=56010
2023-05-26 09:55:24 | INFO | train_inner | epoch 008:   4283 / 6686 loss=4.263, nll_loss=2.652, ppl=6.28, wps=52602.5, ups=0.92, wpb=56974.6, bsz=1470.3, num_updates=51000, lr=0.000280056, gnorm=0.249, clip=100, loss_scale=16, train_wall=105, wall=56118
2023-05-26 09:57:13 | INFO | train_inner | epoch 008:   4383 / 6686 loss=4.267, nll_loss=2.656, ppl=6.3, wps=52614.7, ups=0.92, wpb=57328.7, bsz=1485.2, num_updates=51100, lr=0.000279782, gnorm=0.245, clip=100, loss_scale=16, train_wall=105, wall=56227
2023-05-26 09:59:02 | INFO | train_inner | epoch 008:   4483 / 6686 loss=4.28, nll_loss=2.67, ppl=6.37, wps=52784.9, ups=0.92, wpb=57191.3, bsz=1474.4, num_updates=51200, lr=0.000279508, gnorm=0.247, clip=100, loss_scale=16, train_wall=105, wall=56336
2023-05-26 10:00:50 | INFO | train_inner | epoch 008:   4583 / 6686 loss=4.276, nll_loss=2.666, ppl=6.35, wps=52818.1, ups=0.92, wpb=57415.1, bsz=1475.6, num_updates=51300, lr=0.000279236, gnorm=0.243, clip=100, loss_scale=16, train_wall=105, wall=56444
2023-05-26 10:02:38 | INFO | train_inner | epoch 008:   4683 / 6686 loss=4.262, nll_loss=2.651, ppl=6.28, wps=52793.1, ups=0.92, wpb=57117.8, bsz=1501.3, num_updates=51400, lr=0.000278964, gnorm=0.247, clip=100, loss_scale=28, train_wall=104, wall=56553
2023-05-26 10:03:29 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 10:04:28 | INFO | train_inner | epoch 008:   4784 / 6686 loss=4.276, nll_loss=2.666, ppl=6.35, wps=52310.3, ups=0.91, wpb=57201.3, bsz=1485.7, num_updates=51500, lr=0.000278693, gnorm=0.248, clip=100, loss_scale=23, train_wall=106, wall=56662
2023-05-26 10:06:16 | INFO | train_inner | epoch 008:   4884 / 6686 loss=4.273, nll_loss=2.663, ppl=6.33, wps=52536.8, ups=0.92, wpb=57036.3, bsz=1456.6, num_updates=51600, lr=0.000278423, gnorm=0.247, clip=100, loss_scale=16, train_wall=105, wall=56771
2023-05-26 10:08:05 | INFO | train_inner | epoch 008:   4984 / 6686 loss=4.274, nll_loss=2.665, ppl=6.34, wps=52870.4, ups=0.92, wpb=57302.8, bsz=1490.5, num_updates=51700, lr=0.000278154, gnorm=0.246, clip=100, loss_scale=16, train_wall=105, wall=56879
2023-05-26 10:09:53 | INFO | train_inner | epoch 008:   5084 / 6686 loss=4.266, nll_loss=2.655, ppl=6.3, wps=52793.8, ups=0.92, wpb=57199.1, bsz=1475.3, num_updates=51800, lr=0.000277885, gnorm=0.246, clip=100, loss_scale=16, train_wall=105, wall=56987
2023-05-26 10:11:42 | INFO | train_inner | epoch 008:   5184 / 6686 loss=4.268, nll_loss=2.657, ppl=6.31, wps=52656.2, ups=0.92, wpb=57185, bsz=1474.2, num_updates=51900, lr=0.000277617, gnorm=0.246, clip=100, loss_scale=16, train_wall=105, wall=57096
2023-05-26 10:13:30 | INFO | train_inner | epoch 008:   5284 / 6686 loss=4.27, nll_loss=2.66, ppl=6.32, wps=52742.8, ups=0.92, wpb=57304.8, bsz=1467.7, num_updates=52000, lr=0.00027735, gnorm=0.246, clip=100, loss_scale=23, train_wall=105, wall=57205
2023-05-26 10:14:02 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 10:15:20 | INFO | train_inner | epoch 008:   5385 / 6686 loss=4.268, nll_loss=2.658, ppl=6.31, wps=52185.4, ups=0.91, wpb=57317.5, bsz=1474.2, num_updates=52100, lr=0.000277084, gnorm=0.247, clip=100, loss_scale=20, train_wall=106, wall=57314
2023-05-26 10:17:09 | INFO | train_inner | epoch 008:   5485 / 6686 loss=4.27, nll_loss=2.659, ppl=6.32, wps=52813.8, ups=0.92, wpb=57260, bsz=1488.1, num_updates=52200, lr=0.000276818, gnorm=0.244, clip=100, loss_scale=16, train_wall=105, wall=57423
2023-05-26 10:18:57 | INFO | train_inner | epoch 008:   5585 / 6686 loss=4.281, nll_loss=2.672, ppl=6.37, wps=52982.8, ups=0.93, wpb=57231.6, bsz=1469, num_updates=52300, lr=0.000276553, gnorm=0.246, clip=100, loss_scale=16, train_wall=104, wall=57531
2023-05-26 10:20:45 | INFO | train_inner | epoch 008:   5685 / 6686 loss=4.254, nll_loss=2.642, ppl=6.24, wps=52748.9, ups=0.92, wpb=57205.4, bsz=1477.4, num_updates=52400, lr=0.000276289, gnorm=0.249, clip=100, loss_scale=16, train_wall=105, wall=57639
2023-05-26 10:22:34 | INFO | train_inner | epoch 008:   5785 / 6686 loss=4.268, nll_loss=2.658, ppl=6.31, wps=52696.6, ups=0.92, wpb=57225, bsz=1469.6, num_updates=52500, lr=0.000276026, gnorm=0.25, clip=100, loss_scale=16, train_wall=105, wall=57748
2023-05-26 10:23:28 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 10:24:23 | INFO | train_inner | epoch 008:   5886 / 6686 loss=4.266, nll_loss=2.655, ppl=6.3, wps=52090.8, ups=0.91, wpb=57161.2, bsz=1495, num_updates=52600, lr=0.000275764, gnorm=0.25, clip=100, loss_scale=18, train_wall=106, wall=57858
2023-05-26 10:26:12 | INFO | train_inner | epoch 008:   5986 / 6686 loss=4.272, nll_loss=2.662, ppl=6.33, wps=52983.9, ups=0.92, wpb=57346.9, bsz=1478, num_updates=52700, lr=0.000275502, gnorm=0.245, clip=100, loss_scale=16, train_wall=105, wall=57966
2023-05-26 10:28:00 | INFO | train_inner | epoch 008:   6086 / 6686 loss=4.264, nll_loss=2.653, ppl=6.29, wps=52683.9, ups=0.92, wpb=57187.5, bsz=1493.5, num_updates=52800, lr=0.000275241, gnorm=0.247, clip=100, loss_scale=16, train_wall=105, wall=58074
2023-05-26 10:29:48 | INFO | train_inner | epoch 008:   6186 / 6686 loss=4.279, nll_loss=2.67, ppl=6.36, wps=52884.6, ups=0.93, wpb=57099.7, bsz=1455.6, num_updates=52900, lr=0.000274981, gnorm=0.25, clip=100, loss_scale=16, train_wall=104, wall=58182
2023-05-26 10:31:37 | INFO | train_inner | epoch 008:   6286 / 6686 loss=4.268, nll_loss=2.657, ppl=6.31, wps=52806.9, ups=0.92, wpb=57209.4, bsz=1495.7, num_updates=53000, lr=0.000274721, gnorm=0.25, clip=100, loss_scale=16, train_wall=105, wall=58291
2023-05-26 10:32:52 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 10:33:26 | INFO | train_inner | epoch 008:   6387 / 6686 loss=4.262, nll_loss=2.651, ppl=6.28, wps=52323.6, ups=0.91, wpb=57200.5, bsz=1480.3, num_updates=53100, lr=0.000274462, gnorm=0.246, clip=100, loss_scale=17, train_wall=106, wall=58400
2023-05-26 10:35:14 | INFO | train_inner | epoch 008:   6487 / 6686 loss=4.277, nll_loss=2.668, ppl=6.35, wps=52612.4, ups=0.92, wpb=56967.1, bsz=1458.6, num_updates=53200, lr=0.000274204, gnorm=0.255, clip=100, loss_scale=16, train_wall=105, wall=58508
2023-05-26 10:37:03 | INFO | train_inner | epoch 008:   6587 / 6686 loss=4.279, nll_loss=2.67, ppl=6.37, wps=52644.6, ups=0.92, wpb=57145.1, bsz=1476.9, num_updates=53300, lr=0.000273947, gnorm=0.244, clip=100, loss_scale=16, train_wall=105, wall=58617
2023-05-26 10:38:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-26 10:38:54 | INFO | fairseq.tasks.translation | example hypothesis: Why?
2023-05-26 10:38:54 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-26 10:38:54 | INFO | fairseq.tasks.translation | example hypothesis: I’ll make you lose so badly that you don’t even have your pants left!
2023-05-26 10:38:54 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-26 10:38:55 | INFO | fairseq.tasks.translation | example hypothesis: Just as Shen Liangchuan heaved a sigh of relief, he heard her say, “I’ll call you to stay in the same room!”
2023-05-26 10:38:55 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-26 10:38:55 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved her hand and entered the elevator.
2023-05-26 10:38:55 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-26 10:38:56 | INFO | fairseq.tasks.translation | example hypothesis: She raised her head and saw Song Cheng standing in the distance!
2023-05-26 10:38:56 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-26 10:38:57 | INFO | fairseq.tasks.translation | example hypothesis: Then, Song Cheng patted his chest. “I’m so scared! Where’s Wang Chuan?”
2023-05-26 10:38:57 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-26 10:38:58 | INFO | fairseq.tasks.translation | example hypothesis: “No, I can’t eat it,” I said.
2023-05-26 10:38:58 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-26 10:38:58 | INFO | fairseq.tasks.translation | example hypothesis: Dreadful first, but Wang Wenhao insisted on him and made the public opinion lean towards Wang Wenhao.
2023-05-26 10:38:58 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-26 10:38:59 | INFO | fairseq.tasks.translation | example hypothesis: With his identity coming like this, Baili Hongzhuang had to be treated even if she did not treat him!
2023-05-26 10:38:59 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-26 10:39:00 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian said, “Mr. Shen, I, I’ve left too much blood and my brain is short of oxygen. I can’t think of anything. Why don’t you give me a hint?”
2023-05-26 10:39:00 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-26 10:39:01 | INFO | fairseq.tasks.translation | example hypothesis: He didn’t know why so many people had heard about it. Since he couldn’t hide it, he might as well tell them.
2023-05-26 10:39:01 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-26 10:39:02 | INFO | fairseq.tasks.translation | example hypothesis: Her deliberately suppressed voice was unable to hide the viciousness and viciousness in her tone.
2023-05-26 10:39:02 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-26 10:39:03 | INFO | fairseq.tasks.translation | example hypothesis: Different levels of beast pets had different strengths, but beast pets were precious and rare. It was impossible for ordinary people to have one, even for the descendants of officials.
2023-05-26 10:39:03 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-26 10:39:04 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chixia gritted her teeth and cursed.
2023-05-26 10:39:04 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-26 10:39:05 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang had concealed it very well, Di Bei Chen could still see the flash of warmth in her eyes.
2023-05-26 10:39:05 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-26 10:39:06 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia walked in, not to mention the guests, even the waiters were nowhere to be seen.
2023-05-26 10:39:06 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-26 10:39:07 | INFO | fairseq.tasks.translation | example hypothesis: This person was none other than the Ye Family’s Fourth Young Lady, Ye Qing Ling.
2023-05-26 10:39:07 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-26 10:39:08 | INFO | fairseq.tasks.translation | example hypothesis: At this moment, she felt as though her chin was about to shatter.
2023-05-26 10:39:08 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-26 10:39:09 | INFO | fairseq.tasks.translation | example hypothesis: “Good Mu Zi, help me. If it wasn't for you, that old man wouldn't have set his eyes on me.”
2023-05-26 10:39:09 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-26 10:39:10 | INFO | fairseq.tasks.translation | example hypothesis: Baili Yuyan was even more excited. This matter was completely under her control. Earlier, Baili Hongzhuang had treated her like this. This time around, she would definitely make it difficult for Baili Hongzhuang.
2023-05-26 10:39:10 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-26 10:39:12 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How could that be? They also have four mages on their side, so of course they won’t surrender so easily. After arguing for a long time, they decided to use the competition to decide how to obtain control over the kingdom in the future.”
2023-05-26 10:39:12 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-26 10:39:13 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a little. Originally, he had been looking for a reason why Li Yuyue couldn’t participate in the royal hunting competition.
2023-05-26 10:39:13 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-26 10:39:14 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my level enough? They’re all the most outstanding people in the country. Is my magic that weak?”
2023-05-26 10:39:14 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-26 10:39:16 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yibei’s words meant that if Fang Chixia didn’t want to go, she didn’t need to go.
2023-05-26 10:39:16 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-26 10:39:18 | INFO | fairseq.tasks.translation | example hypothesis: She tilted her head and saw that the five palm marks on her face were very eye-catching. They swelled up at a speed visible to the naked eye. Reaching out to touch them, she could not help but let out a hissing sound.
2023-05-26 10:39:18 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-26 10:39:19 | INFO | fairseq.tasks.translation | example hypothesis: This... how could this be the charm that the trash could emit?
2023-05-26 10:39:19 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-26 10:39:20 | INFO | fairseq.tasks.translation | example hypothesis: How could Wang Wenhao have found the newspaper agency? The chief editor should have called her and told her not to come to the newspaper agency, but these three people... had plotted against her!
2023-05-26 10:39:20 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-26 10:39:23 | INFO | fairseq.tasks.translation | example hypothesis: Hearing Teacher Di’s praise, I was delighted. I put away the energy ball with my left hand, and shot a beam saber at Teacher Zhen with my right hand. The beam saber landed smoothly. I was shocked, and upon closer inspection, I realized that it was just an afterimage. Teacher Zhen had already moved to my back and shouted, “Berserk Space!”
2023-05-26 10:39:23 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-26 10:39:26 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Initially, we proposed a competition of two out of three, but they said it wasn’t fair because we have Teacher Di and Teacher Zhen. Their rankings are higher than them, and they proposed three out of five. Since we proposed the competition, the competition method can only be decided by them. Three days later, we will have a secret competition in the Royal Stadium. If we don’t win, then we will have to wait for a while
2023-05-26 10:39:26 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-26 10:39:28 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Di used a level-7 spell, Light Bolts. I didn’t use much of this spell because I didn’t have a good control over it. Teacher Di released nine bolts of light to surround me, forming a simple spell formation that prevented me from escaping in a short distance. Then, each bolt of light exploded to form a powerful attack power.
2023-05-26 10:39:28 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-26 10:39:31 | INFO | fairseq.tasks.translation | example hypothesis: Just as Ma Ke and the two teachers walked to the other side of the courtyard, Teacher Zhen cast a Dimensional Slash at me. As expected of the continent’s number one mage. The suction force from the Dimensional Slash was much stronger than what I released. A small spatial crack appeared beside me, and a powerful suction force swept towards me.
2023-05-26 10:39:31 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-26 10:39:31 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 4.209 | nll_loss 2.566 | ppl 5.92 | bleu 21.38 | wps 1955.1 | wpb 2420.8 | bsz 84.5 | num_updates 53399 | best_bleu 21.44
2023-05-26 10:39:31 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-26 10:39:34 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/concat-1-1-0.2-sf[zh-en]/checkpoint8.pt (epoch 8 @ 53399 updates, score 21.38) (writing took 2.930483258329332 seconds)
2023-05-26 10:39:34 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-05-26 10:39:34 | INFO | train | epoch 008 | loss 4.27 | nll_loss 2.659 | ppl 6.32 | wps 52201.5 | ups 0.91 | wpb 57189.8 | bsz 1477.5 | num_updates 53399 | lr 0.000273693 | gnorm 0.247 | clip 100 | loss_scale 23 | train_wall 7013 | wall 58768
2023-05-26 10:39:34 | INFO | fairseq.trainer | begin training epoch 9
2023-05-26 10:39:40 | INFO | train_inner | epoch 009:      1 / 6686 loss=4.259, nll_loss=2.647, ppl=6.26, wps=36044.8, ups=0.64, wpb=56601.6, bsz=1465.2, num_updates=53400, lr=0.00027369, gnorm=0.248, clip=100, loss_scale=16, train_wall=104, wall=58774
2023-05-26 10:41:35 | INFO | train_inner | epoch 009:    101 / 6686 loss=4.245, nll_loss=2.631, ppl=6.19, wps=49751.6, ups=0.87, wpb=57091.6, bsz=1467.3, num_updates=53500, lr=0.000273434, gnorm=0.248, clip=100, loss_scale=16, train_wall=109, wall=58889
2023-05-26 10:43:26 | INFO | train_inner | epoch 009:    201 / 6686 loss=4.25, nll_loss=2.636, ppl=6.22, wps=51302.7, ups=0.9, wpb=57126.2, bsz=1459.2, num_updates=53600, lr=0.000273179, gnorm=0.248, clip=100, loss_scale=19, train_wall=106, wall=59000
2023-05-26 10:45:16 | INFO | train_inner | epoch 009:    301 / 6686 loss=4.248, nll_loss=2.634, ppl=6.21, wps=51884, ups=0.91, wpb=57157.3, bsz=1486.3, num_updates=53700, lr=0.000272925, gnorm=0.244, clip=100, loss_scale=32, train_wall=106, wall=59110
2023-05-26 10:47:05 | INFO | train_inner | epoch 009:    401 / 6686 loss=4.25, nll_loss=2.637, ppl=6.22, wps=52396.1, ups=0.92, wpb=57235.4, bsz=1488.1, num_updates=53800, lr=0.000272671, gnorm=0.244, clip=100, loss_scale=32, train_wall=105, wall=59219
2023-05-26 10:48:54 | INFO | train_inner | epoch 009:    501 / 6686 loss=4.242, nll_loss=2.627, ppl=6.18, wps=52397.5, ups=0.92, wpb=56918.7, bsz=1467.3, num_updates=53900, lr=0.000272418, gnorm=0.245, clip=100, loss_scale=32, train_wall=105, wall=59328
2023-05-26 10:50:20 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 10:50:44 | INFO | train_inner | epoch 009:    602 / 6686 loss=4.252, nll_loss=2.638, ppl=6.23, wps=52099.7, ups=0.91, wpb=57195.9, bsz=1456.3, num_updates=54000, lr=0.000272166, gnorm=0.247, clip=100, loss_scale=28, train_wall=106, wall=59438
2023-05-26 10:52:32 | INFO | train_inner | epoch 009:    702 / 6686 loss=4.25, nll_loss=2.636, ppl=6.22, wps=52689.8, ups=0.92, wpb=57269.5, bsz=1495, num_updates=54100, lr=0.000271914, gnorm=0.246, clip=100, loss_scale=16, train_wall=105, wall=59547
2023-05-26 10:54:21 | INFO | train_inner | epoch 009:    802 / 6686 loss=4.238, nll_loss=2.623, ppl=6.16, wps=52403.1, ups=0.92, wpb=57092.4, bsz=1501, num_updates=54200, lr=0.000271663, gnorm=0.246, clip=100, loss_scale=16, train_wall=105, wall=59656
2023-05-26 10:56:10 | INFO | train_inner | epoch 009:    902 / 6686 loss=4.244, nll_loss=2.63, ppl=6.19, wps=52820, ups=0.92, wpb=57337.7, bsz=1482.9, num_updates=54300, lr=0.000271413, gnorm=0.249, clip=100, loss_scale=16, train_wall=105, wall=59764
2023-05-26 10:57:59 | INFO | train_inner | epoch 009:   1002 / 6686 loss=4.25, nll_loss=2.636, ppl=6.22, wps=52409.6, ups=0.92, wpb=57179, bsz=1459.1, num_updates=54400, lr=0.000271163, gnorm=0.245, clip=100, loss_scale=16, train_wall=105, wall=59873
2023-05-26 10:59:48 | INFO | train_inner | epoch 009:   1102 / 6686 loss=4.259, nll_loss=2.647, ppl=6.26, wps=52387.7, ups=0.92, wpb=56936.4, bsz=1452.4, num_updates=54500, lr=0.000270914, gnorm=0.249, clip=100, loss_scale=18, train_wall=105, wall=59982
2023-05-26 11:01:36 | INFO | train_inner | epoch 009:   1202 / 6686 loss=4.247, nll_loss=2.633, ppl=6.2, wps=52722.6, ups=0.92, wpb=57149.8, bsz=1459.8, num_updates=54600, lr=0.000270666, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=60090
2023-05-26 11:03:25 | INFO | train_inner | epoch 009:   1302 / 6686 loss=4.247, nll_loss=2.634, ppl=6.21, wps=52748, ups=0.92, wpb=57384.5, bsz=1480.7, num_updates=54700, lr=0.000270418, gnorm=0.246, clip=100, loss_scale=32, train_wall=105, wall=60199
2023-05-26 11:05:13 | INFO | train_inner | epoch 009:   1402 / 6686 loss=4.247, nll_loss=2.634, ppl=6.21, wps=52804, ups=0.92, wpb=57203.6, bsz=1484.4, num_updates=54800, lr=0.000270172, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=60307
2023-05-26 11:07:02 | INFO | train_inner | epoch 009:   1502 / 6686 loss=4.262, nll_loss=2.65, ppl=6.28, wps=52673.3, ups=0.92, wpb=57321.7, bsz=1489.8, num_updates=54900, lr=0.000269925, gnorm=0.25, clip=100, loss_scale=32, train_wall=105, wall=60416
2023-05-26 11:08:51 | INFO | train_inner | epoch 009:   1602 / 6686 loss=4.244, nll_loss=2.63, ppl=6.19, wps=52722, ups=0.92, wpb=57311.1, bsz=1502.1, num_updates=55000, lr=0.00026968, gnorm=0.243, clip=100, loss_scale=32, train_wall=105, wall=60525
2023-05-26 11:08:55 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 11:10:41 | INFO | train_inner | epoch 009:   1703 / 6686 loss=4.254, nll_loss=2.642, ppl=6.24, wps=52036, ups=0.91, wpb=57320.9, bsz=1466.3, num_updates=55100, lr=0.000269435, gnorm=0.247, clip=100, loss_scale=33, train_wall=106, wall=60635
2023-05-26 11:11:19 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 11:12:30 | INFO | train_inner | epoch 009:   1804 / 6686 loss=4.256, nll_loss=2.644, ppl=6.25, wps=52402.6, ups=0.92, wpb=57192.5, bsz=1454.9, num_updates=55200, lr=0.000269191, gnorm=0.246, clip=100, loss_scale=21, train_wall=105, wall=60744
2023-05-26 11:14:18 | INFO | train_inner | epoch 009:   1904 / 6686 loss=4.257, nll_loss=2.645, ppl=6.26, wps=52907.4, ups=0.93, wpb=57159.8, bsz=1468, num_updates=55300, lr=0.000268947, gnorm=0.246, clip=100, loss_scale=16, train_wall=104, wall=60852
2023-05-26 11:16:07 | INFO | train_inner | epoch 009:   2004 / 6686 loss=4.253, nll_loss=2.64, ppl=6.23, wps=52817.7, ups=0.92, wpb=57248, bsz=1472.6, num_updates=55400, lr=0.000268705, gnorm=0.248, clip=100, loss_scale=16, train_wall=105, wall=60961
2023-05-26 11:17:55 | INFO | train_inner | epoch 009:   2104 / 6686 loss=4.243, nll_loss=2.629, ppl=6.18, wps=52636.7, ups=0.92, wpb=57306.8, bsz=1499.4, num_updates=55500, lr=0.000268462, gnorm=0.25, clip=100, loss_scale=16, train_wall=105, wall=61070
2023-05-26 11:19:44 | INFO | train_inner | epoch 009:   2204 / 6686 loss=4.259, nll_loss=2.647, ppl=6.26, wps=52654.7, ups=0.92, wpb=57231.1, bsz=1463.4, num_updates=55600, lr=0.000268221, gnorm=0.251, clip=100, loss_scale=16, train_wall=105, wall=61178
2023-05-26 11:21:33 | INFO | train_inner | epoch 009:   2304 / 6686 loss=4.259, nll_loss=2.647, ppl=6.27, wps=52769.7, ups=0.92, wpb=57216.1, bsz=1464.8, num_updates=55700, lr=0.00026798, gnorm=0.251, clip=100, loss_scale=25, train_wall=105, wall=61287
2023-05-26 11:23:21 | INFO | train_inner | epoch 009:   2404 / 6686 loss=4.253, nll_loss=2.64, ppl=6.23, wps=52581.7, ups=0.92, wpb=57173.5, bsz=1464.3, num_updates=55800, lr=0.00026774, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=61395
2023-05-26 11:25:10 | INFO | train_inner | epoch 009:   2504 / 6686 loss=4.257, nll_loss=2.645, ppl=6.26, wps=52520.4, ups=0.92, wpb=57123.7, bsz=1480.6, num_updates=55900, lr=0.0002675, gnorm=0.242, clip=100, loss_scale=32, train_wall=105, wall=61504
2023-05-26 11:26:59 | INFO | train_inner | epoch 009:   2604 / 6686 loss=4.242, nll_loss=2.628, ppl=6.18, wps=52632.2, ups=0.92, wpb=57341.8, bsz=1524.3, num_updates=56000, lr=0.000267261, gnorm=0.245, clip=100, loss_scale=32, train_wall=105, wall=61613
2023-05-26 11:28:47 | INFO | train_inner | epoch 009:   2704 / 6686 loss=4.258, nll_loss=2.646, ppl=6.26, wps=52816.4, ups=0.92, wpb=57267.9, bsz=1472, num_updates=56100, lr=0.000267023, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=61722
2023-05-26 11:30:06 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 11:30:38 | INFO | train_inner | epoch 009:   2805 / 6686 loss=4.257, nll_loss=2.645, ppl=6.25, wps=51900.9, ups=0.91, wpb=57228.6, bsz=1488.5, num_updates=56200, lr=0.000266785, gnorm=0.249, clip=100, loss_scale=36, train_wall=106, wall=61832
2023-05-26 11:32:26 | INFO | train_inner | epoch 009:   2905 / 6686 loss=4.26, nll_loss=2.648, ppl=6.27, wps=52633.7, ups=0.92, wpb=57074.7, bsz=1478.9, num_updates=56300, lr=0.000266548, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=61940
2023-05-26 11:34:15 | INFO | train_inner | epoch 009:   3005 / 6686 loss=4.249, nll_loss=2.636, ppl=6.22, wps=52806.6, ups=0.92, wpb=57392.7, bsz=1483.3, num_updates=56400, lr=0.000266312, gnorm=0.244, clip=100, loss_scale=32, train_wall=105, wall=62049
2023-05-26 11:36:03 | INFO | train_inner | epoch 009:   3105 / 6686 loss=4.252, nll_loss=2.64, ppl=6.23, wps=52780, ups=0.92, wpb=57088.2, bsz=1482.4, num_updates=56500, lr=0.000266076, gnorm=0.249, clip=100, loss_scale=32, train_wall=104, wall=62157
2023-05-26 11:37:52 | INFO | train_inner | epoch 009:   3205 / 6686 loss=4.251, nll_loss=2.638, ppl=6.23, wps=52323.8, ups=0.92, wpb=57056.2, bsz=1510.8, num_updates=56600, lr=0.000265841, gnorm=0.246, clip=100, loss_scale=32, train_wall=105, wall=62266
2023-05-26 11:39:29 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 11:39:42 | INFO | train_inner | epoch 009:   3306 / 6686 loss=4.262, nll_loss=2.651, ppl=6.28, wps=52059.3, ups=0.91, wpb=57230.5, bsz=1446.5, num_updates=56700, lr=0.000265606, gnorm=0.248, clip=100, loss_scale=34, train_wall=106, wall=62376
2023-05-26 11:41:30 | INFO | train_inner | epoch 009:   3406 / 6686 loss=4.255, nll_loss=2.643, ppl=6.25, wps=52765.9, ups=0.92, wpb=57185.1, bsz=1474.1, num_updates=56800, lr=0.000265372, gnorm=0.245, clip=100, loss_scale=32, train_wall=105, wall=62484
2023-05-26 11:43:19 | INFO | train_inner | epoch 009:   3506 / 6686 loss=4.244, nll_loss=2.63, ppl=6.19, wps=52678.7, ups=0.92, wpb=57266.1, bsz=1479.1, num_updates=56900, lr=0.000265139, gnorm=0.244, clip=100, loss_scale=32, train_wall=105, wall=62593
2023-05-26 11:45:08 | INFO | train_inner | epoch 009:   3606 / 6686 loss=4.251, nll_loss=2.638, ppl=6.23, wps=52668.9, ups=0.92, wpb=57319, bsz=1466, num_updates=57000, lr=0.000264906, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=62702
2023-05-26 11:46:57 | INFO | train_inner | epoch 009:   3706 / 6686 loss=4.252, nll_loss=2.639, ppl=6.23, wps=52641.7, ups=0.92, wpb=57267.7, bsz=1468.6, num_updates=57100, lr=0.000264674, gnorm=0.246, clip=100, loss_scale=32, train_wall=105, wall=62811
2023-05-26 11:48:45 | INFO | train_inner | epoch 009:   3806 / 6686 loss=4.256, nll_loss=2.644, ppl=6.25, wps=52855.8, ups=0.92, wpb=57305.7, bsz=1489.6, num_updates=57200, lr=0.000264443, gnorm=0.245, clip=100, loss_scale=32, train_wall=105, wall=62919
2023-05-26 11:49:08 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 11:50:35 | INFO | train_inner | epoch 009:   3907 / 6686 loss=4.262, nll_loss=2.651, ppl=6.28, wps=52048.8, ups=0.91, wpb=57029.7, bsz=1466.4, num_updates=57300, lr=0.000264212, gnorm=0.248, clip=100, loss_scale=38, train_wall=106, wall=63029
2023-05-26 11:52:23 | INFO | train_inner | epoch 009:   4007 / 6686 loss=4.24, nll_loss=2.626, ppl=6.17, wps=52731.1, ups=0.92, wpb=57122.8, bsz=1468.7, num_updates=57400, lr=0.000263982, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=63137
2023-05-26 11:54:12 | INFO | train_inner | epoch 009:   4107 / 6686 loss=4.253, nll_loss=2.64, ppl=6.24, wps=52695.3, ups=0.92, wpb=57241, bsz=1495.8, num_updates=57500, lr=0.000263752, gnorm=0.252, clip=100, loss_scale=32, train_wall=105, wall=63246
2023-05-26 11:56:00 | INFO | train_inner | epoch 009:   4207 / 6686 loss=4.247, nll_loss=2.634, ppl=6.21, wps=52696.6, ups=0.92, wpb=57124.6, bsz=1466.6, num_updates=57600, lr=0.000263523, gnorm=0.246, clip=100, loss_scale=32, train_wall=105, wall=63354
2023-05-26 11:57:49 | INFO | train_inner | epoch 009:   4307 / 6686 loss=4.245, nll_loss=2.631, ppl=6.2, wps=52554.8, ups=0.92, wpb=57249.4, bsz=1513, num_updates=57700, lr=0.000263295, gnorm=0.245, clip=100, loss_scale=32, train_wall=105, wall=63463
2023-05-26 11:58:26 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 11:59:39 | INFO | train_inner | epoch 009:   4408 / 6686 loss=4.262, nll_loss=2.651, ppl=6.28, wps=52104.4, ups=0.91, wpb=57129.1, bsz=1464.6, num_updates=57800, lr=0.000263067, gnorm=0.25, clip=100, loss_scale=33, train_wall=106, wall=63573
2023-05-26 12:01:27 | INFO | train_inner | epoch 009:   4508 / 6686 loss=4.25, nll_loss=2.638, ppl=6.22, wps=52602.8, ups=0.92, wpb=57214.6, bsz=1481.8, num_updates=57900, lr=0.00026284, gnorm=0.25, clip=100, loss_scale=32, train_wall=105, wall=63682
2023-05-26 12:01:44 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 12:03:17 | INFO | train_inner | epoch 009:   4609 / 6686 loss=4.263, nll_loss=2.652, ppl=6.28, wps=52158.3, ups=0.91, wpb=57232.4, bsz=1479.7, num_updates=58000, lr=0.000262613, gnorm=0.253, clip=100, loss_scale=18, train_wall=106, wall=63791
2023-05-26 12:05:06 | INFO | train_inner | epoch 009:   4709 / 6686 loss=4.248, nll_loss=2.635, ppl=6.21, wps=52569.2, ups=0.92, wpb=57107.5, bsz=1478.5, num_updates=58100, lr=0.000262387, gnorm=0.245, clip=100, loss_scale=16, train_wall=105, wall=63900
2023-05-26 12:06:55 | INFO | train_inner | epoch 009:   4809 / 6686 loss=4.25, nll_loss=2.637, ppl=6.22, wps=52610, ups=0.92, wpb=57303.4, bsz=1508.1, num_updates=58200, lr=0.000262161, gnorm=0.249, clip=100, loss_scale=16, train_wall=105, wall=64009
2023-05-26 12:08:43 | INFO | train_inner | epoch 009:   4909 / 6686 loss=4.251, nll_loss=2.639, ppl=6.23, wps=52504.2, ups=0.92, wpb=57084.8, bsz=1471.2, num_updates=58300, lr=0.000261936, gnorm=0.244, clip=100, loss_scale=16, train_wall=105, wall=64118
2023-05-26 12:10:32 | INFO | train_inner | epoch 009:   5009 / 6686 loss=4.257, nll_loss=2.645, ppl=6.26, wps=52642.9, ups=0.92, wpb=57346.8, bsz=1480.2, num_updates=58400, lr=0.000261712, gnorm=0.245, clip=100, loss_scale=16, train_wall=105, wall=64226
2023-05-26 12:12:21 | INFO | train_inner | epoch 009:   5109 / 6686 loss=4.249, nll_loss=2.637, ppl=6.22, wps=52764.5, ups=0.92, wpb=57159.1, bsz=1487.1, num_updates=58500, lr=0.000261488, gnorm=0.251, clip=100, loss_scale=28, train_wall=105, wall=64335
2023-05-26 12:14:09 | INFO | train_inner | epoch 009:   5209 / 6686 loss=4.248, nll_loss=2.635, ppl=6.21, wps=52546.7, ups=0.92, wpb=57141.9, bsz=1467.6, num_updates=58600, lr=0.000261265, gnorm=0.246, clip=100, loss_scale=32, train_wall=105, wall=64444
2023-05-26 12:15:58 | INFO | train_inner | epoch 009:   5309 / 6686 loss=4.247, nll_loss=2.635, ppl=6.21, wps=52708.6, ups=0.92, wpb=57181.2, bsz=1497.8, num_updates=58700, lr=0.000261042, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=64552
2023-05-26 12:17:46 | INFO | train_inner | epoch 009:   5409 / 6686 loss=4.251, nll_loss=2.639, ppl=6.23, wps=52550.4, ups=0.92, wpb=56988.5, bsz=1455.9, num_updates=58800, lr=0.00026082, gnorm=0.25, clip=100, loss_scale=32, train_wall=104, wall=64661
2023-05-26 12:19:35 | INFO | train_inner | epoch 009:   5509 / 6686 loss=4.252, nll_loss=2.64, ppl=6.23, wps=52749.5, ups=0.92, wpb=57242, bsz=1468.7, num_updates=58900, lr=0.000260599, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=64769
2023-05-26 12:20:20 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 12:21:24 | INFO | train_inner | epoch 009:   5610 / 6686 loss=4.247, nll_loss=2.634, ppl=6.21, wps=52144.9, ups=0.91, wpb=57150.4, bsz=1494.7, num_updates=59000, lr=0.000260378, gnorm=0.247, clip=100, loss_scale=33, train_wall=106, wall=64879
2023-05-26 12:23:13 | INFO | train_inner | epoch 009:   5710 / 6686 loss=4.257, nll_loss=2.645, ppl=6.26, wps=52809.2, ups=0.92, wpb=57243.4, bsz=1466.7, num_updates=59100, lr=0.000260157, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=64987
2023-05-26 12:25:02 | INFO | train_inner | epoch 009:   5810 / 6686 loss=4.26, nll_loss=2.649, ppl=6.27, wps=52603.5, ups=0.92, wpb=57141.8, bsz=1475.5, num_updates=59200, lr=0.000259938, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=65096
2023-05-26 12:25:28 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 12:26:52 | INFO | train_inner | epoch 009:   5911 / 6686 loss=4.251, nll_loss=2.639, ppl=6.23, wps=52132.1, ups=0.91, wpb=57440.6, bsz=1485.3, num_updates=59300, lr=0.000259718, gnorm=0.244, clip=100, loss_scale=20, train_wall=106, wall=65206
2023-05-26 12:28:41 | INFO | train_inner | epoch 009:   6011 / 6686 loss=4.253, nll_loss=2.641, ppl=6.24, wps=52444.2, ups=0.92, wpb=57070.3, bsz=1470.3, num_updates=59400, lr=0.0002595, gnorm=0.249, clip=100, loss_scale=16, train_wall=105, wall=65315
2023-05-26 12:30:29 | INFO | train_inner | epoch 009:   6111 / 6686 loss=4.261, nll_loss=2.65, ppl=6.28, wps=52700.6, ups=0.92, wpb=57118.2, bsz=1462, num_updates=59500, lr=0.000259281, gnorm=0.248, clip=100, loss_scale=16, train_wall=105, wall=65423
2023-05-26 12:32:17 | INFO | train_inner | epoch 009:   6211 / 6686 loss=4.263, nll_loss=2.653, ppl=6.29, wps=52759.3, ups=0.92, wpb=57137.6, bsz=1458.7, num_updates=59600, lr=0.000259064, gnorm=0.246, clip=100, loss_scale=16, train_wall=105, wall=65531
2023-05-26 12:34:06 | INFO | train_inner | epoch 009:   6311 / 6686 loss=4.244, nll_loss=2.631, ppl=6.19, wps=52746.2, ups=0.92, wpb=57243.1, bsz=1497.7, num_updates=59700, lr=0.000258847, gnorm=0.242, clip=100, loss_scale=16, train_wall=105, wall=65640
2023-05-26 12:35:54 | INFO | train_inner | epoch 009:   6411 / 6686 loss=4.252, nll_loss=2.64, ppl=6.23, wps=52807.9, ups=0.92, wpb=57312.2, bsz=1481, num_updates=59800, lr=0.00025863, gnorm=0.248, clip=100, loss_scale=27, train_wall=105, wall=65748
2023-05-26 12:37:43 | INFO | train_inner | epoch 009:   6511 / 6686 loss=4.267, nll_loss=2.657, ppl=6.31, wps=52549.8, ups=0.92, wpb=56988.6, bsz=1468.6, num_updates=59900, lr=0.000258414, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=65857
2023-05-26 12:39:31 | INFO | train_inner | epoch 009:   6611 / 6686 loss=4.256, nll_loss=2.644, ppl=6.25, wps=52756.3, ups=0.92, wpb=57356.2, bsz=1479.1, num_updates=60000, lr=0.000258199, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=65966
2023-05-26 12:40:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-26 12:40:57 | INFO | fairseq.tasks.translation | example hypothesis: Why was that?
2023-05-26 12:40:57 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-26 12:40:57 | INFO | fairseq.tasks.translation | example hypothesis: I’ll make you lose so badly that you don’t even have pants left!
2023-05-26 12:40:57 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-26 12:40:58 | INFO | fairseq.tasks.translation | example hypothesis: Just as Shen Liangchuan heaved a sigh of relief, he heard her say, “I’ll call you in the same room!”
2023-05-26 12:40:58 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-26 12:40:59 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved her hand and entered the elevator.
2023-05-26 12:40:59 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-26 12:40:59 | INFO | fairseq.tasks.translation | example hypothesis: She looked up and saw Song Cheng standing in the distance!
2023-05-26 12:40:59 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-26 12:41:00 | INFO | fairseq.tasks.translation | example hypothesis: Song Cheng patted his chest. “You scared me to death! Where’s Wang Chuan?”
2023-05-26 12:41:00 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-26 12:41:01 | INFO | fairseq.tasks.translation | example hypothesis: I said, “No, I can’t eat it.”
2023-05-26 12:41:01 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-26 12:41:01 | INFO | fairseq.tasks.translation | example hypothesis: Dreadful at first, but Wang Wenhao insisted on him and made the public opinion biased towards Wang Wenhao.
2023-05-26 12:41:01 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-26 12:41:02 | INFO | fairseq.tasks.translation | example hypothesis: With his identity, coming here like this, Baili Hongzhuang had to be treated even if she did not treat him!
2023-05-26 12:41:02 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-26 12:41:03 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian said, “Mr. Shen, I, I’ve left too much blood and am short of oxygen. I can’t think of anything. Why don’t you give me a hint?”
2023-05-26 12:41:03 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-26 12:41:04 | INFO | fairseq.tasks.translation | example hypothesis: He didn't know why so many people had heard of this matter. Since he couldn't hide it any longer, he might as well tell them.
2023-05-26 12:41:04 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-26 12:41:05 | INFO | fairseq.tasks.translation | example hypothesis: She deliberately lowered her voice, but she could not conceal the hostility and ruthlessness in her tone.
2023-05-26 12:41:05 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-26 12:41:06 | INFO | fairseq.tasks.translation | example hypothesis: Beast pets of different levels were different in strength, but beast pets were precious and rare. It was impossible for ordinary people to have one, and even the descendants of officials could not have one.
2023-05-26 12:41:06 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-26 12:41:07 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chixia gritted his teeth and cursed in a low voice.
2023-05-26 12:41:07 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-26 12:41:08 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang had concealed it well, Di Beichen could still see the ripple in her eyes and a hint of warmth could be seen in them.
2023-05-26 12:41:08 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-26 12:41:09 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia walked in, not to mention the guests, she didn't even see a few waiters.
2023-05-26 12:41:09 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-26 12:41:10 | INFO | fairseq.tasks.translation | example hypothesis: This person was Ye Qing-Ling, the fourth young miss of the Ye family.
2023-05-26 12:41:10 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-26 12:41:11 | INFO | fairseq.tasks.translation | example hypothesis: At this moment, she felt as if her chin was about to shatter.
2023-05-26 12:41:11 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-26 12:41:12 | INFO | fairseq.tasks.translation | example hypothesis: “Good Mu Zi, help me. If it wasn't for you, that old man wouldn't have targeted me.”
2023-05-26 12:41:12 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-26 12:41:14 | INFO | fairseq.tasks.translation | example hypothesis: Bai Li Yu Yan was even more excited. She was the one who was in charge of this matter. Earlier, Bai Li Hong Zhuang had treated her like this. This time around, she would definitely make Bai Li Hong Zhuang suffer.
2023-05-26 12:41:14 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-26 12:41:15 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How could that be? They’re also four mages, so of course they won’t surrender so easily. After arguing for a long time, they decided to use the competition to decide how to obtain control of the Kingdom of Axia.”
2023-05-26 12:41:15 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-26 12:41:16 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a little. He had always been looking for a reason why Li Yuyue couldn’t participate in the royal hunting competition.
2023-05-26 12:41:16 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-26 12:41:17 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my standard good? They’re all the best talents in the country. Is my magic that weak?”
2023-05-26 12:41:17 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-26 12:41:19 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yi Bei’s words meant that if Fang Chi Xia didn’t want to go, then there was no need to go.
2023-05-26 12:41:19 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-26 12:41:21 | INFO | fairseq.tasks.translation | example hypothesis: She tilted her head to the side and saw that the five palm prints on her cheeks were very eye-catching. They were swelling at a speed visible to the naked eye. She reached out to touch them and could not help but let out a hiss.
2023-05-26 12:41:21 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-26 12:41:22 | INFO | fairseq.tasks.translation | example hypothesis: This... how could this be the charm that that trash could emit?
2023-05-26 12:41:22 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-26 12:41:23 | INFO | fairseq.tasks.translation | example hypothesis: How could Wang Wenhao have found the news agency? The chief editor should have called her and told her not to come to the news agency. However, these three people... had plotted against her!
2023-05-26 12:41:23 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-26 12:41:26 | INFO | fairseq.tasks.translation | example hypothesis: Hearing Teacher Di’s praise, I was delighted. I took back the energy ball with my left hand, and a light sword shot out from my right hand towards Teacher Zhen. The light sword actually landed smoothly. I was shocked, and upon closer inspection, I realized that it was just an afterimage. Teacher Zhen had already moved to my back and shouted, “Berserk Space!”
2023-05-26 12:41:26 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-26 12:41:29 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Originally, we proposed a two out of three competition, but they said that it wasn’t fair, because we had Teacher Di and Teacher Zhen, and their rankings were higher than them. They proposed five matches and three wins, and since we proposed the competition, we could only listen to them in the end. In three days, we will have a secret competition in the Royal Colosseum.”
2023-05-26 12:41:29 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-26 12:41:30 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Zhen was using a light spell of the seventh rank, Light Lightning Bolt. I didn’t use this spell very often, because it wasn’t ideal for me to control it. Teacher Zhen released nine lightning bolts and surrounded me, forming a simple spell formation that prevented me from escaping in a short distance. Then, the lightning bolts exploded one after another to form a powerful attack.
2023-05-26 12:41:30 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-26 12:41:34 | INFO | fairseq.tasks.translation | example hypothesis: As soon as Ma Ke and the two teachers walked to the other side, Teacher Zhen shot a small Dimensional Slash at me. As expected of the continent’s number one Magician. The suction force of the small Dimensional Slash was much stronger than mine. A small spatial crack appeared beside me, and a powerful suction force swept towards me.
2023-05-26 12:41:34 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-26 12:41:34 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 4.195 | nll_loss 2.551 | ppl 5.86 | bleu 21.5 | wps 1974.8 | wpb 2420.8 | bsz 84.5 | num_updates 60075 | best_bleu 21.5
2023-05-26 12:41:34 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-26 12:41:38 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/concat-1-1-0.2-sf[zh-en]/checkpoint9.pt (epoch 9 @ 60075 updates, score 21.5) (writing took 4.1101477695629 seconds)
2023-05-26 12:41:38 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-05-26 12:41:38 | INFO | train | epoch 009 | loss 4.252 | nll_loss 2.64 | ppl 6.23 | wps 52128.9 | ups 0.91 | wpb 57189.4 | bsz 1477.5 | num_updates 60075 | lr 0.000258038 | gnorm 0.247 | clip 100 | loss_scale 27 | train_wall 7017 | wall 66092
2023-05-26 12:41:38 | INFO | fairseq.trainer | begin training epoch 10
2023-05-26 12:42:13 | INFO | train_inner | epoch 010:     25 / 6686 loss=4.246, nll_loss=2.633, ppl=6.2, wps=35163.7, ups=0.62, wpb=56710.4, bsz=1465.7, num_updates=60100, lr=0.000257984, gnorm=0.249, clip=100, loss_scale=32, train_wall=106, wall=66127
2023-05-26 12:44:06 | INFO | train_inner | epoch 010:    125 / 6686 loss=4.23, nll_loss=2.614, ppl=6.12, wps=50588.3, ups=0.88, wpb=57302, bsz=1465.5, num_updates=60200, lr=0.00025777, gnorm=0.245, clip=100, loss_scale=32, train_wall=108, wall=66240
2023-05-26 12:45:04 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 12:45:59 | INFO | train_inner | epoch 010:    226 / 6686 loss=4.216, nll_loss=2.598, ppl=6.05, wps=50720.3, ups=0.89, wpb=57167.1, bsz=1481, num_updates=60300, lr=0.000257556, gnorm=0.25, clip=100, loss_scale=34, train_wall=108, wall=66353
2023-05-26 12:47:48 | INFO | train_inner | epoch 010:    326 / 6686 loss=4.223, nll_loss=2.606, ppl=6.09, wps=52348.7, ups=0.92, wpb=57155.1, bsz=1507.4, num_updates=60400, lr=0.000257343, gnorm=0.244, clip=100, loss_scale=32, train_wall=105, wall=66462
2023-05-26 12:49:37 | INFO | train_inner | epoch 010:    426 / 6686 loss=4.226, nll_loss=2.61, ppl=6.1, wps=52236.5, ups=0.91, wpb=57173.3, bsz=1490.1, num_updates=60500, lr=0.00025713, gnorm=0.245, clip=100, loss_scale=32, train_wall=105, wall=66572
2023-05-26 12:51:26 | INFO | train_inner | epoch 010:    526 / 6686 loss=4.234, nll_loss=2.62, ppl=6.15, wps=52698.9, ups=0.92, wpb=57208.7, bsz=1478.5, num_updates=60600, lr=0.000256917, gnorm=0.246, clip=100, loss_scale=32, train_wall=105, wall=66680
2023-05-26 12:53:15 | INFO | train_inner | epoch 010:    626 / 6686 loss=4.232, nll_loss=2.617, ppl=6.13, wps=52533.6, ups=0.92, wpb=57149.2, bsz=1454.6, num_updates=60700, lr=0.000256706, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=66789
2023-05-26 12:54:29 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 12:55:04 | INFO | train_inner | epoch 010:    727 / 6686 loss=4.235, nll_loss=2.62, ppl=6.15, wps=51992.1, ups=0.91, wpb=56996.5, bsz=1488.2, num_updates=60800, lr=0.000256495, gnorm=0.248, clip=100, loss_scale=34, train_wall=106, wall=66898
2023-05-26 12:56:53 | INFO | train_inner | epoch 010:    827 / 6686 loss=4.242, nll_loss=2.628, ppl=6.18, wps=52590.3, ups=0.92, wpb=57227.3, bsz=1461.8, num_updates=60900, lr=0.000256284, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=67007
2023-05-26 12:58:42 | INFO | train_inner | epoch 010:    927 / 6686 loss=4.236, nll_loss=2.621, ppl=6.15, wps=52689.6, ups=0.92, wpb=57278.7, bsz=1505.8, num_updates=61000, lr=0.000256074, gnorm=0.244, clip=100, loss_scale=32, train_wall=105, wall=67116
2023-05-26 13:00:30 | INFO | train_inner | epoch 010:   1027 / 6686 loss=4.235, nll_loss=2.62, ppl=6.15, wps=52776.6, ups=0.92, wpb=57204.4, bsz=1475, num_updates=61100, lr=0.000255864, gnorm=0.244, clip=100, loss_scale=32, train_wall=105, wall=67224
2023-05-26 13:02:19 | INFO | train_inner | epoch 010:   1127 / 6686 loss=4.23, nll_loss=2.614, ppl=6.12, wps=52553.5, ups=0.92, wpb=57117, bsz=1478.8, num_updates=61200, lr=0.000255655, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=67333
2023-05-26 13:04:02 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 13:04:08 | INFO | train_inner | epoch 010:   1228 / 6686 loss=4.238, nll_loss=2.624, ppl=6.16, wps=52312.5, ups=0.91, wpb=57232.9, bsz=1474.3, num_updates=61300, lr=0.000255446, gnorm=0.25, clip=100, loss_scale=37, train_wall=106, wall=67443
2023-05-26 13:05:57 | INFO | train_inner | epoch 010:   1328 / 6686 loss=4.24, nll_loss=2.625, ppl=6.17, wps=52617.3, ups=0.92, wpb=57136.3, bsz=1466.5, num_updates=61400, lr=0.000255238, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=67551
2023-05-26 13:07:46 | INFO | train_inner | epoch 010:   1428 / 6686 loss=4.244, nll_loss=2.631, ppl=6.19, wps=52366.8, ups=0.92, wpb=57186.1, bsz=1465.4, num_updates=61500, lr=0.000255031, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=67660
2023-05-26 13:09:35 | INFO | train_inner | epoch 010:   1528 / 6686 loss=4.241, nll_loss=2.627, ppl=6.18, wps=52615.5, ups=0.92, wpb=57083.6, bsz=1472.6, num_updates=61600, lr=0.000254824, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=67769
2023-05-26 13:11:23 | INFO | train_inner | epoch 010:   1628 / 6686 loss=4.241, nll_loss=2.627, ppl=6.18, wps=52835.5, ups=0.92, wpb=57411.3, bsz=1488.1, num_updates=61700, lr=0.000254617, gnorm=0.245, clip=100, loss_scale=32, train_wall=105, wall=67877
2023-05-26 13:13:12 | INFO | train_inner | epoch 010:   1728 / 6686 loss=4.234, nll_loss=2.619, ppl=6.14, wps=52799, ups=0.92, wpb=57192.7, bsz=1484.4, num_updates=61800, lr=0.000254411, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=67986
2023-05-26 13:13:21 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 13:15:01 | INFO | train_inner | epoch 010:   1829 / 6686 loss=4.243, nll_loss=2.629, ppl=6.19, wps=52037.9, ups=0.91, wpb=57039, bsz=1485.8, num_updates=61900, lr=0.000254205, gnorm=0.249, clip=100, loss_scale=33, train_wall=106, wall=68095
2023-05-26 13:16:50 | INFO | train_inner | epoch 010:   1929 / 6686 loss=4.239, nll_loss=2.625, ppl=6.17, wps=52573.6, ups=0.92, wpb=57211, bsz=1469.2, num_updates=62000, lr=0.000254, gnorm=0.246, clip=100, loss_scale=32, train_wall=105, wall=68204
2023-05-26 13:17:03 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 13:18:40 | INFO | train_inner | epoch 010:   2030 / 6686 loss=4.249, nll_loss=2.636, ppl=6.22, wps=52023.6, ups=0.91, wpb=57251.1, bsz=1464, num_updates=62100, lr=0.000253796, gnorm=0.249, clip=100, loss_scale=18, train_wall=106, wall=68314
2023-05-26 13:20:29 | INFO | train_inner | epoch 010:   2130 / 6686 loss=4.246, nll_loss=2.633, ppl=6.2, wps=52445.1, ups=0.92, wpb=56976.3, bsz=1449.3, num_updates=62200, lr=0.000253592, gnorm=0.248, clip=100, loss_scale=16, train_wall=105, wall=68423
2023-05-26 13:22:17 | INFO | train_inner | epoch 010:   2230 / 6686 loss=4.236, nll_loss=2.621, ppl=6.15, wps=52820, ups=0.92, wpb=57352.4, bsz=1507, num_updates=62300, lr=0.000253388, gnorm=0.247, clip=100, loss_scale=16, train_wall=105, wall=68532
2023-05-26 13:24:06 | INFO | train_inner | epoch 010:   2330 / 6686 loss=4.236, nll_loss=2.621, ppl=6.15, wps=52741.8, ups=0.92, wpb=57312.4, bsz=1490.4, num_updates=62400, lr=0.000253185, gnorm=0.248, clip=100, loss_scale=16, train_wall=105, wall=68640
2023-05-26 13:25:55 | INFO | train_inner | epoch 010:   2430 / 6686 loss=4.234, nll_loss=2.619, ppl=6.14, wps=52319.1, ups=0.91, wpb=57187, bsz=1483.8, num_updates=62500, lr=0.000252982, gnorm=0.246, clip=100, loss_scale=16, train_wall=106, wall=68749
2023-05-26 13:27:45 | INFO | train_inner | epoch 010:   2530 / 6686 loss=4.234, nll_loss=2.619, ppl=6.14, wps=52531.1, ups=0.91, wpb=57417.2, bsz=1499.9, num_updates=62600, lr=0.00025278, gnorm=0.249, clip=100, loss_scale=28, train_wall=105, wall=68859
2023-05-26 13:29:33 | INFO | train_inner | epoch 010:   2630 / 6686 loss=4.24, nll_loss=2.627, ppl=6.18, wps=52821.1, ups=0.92, wpb=57310.8, bsz=1485, num_updates=62700, lr=0.000252578, gnorm=0.251, clip=100, loss_scale=32, train_wall=105, wall=68967
2023-05-26 13:31:22 | INFO | train_inner | epoch 010:   2730 / 6686 loss=4.237, nll_loss=2.622, ppl=6.16, wps=52504.7, ups=0.92, wpb=57025.1, bsz=1478.2, num_updates=62800, lr=0.000252377, gnorm=0.25, clip=100, loss_scale=32, train_wall=105, wall=69076
2023-05-26 13:33:10 | INFO | train_inner | epoch 010:   2830 / 6686 loss=4.234, nll_loss=2.62, ppl=6.15, wps=52841.1, ups=0.92, wpb=57361.4, bsz=1468.8, num_updates=62900, lr=0.000252177, gnorm=0.244, clip=100, loss_scale=32, train_wall=105, wall=69184
2023-05-26 13:34:59 | INFO | train_inner | epoch 010:   2930 / 6686 loss=4.25, nll_loss=2.638, ppl=6.22, wps=52496.5, ups=0.92, wpb=57237.5, bsz=1466.2, num_updates=63000, lr=0.000251976, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=69294
2023-05-26 13:35:17 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 13:36:49 | INFO | train_inner | epoch 010:   3031 / 6686 loss=4.235, nll_loss=2.62, ppl=6.15, wps=52101.9, ups=0.91, wpb=57349.7, bsz=1471.9, num_updates=63100, lr=0.000251777, gnorm=0.247, clip=100, loss_scale=18, train_wall=106, wall=69404
2023-05-26 13:38:38 | INFO | train_inner | epoch 010:   3131 / 6686 loss=4.232, nll_loss=2.618, ppl=6.14, wps=52522, ups=0.92, wpb=57248.3, bsz=1491.2, num_updates=63200, lr=0.000251577, gnorm=0.251, clip=100, loss_scale=16, train_wall=105, wall=69513
2023-05-26 13:40:27 | INFO | train_inner | epoch 010:   3231 / 6686 loss=4.247, nll_loss=2.634, ppl=6.21, wps=52604.4, ups=0.92, wpb=57176.1, bsz=1455.3, num_updates=63300, lr=0.000251379, gnorm=0.25, clip=100, loss_scale=16, train_wall=105, wall=69621
2023-05-26 13:42:16 | INFO | train_inner | epoch 010:   3331 / 6686 loss=4.239, nll_loss=2.625, ppl=6.17, wps=52482.7, ups=0.92, wpb=57249.9, bsz=1465.9, num_updates=63400, lr=0.00025118, gnorm=0.247, clip=100, loss_scale=16, train_wall=105, wall=69730
2023-05-26 13:44:05 | INFO | train_inner | epoch 010:   3431 / 6686 loss=4.241, nll_loss=2.627, ppl=6.18, wps=52477.5, ups=0.92, wpb=57136.5, bsz=1473.2, num_updates=63500, lr=0.000250982, gnorm=0.25, clip=100, loss_scale=16, train_wall=105, wall=69839
2023-05-26 13:45:44 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 13:45:55 | INFO | train_inner | epoch 010:   3532 / 6686 loss=4.238, nll_loss=2.624, ppl=6.16, wps=52059, ups=0.91, wpb=57288.8, bsz=1478.6, num_updates=63600, lr=0.000250785, gnorm=0.248, clip=100, loss_scale=26, train_wall=106, wall=69949
2023-05-26 13:47:44 | INFO | train_inner | epoch 010:   3632 / 6686 loss=4.243, nll_loss=2.629, ppl=6.19, wps=52606.6, ups=0.92, wpb=57260.7, bsz=1482.3, num_updates=63700, lr=0.000250588, gnorm=0.246, clip=100, loss_scale=16, train_wall=105, wall=70058
2023-05-26 13:49:33 | INFO | train_inner | epoch 010:   3732 / 6686 loss=4.237, nll_loss=2.623, ppl=6.16, wps=52656.1, ups=0.92, wpb=57160.8, bsz=1477.1, num_updates=63800, lr=0.000250392, gnorm=0.246, clip=100, loss_scale=16, train_wall=105, wall=70167
2023-05-26 13:51:22 | INFO | train_inner | epoch 010:   3832 / 6686 loss=4.231, nll_loss=2.616, ppl=6.13, wps=52676.6, ups=0.92, wpb=57365.9, bsz=1479, num_updates=63900, lr=0.000250196, gnorm=0.247, clip=100, loss_scale=16, train_wall=105, wall=70276
2023-05-26 13:53:10 | INFO | train_inner | epoch 010:   3932 / 6686 loss=4.239, nll_loss=2.626, ppl=6.17, wps=52629.3, ups=0.92, wpb=57295.6, bsz=1470.9, num_updates=64000, lr=0.00025, gnorm=0.246, clip=100, loss_scale=16, train_wall=105, wall=70385
2023-05-26 13:54:59 | INFO | train_inner | epoch 010:   4032 / 6686 loss=4.239, nll_loss=2.626, ppl=6.17, wps=52507.5, ups=0.92, wpb=57133.5, bsz=1463.4, num_updates=64100, lr=0.000249805, gnorm=0.251, clip=100, loss_scale=16, train_wall=105, wall=70493
2023-05-26 13:56:48 | INFO | train_inner | epoch 010:   4132 / 6686 loss=4.243, nll_loss=2.63, ppl=6.19, wps=52589, ups=0.92, wpb=57079.7, bsz=1488.9, num_updates=64200, lr=0.00024961, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=70602
2023-05-26 13:58:37 | INFO | train_inner | epoch 010:   4232 / 6686 loss=4.239, nll_loss=2.625, ppl=6.17, wps=52539.4, ups=0.92, wpb=57190, bsz=1500.1, num_updates=64300, lr=0.000249416, gnorm=0.25, clip=100, loss_scale=32, train_wall=105, wall=70711
2023-05-26 14:00:25 | INFO | train_inner | epoch 010:   4332 / 6686 loss=4.238, nll_loss=2.625, ppl=6.17, wps=52702.7, ups=0.92, wpb=57229.5, bsz=1481.1, num_updates=64400, lr=0.000249222, gnorm=0.251, clip=100, loss_scale=32, train_wall=105, wall=70819
2023-05-26 14:02:14 | INFO | train_inner | epoch 010:   4432 / 6686 loss=4.234, nll_loss=2.62, ppl=6.15, wps=52550.6, ups=0.92, wpb=57255.6, bsz=1510.6, num_updates=64500, lr=0.000249029, gnorm=0.246, clip=100, loss_scale=32, train_wall=105, wall=70928
2023-05-26 14:04:03 | INFO | train_inner | epoch 010:   4532 / 6686 loss=4.231, nll_loss=2.617, ppl=6.13, wps=52705.9, ups=0.92, wpb=57230.9, bsz=1498.8, num_updates=64600, lr=0.000248836, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=71037
2023-05-26 14:04:19 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 14:05:53 | INFO | train_inner | epoch 010:   4633 / 6686 loss=4.251, nll_loss=2.64, ppl=6.23, wps=51927.1, ups=0.91, wpb=57014.2, bsz=1473.2, num_updates=64700, lr=0.000248644, gnorm=0.248, clip=100, loss_scale=32, train_wall=106, wall=71147
2023-05-26 14:07:41 | INFO | train_inner | epoch 010:   4733 / 6686 loss=4.248, nll_loss=2.636, ppl=6.21, wps=52470.2, ups=0.92, wpb=57105.4, bsz=1448.2, num_updates=64800, lr=0.000248452, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=71256
2023-05-26 14:09:30 | INFO | train_inner | epoch 010:   4833 / 6686 loss=4.234, nll_loss=2.62, ppl=6.15, wps=52597.5, ups=0.92, wpb=57056.3, bsz=1501.8, num_updates=64900, lr=0.000248261, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=71364
2023-05-26 14:11:19 | INFO | train_inner | epoch 010:   4933 / 6686 loss=4.224, nll_loss=2.608, ppl=6.1, wps=52665.4, ups=0.92, wpb=57312.7, bsz=1487.1, num_updates=65000, lr=0.000248069, gnorm=0.246, clip=100, loss_scale=32, train_wall=105, wall=71473
2023-05-26 14:13:07 | INFO | train_inner | epoch 010:   5033 / 6686 loss=4.252, nll_loss=2.64, ppl=6.23, wps=52666, ups=0.92, wpb=57236.4, bsz=1459.8, num_updates=65100, lr=0.000247879, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=71582
2023-05-26 14:13:24 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 14:14:58 | INFO | train_inner | epoch 010:   5134 / 6686 loss=4.227, nll_loss=2.612, ppl=6.11, wps=51873.2, ups=0.91, wpb=57130.7, bsz=1475, num_updates=65200, lr=0.000247689, gnorm=0.246, clip=100, loss_scale=18, train_wall=106, wall=71692
2023-05-26 14:16:46 | INFO | train_inner | epoch 010:   5234 / 6686 loss=4.234, nll_loss=2.62, ppl=6.15, wps=52562.4, ups=0.92, wpb=57031.2, bsz=1487.8, num_updates=65300, lr=0.000247499, gnorm=0.25, clip=100, loss_scale=16, train_wall=105, wall=71800
2023-05-26 14:18:35 | INFO | train_inner | epoch 010:   5334 / 6686 loss=4.24, nll_loss=2.626, ppl=6.18, wps=52285.7, ups=0.91, wpb=57222.1, bsz=1484.3, num_updates=65400, lr=0.00024731, gnorm=0.245, clip=100, loss_scale=16, train_wall=106, wall=71910
2023-05-26 14:20:24 | INFO | train_inner | epoch 010:   5434 / 6686 loss=4.244, nll_loss=2.631, ppl=6.2, wps=52426.9, ups=0.92, wpb=57043.8, bsz=1468.2, num_updates=65500, lr=0.000247121, gnorm=0.248, clip=100, loss_scale=16, train_wall=105, wall=72018
2023-05-26 14:22:13 | INFO | train_inner | epoch 010:   5534 / 6686 loss=4.239, nll_loss=2.626, ppl=6.17, wps=52527.2, ups=0.92, wpb=57205.9, bsz=1473.8, num_updates=65600, lr=0.000246932, gnorm=0.247, clip=100, loss_scale=16, train_wall=105, wall=72127
2023-05-26 14:24:02 | INFO | train_inner | epoch 010:   5634 / 6686 loss=4.238, nll_loss=2.625, ppl=6.17, wps=52378.9, ups=0.92, wpb=57144.6, bsz=1486.5, num_updates=65700, lr=0.000246744, gnorm=0.247, clip=100, loss_scale=28, train_wall=105, wall=72236
2023-05-26 14:25:13 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 14:25:52 | INFO | train_inner | epoch 010:   5735 / 6686 loss=4.237, nll_loss=2.624, ppl=6.16, wps=52146.6, ups=0.91, wpb=57255, bsz=1472.2, num_updates=65800, lr=0.000246557, gnorm=0.245, clip=100, loss_scale=26, train_wall=106, wall=72346
2023-05-26 14:27:41 | INFO | train_inner | epoch 010:   5835 / 6686 loss=4.238, nll_loss=2.624, ppl=6.17, wps=52685, ups=0.92, wpb=57265.6, bsz=1480.5, num_updates=65900, lr=0.00024637, gnorm=0.248, clip=100, loss_scale=16, train_wall=105, wall=72455
2023-05-26 14:29:30 | INFO | train_inner | epoch 010:   5935 / 6686 loss=4.23, nll_loss=2.615, ppl=6.13, wps=52587.8, ups=0.92, wpb=57219.2, bsz=1467.8, num_updates=66000, lr=0.000246183, gnorm=0.246, clip=100, loss_scale=16, train_wall=105, wall=72564
2023-05-26 14:31:18 | INFO | train_inner | epoch 010:   6035 / 6686 loss=4.237, nll_loss=2.623, ppl=6.16, wps=52687.5, ups=0.92, wpb=57286.1, bsz=1475.2, num_updates=66100, lr=0.000245997, gnorm=0.248, clip=100, loss_scale=16, train_wall=105, wall=72672
2023-05-26 14:33:07 | INFO | train_inner | epoch 010:   6135 / 6686 loss=4.244, nll_loss=2.631, ppl=6.2, wps=52719.5, ups=0.92, wpb=57291, bsz=1463.9, num_updates=66200, lr=0.000245811, gnorm=0.248, clip=100, loss_scale=16, train_wall=105, wall=72781
2023-05-26 14:34:56 | INFO | train_inner | epoch 010:   6235 / 6686 loss=4.229, nll_loss=2.615, ppl=6.12, wps=52407.5, ups=0.92, wpb=57158.2, bsz=1479.6, num_updates=66300, lr=0.000245625, gnorm=0.244, clip=100, loss_scale=20, train_wall=105, wall=72890
2023-05-26 14:36:45 | INFO | train_inner | epoch 010:   6335 / 6686 loss=4.237, nll_loss=2.624, ppl=6.16, wps=52557.5, ups=0.92, wpb=57147.5, bsz=1467.3, num_updates=66400, lr=0.00024544, gnorm=0.244, clip=100, loss_scale=32, train_wall=105, wall=72999
2023-05-26 14:38:33 | INFO | train_inner | epoch 010:   6435 / 6686 loss=4.231, nll_loss=2.617, ppl=6.13, wps=52599.8, ups=0.92, wpb=57134.3, bsz=1479.6, num_updates=66500, lr=0.000245256, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=73108
2023-05-26 14:40:22 | INFO | train_inner | epoch 010:   6535 / 6686 loss=4.245, nll_loss=2.633, ppl=6.2, wps=52555, ups=0.92, wpb=57260.3, bsz=1452, num_updates=66600, lr=0.000245072, gnorm=0.246, clip=100, loss_scale=32, train_wall=105, wall=73217
2023-05-26 14:42:11 | INFO | train_inner | epoch 010:   6635 / 6686 loss=4.24, nll_loss=2.627, ppl=6.18, wps=52567.6, ups=0.92, wpb=56952.3, bsz=1454.8, num_updates=66700, lr=0.000244888, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=73325
2023-05-26 14:43:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-26 14:43:10 | INFO | fairseq.tasks.translation | example hypothesis: Why? Why?
2023-05-26 14:43:10 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-26 14:43:11 | INFO | fairseq.tasks.translation | example hypothesis: I’ll make you lose so much that you don’t even have pants left!
2023-05-26 14:43:11 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-26 14:43:12 | INFO | fairseq.tasks.translation | example hypothesis: Just as Shen Liangchuan heaved a sigh of relief, he heard her say, “I’ll call for you to stay in the same room!”
2023-05-26 14:43:12 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-26 14:43:12 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved her hand and entered the elevator.
2023-05-26 14:43:12 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-26 14:43:13 | INFO | fairseq.tasks.translation | example hypothesis: She raised her head and saw Song Cheng standing in the distance!
2023-05-26 14:43:13 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-26 14:43:14 | INFO | fairseq.tasks.translation | example hypothesis: Song Cheng patted his chest. “You scared me to death! Where’s Wang Chuan?”
2023-05-26 14:43:14 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-26 14:43:15 | INFO | fairseq.tasks.translation | example hypothesis: “No, I can’t eat it,” I said.
2023-05-26 14:43:15 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-26 14:43:15 | INFO | fairseq.tasks.translation | example hypothesis: Voices were in disbelief at first, but Wang Wenhao insisted on him and made the public opinion lean towards him.
2023-05-26 14:43:15 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-26 14:43:16 | INFO | fairseq.tasks.translation | example hypothesis: With his identity coming here like this, Baili Hongzhuang had to be treated even if she did not treat him!
2023-05-26 14:43:16 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-26 14:43:17 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian said, “Mr. Shen, I, I’ve left too much blood and my brain is lacking oxygen. I can’t figure it out. Why don’t you give me a hint?”
2023-05-26 14:43:17 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-26 14:43:18 | INFO | fairseq.tasks.translation | example hypothesis: He didn’t know why so many people had heard about it. Since it couldn’t be concealed, he might as well tell them.
2023-05-26 14:43:18 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-26 14:43:19 | INFO | fairseq.tasks.translation | example hypothesis: She deliberately lowered her voice, but it was unable to conceal the viciousness and ruthlessness in her tone.
2023-05-26 14:43:19 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-26 14:43:20 | INFO | fairseq.tasks.translation | example hypothesis: Beasts of different levels were different in strength, but a beast pet was precious and rare. It was impossible for ordinary people to possess it. Even the descendants of officials could not possess it.
2023-05-26 14:43:20 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-26 14:43:21 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chixia gritted his teeth and cursed in a low voice.
2023-05-26 14:43:21 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-26 14:43:22 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang concealed it very well, Di Beichen still saw the waves in her eyes and felt a little warm.
2023-05-26 14:43:22 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-26 14:43:23 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia walked in, she didn't even see a few waiters, let alone the guests.
2023-05-26 14:43:23 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-26 14:43:24 | INFO | fairseq.tasks.translation | example hypothesis: This person was the Ye Family's fourth young miss, Ye Qingling.
2023-05-26 14:43:24 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-26 14:43:25 | INFO | fairseq.tasks.translation | example hypothesis: Because at this moment, she felt as if her chin was about to shatter.
2023-05-26 14:43:25 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-26 14:43:27 | INFO | fairseq.tasks.translation | example hypothesis: “Good Mu Zi, help me. If it wasn't for you, that old guy wouldn't have targeted me.”
2023-05-26 14:43:27 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-26 14:43:28 | INFO | fairseq.tasks.translation | example hypothesis: Baili Yu Yan was even more excited. This matter was completely under her control. Earlier, Baili Hong Zhuang had treated her like that. This time around, she would definitely make Baili Hong Zhuang feel bad.
2023-05-26 14:43:28 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-26 14:43:29 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How could that be? They also have four mages on their side, so of course they won’t surrender so easily. After arguing for a long time, they decided on how to get control of the Kingdom of Axia through the competition.”
2023-05-26 14:43:29 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-26 14:43:30 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a little. Originally, he had been looking for a reason for Li Yuyue not being able to participate in the Royal Family Hunting Competition.
2023-05-26 14:43:30 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-26 14:43:32 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my standard good? He’s all the best people in the country. Is my magic that weak?”
2023-05-26 14:43:32 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-26 14:43:34 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yibei’s meaning was that if Fang Chixia didn’t want to go, then there was no need to go.
2023-05-26 14:43:34 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-26 14:43:36 | INFO | fairseq.tasks.translation | example hypothesis: She tilted her head and saw that the five palm prints on her cheek were very conspicuous. They were swelling at a speed visible to the naked eye. When she reached out and touched them, she could not help but let out a hissing sound.
2023-05-26 14:43:36 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-26 14:43:37 | INFO | fairseq.tasks.translation | example hypothesis: This... how could this be the charm that that trash could emit?
2023-05-26 14:43:37 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-26 14:43:38 | INFO | fairseq.tasks.translation | example hypothesis: How could Wang Wenhao have found the newspaper and the chief editor? They should have called her to tell her not to come to the newspaper, but these three people... had schemed against her!
2023-05-26 14:43:38 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-26 14:43:41 | INFO | fairseq.tasks.translation | example hypothesis: Hearing Teacher Di’s praise, I was delighted. I took back the energy ball with my left hand, and a light sword shot out from my right hand towards Teacher Zhen. The light sword actually managed to land smoothly. I was startled, but upon closer inspection, I realized that it was just an afterimage. Teacher Zhen had already moved to my back and shouted, “Berserk Space!”
2023-05-26 14:43:41 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-26 14:43:44 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Originally, we proposed a two out of three competition, but their side said it wasn’t fair, because we have Teacher Di and Teacher Zhen, who are ranked higher than them. They proposed a three out of five competition, and since we proposed the competition, we can only listen to them in the end. In three days’ time, we will secretly compete in the Royal Colosseum. If we don’t win, then we will lose.”
2023-05-26 14:43:44 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-26 14:43:46 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Di used the light element level 7 spell, Light Bolt Burst. I rarely used this spell because my control over it wasn’t ideal. Teacher Di released nine lightning bolts to surround me, forming a simple formation that prevented me from escaping in a short distance. Then the lightning bolts exploded one after another to form a powerful attack.
2023-05-26 14:43:46 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-26 14:43:49 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke and the two teachers had just walked to the other side when Teacher Zhen sent out a Small Dimension Slash at me. As expected of the continent’s number one Magician, the Small Dimension Slash’s suction force was actually much stronger than mine. A small spatial rift appeared beside me, and a strong suction force swept towards me.
2023-05-26 14:43:49 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-26 14:43:49 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 4.202 | nll_loss 2.568 | ppl 5.93 | bleu 21.34 | wps 1887.2 | wpb 2420.8 | bsz 84.5 | num_updates 66751 | best_bleu 21.5
2023-05-26 14:43:49 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-26 14:43:52 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/concat-1-1-0.2-sf[zh-en]/checkpoint10.pt (epoch 10 @ 66751 updates, score 21.34) (writing took 2.893431837670505 seconds)
2023-05-26 14:43:52 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-05-26 14:43:52 | INFO | train | epoch 010 | loss 4.237 | nll_loss 2.623 | ppl 6.16 | wps 52058.9 | ups 0.91 | wpb 57190 | bsz 1477.4 | num_updates 66751 | lr 0.000244794 | gnorm 0.247 | clip 100 | loss_scale 26 | train_wall 7024 | wall 73426
2023-05-26 14:43:52 | INFO | fairseq.trainer | begin training epoch 11
2023-05-26 14:45:04 | INFO | train_inner | epoch 011:     49 / 6686 loss=4.221, nll_loss=2.605, ppl=6.08, wps=32683.4, ups=0.58, wpb=56599, bsz=1471.5, num_updates=66800, lr=0.000244704, gnorm=0.249, clip=100, loss_scale=36, train_wall=107, wall=73498
2023-05-26 14:45:38 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 14:47:06 | INFO | train_inner | epoch 011:    150 / 6686 loss=4.206, nll_loss=2.588, ppl=6.01, wps=46974.7, ups=0.82, wpb=57256.9, bsz=1472.2, num_updates=66900, lr=0.000244521, gnorm=0.246, clip=100, loss_scale=41, train_wall=110, wall=73620
2023-05-26 14:49:01 | INFO | train_inner | epoch 011:    250 / 6686 loss=4.209, nll_loss=2.592, ppl=6.03, wps=49733.1, ups=0.87, wpb=57160.2, bsz=1490.1, num_updates=67000, lr=0.000244339, gnorm=0.246, clip=100, loss_scale=32, train_wall=106, wall=73735
2023-05-26 14:50:51 | INFO | train_inner | epoch 011:    350 / 6686 loss=4.22, nll_loss=2.604, ppl=6.08, wps=51996.2, ups=0.91, wpb=57190, bsz=1462.9, num_updates=67100, lr=0.000244157, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=73845
2023-05-26 14:50:57 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 14:52:41 | INFO | train_inner | epoch 011:    451 / 6686 loss=4.218, nll_loss=2.602, ppl=6.07, wps=51937.6, ups=0.91, wpb=57273.4, bsz=1466.6, num_updates=67200, lr=0.000243975, gnorm=0.251, clip=100, loss_scale=17, train_wall=106, wall=73955
2023-05-26 14:54:31 | INFO | train_inner | epoch 011:    551 / 6686 loss=4.217, nll_loss=2.601, ppl=6.07, wps=52350.2, ups=0.91, wpb=57386.9, bsz=1487.2, num_updates=67300, lr=0.000243794, gnorm=0.249, clip=100, loss_scale=16, train_wall=106, wall=74065
2023-05-26 14:56:19 | INFO | train_inner | epoch 011:    651 / 6686 loss=4.214, nll_loss=2.597, ppl=6.05, wps=52455, ups=0.92, wpb=56996, bsz=1453.3, num_updates=67400, lr=0.000243613, gnorm=0.248, clip=100, loss_scale=16, train_wall=105, wall=74173
2023-05-26 14:58:08 | INFO | train_inner | epoch 011:    751 / 6686 loss=4.215, nll_loss=2.598, ppl=6.05, wps=52663.3, ups=0.92, wpb=57150.8, bsz=1460.7, num_updates=67500, lr=0.000243432, gnorm=0.253, clip=100, loss_scale=16, train_wall=105, wall=74282
2023-05-26 14:59:57 | INFO | train_inner | epoch 011:    851 / 6686 loss=4.227, nll_loss=2.611, ppl=6.11, wps=52646.4, ups=0.92, wpb=57287.2, bsz=1481.3, num_updates=67600, lr=0.000243252, gnorm=0.245, clip=100, loss_scale=16, train_wall=105, wall=74391
2023-05-26 15:01:34 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 15:01:46 | INFO | train_inner | epoch 011:    952 / 6686 loss=4.214, nll_loss=2.597, ppl=6.05, wps=52057.5, ups=0.91, wpb=57103.5, bsz=1476.5, num_updates=67700, lr=0.000243072, gnorm=0.247, clip=100, loss_scale=28, train_wall=106, wall=74500
2023-05-26 15:03:36 | INFO | train_inner | epoch 011:   1052 / 6686 loss=4.222, nll_loss=2.606, ppl=6.09, wps=52500.3, ups=0.92, wpb=57314.5, bsz=1489.8, num_updates=67800, lr=0.000242893, gnorm=0.245, clip=100, loss_scale=16, train_wall=105, wall=74610
2023-05-26 15:05:24 | INFO | train_inner | epoch 011:   1152 / 6686 loss=4.212, nll_loss=2.595, ppl=6.04, wps=52644.9, ups=0.92, wpb=57172.8, bsz=1514.7, num_updates=67900, lr=0.000242714, gnorm=0.251, clip=100, loss_scale=16, train_wall=105, wall=74718
2023-05-26 15:07:13 | INFO | train_inner | epoch 011:   1252 / 6686 loss=4.218, nll_loss=2.602, ppl=6.07, wps=52534.9, ups=0.92, wpb=57253.4, bsz=1488.6, num_updates=68000, lr=0.000242536, gnorm=0.248, clip=100, loss_scale=16, train_wall=105, wall=74827
2023-05-26 15:09:02 | INFO | train_inner | epoch 011:   1352 / 6686 loss=4.216, nll_loss=2.599, ppl=6.06, wps=52675.3, ups=0.92, wpb=57313.4, bsz=1496.1, num_updates=68100, lr=0.000242357, gnorm=0.246, clip=100, loss_scale=16, train_wall=105, wall=74936
2023-05-26 15:10:50 | INFO | train_inner | epoch 011:   1452 / 6686 loss=4.225, nll_loss=2.61, ppl=6.1, wps=52752.1, ups=0.92, wpb=57253.3, bsz=1495.8, num_updates=68200, lr=0.00024218, gnorm=0.249, clip=100, loss_scale=16, train_wall=105, wall=75045
2023-05-26 15:12:39 | INFO | train_inner | epoch 011:   1552 / 6686 loss=4.232, nll_loss=2.618, ppl=6.14, wps=52766.4, ups=0.92, wpb=57112.8, bsz=1456.5, num_updates=68300, lr=0.000242002, gnorm=0.249, clip=100, loss_scale=32, train_wall=104, wall=75153
2023-05-26 15:14:28 | INFO | train_inner | epoch 011:   1652 / 6686 loss=4.221, nll_loss=2.605, ppl=6.08, wps=52543.4, ups=0.92, wpb=57337.4, bsz=1504, num_updates=68400, lr=0.000241825, gnorm=0.243, clip=100, loss_scale=32, train_wall=105, wall=75262
2023-05-26 15:16:17 | INFO | train_inner | epoch 011:   1752 / 6686 loss=4.224, nll_loss=2.608, ppl=6.1, wps=52293.9, ups=0.91, wpb=57207.7, bsz=1465.2, num_updates=68500, lr=0.000241649, gnorm=0.247, clip=100, loss_scale=32, train_wall=106, wall=75371
2023-05-26 15:18:06 | INFO | train_inner | epoch 011:   1852 / 6686 loss=4.22, nll_loss=2.603, ppl=6.08, wps=52769.1, ups=0.92, wpb=57156.5, bsz=1456, num_updates=68600, lr=0.000241473, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=75480
2023-05-26 15:19:54 | INFO | train_inner | epoch 011:   1952 / 6686 loss=4.224, nll_loss=2.609, ppl=6.1, wps=52943.9, ups=0.92, wpb=57387.1, bsz=1502.2, num_updates=68700, lr=0.000241297, gnorm=0.244, clip=100, loss_scale=32, train_wall=105, wall=75588
2023-05-26 15:20:10 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 15:20:50 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 15:21:45 | INFO | train_inner | epoch 011:   2054 / 6686 loss=4.222, nll_loss=2.606, ppl=6.09, wps=51622.1, ups=0.9, wpb=57145.8, bsz=1466.7, num_updates=68800, lr=0.000241121, gnorm=0.247, clip=100, loss_scale=25, train_wall=107, wall=75699
2023-05-26 15:23:34 | INFO | train_inner | epoch 011:   2154 / 6686 loss=4.225, nll_loss=2.61, ppl=6.1, wps=52469.6, ups=0.92, wpb=57192.6, bsz=1483.4, num_updates=68900, lr=0.000240946, gnorm=0.247, clip=100, loss_scale=16, train_wall=105, wall=75808
2023-05-26 15:25:22 | INFO | train_inner | epoch 011:   2254 / 6686 loss=4.234, nll_loss=2.619, ppl=6.14, wps=52881.3, ups=0.92, wpb=57278.3, bsz=1451.4, num_updates=69000, lr=0.000240772, gnorm=0.244, clip=100, loss_scale=16, train_wall=104, wall=75916
2023-05-26 15:27:11 | INFO | train_inner | epoch 011:   2354 / 6686 loss=4.224, nll_loss=2.609, ppl=6.1, wps=52505.5, ups=0.92, wpb=57094.8, bsz=1489.4, num_updates=69100, lr=0.000240597, gnorm=0.249, clip=100, loss_scale=16, train_wall=105, wall=76025
2023-05-26 15:29:00 | INFO | train_inner | epoch 011:   2454 / 6686 loss=4.221, nll_loss=2.605, ppl=6.08, wps=52491.5, ups=0.92, wpb=57310.3, bsz=1488.3, num_updates=69200, lr=0.000240424, gnorm=0.249, clip=100, loss_scale=16, train_wall=105, wall=76134
2023-05-26 15:30:37 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 15:30:49 | INFO | train_inner | epoch 011:   2555 / 6686 loss=4.225, nll_loss=2.609, ppl=6.1, wps=52209.9, ups=0.92, wpb=56981.7, bsz=1470.4, num_updates=69300, lr=0.00024025, gnorm=0.249, clip=100, loss_scale=20, train_wall=105, wall=76243
2023-05-26 15:32:38 | INFO | train_inner | epoch 011:   2655 / 6686 loss=4.231, nll_loss=2.617, ppl=6.13, wps=52539.4, ups=0.92, wpb=57068.3, bsz=1467.7, num_updates=69400, lr=0.000240077, gnorm=0.249, clip=100, loss_scale=16, train_wall=105, wall=76352
2023-05-26 15:34:27 | INFO | train_inner | epoch 011:   2755 / 6686 loss=4.234, nll_loss=2.62, ppl=6.15, wps=52498.4, ups=0.92, wpb=57161, bsz=1456.2, num_updates=69500, lr=0.000239904, gnorm=0.247, clip=100, loss_scale=16, train_wall=105, wall=76461
2023-05-26 15:36:15 | INFO | train_inner | epoch 011:   2855 / 6686 loss=4.224, nll_loss=2.609, ppl=6.1, wps=52464.1, ups=0.92, wpb=57099.4, bsz=1475.2, num_updates=69600, lr=0.000239732, gnorm=0.248, clip=100, loss_scale=16, train_wall=105, wall=76570
2023-05-26 15:38:04 | INFO | train_inner | epoch 011:   2955 / 6686 loss=4.223, nll_loss=2.607, ppl=6.09, wps=52442.7, ups=0.92, wpb=57178.9, bsz=1459.6, num_updates=69700, lr=0.00023956, gnorm=0.246, clip=100, loss_scale=16, train_wall=105, wall=76679
2023-05-26 15:39:53 | INFO | train_inner | epoch 011:   3055 / 6686 loss=4.233, nll_loss=2.619, ppl=6.14, wps=52449.2, ups=0.92, wpb=56941.1, bsz=1457, num_updates=69800, lr=0.000239388, gnorm=0.251, clip=100, loss_scale=16, train_wall=105, wall=76787
2023-05-26 15:41:42 | INFO | train_inner | epoch 011:   3155 / 6686 loss=4.219, nll_loss=2.603, ppl=6.07, wps=52610.1, ups=0.92, wpb=57180.2, bsz=1479.2, num_updates=69900, lr=0.000239217, gnorm=0.252, clip=100, loss_scale=32, train_wall=105, wall=76896
2023-05-26 15:43:30 | INFO | train_inner | epoch 011:   3255 / 6686 loss=4.235, nll_loss=2.622, ppl=6.15, wps=52589, ups=0.92, wpb=57208.7, bsz=1469.6, num_updates=70000, lr=0.000239046, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=77005
2023-05-26 15:45:20 | INFO | train_inner | epoch 011:   3355 / 6686 loss=4.214, nll_loss=2.597, ppl=6.05, wps=52627.9, ups=0.92, wpb=57391.2, bsz=1492.4, num_updates=70100, lr=0.000238875, gnorm=0.25, clip=100, loss_scale=32, train_wall=105, wall=77114
2023-05-26 15:47:07 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 15:47:09 | INFO | train_inner | epoch 011:   3456 / 6686 loss=4.222, nll_loss=2.607, ppl=6.09, wps=52280.2, ups=0.91, wpb=57419, bsz=1498.6, num_updates=70200, lr=0.000238705, gnorm=0.247, clip=100, loss_scale=32, train_wall=106, wall=77223
2023-05-26 15:48:58 | INFO | train_inner | epoch 011:   3556 / 6686 loss=4.234, nll_loss=2.62, ppl=6.15, wps=52767.3, ups=0.92, wpb=57204, bsz=1459.9, num_updates=70300, lr=0.000238535, gnorm=0.247, clip=100, loss_scale=16, train_wall=105, wall=77332
2023-05-26 15:50:46 | INFO | train_inner | epoch 011:   3656 / 6686 loss=4.216, nll_loss=2.6, ppl=6.06, wps=52842.9, ups=0.92, wpb=57272.4, bsz=1475.6, num_updates=70400, lr=0.000238366, gnorm=0.244, clip=100, loss_scale=16, train_wall=104, wall=77440
2023-05-26 15:52:35 | INFO | train_inner | epoch 011:   3756 / 6686 loss=4.218, nll_loss=2.602, ppl=6.07, wps=52691.8, ups=0.92, wpb=57446.5, bsz=1468.2, num_updates=70500, lr=0.000238197, gnorm=0.249, clip=100, loss_scale=16, train_wall=105, wall=77549
2023-05-26 15:54:24 | INFO | train_inner | epoch 011:   3856 / 6686 loss=4.222, nll_loss=2.607, ppl=6.09, wps=52607, ups=0.92, wpb=57326.6, bsz=1483.5, num_updates=70600, lr=0.000238028, gnorm=0.244, clip=100, loss_scale=16, train_wall=105, wall=77658
2023-05-26 15:56:13 | INFO | train_inner | epoch 011:   3956 / 6686 loss=4.23, nll_loss=2.615, ppl=6.13, wps=52502.3, ups=0.92, wpb=57079, bsz=1465, num_updates=70700, lr=0.000237859, gnorm=0.248, clip=100, loss_scale=16, train_wall=105, wall=77767
2023-05-26 15:58:02 | INFO | train_inner | epoch 011:   4056 / 6686 loss=4.233, nll_loss=2.619, ppl=6.14, wps=52569.2, ups=0.92, wpb=57155.8, bsz=1477.4, num_updates=70800, lr=0.000237691, gnorm=0.247, clip=100, loss_scale=31, train_wall=105, wall=77876
2023-05-26 15:59:50 | INFO | train_inner | epoch 011:   4156 / 6686 loss=4.23, nll_loss=2.616, ppl=6.13, wps=52684.6, ups=0.92, wpb=57085.4, bsz=1481.9, num_updates=70900, lr=0.000237524, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=77984
2023-05-26 16:01:39 | INFO | train_inner | epoch 011:   4256 / 6686 loss=4.226, nll_loss=2.611, ppl=6.11, wps=52508.2, ups=0.92, wpb=57091.3, bsz=1473.8, num_updates=71000, lr=0.000237356, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=78093
2023-05-26 16:03:27 | INFO | train_inner | epoch 011:   4356 / 6686 loss=4.231, nll_loss=2.617, ppl=6.13, wps=52567.9, ups=0.92, wpb=57107.3, bsz=1467.3, num_updates=71100, lr=0.000237189, gnorm=0.25, clip=100, loss_scale=32, train_wall=105, wall=78201
2023-05-26 16:05:16 | INFO | train_inner | epoch 011:   4456 / 6686 loss=4.226, nll_loss=2.612, ppl=6.11, wps=52471.8, ups=0.92, wpb=57254, bsz=1468.7, num_updates=71200, lr=0.000237023, gnorm=0.245, clip=100, loss_scale=32, train_wall=105, wall=78311
2023-05-26 16:05:59 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 16:07:06 | INFO | train_inner | epoch 011:   4557 / 6686 loss=4.226, nll_loss=2.611, ppl=6.11, wps=52176.6, ups=0.91, wpb=57253.9, bsz=1486.5, num_updates=71300, lr=0.000236856, gnorm=0.25, clip=100, loss_scale=37, train_wall=106, wall=78420
2023-05-26 16:08:55 | INFO | train_inner | epoch 011:   4657 / 6686 loss=4.23, nll_loss=2.615, ppl=6.13, wps=52553.2, ups=0.92, wpb=57058.2, bsz=1462.9, num_updates=71400, lr=0.000236691, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=78529
2023-05-26 16:10:43 | INFO | train_inner | epoch 011:   4757 / 6686 loss=4.229, nll_loss=2.614, ppl=6.12, wps=52772.1, ups=0.92, wpb=57209.5, bsz=1491.4, num_updates=71500, lr=0.000236525, gnorm=0.246, clip=100, loss_scale=32, train_wall=105, wall=78637
2023-05-26 16:12:32 | INFO | train_inner | epoch 011:   4857 / 6686 loss=4.222, nll_loss=2.607, ppl=6.09, wps=52748.2, ups=0.92, wpb=57228, bsz=1490.5, num_updates=71600, lr=0.00023636, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=78746
2023-05-26 16:14:20 | INFO | train_inner | epoch 011:   4957 / 6686 loss=4.237, nll_loss=2.624, ppl=6.16, wps=52285.7, ups=0.92, wpb=56893.2, bsz=1474.7, num_updates=71700, lr=0.000236195, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=78855
2023-05-26 16:15:16 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 16:16:10 | INFO | train_inner | epoch 011:   5058 / 6686 loss=4.23, nll_loss=2.615, ppl=6.13, wps=52066.2, ups=0.91, wpb=57222.9, bsz=1478.9, num_updates=71800, lr=0.00023603, gnorm=0.247, clip=100, loss_scale=32, train_wall=106, wall=78964
2023-05-26 16:17:59 | INFO | train_inner | epoch 011:   5158 / 6686 loss=4.227, nll_loss=2.612, ppl=6.11, wps=52624.3, ups=0.92, wpb=57155.4, bsz=1472.4, num_updates=71900, lr=0.000235866, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=79073
2023-05-26 16:18:38 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 16:19:48 | INFO | train_inner | epoch 011:   5259 / 6686 loss=4.228, nll_loss=2.614, ppl=6.12, wps=52146.4, ups=0.91, wpb=57043.2, bsz=1493.4, num_updates=72000, lr=0.000235702, gnorm=0.249, clip=100, loss_scale=22, train_wall=106, wall=79183
2023-05-26 16:21:37 | INFO | train_inner | epoch 011:   5359 / 6686 loss=4.23, nll_loss=2.616, ppl=6.13, wps=52721.8, ups=0.92, wpb=57246.7, bsz=1471.6, num_updates=72100, lr=0.000235539, gnorm=0.247, clip=100, loss_scale=16, train_wall=105, wall=79291
2023-05-26 16:23:26 | INFO | train_inner | epoch 011:   5459 / 6686 loss=4.229, nll_loss=2.615, ppl=6.13, wps=52578, ups=0.92, wpb=57117.3, bsz=1474.6, num_updates=72200, lr=0.000235376, gnorm=0.246, clip=100, loss_scale=16, train_wall=105, wall=79400
2023-05-26 16:25:14 | INFO | train_inner | epoch 011:   5559 / 6686 loss=4.218, nll_loss=2.603, ppl=6.08, wps=52483.1, ups=0.92, wpb=57091.9, bsz=1505.5, num_updates=72300, lr=0.000235213, gnorm=0.245, clip=100, loss_scale=16, train_wall=105, wall=79509
2023-05-26 16:27:03 | INFO | train_inner | epoch 011:   5659 / 6686 loss=4.236, nll_loss=2.622, ppl=6.16, wps=52742.8, ups=0.92, wpb=57356.7, bsz=1478.1, num_updates=72400, lr=0.00023505, gnorm=0.246, clip=100, loss_scale=16, train_wall=105, wall=79617
2023-05-26 16:28:52 | INFO | train_inner | epoch 011:   5759 / 6686 loss=4.232, nll_loss=2.618, ppl=6.14, wps=52645.7, ups=0.92, wpb=57280.4, bsz=1452.2, num_updates=72500, lr=0.000234888, gnorm=0.247, clip=100, loss_scale=25, train_wall=105, wall=79726
2023-05-26 16:30:40 | INFO | train_inner | epoch 011:   5859 / 6686 loss=4.24, nll_loss=2.628, ppl=6.18, wps=52636.5, ups=0.92, wpb=57014.4, bsz=1473.9, num_updates=72600, lr=0.000234726, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=79834
2023-05-26 16:32:29 | INFO | train_inner | epoch 011:   5959 / 6686 loss=4.213, nll_loss=2.597, ppl=6.05, wps=52542.8, ups=0.92, wpb=57295.4, bsz=1504.5, num_updates=72700, lr=0.000234565, gnorm=0.244, clip=100, loss_scale=32, train_wall=105, wall=79943
2023-05-26 16:34:18 | INFO | train_inner | epoch 011:   6059 / 6686 loss=4.23, nll_loss=2.616, ppl=6.13, wps=52432.7, ups=0.92, wpb=57225.2, bsz=1474.9, num_updates=72800, lr=0.000234404, gnorm=0.245, clip=100, loss_scale=32, train_wall=105, wall=80053
2023-05-26 16:36:07 | INFO | train_inner | epoch 011:   6159 / 6686 loss=4.222, nll_loss=2.607, ppl=6.09, wps=52624.5, ups=0.92, wpb=57274.1, bsz=1494.3, num_updates=72900, lr=0.000234243, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=80161
2023-05-26 16:37:14 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 16:37:57 | INFO | train_inner | epoch 011:   6260 / 6686 loss=4.22, nll_loss=2.605, ppl=6.08, wps=52343.8, ups=0.91, wpb=57304.4, bsz=1476.7, num_updates=73000, lr=0.000234082, gnorm=0.246, clip=100, loss_scale=33, train_wall=106, wall=80271
2023-05-26 16:39:45 | INFO | train_inner | epoch 011:   6360 / 6686 loss=4.241, nll_loss=2.628, ppl=6.18, wps=52578, ups=0.92, wpb=57082, bsz=1468.9, num_updates=73100, lr=0.000233922, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=80379
2023-05-26 16:41:34 | INFO | train_inner | epoch 011:   6460 / 6686 loss=4.225, nll_loss=2.61, ppl=6.1, wps=52727.1, ups=0.92, wpb=57290.5, bsz=1485.1, num_updates=73200, lr=0.000233762, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=80488
2023-05-26 16:43:23 | INFO | train_inner | epoch 011:   6560 / 6686 loss=4.222, nll_loss=2.606, ppl=6.09, wps=52326.5, ups=0.92, wpb=57107.7, bsz=1481.5, num_updates=73300, lr=0.000233603, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=80597
2023-05-26 16:45:12 | INFO | train_inner | epoch 011:   6660 / 6686 loss=4.221, nll_loss=2.606, ppl=6.09, wps=52676.4, ups=0.92, wpb=57379.7, bsz=1483, num_updates=73400, lr=0.000233444, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=80706
2023-05-26 16:45:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-26 16:45:44 | INFO | fairseq.tasks.translation | example hypothesis: Why was that?
2023-05-26 16:45:44 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-26 16:45:45 | INFO | fairseq.tasks.translation | example hypothesis: I’ll make you lose so soon that you don’t even have your pants left!
2023-05-26 16:45:45 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-26 16:45:45 | INFO | fairseq.tasks.translation | example hypothesis: Just as Shen Liangchuan heaved a sigh of relief, he heard her say, “I’ll call you in the same room!”
2023-05-26 16:45:45 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-26 16:45:46 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved her hand and entered the elevator.
2023-05-26 16:45:46 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-26 16:45:47 | INFO | fairseq.tasks.translation | example hypothesis: She raised her head and saw Song Cheng standing in the distance!
2023-05-26 16:45:47 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-26 16:45:47 | INFO | fairseq.tasks.translation | example hypothesis: Song Cheng patted his chest. “You scared me to death! Where’s Wang Chuan?”
2023-05-26 16:45:47 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-26 16:45:48 | INFO | fairseq.tasks.translation | example hypothesis: I said, “No, I can’t eat it.”
2023-05-26 16:45:48 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-26 16:45:49 | INFO | fairseq.tasks.translation | example hypothesis: Wenhao Wang insisted on him, allowing the public opinion to lean towards him.
2023-05-26 16:45:49 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-26 16:45:50 | INFO | fairseq.tasks.translation | example hypothesis: Coming here with his identity, Baili Hongzhuang had to be treated even if she did not want to!
2023-05-26 16:45:50 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-26 16:45:51 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian said, “Mr. Shen, I, I’ve kept too much blood and my brain is lacking oxygen. I can’t figure it out. Why don’t you give me a hint?”
2023-05-26 16:45:51 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-26 16:45:52 | INFO | fairseq.tasks.translation | example hypothesis: He didn't know why so many people had heard of this. Since he couldn't hide it any longer, he might as well tell them.
2023-05-26 16:45:52 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-26 16:45:53 | INFO | fairseq.tasks.translation | example hypothesis: She deliberately lowered her voice, but it was unable to conceal the viciousness and viciousness in her tone.
2023-05-26 16:45:53 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-26 16:45:53 | INFO | fairseq.tasks.translation | example hypothesis: Beast pets of different levels were different in strength, but beast pets were precious and rare. It was impossible for an ordinary person to have one. Even the descendants of officials could not have one.
2023-05-26 16:45:53 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-26 16:45:54 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chixia gritted her teeth and cursed in a low voice.
2023-05-26 16:45:54 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-26 16:45:55 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang had concealed it very well, Di Beichen still saw the flash of emotions in her eyes, and a hint of warmth filled his eyes.
2023-05-26 16:45:55 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-26 16:45:56 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia walked in, not to mention the guests, even the waiters were nowhere to be seen.
2023-05-26 16:45:56 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-26 16:45:58 | INFO | fairseq.tasks.translation | example hypothesis: This person was the fourth miss of the Ye family, Ye Qing Ling.
2023-05-26 16:45:58 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-26 16:45:59 | INFO | fairseq.tasks.translation | example hypothesis: At this moment, she felt as if her chin was about to break.
2023-05-26 16:45:59 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-26 16:46:00 | INFO | fairseq.tasks.translation | example hypothesis: “Good Mu Zi, help me. If it wasn't for you, that old man wouldn't have targeted me.”
2023-05-26 16:46:00 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-26 16:46:01 | INFO | fairseq.tasks.translation | example hypothesis: Bai Li Yu Yan was even more excited. This matter was completely directed by her. Earlier, Bai Li Hong Zhuang had treated her like this. This time around, she would definitely make it difficult for Bai Li Hong Zhuang.
2023-05-26 16:46:01 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-26 16:46:02 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How could that be? They also have four mages on their side, so of course they won’t surrender so easily. After arguing for a long time, they finally decided how to obtain control over the Kingdom of Alla through the competition.”
2023-05-26 16:46:02 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-26 16:46:04 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a little. He had always been looking for a reason why Li Yuyue couldn’t participate in the Imperial Family Hunting Competition.
2023-05-26 16:46:04 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-26 16:46:05 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my level good enough? They’re all the most outstanding people in the country. Is my magic that weak?”
2023-05-26 16:46:05 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-26 16:46:07 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yibei meant that if Fang Chixia didn’t want to go, then there was no need to go.
2023-05-26 16:46:07 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-26 16:46:08 | INFO | fairseq.tasks.translation | example hypothesis: She tilted her head and saw that the five palm marks on her cheeks were very eye-catching. They were swelling at a speed visible to the naked eye. She reached out to touch them and could not help but let out a hissing sound.
2023-05-26 16:46:08 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-26 16:46:10 | INFO | fairseq.tasks.translation | example hypothesis: This... how could this be the charm that that trash could emit?
2023-05-26 16:46:10 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-26 16:46:11 | INFO | fairseq.tasks.translation | example hypothesis: How did Wang Wenhao manage to find the newspaper firm? The chief editor should have called her to not come to the newspaper firm, but these three people... had schemed against her!
2023-05-26 16:46:11 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-26 16:46:13 | INFO | fairseq.tasks.translation | example hypothesis: Hearing Teacher Di’s praise, I was overjoyed. I retracted the energy ball with my left hand, and a light sword shot out from my right hand towards Teacher Zhen. The light sword actually managed to land smoothly. I was shocked, but upon closer inspection, I realized that it was just an afterimage. Teacher Zhen had already moved to my back and shouted, “Berserk Space!”
2023-05-26 16:46:13 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-26 16:46:16 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Originally, we suggested that we win two out of three, but they said that it wasn’t fair, because we have Teacher Di and Teacher Zhen, who are ranked higher than them, so they suggested that we win three out of five. Since we were the ones who suggested the competition, we can only listen to them in the end. Three days from now, we’ll compete in secret in the Royal Coliseum. If we don’t win,
2023-05-26 16:46:16 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-26 16:46:18 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Zhen used a seventh-ranked spell, Light Thunder Consecutive Storm. I rarely used this spell, because my control over it wasn’t ideal. Teacher Zhen sent out nine lightning bolts to surround me, forming a simple spell formation that prevented me from escaping in a short distance. After that, the lightning bolts exploded and formed a powerful attack.
2023-05-26 16:46:18 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-26 16:46:22 | INFO | fairseq.tasks.translation | example hypothesis: As soon as Ma Ke and the two teachers walked to the other side, Teacher Zhen sent out a Lesser Dimensional Slash at me. As expected of the continent’s number one Magician. The suction force of the Lesser Dimensional Slash was much stronger than mine. A small spatial crack appeared beside me, and a strong suction force swept towards me.
2023-05-26 16:46:22 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-26 16:46:22 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 4.19 | nll_loss 2.548 | ppl 5.85 | bleu 21.29 | wps 1958.6 | wpb 2420.8 | bsz 84.5 | num_updates 73426 | best_bleu 21.5
2023-05-26 16:46:22 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-26 16:46:25 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/concat-1-1-0.2-sf[zh-en]/checkpoint11.pt (epoch 11 @ 73426 updates, score 21.29) (writing took 2.9559942139312625 seconds)
2023-05-26 16:46:25 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-05-26 16:46:25 | INFO | train | epoch 011 | loss 4.224 | nll_loss 2.609 | ppl 6.1 | wps 51919.5 | ups 0.91 | wpb 57190.1 | bsz 1477.5 | num_updates 73426 | lr 0.000233402 | gnorm 0.248 | clip 100 | loss_scale 25 | train_wall 7025 | wall 80779
2023-05-26 16:46:25 | INFO | fairseq.trainer | begin training epoch 12
2023-05-26 16:47:43 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 16:48:04 | INFO | train_inner | epoch 012:     75 / 6686 loss=4.203, nll_loss=2.585, ppl=6, wps=32929.6, ups=0.58, wpb=56689.3, bsz=1474.4, num_updates=73500, lr=0.000233285, gnorm=0.25, clip=100, loss_scale=35, train_wall=109, wall=80878
2023-05-26 16:50:01 | INFO | train_inner | epoch 012:    175 / 6686 loss=4.198, nll_loss=2.579, ppl=5.98, wps=48916.7, ups=0.86, wpb=57194, bsz=1466.9, num_updates=73600, lr=0.000233126, gnorm=0.249, clip=100, loss_scale=32, train_wall=107, wall=80995
2023-05-26 16:51:54 | INFO | train_inner | epoch 012:    275 / 6686 loss=4.201, nll_loss=2.583, ppl=5.99, wps=50618.8, ups=0.89, wpb=57135.8, bsz=1489, num_updates=73700, lr=0.000232968, gnorm=0.249, clip=100, loss_scale=32, train_wall=106, wall=81108
2023-05-26 16:53:44 | INFO | train_inner | epoch 012:    375 / 6686 loss=4.21, nll_loss=2.593, ppl=6.03, wps=52220.1, ups=0.91, wpb=57324, bsz=1479.1, num_updates=73800, lr=0.00023281, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=81218
2023-05-26 16:55:33 | INFO | train_inner | epoch 012:    475 / 6686 loss=4.207, nll_loss=2.589, ppl=6.02, wps=52202.6, ups=0.92, wpb=57034.5, bsz=1448.7, num_updates=73900, lr=0.000232653, gnorm=0.251, clip=100, loss_scale=32, train_wall=105, wall=81327
2023-05-26 16:57:22 | INFO | train_inner | epoch 012:    575 / 6686 loss=4.206, nll_loss=2.588, ppl=6.01, wps=52606.6, ups=0.92, wpb=57131.3, bsz=1483.4, num_updates=74000, lr=0.000232495, gnorm=0.245, clip=100, loss_scale=34, train_wall=105, wall=81436
2023-05-26 16:58:18 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 16:59:11 | INFO | train_inner | epoch 012:    676 / 6686 loss=4.209, nll_loss=2.592, ppl=6.03, wps=52189.4, ups=0.91, wpb=57193.3, bsz=1475.3, num_updates=74100, lr=0.000232338, gnorm=0.247, clip=100, loss_scale=48, train_wall=106, wall=81545
2023-05-26 17:01:00 | INFO | train_inner | epoch 012:    776 / 6686 loss=4.213, nll_loss=2.596, ppl=6.05, wps=52688.5, ups=0.92, wpb=57223.4, bsz=1469.4, num_updates=74200, lr=0.000232182, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=81654
2023-05-26 17:02:48 | INFO | train_inner | epoch 012:    876 / 6686 loss=4.216, nll_loss=2.6, ppl=6.06, wps=52696.7, ups=0.92, wpb=57106.7, bsz=1458.6, num_updates=74300, lr=0.000232025, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=81762
2023-05-26 17:04:37 | INFO | train_inner | epoch 012:    976 / 6686 loss=4.206, nll_loss=2.589, ppl=6.02, wps=52348.6, ups=0.92, wpb=57101, bsz=1497.5, num_updates=74400, lr=0.000231869, gnorm=0.25, clip=100, loss_scale=32, train_wall=105, wall=81871
2023-05-26 17:06:26 | INFO | train_inner | epoch 012:   1076 / 6686 loss=4.21, nll_loss=2.593, ppl=6.03, wps=52738.8, ups=0.92, wpb=57149.8, bsz=1478.3, num_updates=74500, lr=0.000231714, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=81980
2023-05-26 17:08:14 | INFO | train_inner | epoch 012:   1176 / 6686 loss=4.214, nll_loss=2.597, ppl=6.05, wps=52782.2, ups=0.92, wpb=57168.8, bsz=1461, num_updates=74600, lr=0.000231558, gnorm=0.249, clip=100, loss_scale=44, train_wall=105, wall=82088
2023-05-26 17:08:25 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 17:10:04 | INFO | train_inner | epoch 012:   1277 / 6686 loss=4.207, nll_loss=2.59, ppl=6.02, wps=52258.5, ups=0.91, wpb=57370.9, bsz=1495.6, num_updates=74700, lr=0.000231403, gnorm=0.247, clip=100, loss_scale=35, train_wall=106, wall=82198
2023-05-26 17:11:52 | INFO | train_inner | epoch 012:   1377 / 6686 loss=4.209, nll_loss=2.592, ppl=6.03, wps=52720.3, ups=0.92, wpb=57184.7, bsz=1450.6, num_updates=74800, lr=0.000231249, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=82306
2023-05-26 17:13:41 | INFO | train_inner | epoch 012:   1477 / 6686 loss=4.2, nll_loss=2.582, ppl=5.99, wps=52578.7, ups=0.92, wpb=57263.6, bsz=1488, num_updates=74900, lr=0.000231094, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=82415
2023-05-26 17:15:30 | INFO | train_inner | epoch 012:   1577 / 6686 loss=4.211, nll_loss=2.594, ppl=6.04, wps=52508.7, ups=0.92, wpb=57132.8, bsz=1483.4, num_updates=75000, lr=0.00023094, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=82524
2023-05-26 17:17:18 | INFO | train_inner | epoch 012:   1677 / 6686 loss=4.202, nll_loss=2.584, ppl=5.99, wps=52635.4, ups=0.92, wpb=57091.4, bsz=1486.8, num_updates=75100, lr=0.000230786, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=82633
2023-05-26 17:18:08 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 17:19:08 | INFO | train_inner | epoch 012:   1778 / 6686 loss=4.21, nll_loss=2.593, ppl=6.03, wps=52294.5, ups=0.91, wpb=57269.7, bsz=1490.2, num_updates=75200, lr=0.000230633, gnorm=0.249, clip=100, loss_scale=40, train_wall=106, wall=82742
2023-05-26 17:20:57 | INFO | train_inner | epoch 012:   1878 / 6686 loss=4.208, nll_loss=2.591, ppl=6.03, wps=52659.5, ups=0.92, wpb=57289.4, bsz=1478.3, num_updates=75300, lr=0.00023048, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=82851
2023-05-26 17:22:46 | INFO | train_inner | epoch 012:   1978 / 6686 loss=4.213, nll_loss=2.596, ppl=6.05, wps=52457.9, ups=0.92, wpb=57168.7, bsz=1484.7, num_updates=75400, lr=0.000230327, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=82960
2023-05-26 17:24:34 | INFO | train_inner | epoch 012:   2078 / 6686 loss=4.226, nll_loss=2.611, ppl=6.11, wps=52634.1, ups=0.92, wpb=57213.5, bsz=1477.8, num_updates=75500, lr=0.000230174, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=83069
2023-05-26 17:26:23 | INFO | train_inner | epoch 012:   2178 / 6686 loss=4.218, nll_loss=2.602, ppl=6.07, wps=52665.9, ups=0.92, wpb=57068.3, bsz=1468.2, num_updates=75600, lr=0.000230022, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=83177
2023-05-26 17:27:36 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 17:28:13 | INFO | train_inner | epoch 012:   2279 / 6686 loss=4.208, nll_loss=2.591, ppl=6.03, wps=52098.7, ups=0.91, wpb=57244, bsz=1484.6, num_updates=75700, lr=0.00022987, gnorm=0.252, clip=100, loss_scale=35, train_wall=106, wall=83287
2023-05-26 17:30:01 | INFO | train_inner | epoch 012:   2379 / 6686 loss=4.219, nll_loss=2.603, ppl=6.08, wps=52616.7, ups=0.92, wpb=56892.1, bsz=1458.8, num_updates=75800, lr=0.000229718, gnorm=0.25, clip=100, loss_scale=32, train_wall=104, wall=83395
2023-05-26 17:31:49 | INFO | train_inner | epoch 012:   2479 / 6686 loss=4.208, nll_loss=2.591, ppl=6.02, wps=52749.8, ups=0.92, wpb=57207, bsz=1487.8, num_updates=75900, lr=0.000229567, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=83503
2023-05-26 17:33:38 | INFO | train_inner | epoch 012:   2579 / 6686 loss=4.214, nll_loss=2.598, ppl=6.05, wps=52472.3, ups=0.92, wpb=57182.1, bsz=1485.6, num_updates=76000, lr=0.000229416, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=83612
2023-05-26 17:35:27 | INFO | train_inner | epoch 012:   2679 / 6686 loss=4.204, nll_loss=2.586, ppl=6, wps=52548.6, ups=0.92, wpb=57168.3, bsz=1481.3, num_updates=76100, lr=0.000229265, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=83721
2023-05-26 17:36:55 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 17:37:16 | INFO | train_inner | epoch 012:   2780 / 6686 loss=4.208, nll_loss=2.591, ppl=6.02, wps=52272, ups=0.92, wpb=57126.2, bsz=1488.6, num_updates=76200, lr=0.000229114, gnorm=0.249, clip=100, loss_scale=33, train_wall=105, wall=83830
2023-05-26 17:39:05 | INFO | train_inner | epoch 012:   2880 / 6686 loss=4.218, nll_loss=2.603, ppl=6.07, wps=52868.3, ups=0.92, wpb=57351.1, bsz=1490.4, num_updates=76300, lr=0.000228964, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=83939
2023-05-26 17:40:54 | INFO | train_inner | epoch 012:   2980 / 6686 loss=4.208, nll_loss=2.591, ppl=6.03, wps=52698.1, ups=0.92, wpb=57360.8, bsz=1511, num_updates=76400, lr=0.000228814, gnorm=0.246, clip=100, loss_scale=32, train_wall=105, wall=84048
2023-05-26 17:42:42 | INFO | train_inner | epoch 012:   3080 / 6686 loss=4.209, nll_loss=2.592, ppl=6.03, wps=52586.4, ups=0.92, wpb=57159.8, bsz=1470.6, num_updates=76500, lr=0.000228665, gnorm=0.25, clip=100, loss_scale=32, train_wall=105, wall=84157
2023-05-26 17:44:31 | INFO | train_inner | epoch 012:   3180 / 6686 loss=4.218, nll_loss=2.602, ppl=6.07, wps=52559.5, ups=0.92, wpb=57140.5, bsz=1466.2, num_updates=76600, lr=0.000228515, gnorm=0.251, clip=100, loss_scale=32, train_wall=105, wall=84265
2023-05-26 17:46:16 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 17:46:21 | INFO | train_inner | epoch 012:   3281 / 6686 loss=4.222, nll_loss=2.607, ppl=6.09, wps=52151.9, ups=0.91, wpb=57096.4, bsz=1473.8, num_updates=76700, lr=0.000228366, gnorm=0.247, clip=100, loss_scale=34, train_wall=106, wall=84375
2023-05-26 17:48:09 | INFO | train_inner | epoch 012:   3381 / 6686 loss=4.214, nll_loss=2.598, ppl=6.05, wps=52679.3, ups=0.92, wpb=57200.3, bsz=1478.6, num_updates=76800, lr=0.000228218, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=84483
2023-05-26 17:49:58 | INFO | train_inner | epoch 012:   3481 / 6686 loss=4.207, nll_loss=2.59, ppl=6.02, wps=52430.2, ups=0.92, wpb=57184, bsz=1484.5, num_updates=76900, lr=0.000228069, gnorm=0.25, clip=100, loss_scale=32, train_wall=105, wall=84592
2023-05-26 17:51:47 | INFO | train_inner | epoch 012:   3581 / 6686 loss=4.219, nll_loss=2.604, ppl=6.08, wps=52431.9, ups=0.92, wpb=57211.2, bsz=1471.2, num_updates=77000, lr=0.000227921, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=84702
2023-05-26 17:53:37 | INFO | train_inner | epoch 012:   3681 / 6686 loss=4.215, nll_loss=2.599, ppl=6.06, wps=52268.3, ups=0.92, wpb=57109.3, bsz=1496.4, num_updates=77100, lr=0.000227773, gnorm=0.255, clip=100, loss_scale=32, train_wall=106, wall=84811
2023-05-26 17:55:25 | INFO | train_inner | epoch 012:   3781 / 6686 loss=4.218, nll_loss=2.602, ppl=6.07, wps=52730.5, ups=0.92, wpb=57390.8, bsz=1481.6, num_updates=77200, lr=0.000227626, gnorm=0.252, clip=100, loss_scale=32, train_wall=105, wall=84920
2023-05-26 17:55:57 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 17:57:16 | INFO | train_inner | epoch 012:   3882 / 6686 loss=4.217, nll_loss=2.601, ppl=6.07, wps=52023.5, ups=0.91, wpb=57299.2, bsz=1471.8, num_updates=77300, lr=0.000227478, gnorm=0.248, clip=100, loss_scale=39, train_wall=106, wall=85030
2023-05-26 17:58:08 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 17:59:05 | INFO | train_inner | epoch 012:   3983 / 6686 loss=4.219, nll_loss=2.603, ppl=6.08, wps=52158, ups=0.91, wpb=57266.9, bsz=1474.9, num_updates=77400, lr=0.000227331, gnorm=0.248, clip=100, loss_scale=23, train_wall=106, wall=85140
2023-05-26 18:00:54 | INFO | train_inner | epoch 012:   4083 / 6686 loss=4.217, nll_loss=2.601, ppl=6.07, wps=52583.5, ups=0.92, wpb=57040.2, bsz=1461, num_updates=77500, lr=0.000227185, gnorm=0.249, clip=100, loss_scale=16, train_wall=105, wall=85248
2023-05-26 18:02:43 | INFO | train_inner | epoch 012:   4183 / 6686 loss=4.215, nll_loss=2.599, ppl=6.06, wps=52518, ups=0.92, wpb=57158.6, bsz=1475.1, num_updates=77600, lr=0.000227038, gnorm=0.253, clip=100, loss_scale=16, train_wall=105, wall=85357
2023-05-26 18:04:31 | INFO | train_inner | epoch 012:   4283 / 6686 loss=4.213, nll_loss=2.597, ppl=6.05, wps=52757.7, ups=0.92, wpb=57238.8, bsz=1481, num_updates=77700, lr=0.000226892, gnorm=0.248, clip=100, loss_scale=16, train_wall=105, wall=85465
2023-05-26 18:06:20 | INFO | train_inner | epoch 012:   4383 / 6686 loss=4.216, nll_loss=2.601, ppl=6.07, wps=52806.1, ups=0.92, wpb=57235.3, bsz=1472.1, num_updates=77800, lr=0.000226746, gnorm=0.249, clip=100, loss_scale=16, train_wall=105, wall=85574
2023-05-26 18:08:08 | INFO | train_inner | epoch 012:   4483 / 6686 loss=4.212, nll_loss=2.596, ppl=6.04, wps=52651.5, ups=0.92, wpb=57027.6, bsz=1499.6, num_updates=77900, lr=0.000226601, gnorm=0.246, clip=100, loss_scale=23, train_wall=105, wall=85682
2023-05-26 18:09:56 | INFO | train_inner | epoch 012:   4583 / 6686 loss=4.222, nll_loss=2.607, ppl=6.09, wps=52789, ups=0.92, wpb=57221.3, bsz=1455.8, num_updates=78000, lr=0.000226455, gnorm=0.251, clip=100, loss_scale=32, train_wall=105, wall=85790
2023-05-26 18:10:59 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 18:11:47 | INFO | train_inner | epoch 012:   4684 / 6686 loss=4.207, nll_loss=2.589, ppl=6.02, wps=52039.5, ups=0.91, wpb=57385.9, bsz=1499.8, num_updates=78100, lr=0.00022631, gnorm=0.25, clip=100, loss_scale=25, train_wall=106, wall=85901
2023-05-26 18:13:36 | INFO | train_inner | epoch 012:   4784 / 6686 loss=4.209, nll_loss=2.592, ppl=6.03, wps=52469.1, ups=0.92, wpb=57210.7, bsz=1473.2, num_updates=78200, lr=0.000226166, gnorm=0.248, clip=100, loss_scale=16, train_wall=105, wall=86010
2023-05-26 18:15:24 | INFO | train_inner | epoch 012:   4884 / 6686 loss=4.219, nll_loss=2.604, ppl=6.08, wps=52833.7, ups=0.92, wpb=57134.4, bsz=1476.5, num_updates=78300, lr=0.000226021, gnorm=0.248, clip=100, loss_scale=16, train_wall=104, wall=86118
2023-05-26 18:17:12 | INFO | train_inner | epoch 012:   4984 / 6686 loss=4.211, nll_loss=2.595, ppl=6.04, wps=52678.3, ups=0.92, wpb=57208.4, bsz=1495.5, num_updates=78400, lr=0.000225877, gnorm=0.247, clip=100, loss_scale=16, train_wall=105, wall=86227
2023-05-26 18:19:01 | INFO | train_inner | epoch 012:   5084 / 6686 loss=4.214, nll_loss=2.598, ppl=6.06, wps=52817.2, ups=0.92, wpb=57244.4, bsz=1484, num_updates=78500, lr=0.000225733, gnorm=0.251, clip=100, loss_scale=16, train_wall=105, wall=86335
2023-05-26 18:20:49 | INFO | train_inner | epoch 012:   5184 / 6686 loss=4.209, nll_loss=2.592, ppl=6.03, wps=52812.9, ups=0.92, wpb=57375.4, bsz=1486.6, num_updates=78600, lr=0.000225589, gnorm=0.253, clip=100, loss_scale=21, train_wall=105, wall=86444
2023-05-26 18:22:38 | INFO | train_inner | epoch 012:   5284 / 6686 loss=4.209, nll_loss=2.592, ppl=6.03, wps=52681.3, ups=0.92, wpb=57267.9, bsz=1460.4, num_updates=78700, lr=0.000225446, gnorm=0.245, clip=100, loss_scale=32, train_wall=105, wall=86552
2023-05-26 18:24:27 | INFO | train_inner | epoch 012:   5384 / 6686 loss=4.22, nll_loss=2.605, ppl=6.08, wps=52438.5, ups=0.92, wpb=57265.6, bsz=1455.6, num_updates=78800, lr=0.000225303, gnorm=0.249, clip=100, loss_scale=32, train_wall=106, wall=86661
2023-05-26 18:26:16 | INFO | train_inner | epoch 012:   5484 / 6686 loss=4.223, nll_loss=2.608, ppl=6.1, wps=52614, ups=0.92, wpb=57004.1, bsz=1483.8, num_updates=78900, lr=0.00022516, gnorm=0.252, clip=100, loss_scale=32, train_wall=105, wall=86770
2023-05-26 18:28:04 | INFO | train_inner | epoch 012:   5584 / 6686 loss=4.22, nll_loss=2.605, ppl=6.09, wps=52733.7, ups=0.92, wpb=57181.1, bsz=1477.3, num_updates=79000, lr=0.000225018, gnorm=0.253, clip=100, loss_scale=32, train_wall=105, wall=86878
2023-05-26 18:29:52 | INFO | train_inner | epoch 012:   5684 / 6686 loss=4.242, nll_loss=2.629, ppl=6.19, wps=52987.3, ups=0.92, wpb=57331.2, bsz=1470.1, num_updates=79100, lr=0.000224875, gnorm=0.25, clip=100, loss_scale=39, train_wall=105, wall=86986
2023-05-26 18:29:54 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 18:31:42 | INFO | train_inner | epoch 012:   5785 / 6686 loss=4.217, nll_loss=2.602, ppl=6.07, wps=51993, ups=0.91, wpb=57159.4, bsz=1486.5, num_updates=79200, lr=0.000224733, gnorm=0.247, clip=100, loss_scale=32, train_wall=106, wall=87096
2023-05-26 18:33:31 | INFO | train_inner | epoch 012:   5885 / 6686 loss=4.213, nll_loss=2.597, ppl=6.05, wps=52412.6, ups=0.92, wpb=57145.2, bsz=1486.5, num_updates=79300, lr=0.000224592, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=87205
2023-05-26 18:35:20 | INFO | train_inner | epoch 012:   5985 / 6686 loss=4.222, nll_loss=2.607, ppl=6.09, wps=52661, ups=0.92, wpb=57368.1, bsz=1470.2, num_updates=79400, lr=0.00022445, gnorm=0.251, clip=100, loss_scale=32, train_wall=105, wall=87314
2023-05-26 18:37:09 | INFO | train_inner | epoch 012:   6085 / 6686 loss=4.227, nll_loss=2.613, ppl=6.12, wps=52690.1, ups=0.92, wpb=57079.4, bsz=1460.3, num_updates=79500, lr=0.000224309, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=87423
2023-05-26 18:38:57 | INFO | train_inner | epoch 012:   6185 / 6686 loss=4.218, nll_loss=2.603, ppl=6.08, wps=52612.3, ups=0.92, wpb=57147.1, bsz=1453.7, num_updates=79600, lr=0.000224168, gnorm=0.251, clip=100, loss_scale=32, train_wall=105, wall=87531
2023-05-26 18:39:14 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 18:40:47 | INFO | train_inner | epoch 012:   6286 / 6686 loss=4.221, nll_loss=2.606, ppl=6.09, wps=52171.8, ups=0.91, wpb=57178.6, bsz=1460.2, num_updates=79700, lr=0.000224027, gnorm=0.245, clip=100, loss_scale=33, train_wall=106, wall=87641
2023-05-26 18:42:36 | INFO | train_inner | epoch 012:   6386 / 6686 loss=4.211, nll_loss=2.595, ppl=6.04, wps=52550, ups=0.92, wpb=57147, bsz=1448.2, num_updates=79800, lr=0.000223887, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=87750
2023-05-26 18:44:25 | INFO | train_inner | epoch 012:   6486 / 6686 loss=4.202, nll_loss=2.585, ppl=6, wps=52599.5, ups=0.92, wpb=57365.4, bsz=1505.5, num_updates=79900, lr=0.000223747, gnorm=0.246, clip=100, loss_scale=32, train_wall=105, wall=87859
2023-05-26 18:46:13 | INFO | train_inner | epoch 012:   6586 / 6686 loss=4.215, nll_loss=2.599, ppl=6.06, wps=52862.3, ups=0.92, wpb=57194.9, bsz=1493.1, num_updates=80000, lr=0.000223607, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=87967
2023-05-26 18:48:00 | INFO | train_inner | epoch 012:   6686 / 6686 loss=4.223, nll_loss=2.609, ppl=6.1, wps=52844.1, ups=0.93, wpb=56869.1, bsz=1470.7, num_updates=80100, lr=0.000223467, gnorm=0.253, clip=100, loss_scale=32, train_wall=104, wall=88075
2023-05-26 18:48:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-26 18:48:05 | INFO | fairseq.tasks.translation | example hypothesis: Why was that?
2023-05-26 18:48:05 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-26 18:48:06 | INFO | fairseq.tasks.translation | example hypothesis: I’ll make you lose so much that you don’t even have your pants left!
2023-05-26 18:48:06 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-26 18:48:06 | INFO | fairseq.tasks.translation | example hypothesis: Just as Shen Liangchuan heaved a sigh of relief, she said, “I’ll call you in the same room!”
2023-05-26 18:48:06 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-26 18:48:07 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved her hand and entered the elevator.
2023-05-26 18:48:07 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-26 18:48:08 | INFO | fairseq.tasks.translation | example hypothesis: She raised her head and saw Song Cheng standing in the distance!
2023-05-26 18:48:08 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-26 18:48:08 | INFO | fairseq.tasks.translation | example hypothesis: Song Cheng patted his chest. “You scared me to death! Where’s Wang Chuan?”
2023-05-26 18:48:08 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-26 18:48:09 | INFO | fairseq.tasks.translation | example hypothesis: “No, I can’t eat it,” I said.
2023-05-26 18:48:09 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-26 18:48:10 | INFO | fairseq.tasks.translation | example hypothesis: In the beginning, no one believed him, but Wang Wenhao insisted on him, letting the public opinion lean towards him.
2023-05-26 18:48:10 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-26 18:48:11 | INFO | fairseq.tasks.translation | example hypothesis: With his status, he came here like this. Baili Hongzhuang had to be treated even if he did not want to!
2023-05-26 18:48:11 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-26 18:48:12 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian: “Mr. Shen, I... I left too much blood and my brain lacks oxygen. I can’t figure it out. Why don’t you give me a hint?”
2023-05-26 18:48:12 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-26 18:48:13 | INFO | fairseq.tasks.translation | example hypothesis: He didn't know why so many people had heard about it. Since he couldn't hide it anymore, he might as well tell them.
2023-05-26 18:48:13 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-26 18:48:13 | INFO | fairseq.tasks.translation | example hypothesis: She deliberately lowered her voice, but it was unable to hide the viciousness and ruthlessness in her tone.
2023-05-26 18:48:13 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-26 18:48:14 | INFO | fairseq.tasks.translation | example hypothesis: Beast pets of different levels were different in strength, but a beast pet was precious and rare. It was impossible for ordinary people to possess it, and even the children of officials would not be able to possess it.
2023-05-26 18:48:14 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-26 18:48:15 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chixia gritted her teeth and cursed.
2023-05-26 18:48:15 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-26 18:48:16 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang had concealed it very well, Di Bei Chen could still see the ripples flashing across her eyes.
2023-05-26 18:48:16 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-26 18:48:17 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia walked in, not to mention the guests, she didn't even see a few waiters.
2023-05-26 18:48:17 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-26 18:48:18 | INFO | fairseq.tasks.translation | example hypothesis: This person was the Ye Family’s fourth young miss – Ye Qing Ling.
2023-05-26 18:48:18 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-26 18:48:20 | INFO | fairseq.tasks.translation | example hypothesis: Because at this moment, she felt as if her chin was about to shatter.
2023-05-26 18:48:20 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-26 18:48:21 | INFO | fairseq.tasks.translation | example hypothesis: “Good Mu Zi, help me. If it wasn't for you, that old guy wouldn't have targeted me.”
2023-05-26 18:48:21 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-26 18:48:22 | INFO | fairseq.tasks.translation | example hypothesis: Bai Li Yu Yan was even more excited. She was the one in charge of this. Earlier, Bai Li Hong Zhuang had treated her like this. This time, she would definitely make Bai Li Hong Zhuang feel bad too.
2023-05-26 18:48:22 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-26 18:48:23 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How could that be? They also have four mages on their side, of course they won’t surrender so easily. After arguing for a long time, they finally decided on how to obtain control over the Kingdom of A Xia in the future.”
2023-05-26 18:48:23 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-26 18:48:25 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a little. He had always been looking for a reason for Li Yuyue to not participate in the royal hunting competition.
2023-05-26 18:48:25 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-26 18:48:26 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my standard good? Those people are all the most outstanding people in the country. Is my magic that weak?”
2023-05-26 18:48:26 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-26 18:48:28 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yi Bei’s meaning was that if Fang Chi Xia didn’t want to go, then there was no need to go.
2023-05-26 18:48:28 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-26 18:48:29 | INFO | fairseq.tasks.translation | example hypothesis: She tilted her head and saw that the five palm marks on her cheek were very conspicuous. They were swelling at a speed visible to the naked eye. When she touched them, she could not help but let out a hissing sound.
2023-05-26 18:48:29 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-26 18:48:31 | INFO | fairseq.tasks.translation | example hypothesis: This... how could this be the charm that that trash could emit?
2023-05-26 18:48:31 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-26 18:48:32 | INFO | fairseq.tasks.translation | example hypothesis: How could Wang Wenhao have found the newspaper agency? The chief editor should have called to tell her not to come to the newspaper agency, but these three people... had schemed against her!
2023-05-26 18:48:32 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-26 18:48:34 | INFO | fairseq.tasks.translation | example hypothesis: I was delighted to hear Teacher Di’s praise. I took back the energy ball with my left hand, and a light sword shot out from my right hand towards Teacher Zhen. I was shocked to see that the light sword was able to land smoothly. When I took a closer look, I realized that it was just an afterimage.
2023-05-26 18:48:34 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-26 18:48:37 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Originally, we proposed a competition of two out of three, but they said that it wasn’t fair, because we have Teacher D and Teacher Zhen, and their ranking is even higher than them. They proposed five out of five out of three, and since we were the ones who proposed the competition, we can only listen to them in the end. Three days from now, we will secretly compete in the Royal Arena. As for the other two, we
2023-05-26 18:48:37 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-26 18:48:39 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Di used a level-7 light-type spell, Light Thunder Burst. I didn’t use this spell very often, because I didn’t have a very good control over it. Teacher Di released nine lightning bolts and surrounded me, forming a simple formation that prevented me from escaping in a short distance. Then, the lightning bolts exploded one after another to form a powerful attack.
2023-05-26 18:48:39 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-26 18:48:42 | INFO | fairseq.tasks.translation | example hypothesis: As soon as Ma Ke and the two teachers walked to the other side, Teacher Zhen shot out a small Dimensional Slash at me. As expected of the continent’s number one Magician. The suction force of his small Dimensional Slash was much stronger than mine. A small spatial crack appeared beside me, and a powerful suction force swept towards me.
2023-05-26 18:48:42 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-26 18:48:42 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.183 | nll_loss 2.537 | ppl 5.81 | bleu 21.47 | wps 1975.7 | wpb 2420.8 | bsz 84.5 | num_updates 80100 | best_bleu 21.5
2023-05-26 18:48:42 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-26 18:48:50 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/concat-1-1-0.2-sf[zh-en]/checkpoint12.pt (epoch 12 @ 80100 updates, score 21.47) (writing took 8.11586167383939 seconds)
2023-05-26 18:48:50 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-05-26 18:48:50 | INFO | train | epoch 012 | loss 4.213 | nll_loss 2.597 | ppl 6.05 | wps 51960.9 | ups 0.91 | wpb 57190.6 | bsz 1477.4 | num_updates 80100 | lr 0.000223467 | gnorm 0.249 | clip 100 | loss_scale 31 | train_wall 7022 | wall 88125
2023-05-26 18:48:51 | INFO | fairseq.trainer | begin training epoch 13
2023-05-26 18:49:44 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 18:51:09 | INFO | train_inner | epoch 013:    101 / 6686 loss=4.178, nll_loss=2.557, ppl=5.89, wps=30411.7, ups=0.53, wpb=57282.7, bsz=1461, num_updates=80200, lr=0.000223328, gnorm=0.249, clip=100, loss_scale=33, train_wall=110, wall=88263
2023-05-26 18:53:04 | INFO | train_inner | epoch 013:    201 / 6686 loss=4.179, nll_loss=2.558, ppl=5.89, wps=49595.5, ups=0.87, wpb=57261.5, bsz=1485.8, num_updates=80300, lr=0.000223189, gnorm=0.247, clip=100, loss_scale=32, train_wall=108, wall=88378
2023-05-26 18:54:55 | INFO | train_inner | epoch 013:    301 / 6686 loss=4.185, nll_loss=2.565, ppl=5.92, wps=51564.7, ups=0.9, wpb=57130.8, bsz=1494.5, num_updates=80400, lr=0.00022305, gnorm=0.248, clip=100, loss_scale=32, train_wall=106, wall=88489
2023-05-26 18:56:45 | INFO | train_inner | epoch 013:    401 / 6686 loss=4.201, nll_loss=2.582, ppl=5.99, wps=52290.3, ups=0.91, wpb=57255.5, bsz=1469.2, num_updates=80500, lr=0.000222911, gnorm=0.25, clip=100, loss_scale=32, train_wall=106, wall=88599
2023-05-26 18:58:34 | INFO | train_inner | epoch 013:    501 / 6686 loss=4.187, nll_loss=2.567, ppl=5.93, wps=52606.8, ups=0.92, wpb=57450.4, bsz=1508.6, num_updates=80600, lr=0.000222773, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=88708
2023-05-26 18:59:58 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 19:00:23 | INFO | train_inner | epoch 013:    602 / 6686 loss=4.202, nll_loss=2.584, ppl=5.99, wps=52149.4, ups=0.91, wpb=57149.7, bsz=1449.7, num_updates=80700, lr=0.000222635, gnorm=0.249, clip=100, loss_scale=43, train_wall=106, wall=88817
2023-05-26 19:02:12 | INFO | train_inner | epoch 013:    702 / 6686 loss=4.207, nll_loss=2.59, ppl=6.02, wps=52569.9, ups=0.92, wpb=57078, bsz=1454.9, num_updates=80800, lr=0.000222497, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=88926
2023-05-26 19:04:01 | INFO | train_inner | epoch 013:    802 / 6686 loss=4.197, nll_loss=2.579, ppl=5.97, wps=52538.3, ups=0.92, wpb=57359.6, bsz=1476.8, num_updates=80900, lr=0.00022236, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=89035
2023-05-26 19:05:49 | INFO | train_inner | epoch 013:    902 / 6686 loss=4.198, nll_loss=2.579, ppl=5.98, wps=52865.3, ups=0.92, wpb=57163.8, bsz=1481.5, num_updates=81000, lr=0.000222222, gnorm=0.25, clip=100, loss_scale=32, train_wall=104, wall=89143
2023-05-26 19:07:38 | INFO | train_inner | epoch 013:   1002 / 6686 loss=4.194, nll_loss=2.575, ppl=5.96, wps=52669.2, ups=0.92, wpb=57195.3, bsz=1490.6, num_updates=81100, lr=0.000222085, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=89252
2023-05-26 19:09:21 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 19:09:28 | INFO | train_inner | epoch 013:   1103 / 6686 loss=4.189, nll_loss=2.569, ppl=5.93, wps=52176, ups=0.91, wpb=57335.7, bsz=1480.3, num_updates=81200, lr=0.000221948, gnorm=0.25, clip=100, loss_scale=34, train_wall=106, wall=89362
2023-05-26 19:11:17 | INFO | train_inner | epoch 013:   1203 / 6686 loss=4.203, nll_loss=2.586, ppl=6, wps=52516, ups=0.92, wpb=57172.9, bsz=1500, num_updates=81300, lr=0.000221812, gnorm=0.25, clip=100, loss_scale=32, train_wall=105, wall=89471
2023-05-26 19:13:06 | INFO | train_inner | epoch 013:   1303 / 6686 loss=4.197, nll_loss=2.578, ppl=5.97, wps=52374.5, ups=0.91, wpb=57356.8, bsz=1468.8, num_updates=81400, lr=0.000221676, gnorm=0.253, clip=100, loss_scale=32, train_wall=106, wall=89580
2023-05-26 19:14:54 | INFO | train_inner | epoch 013:   1403 / 6686 loss=4.213, nll_loss=2.597, ppl=6.05, wps=52712.2, ups=0.92, wpb=57084.2, bsz=1441.9, num_updates=81500, lr=0.00022154, gnorm=0.25, clip=100, loss_scale=32, train_wall=105, wall=89689
2023-05-26 19:16:43 | INFO | train_inner | epoch 013:   1503 / 6686 loss=4.199, nll_loss=2.581, ppl=5.98, wps=52541.7, ups=0.92, wpb=57150.2, bsz=1507.8, num_updates=81600, lr=0.000221404, gnorm=0.246, clip=100, loss_scale=32, train_wall=105, wall=89797
2023-05-26 19:18:32 | INFO | train_inner | epoch 013:   1603 / 6686 loss=4.206, nll_loss=2.588, ppl=6.01, wps=52661.2, ups=0.92, wpb=57072.6, bsz=1462.3, num_updates=81700, lr=0.000221268, gnorm=0.254, clip=100, loss_scale=32, train_wall=105, wall=89906
2023-05-26 19:19:17 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 19:20:21 | INFO | train_inner | epoch 013:   1704 / 6686 loss=4.199, nll_loss=2.581, ppl=5.98, wps=52092.7, ups=0.91, wpb=57205.5, bsz=1485, num_updates=81800, lr=0.000221133, gnorm=0.251, clip=100, loss_scale=43, train_wall=106, wall=90016
2023-05-26 19:22:10 | INFO | train_inner | epoch 013:   1804 / 6686 loss=4.209, nll_loss=2.592, ppl=6.03, wps=52284.5, ups=0.92, wpb=57029.2, bsz=1465.5, num_updates=81900, lr=0.000220998, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=90125
2023-05-26 19:24:00 | INFO | train_inner | epoch 013:   1904 / 6686 loss=4.21, nll_loss=2.594, ppl=6.04, wps=52434.2, ups=0.92, wpb=57293, bsz=1474.2, num_updates=82000, lr=0.000220863, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=90234
2023-05-26 19:25:48 | INFO | train_inner | epoch 013:   2004 / 6686 loss=4.207, nll_loss=2.59, ppl=6.02, wps=52512, ups=0.92, wpb=57033.5, bsz=1458.6, num_updates=82100, lr=0.000220729, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=90342
2023-05-26 19:27:37 | INFO | train_inner | epoch 013:   2104 / 6686 loss=4.197, nll_loss=2.579, ppl=5.97, wps=52534.8, ups=0.92, wpb=57269, bsz=1483.2, num_updates=82200, lr=0.000220594, gnorm=0.252, clip=100, loss_scale=32, train_wall=105, wall=90451
2023-05-26 19:28:53 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 19:29:27 | INFO | train_inner | epoch 013:   2205 / 6686 loss=4.197, nll_loss=2.579, ppl=5.97, wps=52057.8, ups=0.91, wpb=57087.4, bsz=1469.9, num_updates=82300, lr=0.00022046, gnorm=0.25, clip=100, loss_scale=37, train_wall=106, wall=90561
2023-05-26 19:31:15 | INFO | train_inner | epoch 013:   2305 / 6686 loss=4.197, nll_loss=2.579, ppl=5.98, wps=52757.4, ups=0.92, wpb=57134.8, bsz=1466.3, num_updates=82400, lr=0.000220326, gnorm=0.251, clip=100, loss_scale=32, train_wall=105, wall=90669
2023-05-26 19:33:05 | INFO | train_inner | epoch 013:   2405 / 6686 loss=4.198, nll_loss=2.58, ppl=5.98, wps=52085.2, ups=0.91, wpb=57225.5, bsz=1496.4, num_updates=82500, lr=0.000220193, gnorm=0.25, clip=100, loss_scale=32, train_wall=106, wall=90779
2023-05-26 19:34:54 | INFO | train_inner | epoch 013:   2505 / 6686 loss=4.208, nll_loss=2.592, ppl=6.03, wps=52484.3, ups=0.92, wpb=57117.8, bsz=1456.6, num_updates=82600, lr=0.000220059, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=90888
2023-05-26 19:36:43 | INFO | train_inner | epoch 013:   2605 / 6686 loss=4.204, nll_loss=2.587, ppl=6.01, wps=52464.6, ups=0.92, wpb=57191.7, bsz=1480.6, num_updates=82700, lr=0.000219926, gnorm=0.25, clip=100, loss_scale=32, train_wall=105, wall=90997
2023-05-26 19:38:12 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 19:38:33 | INFO | train_inner | epoch 013:   2706 / 6686 loss=4.207, nll_loss=2.59, ppl=6.02, wps=52164.6, ups=0.91, wpb=57276.7, bsz=1486.7, num_updates=82800, lr=0.000219793, gnorm=0.251, clip=100, loss_scale=32, train_wall=106, wall=91107
2023-05-26 19:40:22 | INFO | train_inner | epoch 013:   2806 / 6686 loss=4.203, nll_loss=2.586, ppl=6, wps=52442.8, ups=0.92, wpb=57107, bsz=1509.2, num_updates=82900, lr=0.000219661, gnorm=0.25, clip=100, loss_scale=32, train_wall=105, wall=91216
2023-05-26 19:40:27 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 19:42:12 | INFO | train_inner | epoch 013:   2907 / 6686 loss=4.195, nll_loss=2.576, ppl=5.96, wps=51872.8, ups=0.91, wpb=57018.3, bsz=1473.8, num_updates=83000, lr=0.000219529, gnorm=0.251, clip=100, loss_scale=17, train_wall=106, wall=91326
2023-05-26 19:44:01 | INFO | train_inner | epoch 013:   3007 / 6686 loss=4.205, nll_loss=2.588, ppl=6.01, wps=52449.2, ups=0.92, wpb=57161.4, bsz=1467.4, num_updates=83100, lr=0.000219396, gnorm=0.249, clip=100, loss_scale=16, train_wall=105, wall=91435
2023-05-26 19:45:49 | INFO | train_inner | epoch 013:   3107 / 6686 loss=4.202, nll_loss=2.585, ppl=6, wps=52693.3, ups=0.92, wpb=57189.7, bsz=1488.6, num_updates=83200, lr=0.000219265, gnorm=0.249, clip=100, loss_scale=16, train_wall=105, wall=91543
2023-05-26 19:47:38 | INFO | train_inner | epoch 013:   3207 / 6686 loss=4.211, nll_loss=2.595, ppl=6.04, wps=52612.2, ups=0.92, wpb=57118.3, bsz=1465, num_updates=83300, lr=0.000219133, gnorm=0.25, clip=100, loss_scale=16, train_wall=105, wall=91652
2023-05-26 19:49:27 | INFO | train_inner | epoch 013:   3307 / 6686 loss=4.204, nll_loss=2.587, ppl=6.01, wps=52493.8, ups=0.92, wpb=57121.2, bsz=1482.3, num_updates=83400, lr=0.000219001, gnorm=0.25, clip=100, loss_scale=16, train_wall=105, wall=91761
2023-05-26 19:51:16 | INFO | train_inner | epoch 013:   3407 / 6686 loss=4.205, nll_loss=2.588, ppl=6.01, wps=52491.9, ups=0.91, wpb=57400.1, bsz=1488.2, num_updates=83500, lr=0.00021887, gnorm=0.247, clip=100, loss_scale=30, train_wall=105, wall=91870
2023-05-26 19:53:05 | INFO | train_inner | epoch 013:   3507 / 6686 loss=4.205, nll_loss=2.589, ppl=6.02, wps=52469, ups=0.92, wpb=57056.7, bsz=1488.5, num_updates=83600, lr=0.000218739, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=91979
2023-05-26 19:54:54 | INFO | train_inner | epoch 013:   3607 / 6686 loss=4.213, nll_loss=2.597, ppl=6.05, wps=52653, ups=0.92, wpb=57345.4, bsz=1472.9, num_updates=83700, lr=0.000218609, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=92088
2023-05-26 19:56:42 | INFO | train_inner | epoch 013:   3707 / 6686 loss=4.217, nll_loss=2.602, ppl=6.07, wps=52755.3, ups=0.92, wpb=57300.7, bsz=1467.7, num_updates=83800, lr=0.000218478, gnorm=0.253, clip=100, loss_scale=32, train_wall=105, wall=92196
2023-05-26 19:58:31 | INFO | train_inner | epoch 013:   3807 / 6686 loss=4.194, nll_loss=2.575, ppl=5.96, wps=52675.8, ups=0.92, wpb=57171, bsz=1501, num_updates=83900, lr=0.000218348, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=92305
2023-05-26 19:59:07 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 20:00:21 | INFO | train_inner | epoch 013:   3908 / 6686 loss=4.208, nll_loss=2.592, ppl=6.03, wps=52119, ups=0.91, wpb=57342.3, bsz=1492.6, num_updates=84000, lr=0.000218218, gnorm=0.247, clip=100, loss_scale=34, train_wall=106, wall=92415
2023-05-26 20:02:10 | INFO | train_inner | epoch 013:   4008 / 6686 loss=4.197, nll_loss=2.579, ppl=5.97, wps=52606.2, ups=0.92, wpb=57253.7, bsz=1478.4, num_updates=84100, lr=0.000218088, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=92524
2023-05-26 20:03:58 | INFO | train_inner | epoch 013:   4108 / 6686 loss=4.199, nll_loss=2.582, ppl=5.99, wps=52699.8, ups=0.92, wpb=57334.7, bsz=1480.2, num_updates=84200, lr=0.000217959, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=92633
2023-05-26 20:05:47 | INFO | train_inner | epoch 013:   4208 / 6686 loss=4.216, nll_loss=2.6, ppl=6.06, wps=52523.3, ups=0.92, wpb=57215.5, bsz=1471.4, num_updates=84300, lr=0.000217829, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=92742
2023-05-26 20:07:36 | INFO | train_inner | epoch 013:   4308 / 6686 loss=4.219, nll_loss=2.604, ppl=6.08, wps=52731.9, ups=0.92, wpb=57131.5, bsz=1471, num_updates=84400, lr=0.0002177, gnorm=0.25, clip=100, loss_scale=32, train_wall=105, wall=92850
2023-05-26 20:08:29 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 20:09:26 | INFO | train_inner | epoch 013:   4409 / 6686 loss=4.211, nll_loss=2.595, ppl=6.04, wps=52081.1, ups=0.91, wpb=57345.5, bsz=1485.2, num_updates=84500, lr=0.000217571, gnorm=0.253, clip=100, loss_scale=34, train_wall=106, wall=92960
2023-05-26 20:11:15 | INFO | train_inner | epoch 013:   4509 / 6686 loss=4.21, nll_loss=2.594, ppl=6.04, wps=52419.8, ups=0.92, wpb=57131.7, bsz=1477.4, num_updates=84600, lr=0.000217443, gnorm=0.25, clip=100, loss_scale=32, train_wall=105, wall=93069
2023-05-26 20:13:04 | INFO | train_inner | epoch 013:   4609 / 6686 loss=4.206, nll_loss=2.589, ppl=6.02, wps=52547.7, ups=0.92, wpb=57162.7, bsz=1476.2, num_updates=84700, lr=0.000217314, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=93178
2023-05-26 20:14:52 | INFO | train_inner | epoch 013:   4709 / 6686 loss=4.208, nll_loss=2.592, ppl=6.03, wps=52513.9, ups=0.92, wpb=57115.7, bsz=1476.4, num_updates=84800, lr=0.000217186, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=93287
2023-05-26 20:16:41 | INFO | train_inner | epoch 013:   4809 / 6686 loss=4.201, nll_loss=2.584, ppl=6, wps=52513.2, ups=0.92, wpb=57151.2, bsz=1480.6, num_updates=84900, lr=0.000217058, gnorm=0.252, clip=100, loss_scale=32, train_wall=105, wall=93395
2023-05-26 20:18:04 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 20:18:31 | INFO | train_inner | epoch 013:   4910 / 6686 loss=4.206, nll_loss=2.589, ppl=6.02, wps=52224, ups=0.91, wpb=57220.9, bsz=1467.8, num_updates=85000, lr=0.00021693, gnorm=0.25, clip=100, loss_scale=37, train_wall=106, wall=93505
2023-05-26 20:20:19 | INFO | train_inner | epoch 013:   5010 / 6686 loss=4.205, nll_loss=2.588, ppl=6.01, wps=52699.9, ups=0.92, wpb=57207.6, bsz=1500.6, num_updates=85100, lr=0.000216803, gnorm=0.25, clip=100, loss_scale=32, train_wall=105, wall=93614
2023-05-26 20:22:08 | INFO | train_inner | epoch 013:   5110 / 6686 loss=4.209, nll_loss=2.592, ppl=6.03, wps=52455.3, ups=0.92, wpb=57101.7, bsz=1448.6, num_updates=85200, lr=0.000216676, gnorm=0.251, clip=100, loss_scale=32, train_wall=105, wall=93722
2023-05-26 20:22:55 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 20:23:58 | INFO | train_inner | epoch 013:   5211 / 6686 loss=4.198, nll_loss=2.581, ppl=5.98, wps=51898.9, ups=0.91, wpb=57184.3, bsz=1493.1, num_updates=85300, lr=0.000216549, gnorm=0.248, clip=100, loss_scale=23, train_wall=106, wall=93833
2023-05-26 20:25:47 | INFO | train_inner | epoch 013:   5311 / 6686 loss=4.205, nll_loss=2.588, ppl=6.01, wps=52800.9, ups=0.92, wpb=57256.2, bsz=1484.6, num_updates=85400, lr=0.000216422, gnorm=0.25, clip=100, loss_scale=16, train_wall=105, wall=93941
2023-05-26 20:27:35 | INFO | train_inner | epoch 013:   5411 / 6686 loss=4.205, nll_loss=2.588, ppl=6.01, wps=52699.3, ups=0.92, wpb=57235.3, bsz=1474.3, num_updates=85500, lr=0.000216295, gnorm=0.251, clip=100, loss_scale=16, train_wall=105, wall=94050
2023-05-26 20:29:24 | INFO | train_inner | epoch 013:   5511 / 6686 loss=4.206, nll_loss=2.59, ppl=6.02, wps=52778.6, ups=0.92, wpb=57347, bsz=1490.8, num_updates=85600, lr=0.000216169, gnorm=0.249, clip=100, loss_scale=16, train_wall=105, wall=94158
2023-05-26 20:31:13 | INFO | train_inner | epoch 013:   5611 / 6686 loss=4.199, nll_loss=2.582, ppl=5.99, wps=52577.9, ups=0.92, wpb=57191.1, bsz=1475.6, num_updates=85700, lr=0.000216043, gnorm=0.252, clip=100, loss_scale=16, train_wall=105, wall=94267
2023-05-26 20:33:02 | INFO | train_inner | epoch 013:   5711 / 6686 loss=4.21, nll_loss=2.594, ppl=6.04, wps=52306.1, ups=0.92, wpb=57049.4, bsz=1472.2, num_updates=85800, lr=0.000215917, gnorm=0.25, clip=100, loss_scale=24, train_wall=105, wall=94376
2023-05-26 20:34:51 | INFO | train_inner | epoch 013:   5811 / 6686 loss=4.206, nll_loss=2.589, ppl=6.02, wps=52450.8, ups=0.92, wpb=57100, bsz=1488.5, num_updates=85900, lr=0.000215791, gnorm=0.251, clip=100, loss_scale=32, train_wall=105, wall=94485
2023-05-26 20:36:40 | INFO | train_inner | epoch 013:   5911 / 6686 loss=4.212, nll_loss=2.597, ppl=6.05, wps=52629.3, ups=0.92, wpb=57208.5, bsz=1489.1, num_updates=86000, lr=0.000215666, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=94594
2023-05-26 20:38:28 | INFO | train_inner | epoch 013:   6011 / 6686 loss=4.208, nll_loss=2.592, ppl=6.03, wps=52601, ups=0.92, wpb=57204.9, bsz=1472.2, num_updates=86100, lr=0.00021554, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=94702
2023-05-26 20:40:18 | INFO | train_inner | epoch 013:   6111 / 6686 loss=4.217, nll_loss=2.602, ppl=6.07, wps=52415.5, ups=0.92, wpb=57270.4, bsz=1469.3, num_updates=86200, lr=0.000215415, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=94812
2023-05-26 20:41:58 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 20:42:08 | INFO | train_inner | epoch 013:   6212 / 6686 loss=4.226, nll_loss=2.612, ppl=6.11, wps=51981.9, ups=0.91, wpb=57154.4, bsz=1448.1, num_updates=86300, lr=0.00021529, gnorm=0.252, clip=100, loss_scale=40, train_wall=106, wall=94922
2023-05-26 20:42:52 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 20:43:58 | INFO | train_inner | epoch 013:   6313 / 6686 loss=4.203, nll_loss=2.587, ppl=6.01, wps=51962, ups=0.91, wpb=57172.8, bsz=1467.7, num_updates=86400, lr=0.000215166, gnorm=0.251, clip=100, loss_scale=22, train_wall=106, wall=95032
2023-05-26 20:45:46 | INFO | train_inner | epoch 013:   6413 / 6686 loss=4.209, nll_loss=2.593, ppl=6.03, wps=52795.8, ups=0.92, wpb=57294.3, bsz=1461.3, num_updates=86500, lr=0.000215041, gnorm=0.249, clip=100, loss_scale=16, train_wall=105, wall=95140
2023-05-26 20:47:35 | INFO | train_inner | epoch 013:   6513 / 6686 loss=4.194, nll_loss=2.576, ppl=5.96, wps=52682.8, ups=0.92, wpb=57167.6, bsz=1482.6, num_updates=86600, lr=0.000214917, gnorm=0.248, clip=100, loss_scale=16, train_wall=105, wall=95249
2023-05-26 20:49:23 | INFO | train_inner | epoch 013:   6613 / 6686 loss=4.208, nll_loss=2.592, ppl=6.03, wps=52655.4, ups=0.92, wpb=57092.7, bsz=1477.1, num_updates=86700, lr=0.000214793, gnorm=0.252, clip=100, loss_scale=16, train_wall=105, wall=95357
2023-05-26 20:50:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-26 20:50:47 | INFO | fairseq.tasks.translation | example hypothesis: Why was that?
2023-05-26 20:50:47 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-26 20:50:47 | INFO | fairseq.tasks.translation | example hypothesis: I’ll make you lose so much that you don’t even have pants left!
2023-05-26 20:50:47 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-26 20:50:48 | INFO | fairseq.tasks.translation | example hypothesis: Just as Shen Liangchuan heaved a sigh of relief, she said, “I’ll call you in the same room!”
2023-05-26 20:50:48 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-26 20:50:48 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved her hand and entered the elevator.
2023-05-26 20:50:48 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-26 20:50:49 | INFO | fairseq.tasks.translation | example hypothesis: She raised her head and saw Song Cheng standing in the distance!
2023-05-26 20:50:49 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-26 20:50:50 | INFO | fairseq.tasks.translation | example hypothesis: Then, Song Cheng patted his chest. “You scared me to death! Where’s Wang Chuan?”
2023-05-26 20:50:50 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-26 20:50:51 | INFO | fairseq.tasks.translation | example hypothesis: I said, “No, I can’t eat it.”
2023-05-26 20:50:51 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-26 20:50:51 | INFO | fairseq.tasks.translation | example hypothesis: Dreadful first, everyone didn’t believe it, but Wang Wenhao insisted on it, making the public opinion lean towards Wang Wenhao.
2023-05-26 20:50:51 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-26 20:50:52 | INFO | fairseq.tasks.translation | example hypothesis: With his status, coming here like this, Baili Hongzhuang had to be treated even if he did not want to!
2023-05-26 20:50:52 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-26 20:50:53 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian said, “Mr. Shen, I-I’ve kept too much blood and my brain lacks oxygen. I can’t figure it out. Why don’t you give me a hint?”
2023-05-26 20:50:53 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-26 20:50:54 | INFO | fairseq.tasks.translation | example hypothesis: He didn’t know why so many people had heard about it. Since he couldn’t hide it anymore, he might as well tell them.
2023-05-26 20:50:54 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-26 20:50:55 | INFO | fairseq.tasks.translation | example hypothesis: She deliberately lowered her voice, but it was unable to conceal the viciousness and ruthlessness in her tone.
2023-05-26 20:50:55 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-26 20:50:56 | INFO | fairseq.tasks.translation | example hypothesis: Different levels of beast pets had different strengths, but a beast pet was precious and rare. It was impossible for an ordinary person to possess it, and even an official’s child wouldn’t be able to possess it.
2023-05-26 20:50:56 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-26 20:50:57 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chixia clenched her teeth and cursed in a low voice.
2023-05-26 20:50:57 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-26 20:50:58 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang had concealed it very well, Di Bei Chen could still see the waves flashing across her eyes, and his eyes were filled with warmth.
2023-05-26 20:50:58 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-26 20:50:59 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia walked in, she didn't even see a few waiters, let alone the guests.
2023-05-26 20:50:59 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-26 20:51:00 | INFO | fairseq.tasks.translation | example hypothesis: This person was the Fourth Miss of the Ye Family, Ye Qing Ling.
2023-05-26 20:51:00 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-26 20:51:01 | INFO | fairseq.tasks.translation | example hypothesis: At this moment, she felt as if her chin was about to shatter.
2023-05-26 20:51:01 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-26 20:51:02 | INFO | fairseq.tasks.translation | example hypothesis: “Alright Mu Zi, help me. If it wasn't for you, that old man wouldn't have targeted me.”
2023-05-26 20:51:02 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-26 20:51:03 | INFO | fairseq.tasks.translation | example hypothesis: Baili Yu Yan was even more excited. She was the one in charge of this matter. She would definitely make things difficult for Baili Hong Zhuang if Baili Hong Zhuang treated her like this before.
2023-05-26 20:51:03 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-26 20:51:05 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How could that be? They also have four mages on their side, so of course they wouldn’t surrender so easily. After arguing for a long time, they finally decided on how to obtain control over the Kingdom of Axia through the competition.”
2023-05-26 20:51:05 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-26 20:51:06 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a little. Originally, he had been looking for a reason for Li Yuyue not being able to participate in the royal hunting competition.
2023-05-26 20:51:06 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-26 20:51:07 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my level enough? They’re all the best talents in the nation. Is my magic that weak?”
2023-05-26 20:51:07 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-26 20:51:09 | INFO | fairseq.tasks.translation | example hypothesis: Yi Luo’s meaning was that if Fang Chi Xia didn’t want to go, then there was no need to go.
2023-05-26 20:51:09 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-26 20:51:11 | INFO | fairseq.tasks.translation | example hypothesis: She tilted her head and saw that the five palm marks on her face were very eye-catching. They were swelling at a speed visible to the naked eye. When she reached out to touch them, she could not help but hiss.
2023-05-26 20:51:11 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-26 20:51:12 | INFO | fairseq.tasks.translation | example hypothesis: This... how could this be the charm that that trash could emit?
2023-05-26 20:51:12 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-26 20:51:13 | INFO | fairseq.tasks.translation | example hypothesis: How could Wang Wenhao have found the newspaper firm? The chief editor should have called to tell her not to come to the newspaper firm, but these three people... had schemed against her!
2023-05-26 20:51:13 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-26 20:51:16 | INFO | fairseq.tasks.translation | example hypothesis: Hearing Teacher Di’s praise, I was delighted. I retracted the energy ball with my left hand, and a light sword shot out from my right hand towards Teacher Zhen. I was shocked to see that the light sword was able to land smoothly on me. Upon closer inspection, I realized that it was just an afterimage.
2023-05-26 20:51:16 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-26 20:51:19 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Initially, our side proposed a competition of three wins and two wins, but they said it wasn’t fair, because we had Teacher Dy and Teacher Zhen, and their ranking was higher than theirs, so they proposed five wins and three wins. Since we were the ones who proposed the competition, we could only listen to them in the end. Three days later, we will have a secret competition in the Royal Colosseum. If we don’t
2023-05-26 20:51:19 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-26 20:51:20 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Di had used a level-7 light spell, Light Thunder Burst. I rarely used this spell because my control over it wasn’t very good. Teacher Di had cast nine Light Thunder Bursts to surround me, forming a simple spell formation that prevented me from escaping in a short distance. After that, the Light Thunder Bursts exploded in succession to form a powerful attack.
2023-05-26 20:51:20 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-26 20:51:23 | INFO | fairseq.tasks.translation | example hypothesis: As soon as Mark and the two teachers walked to the other side, Teacher Zhen sent out a Small Dimension Slash at me. As expected of the continent’s number one Magician. The suction force of his Small Dimension Slash was much stronger than mine. A small spatial crack appeared beside me, and a strong suction force swept towards me.
2023-05-26 20:51:23 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-26 20:51:24 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.181 | nll_loss 2.536 | ppl 5.8 | bleu 21.42 | wps 1980.3 | wpb 2420.8 | bsz 84.5 | num_updates 86773 | best_bleu 21.5
2023-05-26 20:51:24 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-26 20:51:35 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/concat-1-1-0.2-sf[zh-en]/checkpoint13.pt (epoch 13 @ 86773 updates, score 21.42) (writing took 11.28349651582539 seconds)
2023-05-26 20:51:35 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-05-26 20:51:35 | INFO | train | epoch 013 | loss 4.203 | nll_loss 2.586 | ppl 6 | wps 51818.8 | ups 0.91 | wpb 57190.2 | bsz 1477.5 | num_updates 86773 | lr 0.000214703 | gnorm 0.25 | clip 100 | loss_scale 29 | train_wall 7028 | wall 95489
2023-05-26 20:51:35 | INFO | fairseq.trainer | begin training epoch 14
2023-05-26 20:52:26 | INFO | train_inner | epoch 014:     27 / 6686 loss=4.193, nll_loss=2.575, ppl=5.96, wps=30980.6, ups=0.55, wpb=56673.1, bsz=1479.7, num_updates=86800, lr=0.000214669, gnorm=0.255, clip=100, loss_scale=16, train_wall=106, wall=95540
2023-05-26 20:54:27 | INFO | train_inner | epoch 014:    127 / 6686 loss=4.182, nll_loss=2.562, ppl=5.91, wps=47241.2, ups=0.83, wpb=57006.3, bsz=1464.8, num_updates=86900, lr=0.000214546, gnorm=0.251, clip=100, loss_scale=24, train_wall=109, wall=95661
2023-05-26 20:56:23 | INFO | train_inner | epoch 014:    227 / 6686 loss=4.184, nll_loss=2.564, ppl=5.91, wps=49145, ups=0.86, wpb=57246.1, bsz=1476.5, num_updates=87000, lr=0.000214423, gnorm=0.247, clip=100, loss_scale=32, train_wall=108, wall=95777
2023-05-26 20:58:14 | INFO | train_inner | epoch 014:    327 / 6686 loss=4.189, nll_loss=2.57, ppl=5.94, wps=51833.3, ups=0.9, wpb=57461.5, bsz=1465.3, num_updates=87100, lr=0.000214299, gnorm=0.249, clip=100, loss_scale=32, train_wall=106, wall=95888
2023-05-26 20:59:44 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 21:00:05 | INFO | train_inner | epoch 014:    428 / 6686 loss=4.181, nll_loss=2.561, ppl=5.9, wps=51916.9, ups=0.9, wpb=57385.2, bsz=1491.9, num_updates=87200, lr=0.000214176, gnorm=0.25, clip=100, loss_scale=29, train_wall=106, wall=95999
2023-05-26 21:01:54 | INFO | train_inner | epoch 014:    528 / 6686 loss=4.186, nll_loss=2.566, ppl=5.92, wps=52030, ups=0.91, wpb=56995.1, bsz=1475.4, num_updates=87300, lr=0.000214054, gnorm=0.25, clip=100, loss_scale=16, train_wall=106, wall=96108
2023-05-26 21:03:43 | INFO | train_inner | epoch 014:    628 / 6686 loss=4.187, nll_loss=2.567, ppl=5.93, wps=52609.8, ups=0.92, wpb=57244.2, bsz=1472.7, num_updates=87400, lr=0.000213931, gnorm=0.25, clip=100, loss_scale=16, train_wall=105, wall=96217
2023-05-26 21:05:32 | INFO | train_inner | epoch 014:    728 / 6686 loss=4.188, nll_loss=2.568, ppl=5.93, wps=52383.7, ups=0.92, wpb=57092.6, bsz=1460.2, num_updates=87500, lr=0.000213809, gnorm=0.25, clip=100, loss_scale=16, train_wall=105, wall=96326
2023-05-26 21:07:21 | INFO | train_inner | epoch 014:    828 / 6686 loss=4.193, nll_loss=2.575, ppl=5.96, wps=52632.2, ups=0.92, wpb=57206.5, bsz=1476.8, num_updates=87600, lr=0.000213687, gnorm=0.249, clip=100, loss_scale=16, train_wall=105, wall=96435
2023-05-26 21:09:09 | INFO | train_inner | epoch 014:    928 / 6686 loss=4.196, nll_loss=2.578, ppl=5.97, wps=52686.1, ups=0.92, wpb=57213.7, bsz=1455.2, num_updates=87700, lr=0.000213565, gnorm=0.248, clip=100, loss_scale=17, train_wall=105, wall=96543
2023-05-26 21:10:58 | INFO | train_inner | epoch 014:   1028 / 6686 loss=4.199, nll_loss=2.582, ppl=5.99, wps=52438.4, ups=0.92, wpb=57067.4, bsz=1470.1, num_updates=87800, lr=0.000213443, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=96652
2023-05-26 21:12:16 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 21:12:48 | INFO | train_inner | epoch 014:   1129 / 6686 loss=4.184, nll_loss=2.564, ppl=5.91, wps=51965.1, ups=0.91, wpb=57233.4, bsz=1493.7, num_updates=87900, lr=0.000213322, gnorm=0.253, clip=100, loss_scale=27, train_wall=106, wall=96762
2023-05-26 21:14:37 | INFO | train_inner | epoch 014:   1229 / 6686 loss=4.191, nll_loss=2.572, ppl=5.95, wps=52576, ups=0.92, wpb=57284.6, bsz=1476.8, num_updates=88000, lr=0.000213201, gnorm=0.251, clip=100, loss_scale=16, train_wall=105, wall=96871
2023-05-26 21:16:26 | INFO | train_inner | epoch 014:   1329 / 6686 loss=4.198, nll_loss=2.58, ppl=5.98, wps=52444.7, ups=0.92, wpb=57035.8, bsz=1486.9, num_updates=88100, lr=0.00021308, gnorm=0.251, clip=100, loss_scale=16, train_wall=105, wall=96980
2023-05-26 21:18:15 | INFO | train_inner | epoch 014:   1429 / 6686 loss=4.186, nll_loss=2.567, ppl=5.93, wps=52566.7, ups=0.92, wpb=57224.5, bsz=1496.6, num_updates=88200, lr=0.000212959, gnorm=0.253, clip=100, loss_scale=16, train_wall=105, wall=97089
2023-05-26 21:20:03 | INFO | train_inner | epoch 014:   1529 / 6686 loss=4.194, nll_loss=2.576, ppl=5.96, wps=52714, ups=0.92, wpb=57223.5, bsz=1477.1, num_updates=88300, lr=0.000212838, gnorm=0.252, clip=100, loss_scale=16, train_wall=105, wall=97197
2023-05-26 21:21:52 | INFO | train_inner | epoch 014:   1629 / 6686 loss=4.193, nll_loss=2.574, ppl=5.96, wps=52493, ups=0.92, wpb=57119.1, bsz=1487.8, num_updates=88400, lr=0.000212718, gnorm=0.252, clip=100, loss_scale=19, train_wall=105, wall=97306
2023-05-26 21:23:41 | INFO | train_inner | epoch 014:   1729 / 6686 loss=4.2, nll_loss=2.582, ppl=5.99, wps=52542.5, ups=0.92, wpb=57195.2, bsz=1463.1, num_updates=88500, lr=0.000212598, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=97415
2023-05-26 21:25:30 | INFO | train_inner | epoch 014:   1829 / 6686 loss=4.182, nll_loss=2.562, ppl=5.9, wps=52738, ups=0.92, wpb=57239.9, bsz=1497.4, num_updates=88600, lr=0.000212478, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=97524
2023-05-26 21:27:18 | INFO | train_inner | epoch 014:   1929 / 6686 loss=4.197, nll_loss=2.579, ppl=5.98, wps=52592.8, ups=0.92, wpb=57008.2, bsz=1474.7, num_updates=88700, lr=0.000212358, gnorm=0.253, clip=100, loss_scale=32, train_wall=104, wall=97632
2023-05-26 21:29:07 | INFO | train_inner | epoch 014:   2029 / 6686 loss=4.184, nll_loss=2.564, ppl=5.91, wps=52651.4, ups=0.92, wpb=57304.4, bsz=1496.7, num_updates=88800, lr=0.000212238, gnorm=0.252, clip=100, loss_scale=32, train_wall=105, wall=97741
2023-05-26 21:30:56 | INFO | train_inner | epoch 014:   2129 / 6686 loss=4.196, nll_loss=2.578, ppl=5.97, wps=52571, ups=0.92, wpb=57234.1, bsz=1460.1, num_updates=88900, lr=0.000212119, gnorm=0.25, clip=100, loss_scale=34, train_wall=105, wall=97850
2023-05-26 21:30:59 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 21:32:46 | INFO | train_inner | epoch 014:   2230 / 6686 loss=4.199, nll_loss=2.581, ppl=5.98, wps=51969.6, ups=0.91, wpb=57333.8, bsz=1470.2, num_updates=89000, lr=0.000212, gnorm=0.248, clip=100, loss_scale=33, train_wall=106, wall=97960
2023-05-26 21:34:35 | INFO | train_inner | epoch 014:   2330 / 6686 loss=4.196, nll_loss=2.578, ppl=5.97, wps=52481.7, ups=0.92, wpb=57093.7, bsz=1482, num_updates=89100, lr=0.000211881, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=98069
2023-05-26 21:36:24 | INFO | train_inner | epoch 014:   2430 / 6686 loss=4.189, nll_loss=2.57, ppl=5.94, wps=52417.1, ups=0.92, wpb=57241.6, bsz=1487.8, num_updates=89200, lr=0.000211762, gnorm=0.247, clip=100, loss_scale=32, train_wall=105, wall=98178
2023-05-26 21:38:13 | INFO | train_inner | epoch 014:   2530 / 6686 loss=4.188, nll_loss=2.569, ppl=5.93, wps=52531.6, ups=0.92, wpb=57125.3, bsz=1492.2, num_updates=89300, lr=0.000211643, gnorm=0.25, clip=100, loss_scale=32, train_wall=105, wall=98287
2023-05-26 21:40:02 | INFO | train_inner | epoch 014:   2630 / 6686 loss=4.191, nll_loss=2.573, ppl=5.95, wps=52561, ups=0.92, wpb=57239.2, bsz=1460.9, num_updates=89400, lr=0.000211525, gnorm=0.25, clip=100, loss_scale=32, train_wall=105, wall=98396
2023-05-26 21:40:20 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 21:41:52 | INFO | train_inner | epoch 014:   2731 / 6686 loss=4.185, nll_loss=2.566, ppl=5.92, wps=51926.4, ups=0.91, wpb=57297, bsz=1491, num_updates=89500, lr=0.000211407, gnorm=0.247, clip=100, loss_scale=33, train_wall=106, wall=98506
2023-05-26 21:43:40 | INFO | train_inner | epoch 014:   2831 / 6686 loss=4.188, nll_loss=2.569, ppl=5.93, wps=52714.9, ups=0.92, wpb=57218.2, bsz=1486.3, num_updates=89600, lr=0.000211289, gnorm=0.253, clip=100, loss_scale=32, train_wall=105, wall=98615
2023-05-26 21:43:45 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 21:45:30 | INFO | train_inner | epoch 014:   2932 / 6686 loss=4.197, nll_loss=2.579, ppl=5.98, wps=52161.7, ups=0.91, wpb=57151.9, bsz=1479.3, num_updates=89700, lr=0.000211171, gnorm=0.25, clip=100, loss_scale=16, train_wall=106, wall=98724
2023-05-26 21:47:19 | INFO | train_inner | epoch 014:   3032 / 6686 loss=4.191, nll_loss=2.572, ppl=5.95, wps=52570.3, ups=0.92, wpb=57194.5, bsz=1471.4, num_updates=89800, lr=0.000211053, gnorm=0.25, clip=100, loss_scale=16, train_wall=105, wall=98833
2023-05-26 21:49:07 | INFO | train_inner | epoch 014:   3132 / 6686 loss=4.211, nll_loss=2.595, ppl=6.04, wps=52793.9, ups=0.92, wpb=57118.1, bsz=1475.5, num_updates=89900, lr=0.000210936, gnorm=0.252, clip=100, loss_scale=16, train_wall=104, wall=98941
2023-05-26 21:50:56 | INFO | train_inner | epoch 014:   3232 / 6686 loss=4.189, nll_loss=2.57, ppl=5.94, wps=52373.1, ups=0.91, wpb=57258, bsz=1465.7, num_updates=90000, lr=0.000210819, gnorm=0.251, clip=100, loss_scale=16, train_wall=106, wall=99051
2023-05-26 21:52:44 | INFO | train_inner | epoch 014:   3332 / 6686 loss=4.202, nll_loss=2.585, ppl=6, wps=52927.7, ups=0.93, wpb=57137.2, bsz=1459.9, num_updates=90100, lr=0.000210701, gnorm=0.253, clip=100, loss_scale=16, train_wall=104, wall=99158
2023-05-26 21:54:33 | INFO | train_inner | epoch 014:   3432 / 6686 loss=4.195, nll_loss=2.577, ppl=5.97, wps=52743.2, ups=0.92, wpb=57274.2, bsz=1479.5, num_updates=90200, lr=0.000210585, gnorm=0.255, clip=100, loss_scale=30, train_wall=105, wall=99267
2023-05-26 21:56:22 | INFO | train_inner | epoch 014:   3532 / 6686 loss=4.215, nll_loss=2.599, ppl=6.06, wps=52653.2, ups=0.92, wpb=57218.1, bsz=1477.9, num_updates=90300, lr=0.000210468, gnorm=0.254, clip=100, loss_scale=32, train_wall=105, wall=99376
2023-05-26 21:56:27 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 21:58:11 | INFO | train_inner | epoch 014:   3633 / 6686 loss=4.205, nll_loss=2.589, ppl=6.01, wps=52211.7, ups=0.91, wpb=57234.8, bsz=1474.1, num_updates=90400, lr=0.000210352, gnorm=0.249, clip=100, loss_scale=17, train_wall=106, wall=99485
2023-05-26 22:00:00 | INFO | train_inner | epoch 014:   3733 / 6686 loss=4.199, nll_loss=2.582, ppl=5.99, wps=52622.4, ups=0.92, wpb=57200.4, bsz=1445.4, num_updates=90500, lr=0.000210235, gnorm=0.25, clip=100, loss_scale=16, train_wall=105, wall=99594
2023-05-26 22:01:49 | INFO | train_inner | epoch 014:   3833 / 6686 loss=4.196, nll_loss=2.578, ppl=5.97, wps=52390.5, ups=0.92, wpb=57054.2, bsz=1491.1, num_updates=90600, lr=0.000210119, gnorm=0.25, clip=100, loss_scale=16, train_wall=105, wall=99703
2023-05-26 22:03:37 | INFO | train_inner | epoch 014:   3933 / 6686 loss=4.195, nll_loss=2.577, ppl=5.97, wps=52782.7, ups=0.92, wpb=57143.8, bsz=1478.9, num_updates=90700, lr=0.000210003, gnorm=0.255, clip=100, loss_scale=16, train_wall=105, wall=99811
2023-05-26 22:05:25 | INFO | train_inner | epoch 014:   4033 / 6686 loss=4.204, nll_loss=2.588, ppl=6.01, wps=52785.9, ups=0.92, wpb=57192.5, bsz=1485.8, num_updates=90800, lr=0.000209888, gnorm=0.252, clip=100, loss_scale=16, train_wall=105, wall=99920
2023-05-26 22:07:14 | INFO | train_inner | epoch 014:   4133 / 6686 loss=4.202, nll_loss=2.585, ppl=6, wps=52657.1, ups=0.92, wpb=57173, bsz=1450.7, num_updates=90900, lr=0.000209772, gnorm=0.252, clip=100, loss_scale=30, train_wall=105, wall=100028
2023-05-26 22:09:03 | INFO | train_inner | epoch 014:   4233 / 6686 loss=4.204, nll_loss=2.587, ppl=6.01, wps=52600, ups=0.92, wpb=57195.1, bsz=1472.4, num_updates=91000, lr=0.000209657, gnorm=0.253, clip=100, loss_scale=32, train_wall=105, wall=100137
2023-05-26 22:09:24 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 22:10:54 | INFO | train_inner | epoch 014:   4334 / 6686 loss=4.197, nll_loss=2.579, ppl=5.98, wps=51786.8, ups=0.9, wpb=57351.8, bsz=1502.5, num_updates=91100, lr=0.000209542, gnorm=0.253, clip=100, loss_scale=19, train_wall=107, wall=100248
2023-05-26 22:12:42 | INFO | train_inner | epoch 014:   4434 / 6686 loss=4.186, nll_loss=2.567, ppl=5.93, wps=52710.1, ups=0.92, wpb=57270.1, bsz=1496.8, num_updates=91200, lr=0.000209427, gnorm=0.252, clip=100, loss_scale=16, train_wall=105, wall=100356
2023-05-26 22:14:31 | INFO | train_inner | epoch 014:   4534 / 6686 loss=4.202, nll_loss=2.585, ppl=6, wps=52817.2, ups=0.92, wpb=57271, bsz=1455.5, num_updates=91300, lr=0.000209312, gnorm=0.25, clip=100, loss_scale=16, train_wall=105, wall=100465
2023-05-26 22:16:19 | INFO | train_inner | epoch 014:   4634 / 6686 loss=4.202, nll_loss=2.585, ppl=6, wps=52771.2, ups=0.92, wpb=57226.3, bsz=1475.8, num_updates=91400, lr=0.000209198, gnorm=0.253, clip=100, loss_scale=16, train_wall=105, wall=100573
2023-05-26 22:18:08 | INFO | train_inner | epoch 014:   4734 / 6686 loss=4.201, nll_loss=2.584, ppl=6, wps=52695.6, ups=0.92, wpb=57426.4, bsz=1500.1, num_updates=91500, lr=0.000209083, gnorm=0.249, clip=100, loss_scale=16, train_wall=105, wall=100682
2023-05-26 22:19:57 | INFO | train_inner | epoch 014:   4834 / 6686 loss=4.201, nll_loss=2.583, ppl=5.99, wps=52521.3, ups=0.92, wpb=57206.2, bsz=1488.1, num_updates=91600, lr=0.000208969, gnorm=0.249, clip=100, loss_scale=27, train_wall=105, wall=100791
2023-05-26 22:21:46 | INFO | train_inner | epoch 014:   4934 / 6686 loss=4.197, nll_loss=2.579, ppl=5.98, wps=52482.8, ups=0.92, wpb=57210.4, bsz=1478.2, num_updates=91700, lr=0.000208855, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=100900
2023-05-26 22:23:35 | INFO | train_inner | epoch 014:   5034 / 6686 loss=4.202, nll_loss=2.585, ppl=6, wps=52567.1, ups=0.92, wpb=57185, bsz=1483.1, num_updates=91800, lr=0.000208741, gnorm=0.252, clip=100, loss_scale=32, train_wall=105, wall=101009
2023-05-26 22:25:23 | INFO | train_inner | epoch 014:   5134 / 6686 loss=4.185, nll_loss=2.565, ppl=5.92, wps=52701.4, ups=0.92, wpb=57180.1, bsz=1476.1, num_updates=91900, lr=0.000208628, gnorm=0.251, clip=100, loss_scale=32, train_wall=105, wall=101117
2023-05-26 22:27:12 | INFO | train_inner | epoch 014:   5234 / 6686 loss=4.198, nll_loss=2.581, ppl=5.98, wps=52585.1, ups=0.92, wpb=57233, bsz=1482.4, num_updates=92000, lr=0.000208514, gnorm=0.251, clip=100, loss_scale=32, train_wall=105, wall=101226
2023-05-26 22:29:01 | INFO | train_inner | epoch 014:   5334 / 6686 loss=4.192, nll_loss=2.574, ppl=5.95, wps=52578.1, ups=0.92, wpb=57250.3, bsz=1501.8, num_updates=92100, lr=0.000208401, gnorm=0.251, clip=100, loss_scale=51, train_wall=105, wall=101335
2023-05-26 22:29:13 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 22:30:51 | INFO | train_inner | epoch 014:   5435 / 6686 loss=4.205, nll_loss=2.589, ppl=6.02, wps=51970.6, ups=0.91, wpb=57104.8, bsz=1458, num_updates=92200, lr=0.000208288, gnorm=0.254, clip=100, loss_scale=35, train_wall=106, wall=101445
2023-05-26 22:32:39 | INFO | train_inner | epoch 014:   5535 / 6686 loss=4.2, nll_loss=2.583, ppl=5.99, wps=52710.6, ups=0.92, wpb=57053.3, bsz=1482.3, num_updates=92300, lr=0.000208175, gnorm=0.25, clip=100, loss_scale=32, train_wall=104, wall=101553
2023-05-26 22:34:28 | INFO | train_inner | epoch 014:   5635 / 6686 loss=4.199, nll_loss=2.582, ppl=5.99, wps=52671.6, ups=0.92, wpb=57158.4, bsz=1461, num_updates=92400, lr=0.000208063, gnorm=0.252, clip=100, loss_scale=32, train_wall=105, wall=101662
2023-05-26 22:36:04 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 22:36:17 | INFO | train_inner | epoch 014:   5736 / 6686 loss=4.195, nll_loss=2.577, ppl=5.97, wps=52259.2, ups=0.91, wpb=57203, bsz=1480.7, num_updates=92500, lr=0.00020795, gnorm=0.257, clip=100, loss_scale=30, train_wall=106, wall=101771
2023-05-26 22:38:06 | INFO | train_inner | epoch 014:   5836 / 6686 loss=4.218, nll_loss=2.603, ppl=6.07, wps=52530.3, ups=0.92, wpb=57059.2, bsz=1467.2, num_updates=92600, lr=0.000207838, gnorm=0.249, clip=100, loss_scale=16, train_wall=105, wall=101880
2023-05-26 22:39:55 | INFO | train_inner | epoch 014:   5936 / 6686 loss=4.192, nll_loss=2.575, ppl=5.96, wps=52278.1, ups=0.91, wpb=57152.8, bsz=1485.8, num_updates=92700, lr=0.000207726, gnorm=0.252, clip=100, loss_scale=16, train_wall=106, wall=101989
2023-05-26 22:41:45 | INFO | train_inner | epoch 014:   6036 / 6686 loss=4.197, nll_loss=2.579, ppl=5.98, wps=52325.8, ups=0.91, wpb=57280.8, bsz=1472.8, num_updates=92800, lr=0.000207614, gnorm=0.252, clip=100, loss_scale=16, train_wall=106, wall=102099
2023-05-26 22:43:33 | INFO | train_inner | epoch 014:   6136 / 6686 loss=4.198, nll_loss=2.581, ppl=5.98, wps=52749.6, ups=0.92, wpb=57189.1, bsz=1477, num_updates=92900, lr=0.000207502, gnorm=0.25, clip=100, loss_scale=16, train_wall=105, wall=102207
2023-05-26 22:45:22 | INFO | train_inner | epoch 014:   6236 / 6686 loss=4.194, nll_loss=2.576, ppl=5.96, wps=52608.6, ups=0.92, wpb=57240.8, bsz=1487.2, num_updates=93000, lr=0.00020739, gnorm=0.252, clip=100, loss_scale=16, train_wall=105, wall=102316
2023-05-26 22:47:10 | INFO | train_inner | epoch 014:   6336 / 6686 loss=4.194, nll_loss=2.576, ppl=5.96, wps=52634.9, ups=0.92, wpb=57165.2, bsz=1475, num_updates=93100, lr=0.000207279, gnorm=0.251, clip=100, loss_scale=32, train_wall=105, wall=102425
2023-05-26 22:48:59 | INFO | train_inner | epoch 014:   6436 / 6686 loss=4.197, nll_loss=2.579, ppl=5.98, wps=52441.7, ups=0.92, wpb=57015.3, bsz=1468.2, num_updates=93200, lr=0.000207168, gnorm=0.257, clip=100, loss_scale=32, train_wall=105, wall=102533
2023-05-26 22:50:48 | INFO | train_inner | epoch 014:   6536 / 6686 loss=4.192, nll_loss=2.574, ppl=5.95, wps=52587, ups=0.92, wpb=57297, bsz=1492.7, num_updates=93300, lr=0.000207057, gnorm=0.252, clip=100, loss_scale=32, train_wall=105, wall=102642
2023-05-26 22:52:37 | INFO | train_inner | epoch 014:   6636 / 6686 loss=4.193, nll_loss=2.575, ppl=5.96, wps=52805.9, ups=0.92, wpb=57259.9, bsz=1489.1, num_updates=93400, lr=0.000206946, gnorm=0.25, clip=100, loss_scale=32, train_wall=105, wall=102751
2023-05-26 22:53:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-26 22:53:35 | INFO | fairseq.tasks.translation | example hypothesis: Why was that so?
2023-05-26 22:53:35 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-26 22:53:35 | INFO | fairseq.tasks.translation | example hypothesis: I’ll make you lose so badly that you don’t even have your pants left!
2023-05-26 22:53:35 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-26 22:53:36 | INFO | fairseq.tasks.translation | example hypothesis: Just as Shen Liangchuan heaved a sigh of relief, he heard her say, “I’ll call you in the same room!”
2023-05-26 22:53:36 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-26 22:53:37 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved her hand and entered the elevator.
2023-05-26 22:53:37 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-26 22:53:37 | INFO | fairseq.tasks.translation | example hypothesis: She looked up and saw Song Cheng standing in the distance!
2023-05-26 22:53:37 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-26 22:53:38 | INFO | fairseq.tasks.translation | example hypothesis: Only then did Song Cheng pat his chest. “You scared me to death! Where’s Wang Chuan?”
2023-05-26 22:53:38 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-26 22:53:39 | INFO | fairseq.tasks.translation | example hypothesis: I said, “No, I can’t eat it.”
2023-05-26 22:53:39 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-26 22:53:39 | INFO | fairseq.tasks.translation | example hypothesis: At first, everyone didn’t believe it, but Wang Wenhao insisted on him, making the public opinion lean towards him.
2023-05-26 22:53:39 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-26 22:53:40 | INFO | fairseq.tasks.translation | example hypothesis: With his identity coming here like this, Baili Hongzhuang had to be treated even if she did not want to!
2023-05-26 22:53:40 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-26 22:53:41 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian said, “Mr. Shen, I, I’ve kept too much blood and my brain lacks oxygen. I can’t figure it out. Why don’t you give me a hint?”
2023-05-26 22:53:41 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-26 22:53:42 | INFO | fairseq.tasks.translation | example hypothesis: He didn’t know why so many people had heard of this matter. Since he couldn’t hide it any longer, he might as well tell them.
2023-05-26 22:53:42 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-26 22:53:43 | INFO | fairseq.tasks.translation | example hypothesis: She deliberately lowered her voice, but it was unable to conceal the evil and ruthless tone in her voice.
2023-05-26 22:53:43 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-26 22:53:44 | INFO | fairseq.tasks.translation | example hypothesis: Beast pets of different levels were different in strength, but beast pets were precious and rare. It was impossible for ordinary people to have one, even for the descendants of officials.
2023-05-26 22:53:44 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-26 22:53:45 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chixia bit her teeth and cursed in a low voice.
2023-05-26 22:53:45 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-26 22:53:46 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang had concealed it very well, Di Beichen could still see the flash of warmth in her eyes.
2023-05-26 22:53:46 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-26 22:53:47 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia walked in, she didn't even see many guests, not to mention the waiters.
2023-05-26 22:53:47 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-26 22:53:48 | INFO | fairseq.tasks.translation | example hypothesis: This person was the Ye Family's fourth young miss, Ye Qing Ling.
2023-05-26 22:53:48 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-26 22:53:49 | INFO | fairseq.tasks.translation | example hypothesis: Because at this moment, she felt as if her chin was about to shatter.
2023-05-26 22:53:49 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-26 22:53:51 | INFO | fairseq.tasks.translation | example hypothesis: “Good Mu Zi, help me. If it wasn't for you, that old man wouldn't have targeted me.”
2023-05-26 22:53:51 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-26 22:53:52 | INFO | fairseq.tasks.translation | example hypothesis: Bai Li Yu Yan was even more excited. She was the one who was in charge of this. Bai Li Hong Zhuang had treated her like this before. This time, she would definitely make things difficult for Bai Li Hong Zhuang.
2023-05-26 22:53:52 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-26 22:53:53 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How could that be? They also have four mages on their side, so of course they won’t surrender so easily. After arguing for a long time, they finally decided on how to get control of the Kingdom of Exia in the future.”
2023-05-26 22:53:53 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-26 22:53:54 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a few degrees. He had always been looking for a reason for Li Yuyue not participating in the Imperial Family Hunting Competition.
2023-05-26 22:53:54 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-26 22:53:56 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my level good enough? They’re all the most outstanding people in the country. Is my magic that weak?”
2023-05-26 22:53:56 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-26 22:53:57 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yi Bei’s words meant that if Fang Chi Xia didn’t want to go, then she didn’t need to go.
2023-05-26 22:53:57 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-26 22:53:59 | INFO | fairseq.tasks.translation | example hypothesis: She tilted her head and saw that the five palm prints on her cheeks were very eye-catching. They swelled up at a speed visible to the naked eye. When she reached out to touch them, she could not help but let out a hissing sound.
2023-05-26 22:53:59 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-26 22:54:00 | INFO | fairseq.tasks.translation | example hypothesis: This... how could this be the charm that that trash could emit?
2023-05-26 22:54:00 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-26 22:54:01 | INFO | fairseq.tasks.translation | example hypothesis: How could Wang Wenhao have found the news agency? The chief editor should have called to tell her not to come to the news agency, but these three people... had schemed against her!
2023-05-26 22:54:01 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-26 22:54:04 | INFO | fairseq.tasks.translation | example hypothesis: Hearing Teacher Di’s praise, I was delighted. I withdrew the energy ball with my left hand, and a light sword shot out from my right hand towards Teacher Zhen. The light sword actually managed to hit the target smoothly. I was startled, and upon closer inspection, I realized that it was just an afterimage. Teacher Zhen had already moved behind me and shouted, “Berserk Space!”
2023-05-26 22:54:04 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-26 22:54:07 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Initially, we proposed a two out of three competition, but they said that it wasn’t fair, because we have Teacher Di and Teacher Zhen, and their ranking is higher than theirs. They proposed a five out of three competition, and since we were the ones who proposed the competition, we can only listen to them in the end.
2023-05-26 22:54:07 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-26 22:54:09 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Di had used a light element level 7 spell, Light Thunder Burst. I rarely used this spell because my control over it wasn’t ideal. Teacher Di had cast nine Light Thunder Bursts to surround me, forming a simple formation that prevented me from escaping in a short distance. After that, all the Light Thunder Bursts exploded to form a powerful attack.
2023-05-26 22:54:09 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-26 22:54:12 | INFO | fairseq.tasks.translation | example hypothesis: As soon as Mark and the two teachers walked to the other side, Teacher Zhen shot a small Dimensional Slash at me. As expected of the continent’s number one Magician, the suction force of the small Dimensional Slash was actually much stronger than mine. A small spatial rift appeared beside me, and a powerful suction force immediately swept towards me.
2023-05-26 22:54:12 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-26 22:54:12 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.173 | nll_loss 2.527 | ppl 5.76 | bleu 21.64 | wps 1969.1 | wpb 2420.8 | bsz 84.5 | num_updates 93450 | best_bleu 21.64
2023-05-26 22:54:12 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-26 22:54:18 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/concat-1-1-0.2-sf[zh-en]/checkpoint14.pt (epoch 14 @ 93450 updates, score 21.64) (writing took 5.4215509267523885 seconds)
2023-05-26 22:54:18 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-05-26 22:54:18 | INFO | train | epoch 014 | loss 4.195 | nll_loss 2.577 | ppl 5.97 | wps 51866.2 | ups 0.91 | wpb 57190.6 | bsz 1477.5 | num_updates 93450 | lr 0.00020689 | gnorm 0.251 | clip 100 | loss_scale 25 | train_wall 7025 | wall 102852
2023-05-26 22:54:18 | INFO | fairseq.trainer | begin training epoch 15
2023-05-26 22:55:27 | INFO | train_inner | epoch 015:     50 / 6686 loss=4.18, nll_loss=2.559, ppl=5.89, wps=33223.8, ups=0.59, wpb=56710.6, bsz=1455.6, num_updates=93500, lr=0.000206835, gnorm=0.253, clip=100, loss_scale=32, train_wall=106, wall=102921
2023-05-26 22:56:04 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 22:57:23 | INFO | train_inner | epoch 015:    151 / 6686 loss=4.177, nll_loss=2.556, ppl=5.88, wps=49149.9, ups=0.86, wpb=57105.8, bsz=1491.4, num_updates=93600, lr=0.000206725, gnorm=0.249, clip=100, loss_scale=38, train_wall=108, wall=103038
2023-05-26 22:59:16 | INFO | train_inner | epoch 015:    251 / 6686 loss=4.177, nll_loss=2.556, ppl=5.88, wps=50783, ups=0.89, wpb=57290.2, bsz=1476.9, num_updates=93700, lr=0.000206614, gnorm=0.251, clip=100, loss_scale=32, train_wall=106, wall=103150
2023-05-26 23:01:06 | INFO | train_inner | epoch 015:    351 / 6686 loss=4.175, nll_loss=2.554, ppl=5.87, wps=52090.2, ups=0.91, wpb=57229.9, bsz=1485.7, num_updates=93800, lr=0.000206504, gnorm=0.251, clip=100, loss_scale=32, train_wall=106, wall=103260
2023-05-26 23:02:55 | INFO | train_inner | epoch 015:    451 / 6686 loss=4.187, nll_loss=2.568, ppl=5.93, wps=52610.6, ups=0.92, wpb=57341, bsz=1476.2, num_updates=93900, lr=0.000206394, gnorm=0.251, clip=100, loss_scale=32, train_wall=105, wall=103369
2023-05-26 23:04:44 | INFO | train_inner | epoch 015:    551 / 6686 loss=4.19, nll_loss=2.572, ppl=5.94, wps=52582.5, ups=0.92, wpb=57116.9, bsz=1454.4, num_updates=94000, lr=0.000206284, gnorm=0.253, clip=100, loss_scale=32, train_wall=105, wall=103478
2023-05-26 23:06:11 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 23:06:33 | INFO | train_inner | epoch 015:    652 / 6686 loss=4.186, nll_loss=2.566, ppl=5.92, wps=52045.5, ups=0.91, wpb=57060.2, bsz=1470.5, num_updates=94100, lr=0.000206175, gnorm=0.25, clip=100, loss_scale=44, train_wall=106, wall=103588
2023-05-26 23:08:22 | INFO | train_inner | epoch 015:    752 / 6686 loss=4.178, nll_loss=2.558, ppl=5.89, wps=52515.6, ups=0.92, wpb=57168.3, bsz=1487.4, num_updates=94200, lr=0.000206065, gnorm=0.25, clip=100, loss_scale=32, train_wall=105, wall=103696
2023-05-26 23:10:11 | INFO | train_inner | epoch 015:    852 / 6686 loss=4.191, nll_loss=2.573, ppl=5.95, wps=52448.3, ups=0.92, wpb=57139.3, bsz=1463.8, num_updates=94300, lr=0.000205956, gnorm=0.251, clip=100, loss_scale=32, train_wall=105, wall=103805
2023-05-26 23:12:00 | INFO | train_inner | epoch 015:    952 / 6686 loss=4.187, nll_loss=2.568, ppl=5.93, wps=52703.8, ups=0.92, wpb=57135.3, bsz=1457.9, num_updates=94400, lr=0.000205847, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=103914
2023-05-26 23:13:48 | INFO | train_inner | epoch 015:   1052 / 6686 loss=4.182, nll_loss=2.563, ppl=5.91, wps=52750.4, ups=0.92, wpb=57174.9, bsz=1475.1, num_updates=94500, lr=0.000205738, gnorm=0.248, clip=100, loss_scale=32, train_wall=105, wall=104022
2023-05-26 23:15:37 | INFO | train_inner | epoch 015:   1152 / 6686 loss=4.185, nll_loss=2.565, ppl=5.92, wps=52608.3, ups=0.92, wpb=57258.9, bsz=1473.5, num_updates=94600, lr=0.000205629, gnorm=0.251, clip=100, loss_scale=35, train_wall=105, wall=104131
2023-05-26 23:15:49 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 23:17:27 | INFO | train_inner | epoch 015:   1253 / 6686 loss=4.167, nll_loss=2.545, ppl=5.84, wps=51920.2, ups=0.91, wpb=57099.5, bsz=1504.9, num_updates=94700, lr=0.00020552, gnorm=0.255, clip=100, loss_scale=35, train_wall=106, wall=104241
2023-05-26 23:19:16 | INFO | train_inner | epoch 015:   1353 / 6686 loss=4.185, nll_loss=2.566, ppl=5.92, wps=52357.1, ups=0.92, wpb=57100.6, bsz=1452.8, num_updates=94800, lr=0.000205412, gnorm=0.252, clip=100, loss_scale=32, train_wall=105, wall=104350
2023-05-26 23:21:05 | INFO | train_inner | epoch 015:   1453 / 6686 loss=4.179, nll_loss=2.559, ppl=5.89, wps=52469.4, ups=0.92, wpb=57252, bsz=1460.9, num_updates=94900, lr=0.000205304, gnorm=0.251, clip=100, loss_scale=32, train_wall=105, wall=104459
2023-05-26 23:21:30 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-26 23:22:54 | INFO | train_inner | epoch 015:   1554 / 6686 loss=4.181, nll_loss=2.562, ppl=5.9, wps=52205.6, ups=0.91, wpb=57155.1, bsz=1485.8, num_updates=95000, lr=0.000205196, gnorm=0.253, clip=100, loss_scale=19, train_wall=106, wall=104569
2023-05-26 23:24:43 | INFO | train_inner | epoch 015:   1654 / 6686 loss=4.186, nll_loss=2.567, ppl=5.93, wps=52567.1, ups=0.92, wpb=57119.8, bsz=1481.2, num_updates=95100, lr=0.000205088, gnorm=0.252, clip=100, loss_scale=16, train_wall=105, wall=104677
2023-05-26 23:26:32 | INFO | train_inner | epoch 015:   1754 / 6686 loss=4.176, nll_loss=2.556, ppl=5.88, wps=52652.5, ups=0.92, wpb=57238, bsz=1488.4, num_updates=95200, lr=0.00020498, gnorm=0.252, clip=100, loss_scale=16, train_wall=105, wall=104786
2023-05-26 23:28:20 | INFO | train_inner | epoch 015:   1854 / 6686 loss=4.187, nll_loss=2.568, ppl=5.93, wps=52590.9, ups=0.92, wpb=56990.3, bsz=1460.2, num_updates=95300, lr=0.000204872, gnorm=0.254, clip=100, loss_scale=16, train_wall=105, wall=104894
2023-05-26 23:30:09 | INFO | train_inner | epoch 015:   1954 / 6686 loss=4.183, nll_loss=2.564, ppl=5.91, wps=52570.9, ups=0.92, wpb=57104.6, bsz=1489, num_updates=95400, lr=0.000204765, gnorm=0.251, clip=100, loss_scale=16, train_wall=105, wall=105003
2023-05-26 23:31:58 | INFO | train_inner | epoch 015:   2054 / 6686 loss=4.186, nll_loss=2.567, ppl=5.92, wps=52567.4, ups=0.92, wpb=57341.5, bsz=1469.5, num_updates=95500, lr=0.000204658, gnorm=0.251, clip=100, loss_scale=27, train_wall=105, wall=105112
2023-05-26 23:33:46 | INFO | train_inner | epoch 015:   2154 / 6686 loss=4.188, nll_loss=2.57, ppl=5.94, wps=52795.2, ups=0.92, wpb=57297.4, bsz=1466.6, num_updates=95600, lr=0.000204551, gnorm=0.252, clip=100, loss_scale=32, train_wall=105, wall=105221
2023-05-26 23:35:35 | INFO | train_inner | epoch 015:   2254 / 6686 loss=4.192, nll_loss=2.574, ppl=5.95, wps=52577.9, ups=0.92, wpb=57085.6, bsz=1481.3, num_updates=95700, lr=0.000204444, gnorm=0.253, clip=100, loss_scale=32, train_wall=105, wall=105329
2023-05-26 23:37:24 | INFO | train_inner | epoch 015:   2354 / 6686 loss=4.175, nll_loss=2.555, ppl=5.88, wps=52794.7, ups=0.92, wpb=57278, bsz=1499.8, num_updates=95800, lr=0.000204337, gnorm=0.25, clip=100, loss_scale=32, train_wall=105, wall=105438
2023-05-26 23:39:12 | INFO | train_inner | epoch 015:   2454 / 6686 loss=4.182, nll_loss=2.563, ppl=5.91, wps=52720.5, ups=0.92, wpb=57235.4, bsz=1480.5, num_updates=95900, lr=0.000204231, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=105546
2023-05-26 23:40:18 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 23:41:02 | INFO | train_inner | epoch 015:   2555 / 6686 loss=4.183, nll_loss=2.563, ppl=5.91, wps=51987.1, ups=0.91, wpb=57229.8, bsz=1492.2, num_updates=96000, lr=0.000204124, gnorm=0.25, clip=100, loss_scale=36, train_wall=106, wall=105656
2023-05-26 23:42:51 | INFO | train_inner | epoch 015:   2655 / 6686 loss=4.181, nll_loss=2.562, ppl=5.91, wps=52684.3, ups=0.92, wpb=57218, bsz=1481.4, num_updates=96100, lr=0.000204018, gnorm=0.252, clip=100, loss_scale=32, train_wall=105, wall=105765
2023-05-26 23:44:39 | INFO | train_inner | epoch 015:   2755 / 6686 loss=4.194, nll_loss=2.577, ppl=5.97, wps=52628.8, ups=0.92, wpb=57108.6, bsz=1456.7, num_updates=96200, lr=0.000203912, gnorm=0.258, clip=100, loss_scale=32, train_wall=105, wall=105873
2023-05-26 23:46:28 | INFO | train_inner | epoch 015:   2855 / 6686 loss=4.181, nll_loss=2.562, ppl=5.9, wps=52710.8, ups=0.92, wpb=57374.5, bsz=1495.8, num_updates=96300, lr=0.000203806, gnorm=0.25, clip=100, loss_scale=32, train_wall=105, wall=105982
2023-05-26 23:48:18 | INFO | train_inner | epoch 015:   2955 / 6686 loss=4.184, nll_loss=2.564, ppl=5.92, wps=52470.5, ups=0.91, wpb=57430.1, bsz=1464.2, num_updates=96400, lr=0.0002037, gnorm=0.255, clip=100, loss_scale=32, train_wall=106, wall=106092
2023-05-26 23:50:07 | INFO | train_inner | epoch 015:   3055 / 6686 loss=4.187, nll_loss=2.568, ppl=5.93, wps=52493.1, ups=0.92, wpb=57196, bsz=1513.8, num_updates=96500, lr=0.000203595, gnorm=0.254, clip=100, loss_scale=42, train_wall=105, wall=106201
2023-05-26 23:50:45 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-26 23:51:56 | INFO | train_inner | epoch 015:   3156 / 6686 loss=4.193, nll_loss=2.575, ppl=5.96, wps=52207.6, ups=0.91, wpb=57128.9, bsz=1484.6, num_updates=96600, lr=0.000203489, gnorm=0.251, clip=100, loss_scale=43, train_wall=106, wall=106310
2023-05-26 23:53:45 | INFO | train_inner | epoch 015:   3256 / 6686 loss=4.187, nll_loss=2.568, ppl=5.93, wps=52610.1, ups=0.92, wpb=57162.7, bsz=1462.1, num_updates=96700, lr=0.000203384, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=106419
2023-05-26 23:55:33 | INFO | train_inner | epoch 015:   3356 / 6686 loss=4.192, nll_loss=2.574, ppl=5.95, wps=52616.1, ups=0.92, wpb=57210.8, bsz=1467.8, num_updates=96800, lr=0.000203279, gnorm=0.25, clip=100, loss_scale=32, train_wall=105, wall=106528
2023-05-26 23:57:22 | INFO | train_inner | epoch 015:   3456 / 6686 loss=4.179, nll_loss=2.559, ppl=5.89, wps=52460.7, ups=0.92, wpb=57179.8, bsz=1484.5, num_updates=96900, lr=0.000203174, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=106637
2023-05-26 23:59:11 | INFO | train_inner | epoch 015:   3556 / 6686 loss=4.188, nll_loss=2.57, ppl=5.94, wps=52543.1, ups=0.92, wpb=57063.8, bsz=1470.3, num_updates=97000, lr=0.000203069, gnorm=0.254, clip=100, loss_scale=32, train_wall=105, wall=106745
2023-05-27 00:00:30 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 00:01:01 | INFO | train_inner | epoch 015:   3657 / 6686 loss=4.192, nll_loss=2.574, ppl=5.96, wps=52029.2, ups=0.91, wpb=57097, bsz=1489.8, num_updates=97100, lr=0.000202965, gnorm=0.252, clip=100, loss_scale=41, train_wall=106, wall=106855
2023-05-27 00:02:50 | INFO | train_inner | epoch 015:   3757 / 6686 loss=4.18, nll_loss=2.56, ppl=5.9, wps=52590.8, ups=0.92, wpb=57207.2, bsz=1474.3, num_updates=97200, lr=0.00020286, gnorm=0.25, clip=100, loss_scale=32, train_wall=105, wall=106964
2023-05-27 00:04:38 | INFO | train_inner | epoch 015:   3857 / 6686 loss=4.194, nll_loss=2.576, ppl=5.96, wps=52713.2, ups=0.92, wpb=57350.8, bsz=1479.8, num_updates=97300, lr=0.000202756, gnorm=0.249, clip=100, loss_scale=32, train_wall=105, wall=107073
2023-05-27 00:06:27 | INFO | train_inner | epoch 015:   3957 / 6686 loss=4.191, nll_loss=2.573, ppl=5.95, wps=52667.4, ups=0.92, wpb=57110.8, bsz=1474.1, num_updates=97400, lr=0.000202652, gnorm=0.252, clip=100, loss_scale=32, train_wall=105, wall=107181
2023-05-27 00:08:16 | INFO | train_inner | epoch 015:   4057 / 6686 loss=4.188, nll_loss=2.569, ppl=5.93, wps=52426.5, ups=0.92, wpb=57061.2, bsz=1460.2, num_updates=97500, lr=0.000202548, gnorm=0.251, clip=100, loss_scale=32, train_wall=105, wall=107290
2023-05-27 00:10:05 | INFO | train_inner | epoch 015:   4157 / 6686 loss=4.191, nll_loss=2.573, ppl=5.95, wps=52526.4, ups=0.92, wpb=57280.8, bsz=1495.4, num_updates=97600, lr=0.000202444, gnorm=0.254, clip=100, loss_scale=37, train_wall=105, wall=107399
2023-05-27 00:10:06 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 00:10:06 | INFO | train_inner | epoch 015:   4158 / 6686 loss=None, nll_loss=None, ppl=0, wps=0, ups=0, wpb=None, bsz=None, num_updates=None, lr=None, gnorm=None, clip=None, loss_scale=32, train_wall=1, wall=107400
2023-05-27 00:10:27 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 00:11:55 | INFO | train_inner | epoch 015:   4259 / 6686 loss=4.185, nll_loss=2.566, ppl=5.92, wps=52031.5, ups=0.91, wpb=57068, bsz=1469, num_updates=97700, lr=0.00020234, gnorm=0.251, clip=100, loss_scale=19, train_wall=106, wall=107510
2023-05-27 00:13:44 | INFO | train_inner | epoch 015:   4359 / 6686 loss=4.201, nll_loss=2.584, ppl=6, wps=52812.6, ups=0.92, wpb=57168.2, bsz=1476.2, num_updates=97800, lr=0.000202237, gnorm=0.254, clip=100, loss_scale=16, train_wall=104, wall=107618
2023-05-27 00:15:32 | INFO | train_inner | epoch 015:   4459 / 6686 loss=4.21, nll_loss=2.594, ppl=6.04, wps=52742.6, ups=0.92, wpb=57117.6, bsz=1467.4, num_updates=97900, lr=0.000202134, gnorm=0.254, clip=100, loss_scale=16, train_wall=105, wall=107726
2023-05-27 00:17:20 | INFO | train_inner | epoch 015:   4559 / 6686 loss=4.198, nll_loss=2.58, ppl=5.98, wps=52669.6, ups=0.92, wpb=57104.9, bsz=1465.7, num_updates=98000, lr=0.000202031, gnorm=0.251, clip=100, loss_scale=16, train_wall=105, wall=107835
2023-05-27 00:19:09 | INFO | train_inner | epoch 015:   4659 / 6686 loss=4.191, nll_loss=2.572, ppl=5.95, wps=52524.5, ups=0.92, wpb=57229.9, bsz=1509, num_updates=98100, lr=0.000201928, gnorm=0.25, clip=100, loss_scale=16, train_wall=105, wall=107944
2023-05-27 00:20:58 | INFO | train_inner | epoch 015:   4759 / 6686 loss=4.187, nll_loss=2.568, ppl=5.93, wps=52731.6, ups=0.92, wpb=57333.1, bsz=1485.3, num_updates=98200, lr=0.000201825, gnorm=0.252, clip=100, loss_scale=27, train_wall=105, wall=108052
2023-05-27 00:22:47 | INFO | train_inner | epoch 015:   4859 / 6686 loss=4.181, nll_loss=2.561, ppl=5.9, wps=52681.4, ups=0.92, wpb=57254.7, bsz=1486.1, num_updates=98300, lr=0.000201722, gnorm=0.25, clip=100, loss_scale=32, train_wall=105, wall=108161
2023-05-27 00:24:35 | INFO | train_inner | epoch 015:   4959 / 6686 loss=4.201, nll_loss=2.584, ppl=6, wps=52600.4, ups=0.92, wpb=56961, bsz=1453.5, num_updates=98400, lr=0.000201619, gnorm=0.253, clip=100, loss_scale=32, train_wall=105, wall=108269
2023-05-27 00:26:24 | INFO | train_inner | epoch 015:   5059 / 6686 loss=4.191, nll_loss=2.573, ppl=5.95, wps=52569, ups=0.92, wpb=57137.2, bsz=1468.4, num_updates=98500, lr=0.000201517, gnorm=0.252, clip=100, loss_scale=32, train_wall=105, wall=108378
2023-05-27 00:27:56 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 00:28:14 | INFO | train_inner | epoch 015:   5160 / 6686 loss=4.183, nll_loss=2.564, ppl=5.91, wps=52091.7, ups=0.91, wpb=57215.4, bsz=1506.5, num_updates=98600, lr=0.000201415, gnorm=0.253, clip=100, loss_scale=29, train_wall=106, wall=108488
2023-05-27 00:30:02 | INFO | train_inner | epoch 015:   5260 / 6686 loss=4.202, nll_loss=2.585, ppl=6, wps=52501, ups=0.92, wpb=57028.5, bsz=1460.4, num_updates=98700, lr=0.000201313, gnorm=0.251, clip=100, loss_scale=16, train_wall=105, wall=108596
2023-05-27 00:31:51 | INFO | train_inner | epoch 015:   5360 / 6686 loss=4.187, nll_loss=2.569, ppl=5.93, wps=52674.1, ups=0.92, wpb=57298.2, bsz=1488.1, num_updates=98800, lr=0.000201211, gnorm=0.252, clip=100, loss_scale=16, train_wall=105, wall=108705
2023-05-27 00:33:40 | INFO | train_inner | epoch 015:   5460 / 6686 loss=4.188, nll_loss=2.57, ppl=5.94, wps=52695.9, ups=0.92, wpb=57132.4, bsz=1475.3, num_updates=98900, lr=0.000201109, gnorm=0.255, clip=100, loss_scale=16, train_wall=105, wall=108814
2023-05-27 00:35:28 | INFO | train_inner | epoch 015:   5560 / 6686 loss=4.182, nll_loss=2.563, ppl=5.91, wps=52926.7, ups=0.92, wpb=57551.6, bsz=1505.2, num_updates=99000, lr=0.000201008, gnorm=0.252, clip=100, loss_scale=16, train_wall=105, wall=108922
2023-05-27 00:37:17 | INFO | train_inner | epoch 015:   5660 / 6686 loss=4.186, nll_loss=2.568, ppl=5.93, wps=52714.7, ups=0.92, wpb=57307.7, bsz=1490.8, num_updates=99100, lr=0.000200906, gnorm=0.25, clip=100, loss_scale=17, train_wall=105, wall=109031
2023-05-27 00:39:06 | INFO | train_inner | epoch 015:   5760 / 6686 loss=4.192, nll_loss=2.574, ppl=5.95, wps=52523.7, ups=0.92, wpb=57310.9, bsz=1480.3, num_updates=99200, lr=0.000200805, gnorm=0.253, clip=100, loss_scale=32, train_wall=105, wall=109140
2023-05-27 00:40:55 | INFO | train_inner | epoch 015:   5860 / 6686 loss=4.201, nll_loss=2.585, ppl=6, wps=52638.7, ups=0.92, wpb=57114.7, bsz=1473.3, num_updates=99300, lr=0.000200704, gnorm=0.253, clip=100, loss_scale=32, train_wall=105, wall=109249
2023-05-27 00:42:18 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 00:42:44 | INFO | train_inner | epoch 015:   5961 / 6686 loss=4.184, nll_loss=2.566, ppl=5.92, wps=51986.2, ups=0.91, wpb=57117.7, bsz=1475.4, num_updates=99400, lr=0.000200603, gnorm=0.251, clip=100, loss_scale=28, train_wall=106, wall=109359
2023-05-27 00:44:33 | INFO | train_inner | epoch 015:   6061 / 6686 loss=4.196, nll_loss=2.579, ppl=5.97, wps=52936.1, ups=0.92, wpb=57270.7, bsz=1459.7, num_updates=99500, lr=0.000200502, gnorm=0.251, clip=100, loss_scale=16, train_wall=104, wall=109467
2023-05-27 00:46:21 | INFO | train_inner | epoch 015:   6161 / 6686 loss=4.197, nll_loss=2.58, ppl=5.98, wps=52702.6, ups=0.92, wpb=57334, bsz=1469.9, num_updates=99600, lr=0.000200401, gnorm=0.252, clip=100, loss_scale=16, train_wall=105, wall=109576
2023-05-27 00:48:11 | INFO | train_inner | epoch 015:   6261 / 6686 loss=4.183, nll_loss=2.564, ppl=5.91, wps=52481.5, ups=0.92, wpb=57218.7, bsz=1479.8, num_updates=99700, lr=0.000200301, gnorm=0.253, clip=100, loss_scale=16, train_wall=105, wall=109685
2023-05-27 00:49:59 | INFO | train_inner | epoch 015:   6361 / 6686 loss=4.179, nll_loss=2.56, ppl=5.9, wps=52849.1, ups=0.92, wpb=57407.5, bsz=1487.9, num_updates=99800, lr=0.0002002, gnorm=0.254, clip=100, loss_scale=16, train_wall=105, wall=109793
2023-05-27 00:51:47 | INFO | train_inner | epoch 015:   6461 / 6686 loss=4.184, nll_loss=2.565, ppl=5.92, wps=52886.6, ups=0.92, wpb=57179, bsz=1481.8, num_updates=99900, lr=0.0002001, gnorm=0.25, clip=100, loss_scale=18, train_wall=104, wall=109901
2023-05-27 00:52:11 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 00:53:37 | INFO | train_inner | epoch 015:   6562 / 6686 loss=4.198, nll_loss=2.581, ppl=5.98, wps=52190.5, ups=0.91, wpb=57166.6, bsz=1464.6, num_updates=100000, lr=0.0002, gnorm=0.252, clip=100, loss_scale=19, train_wall=106, wall=110011
2023-05-27 00:55:25 | INFO | train_inner | epoch 015:   6662 / 6686 loss=4.187, nll_loss=2.568, ppl=5.93, wps=52755.2, ups=0.92, wpb=57285.8, bsz=1483.5, num_updates=100100, lr=0.0001999, gnorm=0.256, clip=100, loss_scale=16, train_wall=105, wall=110120
2023-05-27 00:55:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-27 00:55:56 | INFO | fairseq.tasks.translation | example hypothesis: Why was that?
2023-05-27 00:55:56 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-27 00:55:56 | INFO | fairseq.tasks.translation | example hypothesis: I’ll make you lose until you don’t even have your pants left!
2023-05-27 00:55:56 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-27 00:55:57 | INFO | fairseq.tasks.translation | example hypothesis: Just as Shen Liangchuan heaved a sigh of relief, she said, “I’ll call for you to stay in the same room!”
2023-05-27 00:55:57 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-27 00:55:57 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved her hand and entered the elevator.
2023-05-27 00:55:57 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-27 00:55:58 | INFO | fairseq.tasks.translation | example hypothesis: She raised her head and saw Song Cheng standing in the distance!
2023-05-27 00:55:58 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-27 00:55:59 | INFO | fairseq.tasks.translation | example hypothesis: Song Cheng patted his chest. “You scared me to death! Where’s Wang Chuan?”
2023-05-27 00:55:59 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-27 00:55:59 | INFO | fairseq.tasks.translation | example hypothesis: “No, I can’t eat it,” I said.
2023-05-27 00:55:59 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-27 00:56:00 | INFO | fairseq.tasks.translation | example hypothesis: Voices were not believing it at first, but Wang Wenhao insisted that he was biased towards Wang Wenhao.
2023-05-27 00:56:00 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-27 00:56:01 | INFO | fairseq.tasks.translation | example hypothesis: Coming here like this with his status, Baili Hongzhuang had to be treated even if she did not treat him!
2023-05-27 00:56:01 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-27 00:56:02 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian: “Mr. Shen, I, I’ve kept too much blood and my brain lacks oxygen. I can’t think of anything. Why don’t you give me a hint?”
2023-05-27 00:56:02 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-27 00:56:03 | INFO | fairseq.tasks.translation | example hypothesis: He didn’t know why so many people heard about it. Since he couldn’t hide it anymore, he might as well tell them.
2023-05-27 00:56:03 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-27 00:56:04 | INFO | fairseq.tasks.translation | example hypothesis: She deliberately lowered her voice, but it was unable to conceal the viciousness and viciousness in her tone.
2023-05-27 00:56:04 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-27 00:56:05 | INFO | fairseq.tasks.translation | example hypothesis: Beast pets of different levels were different in strength, but beast pets were precious and hard to come by. It was impossible for an ordinary person to possess one, even for the descendants of officials.
2023-05-27 00:56:05 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-27 00:56:06 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chixia gritted her teeth and cursed in a low voice.
2023-05-27 00:56:06 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-27 00:56:07 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang had concealed it very well, Di Bei Chen could still see the ripples in her eyes and a hint of warmth in them.
2023-05-27 00:56:07 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-27 00:56:08 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia walked in, she didn't even see a few guests, let alone a waiter.
2023-05-27 00:56:08 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-27 00:56:09 | INFO | fairseq.tasks.translation | example hypothesis: This person was the Ye Family's Fourth Miss, Ye Qingling.
2023-05-27 00:56:09 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-27 00:56:10 | INFO | fairseq.tasks.translation | example hypothesis: That was because at this moment, she felt as if her chin was about to shatter.
2023-05-27 00:56:10 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-27 00:56:11 | INFO | fairseq.tasks.translation | example hypothesis: “Good Mu Zi, help me. If it wasn't for you, that old man wouldn't have set his eyes on me.”
2023-05-27 00:56:11 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-27 00:56:12 | INFO | fairseq.tasks.translation | example hypothesis: Baili Yuyan was even more excited. She was the one who was in charge of this. Bai Li Hongzhuang had treated her like this before. This time, she would definitely make Bai Li Hongzhuang suffer as well.
2023-05-27 00:56:12 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-27 00:56:13 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How could that be? They’re also four grand mages, of course they won’t surrender so easily. After arguing for a long time, they decided to use the competition to decide how to obtain control over the Kingdom of Axia in the future.”
2023-05-27 00:56:13 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-27 00:56:15 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a little. He had been looking for a reason for Li Yuyue’s inability to participate in the royal hunting competition.
2023-05-27 00:56:15 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-27 00:56:16 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my level good enough? They’re all the most outstanding people in the country. Is my magic that weak?”
2023-05-27 00:56:16 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-27 00:56:18 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yibei’s words meant that if Fang Chixia didn’t want to go, then she didn’t have to go.
2023-05-27 00:56:18 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-27 00:56:19 | INFO | fairseq.tasks.translation | example hypothesis: Turning her head to the side, she saw that the five palm prints on her cheek were very eye-catching. It was swelling at a speed visible to the naked eye. Reaching out to touch it, she could not help but let out a hiss.
2023-05-27 00:56:19 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-27 00:56:21 | INFO | fairseq.tasks.translation | example hypothesis: This... how could this be the charm that that trash could emit?
2023-05-27 00:56:21 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-27 00:56:22 | INFO | fairseq.tasks.translation | example hypothesis: How did Wang Wenhao manage to find the newspaper agency? The chief editor should have called her and told her not to come, but these three people... had schemed against her!
2023-05-27 00:56:22 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-27 00:56:25 | INFO | fairseq.tasks.translation | example hypothesis: Hearing Teacher Di’s praise, I was delighted. I put away the energy ball with my left hand and shot a light sword at Teacher Zhen with my right hand. The light sword actually managed to land smoothly. I was startled, and upon closer inspection, I discovered that it was just an afterimage. Teacher Zhen had already moved to my back and shouted, “Berserk Space!”
2023-05-27 00:56:25 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-27 00:56:27 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Originally, we proposed a three-on-three competition, but they said it wasn’t fair, because we had Teacher Di and Teacher Zhen, who were ranked higher than them, and they proposed five-on-three wins. Since we proposed the competition, the competition method could only be decided by them. In three days, we will secretly compete in the Royal Coliseum, and the competition will be held in the Royal Coliseum.”
2023-05-27 00:56:27 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-27 00:56:29 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Di used the light-type level-7 spell, Light Thunder Consecutive Explosion. I didn’t use this spell very often, because it wasn’t ideal for me to control it. Teacher Di cast nine Light Thunder Consecutive Explosion to surround me, forming a simple formation that prevented me from escaping in a short distance. Then, the Light Thunder Consecutive Explosion exploded one after another to form a powerful offensive power.
2023-05-27 00:56:29 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-27 00:56:32 | INFO | fairseq.tasks.translation | example hypothesis: Just as Ma Ke and the two teachers walked to the other end, Teacher Zhen sent out a small Dimensional Slash at me. As expected of the continent’s number one Magician. The suction force of his small Dimensional Slash was actually much stronger than mine. A small spatial crack appeared beside me, and a powerful suction force immediately swept towards me.
2023-05-27 00:56:32 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-27 00:56:33 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 4.183 | nll_loss 2.542 | ppl 5.82 | bleu 21.5 | wps 1980.7 | wpb 2420.8 | bsz 84.5 | num_updates 100124 | best_bleu 21.64
2023-05-27 00:56:33 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-27 00:56:40 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/concat-1-1-0.2-sf[zh-en]/checkpoint15.pt (epoch 15 @ 100124 updates, score 21.5) (writing took 7.026340282522142 seconds)
2023-05-27 00:56:40 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-05-27 00:56:40 | INFO | train | epoch 015 | loss 4.187 | nll_loss 2.568 | ppl 5.93 | wps 51986.1 | ups 0.91 | wpb 57189.6 | bsz 1477.5 | num_updates 100124 | lr 0.000199876 | gnorm 0.252 | clip 100 | loss_scale 28 | train_wall 7019 | wall 110194
2023-05-27 00:56:40 | INFO | fairseq.trainer | begin training epoch 16
2023-05-27 00:58:27 | INFO | train_inner | epoch 016:     76 / 6686 loss=4.184, nll_loss=2.564, ppl=5.91, wps=31253, ups=0.55, wpb=56722.3, bsz=1447.4, num_updates=100200, lr=0.0001998, gnorm=0.256, clip=100, loss_scale=16, train_wall=107, wall=110301
2023-05-27 01:00:23 | INFO | train_inner | epoch 016:    176 / 6686 loss=4.162, nll_loss=2.54, ppl=5.82, wps=49124.3, ups=0.86, wpb=57225.1, bsz=1480.6, num_updates=100300, lr=0.000199701, gnorm=0.256, clip=100, loss_scale=16, train_wall=108, wall=110418
2023-05-27 01:02:15 | INFO | train_inner | epoch 016:    276 / 6686 loss=4.161, nll_loss=2.538, ppl=5.81, wps=51415.9, ups=0.9, wpb=57207.3, bsz=1474.2, num_updates=100400, lr=0.000199601, gnorm=0.258, clip=100, loss_scale=16, train_wall=106, wall=110529
2023-05-27 01:04:04 | INFO | train_inner | epoch 016:    376 / 6686 loss=4.165, nll_loss=2.543, ppl=5.83, wps=52491, ups=0.92, wpb=57254, bsz=1501.8, num_updates=100500, lr=0.000199502, gnorm=0.252, clip=100, loss_scale=27, train_wall=105, wall=110638
2023-05-27 01:05:53 | INFO | train_inner | epoch 016:    476 / 6686 loss=4.174, nll_loss=2.553, ppl=5.87, wps=52484.6, ups=0.92, wpb=57182.1, bsz=1482.6, num_updates=100600, lr=0.000199403, gnorm=0.253, clip=100, loss_scale=32, train_wall=105, wall=110747
2023-05-27 01:07:42 | INFO | train_inner | epoch 016:    576 / 6686 loss=4.175, nll_loss=2.554, ppl=5.87, wps=52445.2, ups=0.92, wpb=57123.3, bsz=1469.2, num_updates=100700, lr=0.000199304, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=110856
2023-05-27 01:09:30 | INFO | train_inner | epoch 016:    676 / 6686 loss=4.168, nll_loss=2.547, ppl=5.85, wps=52522.8, ups=0.92, wpb=57064.6, bsz=1471.7, num_updates=100800, lr=0.000199205, gnorm=0.252, clip=100, loss_scale=32, train_wall=105, wall=110964
2023-05-27 01:11:19 | INFO | train_inner | epoch 016:    776 / 6686 loss=4.167, nll_loss=2.546, ppl=5.84, wps=52470.8, ups=0.92, wpb=57260.2, bsz=1499.7, num_updates=100900, lr=0.000199106, gnorm=0.252, clip=100, loss_scale=32, train_wall=105, wall=111074
2023-05-27 01:12:27 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 01:13:09 | INFO | train_inner | epoch 016:    877 / 6686 loss=4.18, nll_loss=2.56, ppl=5.9, wps=52140, ups=0.91, wpb=57244.8, bsz=1463, num_updates=101000, lr=0.000199007, gnorm=0.255, clip=100, loss_scale=37, train_wall=106, wall=111183
2023-05-27 01:14:58 | INFO | train_inner | epoch 016:    977 / 6686 loss=4.181, nll_loss=2.561, ppl=5.9, wps=52585.3, ups=0.92, wpb=57106.3, bsz=1478.8, num_updates=101100, lr=0.000198909, gnorm=0.254, clip=100, loss_scale=32, train_wall=105, wall=111292
2023-05-27 01:16:12 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 01:16:48 | INFO | train_inner | epoch 016:   1078 / 6686 loss=4.162, nll_loss=2.54, ppl=5.82, wps=52015.8, ups=0.91, wpb=57231.7, bsz=1503.8, num_updates=101200, lr=0.000198811, gnorm=0.251, clip=100, loss_scale=27, train_wall=106, wall=111402
2023-05-27 01:18:36 | INFO | train_inner | epoch 016:   1178 / 6686 loss=4.174, nll_loss=2.554, ppl=5.87, wps=52530.7, ups=0.92, wpb=57076.8, bsz=1483.1, num_updates=101300, lr=0.000198713, gnorm=0.256, clip=100, loss_scale=16, train_wall=105, wall=111511
2023-05-27 01:20:25 | INFO | train_inner | epoch 016:   1278 / 6686 loss=4.156, nll_loss=2.534, ppl=5.79, wps=52453.5, ups=0.92, wpb=57132.9, bsz=1501.5, num_updates=101400, lr=0.000198615, gnorm=0.254, clip=100, loss_scale=16, train_wall=105, wall=111620
2023-05-27 01:22:14 | INFO | train_inner | epoch 016:   1378 / 6686 loss=4.164, nll_loss=2.542, ppl=5.82, wps=52546.1, ups=0.92, wpb=57183.8, bsz=1495.3, num_updates=101500, lr=0.000198517, gnorm=0.251, clip=100, loss_scale=16, train_wall=105, wall=111728
2023-05-27 01:24:03 | INFO | train_inner | epoch 016:   1478 / 6686 loss=4.176, nll_loss=2.556, ppl=5.88, wps=52622.4, ups=0.92, wpb=57172.6, bsz=1461.2, num_updates=101600, lr=0.000198419, gnorm=0.255, clip=100, loss_scale=16, train_wall=105, wall=111837
2023-05-27 01:25:52 | INFO | train_inner | epoch 016:   1578 / 6686 loss=4.18, nll_loss=2.56, ppl=5.9, wps=52577, ups=0.92, wpb=57132.9, bsz=1472, num_updates=101700, lr=0.000198321, gnorm=0.257, clip=100, loss_scale=20, train_wall=105, wall=111946
2023-05-27 01:26:32 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 01:27:42 | INFO | train_inner | epoch 016:   1679 / 6686 loss=4.177, nll_loss=2.557, ppl=5.88, wps=52006.4, ups=0.91, wpb=57251.4, bsz=1466.5, num_updates=101800, lr=0.000198224, gnorm=0.257, clip=100, loss_scale=22, train_wall=106, wall=112056
2023-05-27 01:29:30 | INFO | train_inner | epoch 016:   1779 / 6686 loss=4.169, nll_loss=2.548, ppl=5.85, wps=52944.3, ups=0.92, wpb=57441.7, bsz=1489.3, num_updates=101900, lr=0.000198127, gnorm=0.252, clip=100, loss_scale=16, train_wall=105, wall=112164
2023-05-27 01:31:20 | INFO | train_inner | epoch 016:   1879 / 6686 loss=4.174, nll_loss=2.553, ppl=5.87, wps=52488.1, ups=0.91, wpb=57406.9, bsz=1482.2, num_updates=102000, lr=0.00019803, gnorm=0.253, clip=100, loss_scale=16, train_wall=106, wall=112274
2023-05-27 01:33:08 | INFO | train_inner | epoch 016:   1979 / 6686 loss=4.167, nll_loss=2.546, ppl=5.84, wps=52706.3, ups=0.92, wpb=57172.4, bsz=1471.9, num_updates=102100, lr=0.000197933, gnorm=0.254, clip=100, loss_scale=16, train_wall=105, wall=112382
2023-05-27 01:34:57 | INFO | train_inner | epoch 016:   2079 / 6686 loss=4.179, nll_loss=2.559, ppl=5.89, wps=52720.5, ups=0.92, wpb=57266.7, bsz=1486.2, num_updates=102200, lr=0.000197836, gnorm=0.251, clip=100, loss_scale=16, train_wall=105, wall=112491
2023-05-27 01:36:45 | INFO | train_inner | epoch 016:   2179 / 6686 loss=4.189, nll_loss=2.57, ppl=5.94, wps=52555.7, ups=0.92, wpb=57165.5, bsz=1448.7, num_updates=102300, lr=0.000197739, gnorm=0.254, clip=100, loss_scale=24, train_wall=105, wall=112600
2023-05-27 01:38:34 | INFO | train_inner | epoch 016:   2279 / 6686 loss=4.177, nll_loss=2.557, ppl=5.88, wps=52409.3, ups=0.92, wpb=57150.8, bsz=1488.8, num_updates=102400, lr=0.000197642, gnorm=0.254, clip=100, loss_scale=32, train_wall=105, wall=112709
2023-05-27 01:40:23 | INFO | train_inner | epoch 016:   2379 / 6686 loss=4.18, nll_loss=2.56, ppl=5.9, wps=52444.2, ups=0.92, wpb=57039.1, bsz=1472.5, num_updates=102500, lr=0.000197546, gnorm=0.255, clip=100, loss_scale=32, train_wall=105, wall=112817
2023-05-27 01:42:12 | INFO | train_inner | epoch 016:   2479 / 6686 loss=4.185, nll_loss=2.566, ppl=5.92, wps=52502.6, ups=0.92, wpb=57163.3, bsz=1493.8, num_updates=102600, lr=0.00019745, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=112926
2023-05-27 01:44:00 | INFO | train_inner | epoch 016:   2579 / 6686 loss=4.18, nll_loss=2.561, ppl=5.9, wps=52874.2, ups=0.92, wpb=57257, bsz=1470.8, num_updates=102700, lr=0.000197353, gnorm=0.252, clip=100, loss_scale=32, train_wall=104, wall=113035
2023-05-27 01:45:49 | INFO | train_inner | epoch 016:   2679 / 6686 loss=4.179, nll_loss=2.559, ppl=5.89, wps=52496, ups=0.92, wpb=57124.8, bsz=1480, num_updates=102800, lr=0.000197257, gnorm=0.252, clip=100, loss_scale=45, train_wall=105, wall=113143
2023-05-27 01:46:01 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 01:47:39 | INFO | train_inner | epoch 016:   2780 / 6686 loss=4.18, nll_loss=2.56, ppl=5.9, wps=52081.2, ups=0.91, wpb=57289.1, bsz=1472.3, num_updates=102900, lr=0.000197162, gnorm=0.252, clip=100, loss_scale=35, train_wall=106, wall=113253
2023-05-27 01:49:28 | INFO | train_inner | epoch 016:   2880 / 6686 loss=4.181, nll_loss=2.561, ppl=5.9, wps=52450.7, ups=0.92, wpb=57056.7, bsz=1469, num_updates=103000, lr=0.000197066, gnorm=0.253, clip=100, loss_scale=32, train_wall=105, wall=113362
2023-05-27 01:51:17 | INFO | train_inner | epoch 016:   2980 / 6686 loss=4.187, nll_loss=2.569, ppl=5.93, wps=52440, ups=0.92, wpb=57000.8, bsz=1472.4, num_updates=103100, lr=0.00019697, gnorm=0.255, clip=100, loss_scale=32, train_wall=105, wall=113471
2023-05-27 01:53:05 | INFO | train_inner | epoch 016:   3080 / 6686 loss=4.192, nll_loss=2.574, ppl=5.96, wps=52656.1, ups=0.92, wpb=57206.8, bsz=1478.3, num_updates=103200, lr=0.000196875, gnorm=0.253, clip=100, loss_scale=32, train_wall=105, wall=113579
2023-05-27 01:53:26 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 01:54:55 | INFO | train_inner | epoch 016:   3181 / 6686 loss=4.188, nll_loss=2.57, ppl=5.94, wps=52398.1, ups=0.91, wpb=57315.2, bsz=1489.7, num_updates=103300, lr=0.000196779, gnorm=0.257, clip=100, loss_scale=19, train_wall=106, wall=113689
2023-05-27 01:56:43 | INFO | train_inner | epoch 016:   3281 / 6686 loss=4.186, nll_loss=2.567, ppl=5.93, wps=52636.1, ups=0.92, wpb=57141.5, bsz=1460.3, num_updates=103400, lr=0.000196684, gnorm=0.255, clip=100, loss_scale=16, train_wall=105, wall=113797
2023-05-27 01:58:32 | INFO | train_inner | epoch 016:   3381 / 6686 loss=4.177, nll_loss=2.557, ppl=5.89, wps=52637.9, ups=0.92, wpb=57101.3, bsz=1482, num_updates=103500, lr=0.000196589, gnorm=0.254, clip=100, loss_scale=16, train_wall=105, wall=113906
2023-05-27 02:00:20 | INFO | train_inner | epoch 016:   3481 / 6686 loss=4.19, nll_loss=2.572, ppl=5.95, wps=52563.3, ups=0.92, wpb=57056.5, bsz=1448.7, num_updates=103600, lr=0.000196494, gnorm=0.257, clip=100, loss_scale=16, train_wall=105, wall=114014
2023-05-27 02:02:09 | INFO | train_inner | epoch 016:   3581 / 6686 loss=4.183, nll_loss=2.564, ppl=5.91, wps=52647.7, ups=0.92, wpb=57242.5, bsz=1489.9, num_updates=103700, lr=0.0001964, gnorm=0.255, clip=100, loss_scale=16, train_wall=105, wall=114123
2023-05-27 02:03:58 | INFO | train_inner | epoch 016:   3681 / 6686 loss=4.188, nll_loss=2.57, ppl=5.94, wps=52595.1, ups=0.92, wpb=57234.7, bsz=1473.4, num_updates=103800, lr=0.000196305, gnorm=0.255, clip=100, loss_scale=27, train_wall=105, wall=114232
2023-05-27 02:05:47 | INFO | train_inner | epoch 016:   3781 / 6686 loss=4.185, nll_loss=2.567, ppl=5.92, wps=52486.8, ups=0.92, wpb=57103.2, bsz=1460.1, num_updates=103900, lr=0.00019621, gnorm=0.255, clip=100, loss_scale=32, train_wall=105, wall=114341
2023-05-27 02:07:36 | INFO | train_inner | epoch 016:   3881 / 6686 loss=4.186, nll_loss=2.568, ppl=5.93, wps=52437.1, ups=0.92, wpb=57159.9, bsz=1470.2, num_updates=104000, lr=0.000196116, gnorm=0.252, clip=100, loss_scale=32, train_wall=105, wall=114450
2023-05-27 02:08:41 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 02:09:25 | INFO | train_inner | epoch 016:   3982 / 6686 loss=4.19, nll_loss=2.572, ppl=5.95, wps=51831.6, ups=0.91, wpb=56890.1, bsz=1479.5, num_updates=104100, lr=0.000196022, gnorm=0.256, clip=100, loss_scale=25, train_wall=106, wall=114560
2023-05-27 02:11:15 | INFO | train_inner | epoch 016:   4082 / 6686 loss=4.177, nll_loss=2.558, ppl=5.89, wps=52584.6, ups=0.92, wpb=57401.4, bsz=1487.7, num_updates=104200, lr=0.000195928, gnorm=0.253, clip=100, loss_scale=16, train_wall=105, wall=114669
2023-05-27 02:13:03 | INFO | train_inner | epoch 016:   4182 / 6686 loss=4.186, nll_loss=2.567, ppl=5.93, wps=52526.2, ups=0.92, wpb=56989, bsz=1468.7, num_updates=104300, lr=0.000195834, gnorm=0.255, clip=100, loss_scale=16, train_wall=105, wall=114777
2023-05-27 02:14:52 | INFO | train_inner | epoch 016:   4282 / 6686 loss=4.18, nll_loss=2.561, ppl=5.9, wps=52636.5, ups=0.92, wpb=57356.9, bsz=1483, num_updates=104400, lr=0.00019574, gnorm=0.253, clip=100, loss_scale=16, train_wall=105, wall=114886
2023-05-27 02:16:41 | INFO | train_inner | epoch 016:   4382 / 6686 loss=4.186, nll_loss=2.567, ppl=5.93, wps=52319.8, ups=0.92, wpb=57112.3, bsz=1484.2, num_updates=104500, lr=0.000195646, gnorm=0.257, clip=100, loss_scale=16, train_wall=105, wall=114995
2023-05-27 02:18:30 | INFO | train_inner | epoch 016:   4482 / 6686 loss=4.175, nll_loss=2.555, ppl=5.88, wps=52690.3, ups=0.92, wpb=57309.6, bsz=1482.6, num_updates=104600, lr=0.000195553, gnorm=0.249, clip=100, loss_scale=21, train_wall=105, wall=115104
2023-05-27 02:20:19 | INFO | train_inner | epoch 016:   4582 / 6686 loss=4.185, nll_loss=2.567, ppl=5.92, wps=52648.4, ups=0.92, wpb=57151.9, bsz=1472.2, num_updates=104700, lr=0.000195459, gnorm=0.253, clip=100, loss_scale=32, train_wall=105, wall=115213
2023-05-27 02:21:06 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 02:22:09 | INFO | train_inner | epoch 016:   4683 / 6686 loss=4.186, nll_loss=2.568, ppl=5.93, wps=51911.9, ups=0.9, wpb=57416.5, bsz=1489, num_updates=104800, lr=0.000195366, gnorm=0.252, clip=100, loss_scale=23, train_wall=107, wall=115323
2023-05-27 02:23:58 | INFO | train_inner | epoch 016:   4783 / 6686 loss=4.181, nll_loss=2.562, ppl=5.9, wps=52705.1, ups=0.92, wpb=57217.9, bsz=1491.6, num_updates=104900, lr=0.000195273, gnorm=0.254, clip=100, loss_scale=16, train_wall=105, wall=115432
2023-05-27 02:25:46 | INFO | train_inner | epoch 016:   4883 / 6686 loss=4.191, nll_loss=2.573, ppl=5.95, wps=52770.5, ups=0.92, wpb=57127.6, bsz=1477, num_updates=105000, lr=0.00019518, gnorm=0.254, clip=100, loss_scale=16, train_wall=105, wall=115540
2023-05-27 02:27:35 | INFO | train_inner | epoch 016:   4983 / 6686 loss=4.183, nll_loss=2.564, ppl=5.91, wps=52534.7, ups=0.92, wpb=57291.3, bsz=1475, num_updates=105100, lr=0.000195087, gnorm=0.253, clip=100, loss_scale=16, train_wall=105, wall=115649
2023-05-27 02:29:24 | INFO | train_inner | epoch 016:   5083 / 6686 loss=4.197, nll_loss=2.58, ppl=5.98, wps=52511.7, ups=0.92, wpb=57219.7, bsz=1464.4, num_updates=105200, lr=0.000194994, gnorm=0.256, clip=100, loss_scale=16, train_wall=105, wall=115758
2023-05-27 02:31:13 | INFO | train_inner | epoch 016:   5183 / 6686 loss=4.18, nll_loss=2.561, ppl=5.9, wps=52707.6, ups=0.92, wpb=57329.1, bsz=1470.2, num_updates=105300, lr=0.000194902, gnorm=0.253, clip=100, loss_scale=24, train_wall=105, wall=115867
2023-05-27 02:31:25 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 02:33:03 | INFO | train_inner | epoch 016:   5284 / 6686 loss=4.185, nll_loss=2.567, ppl=5.92, wps=52179.1, ups=0.91, wpb=57316.6, bsz=1480.2, num_updates=105400, lr=0.000194809, gnorm=0.252, clip=100, loss_scale=18, train_wall=106, wall=115977
2023-05-27 02:34:52 | INFO | train_inner | epoch 016:   5384 / 6686 loss=4.182, nll_loss=2.563, ppl=5.91, wps=52631.1, ups=0.92, wpb=57318.7, bsz=1473.4, num_updates=105500, lr=0.000194717, gnorm=0.25, clip=100, loss_scale=16, train_wall=105, wall=116086
2023-05-27 02:36:41 | INFO | train_inner | epoch 016:   5484 / 6686 loss=4.176, nll_loss=2.556, ppl=5.88, wps=52408.7, ups=0.91, wpb=57281, bsz=1477.8, num_updates=105600, lr=0.000194625, gnorm=0.253, clip=100, loss_scale=16, train_wall=106, wall=116195
2023-05-27 02:38:30 | INFO | train_inner | epoch 016:   5584 / 6686 loss=4.197, nll_loss=2.58, ppl=5.98, wps=52718.4, ups=0.92, wpb=57347.5, bsz=1457.2, num_updates=105700, lr=0.000194533, gnorm=0.254, clip=100, loss_scale=16, train_wall=105, wall=116304
2023-05-27 02:40:19 | INFO | train_inner | epoch 016:   5684 / 6686 loss=4.193, nll_loss=2.575, ppl=5.96, wps=52313.2, ups=0.92, wpb=57030.7, bsz=1479, num_updates=105800, lr=0.000194441, gnorm=0.255, clip=100, loss_scale=16, train_wall=105, wall=116413
2023-05-27 02:42:08 | INFO | train_inner | epoch 016:   5784 / 6686 loss=4.175, nll_loss=2.555, ppl=5.88, wps=52534, ups=0.92, wpb=57285, bsz=1479.7, num_updates=105900, lr=0.000194349, gnorm=0.254, clip=100, loss_scale=29, train_wall=105, wall=116522
2023-05-27 02:43:57 | INFO | train_inner | epoch 016:   5884 / 6686 loss=4.175, nll_loss=2.555, ppl=5.88, wps=52632.7, ups=0.92, wpb=57442.8, bsz=1497.1, num_updates=106000, lr=0.000194257, gnorm=0.25, clip=100, loss_scale=32, train_wall=105, wall=116631
2023-05-27 02:45:45 | INFO | train_inner | epoch 016:   5984 / 6686 loss=4.192, nll_loss=2.575, ppl=5.96, wps=52727.2, ups=0.92, wpb=57102.5, bsz=1467.8, num_updates=106100, lr=0.000194166, gnorm=0.252, clip=100, loss_scale=32, train_wall=105, wall=116739
2023-05-27 02:47:34 | INFO | train_inner | epoch 016:   6084 / 6686 loss=4.186, nll_loss=2.568, ppl=5.93, wps=52536, ups=0.92, wpb=57261.4, bsz=1475.6, num_updates=106200, lr=0.000194074, gnorm=0.252, clip=100, loss_scale=32, train_wall=105, wall=116848
2023-05-27 02:49:20 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 02:49:24 | INFO | train_inner | epoch 016:   6185 / 6686 loss=4.175, nll_loss=2.555, ppl=5.88, wps=52026.2, ups=0.91, wpb=57217.8, bsz=1483.7, num_updates=106300, lr=0.000193983, gnorm=0.253, clip=100, loss_scale=31, train_wall=106, wall=116958
2023-05-27 02:51:13 | INFO | train_inner | epoch 016:   6285 / 6686 loss=4.192, nll_loss=2.575, ppl=5.96, wps=52577.4, ups=0.92, wpb=57036, bsz=1467.4, num_updates=106400, lr=0.000193892, gnorm=0.253, clip=100, loss_scale=16, train_wall=105, wall=117067
2023-05-27 02:53:01 | INFO | train_inner | epoch 016:   6385 / 6686 loss=4.184, nll_loss=2.566, ppl=5.92, wps=52707, ups=0.92, wpb=57293.4, bsz=1499.4, num_updates=106500, lr=0.000193801, gnorm=0.251, clip=100, loss_scale=16, train_wall=105, wall=117176
2023-05-27 02:54:50 | INFO | train_inner | epoch 016:   6485 / 6686 loss=4.188, nll_loss=2.571, ppl=5.94, wps=52626, ups=0.92, wpb=56978.8, bsz=1465.3, num_updates=106600, lr=0.00019371, gnorm=0.255, clip=100, loss_scale=16, train_wall=105, wall=117284
2023-05-27 02:56:39 | INFO | train_inner | epoch 016:   6585 / 6686 loss=4.177, nll_loss=2.558, ppl=5.89, wps=52428.9, ups=0.92, wpb=57165, bsz=1473, num_updates=106700, lr=0.000193619, gnorm=0.252, clip=100, loss_scale=16, train_wall=105, wall=117393
2023-05-27 02:58:28 | INFO | train_inner | epoch 016:   6685 / 6686 loss=4.18, nll_loss=2.561, ppl=5.9, wps=52438, ups=0.92, wpb=57207.9, bsz=1477.7, num_updates=106800, lr=0.000193528, gnorm=0.254, clip=100, loss_scale=16, train_wall=105, wall=117502
2023-05-27 02:58:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-27 02:58:34 | INFO | fairseq.tasks.translation | example hypothesis: Why was that?
2023-05-27 02:58:34 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-27 02:58:34 | INFO | fairseq.tasks.translation | example hypothesis: I’ll make you lose so much that you don’t even have your pants left!
2023-05-27 02:58:34 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-27 02:58:35 | INFO | fairseq.tasks.translation | example hypothesis: Just as Shen Liangchuan heaved a sigh of relief, she said, “I’ll call for you to stay in the same room!”
2023-05-27 02:58:35 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-27 02:58:35 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved her hand and entered the elevator.
2023-05-27 02:58:35 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-27 02:58:36 | INFO | fairseq.tasks.translation | example hypothesis: When she looked up, she saw Song Cheng standing in the distance!
2023-05-27 02:58:36 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-27 02:58:37 | INFO | fairseq.tasks.translation | example hypothesis: Only then did Song Cheng pat his chest. “You scared me to death! Where’s Wang Chuan?”
2023-05-27 02:58:37 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-27 02:58:37 | INFO | fairseq.tasks.translation | example hypothesis: I said, “No, I can’t eat it.”
2023-05-27 02:58:37 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-27 02:58:38 | INFO | fairseq.tasks.translation | example hypothesis: Everyone didn’t believe it at first, but Wang Wenhao insisted that he would let the public view favor Wang Wenhao.
2023-05-27 02:58:38 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-27 02:58:39 | INFO | fairseq.tasks.translation | example hypothesis: Coming here like this with his identity, Baili Hongzhuang had to be treated even if he did not treat it!
2023-05-27 02:58:39 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-27 02:58:40 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian said, “Mr. Shen, I, I’ve kept too much blood and my brain lacks oxygen. I can’t think of anything. Why don’t you give me a hint?”
2023-05-27 02:58:40 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-27 02:58:41 | INFO | fairseq.tasks.translation | example hypothesis: He didn’t know why so many people heard about it. Since he couldn’t hide it any longer, he might as well tell them.
2023-05-27 02:58:41 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-27 02:58:42 | INFO | fairseq.tasks.translation | example hypothesis: She deliberately lowered her voice, but it could not hide the viciousness and viciousness in her tone.
2023-05-27 02:58:42 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-27 02:58:43 | INFO | fairseq.tasks.translation | example hypothesis: Beast pets of different ranks were different in strength, but beast pets were precious and rare. It was impossible for an ordinary person to possess one, even for the children of officials.
2023-05-27 02:58:43 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-27 02:58:44 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chixia gritted her teeth and cursed in a low voice.
2023-05-27 02:58:44 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-27 02:58:45 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang hid it very well, Di Bei Chen could still see the ripples in her eyes and felt a little warmth in them.
2023-05-27 02:58:45 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-27 02:58:46 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia walked in, not to mention the guests, she didn't even see a few waiters.
2023-05-27 02:58:46 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-27 02:58:47 | INFO | fairseq.tasks.translation | example hypothesis: This person was the fourth young miss of the Ye Family, Ye Qingling.
2023-05-27 02:58:47 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-27 02:58:48 | INFO | fairseq.tasks.translation | example hypothesis: That was because at this moment, she felt as though her chin was about to break.
2023-05-27 02:58:48 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-27 02:58:49 | INFO | fairseq.tasks.translation | example hypothesis: “Good Mu Zi, help me. If it wasn't for you, that old guy wouldn't have targeted me.”
2023-05-27 02:58:49 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-27 02:58:50 | INFO | fairseq.tasks.translation | example hypothesis: Bai Li Yu Yan was even more excited. She was the one in charge of this matter. Earlier, Bai Li Hong Zhuang had treated her like that. This time, she would definitely make things difficult for Bai Li Hong Zhuang.
2023-05-27 02:58:50 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-27 02:58:52 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How could that be? They also have four mages on their side, of course they won’t surrender so easily. After arguing for a long time, they finally decided on how to obtain control over the Kingdom of Alla through the competition.”
2023-05-27 02:58:52 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-27 02:58:53 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a little. Originally, he had been looking for a reason for Li Yuyue not being able to participate in the Imperial Family’s hunting competition.
2023-05-27 02:58:53 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-27 02:58:55 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my standard good? They’re all the most outstanding people in the country, how can my magic be so weak?”
2023-05-27 02:58:55 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-27 02:58:57 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yi Bei’s meaning was that if Fang Chi Xia didn’t want to go, then there was no need to go.
2023-05-27 02:58:57 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-27 02:58:58 | INFO | fairseq.tasks.translation | example hypothesis: She turned her head and saw that the five palm prints on her cheeks were very conspicuous. They were swelling at a speed visible to the naked eye. When she reached out to touch them, she could not help but hiss.
2023-05-27 02:58:58 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-27 02:58:59 | INFO | fairseq.tasks.translation | example hypothesis: This... how could this be the charm that that trash could emit?
2023-05-27 02:58:59 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-27 02:59:00 | INFO | fairseq.tasks.translation | example hypothesis: How could Wang Wenhao have found the newspaper agency? The chief editor should have called her to tell her not to come, but these three people... had schemed against her!
2023-05-27 02:59:00 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-27 02:59:03 | INFO | fairseq.tasks.translation | example hypothesis: Hearing Teacher Di’s praise, I was delighted. I put away the energy ball with my left hand, and a beam of light shot out from my right hand towards Teacher Zhen. The light sword actually hit the target smoothly. I was startled, and upon closer inspection, I realized that it was just an afterimage.
2023-05-27 02:59:03 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-27 02:59:06 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Originally, we proposed a two out of three competition, but their side said it wasn’t fair, because we had Teacher Di and Teacher Zhen, who were ranked higher than them, and they proposed five out of five, and three out of three. Since it was us who proposed the competition, we could only listen to them in the end. Three days from now, we will compete in secret in the Royal Coliseum. If we don’t win,
2023-05-27 02:59:06 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-27 02:59:08 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Di used the light element level 7 spell, Light Thunder Burst. I didn’t use much of this spell because my control over it wasn’t ideal. Teacher Di sent out nine Light Thunder Bursts to surround me, forming a simple formation that prevented me from escaping in a short distance. After that, all the Light Thunder Bursts exploded to form a powerful attack.
2023-05-27 02:59:08 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-27 02:59:11 | INFO | fairseq.tasks.translation | example hypothesis: Just as Mark and the two teachers walked to the other side, Teacher Zhen sent out a Lesser Dimensional Slash towards me. He was indeed worthy of being the continent’s number one Magician. The powerful suction force of his Lesser Dimensional Slash was actually much stronger than mine. A small spatial rift appeared beside me, and a powerful suction force immediately swept towards me.
2023-05-27 02:59:11 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-27 02:59:11 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 4.171 | nll_loss 2.526 | ppl 5.76 | bleu 21.8 | wps 1944.3 | wpb 2420.8 | bsz 84.5 | num_updates 106801 | best_bleu 21.8
2023-05-27 02:59:11 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-27 02:59:17 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/concat-1-1-0.2-sf[zh-en]/checkpoint16.pt (epoch 16 @ 106801 updates, score 21.8) (writing took 5.349092091433704 seconds)
2023-05-27 02:59:17 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-05-27 02:59:17 | INFO | train | epoch 016 | loss 4.18 | nll_loss 2.56 | ppl 5.9 | wps 51904.4 | ups 0.91 | wpb 57190.5 | bsz 1477.5 | num_updates 106801 | lr 0.000193527 | gnorm 0.254 | clip 100 | loss_scale 23 | train_wall 7026 | wall 117551
2023-05-27 02:59:17 | INFO | fairseq.trainer | begin training epoch 17
2023-05-27 03:01:13 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 03:01:29 | INFO | train_inner | epoch 017:    100 / 6686 loss=4.161, nll_loss=2.539, ppl=5.81, wps=31228.7, ups=0.55, wpb=56696.8, bsz=1485.4, num_updates=106900, lr=0.000193438, gnorm=0.259, clip=100, loss_scale=29, train_wall=108, wall=117683
2023-05-27 03:03:24 | INFO | train_inner | epoch 017:    200 / 6686 loss=4.16, nll_loss=2.538, ppl=5.81, wps=49813.3, ups=0.87, wpb=57205.1, bsz=1495.8, num_updates=107000, lr=0.000193347, gnorm=0.257, clip=100, loss_scale=16, train_wall=107, wall=117798
2023-05-27 03:05:14 | INFO | train_inner | epoch 017:    300 / 6686 loss=4.154, nll_loss=2.53, ppl=5.78, wps=51939.4, ups=0.91, wpb=57142.3, bsz=1486.4, num_updates=107100, lr=0.000193257, gnorm=0.256, clip=100, loss_scale=16, train_wall=105, wall=117908
2023-05-27 03:07:04 | INFO | train_inner | epoch 017:    400 / 6686 loss=4.152, nll_loss=2.529, ppl=5.77, wps=52175.2, ups=0.91, wpb=57082.9, bsz=1489.6, num_updates=107200, lr=0.000193167, gnorm=0.254, clip=100, loss_scale=16, train_wall=105, wall=118018
2023-05-27 03:08:53 | INFO | train_inner | epoch 017:    500 / 6686 loss=4.168, nll_loss=2.547, ppl=5.84, wps=52535.7, ups=0.92, wpb=57265.6, bsz=1493.7, num_updates=107300, lr=0.000193077, gnorm=0.257, clip=100, loss_scale=16, train_wall=105, wall=118127
2023-05-27 03:10:41 | INFO | train_inner | epoch 017:    600 / 6686 loss=4.162, nll_loss=2.54, ppl=5.82, wps=52803.3, ups=0.92, wpb=57440.8, bsz=1511.6, num_updates=107400, lr=0.000192987, gnorm=0.251, clip=100, loss_scale=16, train_wall=105, wall=118236
2023-05-27 03:12:30 | INFO | train_inner | epoch 017:    700 / 6686 loss=4.171, nll_loss=2.55, ppl=5.86, wps=52650.9, ups=0.92, wpb=57054.4, bsz=1475.5, num_updates=107500, lr=0.000192897, gnorm=0.255, clip=100, loss_scale=32, train_wall=105, wall=118344
2023-05-27 03:14:19 | INFO | train_inner | epoch 017:    800 / 6686 loss=4.154, nll_loss=2.531, ppl=5.78, wps=52525.8, ups=0.92, wpb=57237.9, bsz=1501.4, num_updates=107600, lr=0.000192807, gnorm=0.254, clip=100, loss_scale=32, train_wall=105, wall=118453
2023-05-27 03:14:47 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 03:16:09 | INFO | train_inner | epoch 017:    901 / 6686 loss=4.161, nll_loss=2.539, ppl=5.81, wps=52170.1, ups=0.91, wpb=57297.4, bsz=1477.9, num_updates=107700, lr=0.000192718, gnorm=0.255, clip=100, loss_scale=20, train_wall=106, wall=118563
2023-05-27 03:17:57 | INFO | train_inner | epoch 017:   1001 / 6686 loss=4.166, nll_loss=2.545, ppl=5.84, wps=52878.6, ups=0.92, wpb=57392.9, bsz=1499.4, num_updates=107800, lr=0.000192629, gnorm=0.254, clip=100, loss_scale=16, train_wall=105, wall=118671
2023-05-27 03:19:46 | INFO | train_inner | epoch 017:   1101 / 6686 loss=4.176, nll_loss=2.556, ppl=5.88, wps=52528.5, ups=0.92, wpb=57090.1, bsz=1457.2, num_updates=107900, lr=0.000192539, gnorm=0.259, clip=100, loss_scale=16, train_wall=105, wall=118780
2023-05-27 03:21:35 | INFO | train_inner | epoch 017:   1201 / 6686 loss=4.168, nll_loss=2.547, ppl=5.84, wps=52698.5, ups=0.92, wpb=57413.8, bsz=1465.7, num_updates=108000, lr=0.00019245, gnorm=0.252, clip=100, loss_scale=16, train_wall=105, wall=118889
2023-05-27 03:23:23 | INFO | train_inner | epoch 017:   1301 / 6686 loss=4.164, nll_loss=2.543, ppl=5.83, wps=52798.8, ups=0.92, wpb=57363.2, bsz=1509.8, num_updates=108100, lr=0.000192361, gnorm=0.256, clip=100, loss_scale=16, train_wall=105, wall=118998
2023-05-27 03:25:12 | INFO | train_inner | epoch 017:   1401 / 6686 loss=4.168, nll_loss=2.546, ppl=5.84, wps=52591, ups=0.92, wpb=57306.9, bsz=1492.4, num_updates=108200, lr=0.000192272, gnorm=0.254, clip=100, loss_scale=26, train_wall=105, wall=119107
2023-05-27 03:27:01 | INFO | train_inner | epoch 017:   1501 / 6686 loss=4.173, nll_loss=2.553, ppl=5.87, wps=52766.6, ups=0.92, wpb=57273.6, bsz=1468.4, num_updates=108300, lr=0.000192183, gnorm=0.258, clip=100, loss_scale=32, train_wall=105, wall=119215
2023-05-27 03:28:50 | INFO | train_inner | epoch 017:   1601 / 6686 loss=4.17, nll_loss=2.549, ppl=5.85, wps=52746.5, ups=0.92, wpb=57325.5, bsz=1469.6, num_updates=108400, lr=0.000192095, gnorm=0.253, clip=100, loss_scale=32, train_wall=105, wall=119324
2023-05-27 03:30:38 | INFO | train_inner | epoch 017:   1701 / 6686 loss=4.166, nll_loss=2.544, ppl=5.83, wps=52686.8, ups=0.92, wpb=57124.4, bsz=1456.8, num_updates=108500, lr=0.000192006, gnorm=0.253, clip=100, loss_scale=32, train_wall=105, wall=119432
2023-05-27 03:32:27 | INFO | train_inner | epoch 017:   1801 / 6686 loss=4.175, nll_loss=2.555, ppl=5.88, wps=52592.2, ups=0.92, wpb=57183.5, bsz=1451, num_updates=108600, lr=0.000191918, gnorm=0.255, clip=100, loss_scale=32, train_wall=105, wall=119541
2023-05-27 03:33:22 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 03:34:16 | INFO | train_inner | epoch 017:   1902 / 6686 loss=4.169, nll_loss=2.548, ppl=5.85, wps=52362, ups=0.91, wpb=57391.8, bsz=1476.6, num_updates=108700, lr=0.000191829, gnorm=0.253, clip=100, loss_scale=33, train_wall=106, wall=119651
2023-05-27 03:36:05 | INFO | train_inner | epoch 017:   2002 / 6686 loss=4.177, nll_loss=2.557, ppl=5.88, wps=52633.9, ups=0.92, wpb=57200.7, bsz=1474.3, num_updates=108800, lr=0.000191741, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=119759
2023-05-27 03:37:54 | INFO | train_inner | epoch 017:   2102 / 6686 loss=4.179, nll_loss=2.559, ppl=5.89, wps=52677.8, ups=0.92, wpb=57262.3, bsz=1469.5, num_updates=108900, lr=0.000191653, gnorm=0.253, clip=100, loss_scale=32, train_wall=105, wall=119868
2023-05-27 03:39:43 | INFO | train_inner | epoch 017:   2202 / 6686 loss=4.186, nll_loss=2.568, ppl=5.93, wps=52410.4, ups=0.92, wpb=56999.6, bsz=1464.5, num_updates=109000, lr=0.000191565, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=119977
2023-05-27 03:41:31 | INFO | train_inner | epoch 017:   2302 / 6686 loss=4.18, nll_loss=2.56, ppl=5.9, wps=52675.2, ups=0.92, wpb=57277.5, bsz=1491.3, num_updates=109100, lr=0.000191477, gnorm=0.257, clip=100, loss_scale=32, train_wall=105, wall=120085
2023-05-27 03:42:52 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 03:43:21 | INFO | train_inner | epoch 017:   2403 / 6686 loss=4.187, nll_loss=2.569, ppl=5.93, wps=52113.3, ups=0.91, wpb=57218.3, bsz=1464.5, num_updates=109200, lr=0.00019139, gnorm=0.257, clip=100, loss_scale=36, train_wall=106, wall=120195
2023-05-27 03:45:10 | INFO | train_inner | epoch 017:   2503 / 6686 loss=4.178, nll_loss=2.558, ppl=5.89, wps=52595.8, ups=0.92, wpb=57164.6, bsz=1469.4, num_updates=109300, lr=0.000191302, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=120304
2023-05-27 03:46:58 | INFO | train_inner | epoch 017:   2603 / 6686 loss=4.178, nll_loss=2.558, ppl=5.89, wps=52782.2, ups=0.92, wpb=57180.1, bsz=1471, num_updates=109400, lr=0.000191215, gnorm=0.255, clip=100, loss_scale=32, train_wall=105, wall=120412
2023-05-27 03:48:47 | INFO | train_inner | epoch 017:   2703 / 6686 loss=4.17, nll_loss=2.549, ppl=5.85, wps=52400.4, ups=0.92, wpb=57155.1, bsz=1475, num_updates=109500, lr=0.000191127, gnorm=0.254, clip=100, loss_scale=32, train_wall=105, wall=120521
2023-05-27 03:49:47 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 03:50:37 | INFO | train_inner | epoch 017:   2804 / 6686 loss=4.174, nll_loss=2.554, ppl=5.87, wps=51937.1, ups=0.91, wpb=57175.3, bsz=1487.5, num_updates=109600, lr=0.00019104, gnorm=0.256, clip=100, loss_scale=25, train_wall=106, wall=120631
2023-05-27 03:52:26 | INFO | train_inner | epoch 017:   2904 / 6686 loss=4.182, nll_loss=2.562, ppl=5.91, wps=52668.4, ups=0.92, wpb=56993.8, bsz=1472.2, num_updates=109700, lr=0.000190953, gnorm=0.257, clip=100, loss_scale=16, train_wall=104, wall=120740
2023-05-27 03:54:14 | INFO | train_inner | epoch 017:   3004 / 6686 loss=4.179, nll_loss=2.56, ppl=5.9, wps=52335.1, ups=0.92, wpb=57002.4, bsz=1460.4, num_updates=109800, lr=0.000190866, gnorm=0.256, clip=100, loss_scale=16, train_wall=105, wall=120849
2023-05-27 03:56:03 | INFO | train_inner | epoch 017:   3104 / 6686 loss=4.181, nll_loss=2.562, ppl=5.9, wps=52884.3, ups=0.92, wpb=57206.4, bsz=1463.9, num_updates=109900, lr=0.000190779, gnorm=0.255, clip=100, loss_scale=16, train_wall=104, wall=120957
2023-05-27 03:57:51 | INFO | train_inner | epoch 017:   3204 / 6686 loss=4.18, nll_loss=2.561, ppl=5.9, wps=52651, ups=0.92, wpb=57136.8, bsz=1472.6, num_updates=110000, lr=0.000190693, gnorm=0.255, clip=100, loss_scale=16, train_wall=105, wall=121065
2023-05-27 03:59:39 | INFO | train_inner | epoch 017:   3304 / 6686 loss=4.17, nll_loss=2.55, ppl=5.86, wps=52748.5, ups=0.92, wpb=57144.2, bsz=1488.2, num_updates=110100, lr=0.000190606, gnorm=0.259, clip=100, loss_scale=22, train_wall=104, wall=121174
2023-05-27 04:01:28 | INFO | train_inner | epoch 017:   3404 / 6686 loss=4.176, nll_loss=2.557, ppl=5.88, wps=52557.9, ups=0.92, wpb=57124.1, bsz=1472.6, num_updates=110200, lr=0.000190519, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=121282
2023-05-27 04:03:17 | INFO | train_inner | epoch 017:   3504 / 6686 loss=4.159, nll_loss=2.537, ppl=5.8, wps=52671, ups=0.92, wpb=57240.5, bsz=1507, num_updates=110300, lr=0.000190433, gnorm=0.253, clip=100, loss_scale=32, train_wall=105, wall=121391
2023-05-27 04:05:05 | INFO | train_inner | epoch 017:   3604 / 6686 loss=4.164, nll_loss=2.543, ppl=5.83, wps=52572.4, ups=0.92, wpb=57035.7, bsz=1477.3, num_updates=110400, lr=0.000190347, gnorm=0.259, clip=100, loss_scale=32, train_wall=105, wall=121499
2023-05-27 04:06:34 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 04:06:55 | INFO | train_inner | epoch 017:   3705 / 6686 loss=4.178, nll_loss=2.558, ppl=5.89, wps=52236, ups=0.91, wpb=57121.2, bsz=1466.2, num_updates=110500, lr=0.000190261, gnorm=0.255, clip=100, loss_scale=29, train_wall=106, wall=121609
2023-05-27 04:08:44 | INFO | train_inner | epoch 017:   3805 / 6686 loss=4.171, nll_loss=2.551, ppl=5.86, wps=52399, ups=0.92, wpb=57141.6, bsz=1449.6, num_updates=110600, lr=0.000190175, gnorm=0.258, clip=100, loss_scale=16, train_wall=105, wall=121718
2023-05-27 04:10:32 | INFO | train_inner | epoch 017:   3905 / 6686 loss=4.172, nll_loss=2.551, ppl=5.86, wps=52706.1, ups=0.92, wpb=57213.6, bsz=1470.6, num_updates=110700, lr=0.000190089, gnorm=0.255, clip=100, loss_scale=16, train_wall=105, wall=121826
2023-05-27 04:12:21 | INFO | train_inner | epoch 017:   4005 / 6686 loss=4.176, nll_loss=2.557, ppl=5.89, wps=52758, ups=0.92, wpb=57151.4, bsz=1478.2, num_updates=110800, lr=0.000190003, gnorm=0.258, clip=100, loss_scale=16, train_wall=105, wall=121935
2023-05-27 04:14:09 | INFO | train_inner | epoch 017:   4105 / 6686 loss=4.161, nll_loss=2.54, ppl=5.82, wps=52497, ups=0.92, wpb=57079.1, bsz=1505.4, num_updates=110900, lr=0.000189917, gnorm=0.253, clip=100, loss_scale=16, train_wall=105, wall=122044
2023-05-27 04:15:58 | INFO | train_inner | epoch 017:   4205 / 6686 loss=4.183, nll_loss=2.564, ppl=5.91, wps=52465.2, ups=0.92, wpb=56989.8, bsz=1466.2, num_updates=111000, lr=0.000189832, gnorm=0.261, clip=100, loss_scale=17, train_wall=105, wall=122152
2023-05-27 04:17:24 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 04:17:48 | INFO | train_inner | epoch 017:   4306 / 6686 loss=4.178, nll_loss=2.559, ppl=5.89, wps=52286.1, ups=0.91, wpb=57364.7, bsz=1473.4, num_updates=111100, lr=0.000189746, gnorm=0.256, clip=100, loss_scale=28, train_wall=106, wall=122262
2023-05-27 04:19:36 | INFO | train_inner | epoch 017:   4406 / 6686 loss=4.18, nll_loss=2.561, ppl=5.9, wps=52566.8, ups=0.92, wpb=57151.3, bsz=1486.6, num_updates=111200, lr=0.000189661, gnorm=0.254, clip=100, loss_scale=16, train_wall=105, wall=122371
2023-05-27 04:21:25 | INFO | train_inner | epoch 017:   4506 / 6686 loss=4.182, nll_loss=2.563, ppl=5.91, wps=52687.7, ups=0.92, wpb=57146.3, bsz=1454.3, num_updates=111300, lr=0.000189576, gnorm=0.253, clip=100, loss_scale=16, train_wall=105, wall=122479
2023-05-27 04:23:14 | INFO | train_inner | epoch 017:   4606 / 6686 loss=4.178, nll_loss=2.559, ppl=5.89, wps=52744, ups=0.92, wpb=57357.7, bsz=1479, num_updates=111400, lr=0.00018949, gnorm=0.253, clip=100, loss_scale=16, train_wall=105, wall=122588
2023-05-27 04:25:02 | INFO | train_inner | epoch 017:   4706 / 6686 loss=4.172, nll_loss=2.551, ppl=5.86, wps=52590, ups=0.92, wpb=57086.7, bsz=1463.5, num_updates=111500, lr=0.000189405, gnorm=0.256, clip=100, loss_scale=16, train_wall=105, wall=122696
2023-05-27 04:26:51 | INFO | train_inner | epoch 017:   4806 / 6686 loss=4.177, nll_loss=2.558, ppl=5.89, wps=52507, ups=0.92, wpb=57101.6, bsz=1490, num_updates=111600, lr=0.000189321, gnorm=0.259, clip=100, loss_scale=18, train_wall=105, wall=122805
2023-05-27 04:28:40 | INFO | train_inner | epoch 017:   4906 / 6686 loss=4.189, nll_loss=2.571, ppl=5.94, wps=52644, ups=0.92, wpb=57200.5, bsz=1453, num_updates=111700, lr=0.000189236, gnorm=0.254, clip=100, loss_scale=32, train_wall=105, wall=122914
2023-05-27 04:30:28 | INFO | train_inner | epoch 017:   5006 / 6686 loss=4.179, nll_loss=2.559, ppl=5.89, wps=52611.1, ups=0.92, wpb=57016.1, bsz=1473.3, num_updates=111800, lr=0.000189151, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=123022
2023-05-27 04:30:29 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 04:30:29 | INFO | train_inner | epoch 017:   5007 / 6686 loss=None, nll_loss=None, ppl=0, wps=0, ups=0, wpb=None, bsz=None, num_updates=None, lr=None, gnorm=None, clip=None, loss_scale=16, train_wall=1, wall=123023
2023-05-27 04:32:17 | INFO | train_inner | epoch 017:   5107 / 6686 loss=4.183, nll_loss=2.564, ppl=5.92, wps=52959.6, ups=0.93, wpb=57172.8, bsz=1472.7, num_updates=111900, lr=0.000189067, gnorm=0.257, clip=100, loss_scale=16, train_wall=104, wall=123131
2023-05-27 04:34:06 | INFO | train_inner | epoch 017:   5207 / 6686 loss=4.178, nll_loss=2.559, ppl=5.89, wps=52538.6, ups=0.92, wpb=57202.1, bsz=1478.3, num_updates=112000, lr=0.000188982, gnorm=0.26, clip=100, loss_scale=16, train_wall=105, wall=123240
2023-05-27 04:35:55 | INFO | train_inner | epoch 017:   5307 / 6686 loss=4.182, nll_loss=2.563, ppl=5.91, wps=52532.6, ups=0.92, wpb=57210.5, bsz=1478, num_updates=112100, lr=0.000188898, gnorm=0.256, clip=100, loss_scale=16, train_wall=105, wall=123349
2023-05-27 04:37:44 | INFO | train_inner | epoch 017:   5407 / 6686 loss=4.172, nll_loss=2.552, ppl=5.87, wps=52748.7, ups=0.92, wpb=57478.8, bsz=1494.6, num_updates=112200, lr=0.000188814, gnorm=0.255, clip=100, loss_scale=16, train_wall=105, wall=123458
2023-05-27 04:38:09 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 04:39:33 | INFO | train_inner | epoch 017:   5508 / 6686 loss=4.173, nll_loss=2.553, ppl=5.87, wps=52269.4, ups=0.91, wpb=57259.3, bsz=1497, num_updates=112300, lr=0.00018873, gnorm=0.255, clip=100, loss_scale=10, train_wall=106, wall=123568
2023-05-27 04:41:22 | INFO | train_inner | epoch 017:   5608 / 6686 loss=4.182, nll_loss=2.563, ppl=5.91, wps=52670.5, ups=0.92, wpb=57192.6, bsz=1453.1, num_updates=112400, lr=0.000188646, gnorm=0.255, clip=100, loss_scale=8, train_wall=105, wall=123676
2023-05-27 04:43:11 | INFO | train_inner | epoch 017:   5708 / 6686 loss=4.171, nll_loss=2.551, ppl=5.86, wps=52632.7, ups=0.92, wpb=57328.1, bsz=1460.2, num_updates=112500, lr=0.000188562, gnorm=0.255, clip=100, loss_scale=8, train_wall=105, wall=123785
2023-05-27 04:45:00 | INFO | train_inner | epoch 017:   5808 / 6686 loss=4.167, nll_loss=2.546, ppl=5.84, wps=52563.5, ups=0.92, wpb=57257.5, bsz=1490.9, num_updates=112600, lr=0.000188478, gnorm=0.256, clip=100, loss_scale=8, train_wall=105, wall=123894
2023-05-27 04:46:48 | INFO | train_inner | epoch 017:   5908 / 6686 loss=4.172, nll_loss=2.552, ppl=5.86, wps=52838.9, ups=0.92, wpb=57210, bsz=1481.7, num_updates=112700, lr=0.000188394, gnorm=0.253, clip=100, loss_scale=8, train_wall=105, wall=124002
2023-05-27 04:48:37 | INFO | train_inner | epoch 017:   6008 / 6686 loss=4.18, nll_loss=2.562, ppl=5.9, wps=52511.5, ups=0.92, wpb=57149.4, bsz=1477, num_updates=112800, lr=0.000188311, gnorm=0.254, clip=100, loss_scale=13, train_wall=105, wall=124111
2023-05-27 04:50:25 | INFO | train_inner | epoch 017:   6108 / 6686 loss=4.189, nll_loss=2.571, ppl=5.94, wps=52684.4, ups=0.92, wpb=57079.8, bsz=1456.9, num_updates=112900, lr=0.000188227, gnorm=0.259, clip=100, loss_scale=16, train_wall=105, wall=124219
2023-05-27 04:52:14 | INFO | train_inner | epoch 017:   6208 / 6686 loss=4.174, nll_loss=2.555, ppl=5.88, wps=52859.8, ups=0.92, wpb=57233.6, bsz=1484.7, num_updates=113000, lr=0.000188144, gnorm=0.255, clip=100, loss_scale=16, train_wall=105, wall=124328
2023-05-27 04:53:27 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 04:54:03 | INFO | train_inner | epoch 017:   6309 / 6686 loss=4.189, nll_loss=2.571, ppl=5.94, wps=52054.6, ups=0.91, wpb=57105.8, bsz=1467.2, num_updates=113100, lr=0.000188061, gnorm=0.258, clip=100, loss_scale=13, train_wall=106, wall=124437
2023-05-27 04:55:52 | INFO | train_inner | epoch 017:   6409 / 6686 loss=4.173, nll_loss=2.554, ppl=5.87, wps=52952.9, ups=0.92, wpb=57379.4, bsz=1508.3, num_updates=113200, lr=0.000187978, gnorm=0.254, clip=100, loss_scale=8, train_wall=105, wall=124546
2023-05-27 04:57:40 | INFO | train_inner | epoch 017:   6509 / 6686 loss=4.179, nll_loss=2.56, ppl=5.9, wps=52734.9, ups=0.92, wpb=57138.1, bsz=1485, num_updates=113300, lr=0.000187895, gnorm=0.257, clip=100, loss_scale=8, train_wall=105, wall=124654
2023-05-27 04:59:28 | INFO | train_inner | epoch 017:   6609 / 6686 loss=4.176, nll_loss=2.557, ppl=5.88, wps=52814.8, ups=0.92, wpb=57189.6, bsz=1485.3, num_updates=113400, lr=0.000187812, gnorm=0.254, clip=100, loss_scale=8, train_wall=105, wall=124762
2023-05-27 05:00:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-27 05:00:57 | INFO | fairseq.tasks.translation | example hypothesis: Why was that?
2023-05-27 05:00:57 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-27 05:00:57 | INFO | fairseq.tasks.translation | example hypothesis: I’ll make you lose so badly that you don’t even have your pants left!
2023-05-27 05:00:57 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-27 05:00:58 | INFO | fairseq.tasks.translation | example hypothesis: Just as Shen Liangchuan heaved a sigh of relief, he heard her say, “I’ll call you to stay in the same room!”
2023-05-27 05:00:58 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-27 05:00:59 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved her hand and entered the elevator.
2023-05-27 05:00:59 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-27 05:00:59 | INFO | fairseq.tasks.translation | example hypothesis: She raised her head and saw Song Cheng standing in the distance!
2023-05-27 05:00:59 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-27 05:01:00 | INFO | fairseq.tasks.translation | example hypothesis: Song Cheng patted his chest. “You scared me to death! Where’s Wang Chuan?”
2023-05-27 05:01:00 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-27 05:01:01 | INFO | fairseq.tasks.translation | example hypothesis: I said, “No, I can’t eat it.”
2023-05-27 05:01:01 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-27 05:01:01 | INFO | fairseq.tasks.translation | example hypothesis: Everyone didn’t believe it at first, but Wang Wenhao insisted that he was biased towards Wang Wenhao.
2023-05-27 05:01:01 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-27 05:01:02 | INFO | fairseq.tasks.translation | example hypothesis: Coming here like this with his identity, Baili Hongzhuang had to be treated even if she did not want to!
2023-05-27 05:01:02 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-27 05:01:03 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian: “Mr. Shen, I, I have kept too much blood and my brain lacks oxygen. I can’t think of anything. Why don’t you give me a hint?”
2023-05-27 05:01:03 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-27 05:01:04 | INFO | fairseq.tasks.translation | example hypothesis: He didn’t know why so many people had heard about it. Since he couldn’t hide it anymore, he might as well tell them.
2023-05-27 05:01:04 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-27 05:01:05 | INFO | fairseq.tasks.translation | example hypothesis: She deliberately lowered her voice, but she could not hide the viciousness and viciousness in her tone.
2023-05-27 05:01:05 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-27 05:01:06 | INFO | fairseq.tasks.translation | example hypothesis: Beast pets of different levels were different in strength, but beast pets were precious and rare. It was impossible for ordinary people to possess one, even for the descendants of officials.
2023-05-27 05:01:06 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-27 05:01:07 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chixia gritted her teeth and cursed in a low voice.
2023-05-27 05:01:07 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-27 05:01:08 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang had concealed it very well, Di Beichen could still see the ripples in her eyes and warmth filled his eyes.
2023-05-27 05:01:08 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-27 05:01:09 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia walked in, she didn't even see a few waiters, let alone guests.
2023-05-27 05:01:09 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-27 05:01:10 | INFO | fairseq.tasks.translation | example hypothesis: This person was the Ye Family's fourth young miss, Ye Qing Ling.
2023-05-27 05:01:10 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-27 05:01:11 | INFO | fairseq.tasks.translation | example hypothesis: Because at this moment, she felt that her chin was about to break.
2023-05-27 05:01:11 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-27 05:01:13 | INFO | fairseq.tasks.translation | example hypothesis: “Good Mu Zi, help me. If it wasn't for you, that old guy wouldn't have targeted me.”
2023-05-27 05:01:13 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-27 05:01:14 | INFO | fairseq.tasks.translation | example hypothesis: Baili Yuyan was even more excited. She was the one who was in charge of this. She would definitely make things difficult for Baili Hongzhuang this time.
2023-05-27 05:01:14 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-27 05:01:15 | INFO | fairseq.tasks.translation | example hypothesis: “How can that be? They’re also four mages, of course they won’t surrender so easily. After arguing for a long time, they decided to use the competition to obtain control over the Kingdom of Axia.”
2023-05-27 05:01:15 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-27 05:01:16 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a little. He had always been looking for reasons for Li Yuyue not being able to participate in the Imperial Family Hunting Competition.
2023-05-27 05:01:16 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-27 05:01:17 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my level good? They’re all the best talents in the country, how can my magic be so weak?”
2023-05-27 05:01:17 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-27 05:01:19 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yi Bei’s meaning was, if Fang Chi Xia didn’t want to go, then there was no need to go.
2023-05-27 05:01:19 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-27 05:01:21 | INFO | fairseq.tasks.translation | example hypothesis: She tilted her head and saw that the five palm prints on her cheeks were very eye-catching. They swelled up at a speed visible to the naked eye. When she reached out to touch them, she couldn’t help but hiss.
2023-05-27 05:01:21 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-27 05:01:22 | INFO | fairseq.tasks.translation | example hypothesis: This... how could this be the charm that that trash could emit?
2023-05-27 05:01:22 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-27 05:01:23 | INFO | fairseq.tasks.translation | example hypothesis: How could Wang Wenhao have found the newspaper firm? The chief editor should have called to inform her not to come to the newspaper firm, but these three people... had schemed against her!
2023-05-27 05:01:23 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-27 05:01:26 | INFO | fairseq.tasks.translation | example hypothesis: Hearing Teacher Di’s praise, I was delighted. I withdrew the energy ball with my left hand, and a beam of light shot out from my right hand towards Teacher Zhen. The beam of light actually managed to hit the target smoothly. I was startled, and upon closer inspection, I realized that it was just an afterimage. Teacher Zhen had already moved to my back, and shouted, “
2023-05-27 05:01:26 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-27 05:01:29 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Originally, we proposed a two out of three competition, but they said it wasn’t fair, because we have Teacher D and Teacher Zhen, and their ranking is higher than them, so they proposed a three out of five competition. Since we proposed the competition, the method of the competition can only be decided by them. Three days later, we will compete in secret in the Royal Coliseum. If we don’t win, then we will lose.”
2023-05-27 05:01:29 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-27 05:01:31 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Di used the light magic of the seventh rank, Light Thunder Burst. I didn’t use this spell much, because my control over it wasn’t ideal. Teacher Di released nine Light Thunder Bursts to surround me, forming a simple formation that prevented me from escaping in a short distance, and then all the Light Thunder Bursts exploded to form a powerful attack.
2023-05-27 05:01:31 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-27 05:01:34 | INFO | fairseq.tasks.translation | example hypothesis: Just as Ma Ke and the two teachers walked to the other side, Teacher Zhen sent out a Lesser Dimensional Slash at me. As expected of the continent’s number one Magician. His Lesser Dimensional Slash’s suction force was actually much stronger than mine. A small spatial crack appeared beside me, and a strong suction force swept towards me.
2023-05-27 05:01:34 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-27 05:01:34 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 4.171 | nll_loss 2.53 | ppl 5.78 | bleu 21.62 | wps 1980.7 | wpb 2420.8 | bsz 84.5 | num_updates 113477 | best_bleu 21.8
2023-05-27 05:01:34 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-27 05:01:41 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/concat-1-1-0.2-sf[zh-en]/checkpoint17.pt (epoch 17 @ 113477 updates, score 21.62) (writing took 7.200384026393294 seconds)
2023-05-27 05:01:41 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-05-27 05:01:41 | INFO | train | epoch 017 | loss 4.174 | nll_loss 2.554 | ppl 5.87 | wps 51983.8 | ups 0.91 | wpb 57190.2 | bsz 1477.5 | num_updates 113477 | lr 0.000187748 | gnorm 0.256 | clip 100 | loss_scale 21 | train_wall 7015 | wall 124895
2023-05-27 05:01:41 | INFO | fairseq.trainer | begin training epoch 18
2023-05-27 05:02:18 | INFO | train_inner | epoch 018:     23 / 6686 loss=4.177, nll_loss=2.558, ppl=5.89, wps=33449.8, ups=0.59, wpb=56755.8, bsz=1460.6, num_updates=113500, lr=0.000187729, gnorm=0.259, clip=100, loss_scale=8, train_wall=105, wall=124932
2023-05-27 05:04:16 | INFO | train_inner | epoch 018:    123 / 6686 loss=4.148, nll_loss=2.524, ppl=5.75, wps=48599.5, ups=0.85, wpb=57280.8, bsz=1491.8, num_updates=113600, lr=0.000187647, gnorm=0.252, clip=100, loss_scale=10, train_wall=108, wall=125050
2023-05-27 05:06:10 | INFO | train_inner | epoch 018:    223 / 6686 loss=4.155, nll_loss=2.531, ppl=5.78, wps=50132.6, ups=0.88, wpb=57156.1, bsz=1476.1, num_updates=113700, lr=0.000187564, gnorm=0.255, clip=100, loss_scale=16, train_wall=106, wall=125164
2023-05-27 05:08:00 | INFO | train_inner | epoch 018:    323 / 6686 loss=4.157, nll_loss=2.534, ppl=5.79, wps=52013.8, ups=0.91, wpb=57242.3, bsz=1465.4, num_updates=113800, lr=0.000187482, gnorm=0.254, clip=100, loss_scale=16, train_wall=106, wall=125274
2023-05-27 05:09:49 | INFO | train_inner | epoch 018:    423 / 6686 loss=4.16, nll_loss=2.538, ppl=5.81, wps=52578, ups=0.92, wpb=57240.2, bsz=1480.9, num_updates=113900, lr=0.000187399, gnorm=0.256, clip=100, loss_scale=16, train_wall=105, wall=125383
2023-05-27 05:11:38 | INFO | train_inner | epoch 018:    523 / 6686 loss=4.144, nll_loss=2.52, ppl=5.74, wps=52543.2, ups=0.92, wpb=57209.9, bsz=1467.7, num_updates=114000, lr=0.000187317, gnorm=0.259, clip=100, loss_scale=16, train_wall=105, wall=125492
2023-05-27 05:13:27 | INFO | train_inner | epoch 018:    623 / 6686 loss=4.163, nll_loss=2.542, ppl=5.82, wps=52418.2, ups=0.92, wpb=57210.2, bsz=1465.4, num_updates=114100, lr=0.000187235, gnorm=0.256, clip=100, loss_scale=18, train_wall=105, wall=125601
2023-05-27 05:15:16 | INFO | train_inner | epoch 018:    723 / 6686 loss=4.16, nll_loss=2.538, ppl=5.81, wps=52350.4, ups=0.92, wpb=56926.1, bsz=1482.3, num_updates=114200, lr=0.000187153, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=125710
2023-05-27 05:17:04 | INFO | train_inner | epoch 018:    823 / 6686 loss=4.154, nll_loss=2.532, ppl=5.78, wps=52479.7, ups=0.92, wpb=57162.4, bsz=1487.1, num_updates=114300, lr=0.000187071, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=125819
2023-05-27 05:18:54 | INFO | train_inner | epoch 018:    923 / 6686 loss=4.149, nll_loss=2.526, ppl=5.76, wps=52529.7, ups=0.92, wpb=57368.1, bsz=1472.6, num_updates=114400, lr=0.000186989, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=125928
2023-05-27 05:20:43 | INFO | train_inner | epoch 018:   1023 / 6686 loss=4.16, nll_loss=2.538, ppl=5.81, wps=52466.8, ups=0.92, wpb=57136.8, bsz=1469.6, num_updates=114500, lr=0.000186908, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=126037
2023-05-27 05:22:31 | INFO | train_inner | epoch 018:   1123 / 6686 loss=4.164, nll_loss=2.543, ppl=5.83, wps=52516.9, ups=0.92, wpb=56979.2, bsz=1455.6, num_updates=114600, lr=0.000186826, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=126145
2023-05-27 05:22:52 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 05:24:21 | INFO | train_inner | epoch 018:   1224 / 6686 loss=4.172, nll_loss=2.552, ppl=5.86, wps=51859.7, ups=0.91, wpb=57148.2, bsz=1469, num_updates=114700, lr=0.000186745, gnorm=0.256, clip=100, loss_scale=37, train_wall=106, wall=126255
2023-05-27 05:26:10 | INFO | train_inner | epoch 018:   1324 / 6686 loss=4.162, nll_loss=2.54, ppl=5.82, wps=52583, ups=0.92, wpb=57107.7, bsz=1457.8, num_updates=114800, lr=0.000186663, gnorm=0.259, clip=100, loss_scale=32, train_wall=105, wall=126364
2023-05-27 05:27:59 | INFO | train_inner | epoch 018:   1424 / 6686 loss=4.162, nll_loss=2.541, ppl=5.82, wps=52503.9, ups=0.92, wpb=57139.6, bsz=1488.3, num_updates=114900, lr=0.000186582, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=126473
2023-05-27 05:29:48 | INFO | train_inner | epoch 018:   1524 / 6686 loss=4.168, nll_loss=2.547, ppl=5.84, wps=52593.1, ups=0.92, wpb=57231.4, bsz=1465, num_updates=115000, lr=0.000186501, gnorm=0.257, clip=100, loss_scale=32, train_wall=105, wall=126582
2023-05-27 05:31:36 | INFO | train_inner | epoch 018:   1624 / 6686 loss=4.166, nll_loss=2.545, ppl=5.83, wps=52491.7, ups=0.92, wpb=57184.6, bsz=1484.5, num_updates=115100, lr=0.00018642, gnorm=0.259, clip=100, loss_scale=32, train_wall=105, wall=126691
2023-05-27 05:32:15 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 05:33:27 | INFO | train_inner | epoch 018:   1725 / 6686 loss=4.169, nll_loss=2.548, ppl=5.85, wps=51762.6, ups=0.91, wpb=57157.6, bsz=1475.4, num_updates=115200, lr=0.000186339, gnorm=0.26, clip=100, loss_scale=34, train_wall=107, wall=126801
2023-05-27 05:35:16 | INFO | train_inner | epoch 018:   1825 / 6686 loss=4.17, nll_loss=2.55, ppl=5.85, wps=52659.8, ups=0.92, wpb=57220.2, bsz=1483.9, num_updates=115300, lr=0.000186258, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=126910
2023-05-27 05:37:05 | INFO | train_inner | epoch 018:   1925 / 6686 loss=4.161, nll_loss=2.539, ppl=5.81, wps=52185.6, ups=0.91, wpb=57307.6, bsz=1498.9, num_updates=115400, lr=0.000186177, gnorm=0.257, clip=100, loss_scale=32, train_wall=106, wall=127020
2023-05-27 05:38:54 | INFO | train_inner | epoch 018:   2025 / 6686 loss=4.169, nll_loss=2.549, ppl=5.85, wps=52626.4, ups=0.92, wpb=57079.2, bsz=1481.4, num_updates=115500, lr=0.000186097, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=127128
2023-05-27 05:40:42 | INFO | train_inner | epoch 018:   2125 / 6686 loss=4.171, nll_loss=2.551, ppl=5.86, wps=52668.8, ups=0.92, wpb=57202.4, bsz=1478.4, num_updates=115600, lr=0.000186016, gnorm=0.255, clip=100, loss_scale=32, train_wall=105, wall=127237
2023-05-27 05:42:31 | INFO | train_inner | epoch 018:   2225 / 6686 loss=4.162, nll_loss=2.54, ppl=5.82, wps=52614.5, ups=0.92, wpb=57260.7, bsz=1482.6, num_updates=115700, lr=0.000185936, gnorm=0.255, clip=100, loss_scale=50, train_wall=105, wall=127345
2023-05-27 05:42:38 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 05:44:21 | INFO | train_inner | epoch 018:   2326 / 6686 loss=4.162, nll_loss=2.541, ppl=5.82, wps=51962.7, ups=0.91, wpb=57048.6, bsz=1465.4, num_updates=115800, lr=0.000185856, gnorm=0.259, clip=100, loss_scale=34, train_wall=106, wall=127455
2023-05-27 05:46:10 | INFO | train_inner | epoch 018:   2426 / 6686 loss=4.148, nll_loss=2.525, ppl=5.75, wps=52390.3, ups=0.92, wpb=57100.1, bsz=1520.2, num_updates=115900, lr=0.000185775, gnorm=0.257, clip=100, loss_scale=32, train_wall=105, wall=127564
2023-05-27 05:47:59 | INFO | train_inner | epoch 018:   2526 / 6686 loss=4.172, nll_loss=2.551, ppl=5.86, wps=52530.7, ups=0.92, wpb=57105.1, bsz=1450.7, num_updates=116000, lr=0.000185695, gnorm=0.253, clip=100, loss_scale=32, train_wall=105, wall=127673
2023-05-27 05:49:48 | INFO | train_inner | epoch 018:   2626 / 6686 loss=4.151, nll_loss=2.529, ppl=5.77, wps=52864.2, ups=0.92, wpb=57512, bsz=1503.4, num_updates=116100, lr=0.000185615, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=127782
2023-05-27 05:51:13 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 05:51:38 | INFO | train_inner | epoch 018:   2727 / 6686 loss=4.168, nll_loss=2.548, ppl=5.85, wps=52000, ups=0.91, wpb=57189.5, bsz=1460.9, num_updates=116200, lr=0.000185535, gnorm=0.256, clip=100, loss_scale=28, train_wall=106, wall=127892
2023-05-27 05:53:27 | INFO | train_inner | epoch 018:   2827 / 6686 loss=4.164, nll_loss=2.543, ppl=5.83, wps=52467.7, ups=0.92, wpb=57270, bsz=1488.1, num_updates=116300, lr=0.000185456, gnorm=0.259, clip=100, loss_scale=16, train_wall=105, wall=128001
2023-05-27 05:55:15 | INFO | train_inner | epoch 018:   2927 / 6686 loss=4.165, nll_loss=2.544, ppl=5.83, wps=52798, ups=0.92, wpb=57182.9, bsz=1494.3, num_updates=116400, lr=0.000185376, gnorm=0.257, clip=100, loss_scale=16, train_wall=105, wall=128109
2023-05-27 05:57:04 | INFO | train_inner | epoch 018:   3027 / 6686 loss=4.167, nll_loss=2.546, ppl=5.84, wps=52628, ups=0.92, wpb=57109.7, bsz=1460.8, num_updates=116500, lr=0.000185296, gnorm=0.259, clip=100, loss_scale=16, train_wall=105, wall=128218
2023-05-27 05:58:52 | INFO | train_inner | epoch 018:   3127 / 6686 loss=4.175, nll_loss=2.555, ppl=5.88, wps=52542.5, ups=0.92, wpb=57194.9, bsz=1471.6, num_updates=116600, lr=0.000185217, gnorm=0.258, clip=100, loss_scale=16, train_wall=105, wall=128327
2023-05-27 06:00:41 | INFO | train_inner | epoch 018:   3227 / 6686 loss=4.169, nll_loss=2.549, ppl=5.85, wps=52615.8, ups=0.92, wpb=57147.5, bsz=1473.5, num_updates=116700, lr=0.000185138, gnorm=0.257, clip=100, loss_scale=18, train_wall=105, wall=128435
2023-05-27 06:02:30 | INFO | train_inner | epoch 018:   3327 / 6686 loss=4.16, nll_loss=2.538, ppl=5.81, wps=52496.6, ups=0.91, wpb=57454.9, bsz=1468, num_updates=116800, lr=0.000185058, gnorm=0.255, clip=100, loss_scale=32, train_wall=106, wall=128545
2023-05-27 06:04:19 | INFO | train_inner | epoch 018:   3427 / 6686 loss=4.172, nll_loss=2.552, ppl=5.86, wps=52687.6, ups=0.92, wpb=57349.1, bsz=1481.2, num_updates=116900, lr=0.000184979, gnorm=0.257, clip=100, loss_scale=32, train_wall=105, wall=128653
2023-05-27 06:06:08 | INFO | train_inner | epoch 018:   3527 / 6686 loss=4.175, nll_loss=2.555, ppl=5.88, wps=52439.4, ups=0.92, wpb=57141.5, bsz=1476.6, num_updates=117000, lr=0.0001849, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=128762
2023-05-27 06:07:58 | INFO | train_inner | epoch 018:   3627 / 6686 loss=4.179, nll_loss=2.559, ppl=5.89, wps=52468.9, ups=0.92, wpb=57303.8, bsz=1484, num_updates=117100, lr=0.000184821, gnorm=0.255, clip=100, loss_scale=32, train_wall=105, wall=128872
2023-05-27 06:09:46 | INFO | train_inner | epoch 018:   3727 / 6686 loss=4.182, nll_loss=2.563, ppl=5.91, wps=52426, ups=0.92, wpb=56828.4, bsz=1446.5, num_updates=117200, lr=0.000184742, gnorm=0.26, clip=100, loss_scale=32, train_wall=105, wall=128980
2023-05-27 06:10:13 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 06:11:36 | INFO | train_inner | epoch 018:   3828 / 6686 loss=4.159, nll_loss=2.537, ppl=5.8, wps=51902.6, ups=0.91, wpb=57159.6, bsz=1489.8, num_updates=117300, lr=0.000184663, gnorm=0.258, clip=100, loss_scale=40, train_wall=106, wall=129090
2023-05-27 06:13:25 | INFO | train_inner | epoch 018:   3928 / 6686 loss=4.175, nll_loss=2.556, ppl=5.88, wps=52629.1, ups=0.92, wpb=57266.9, bsz=1479.4, num_updates=117400, lr=0.000184585, gnorm=0.257, clip=100, loss_scale=32, train_wall=105, wall=129199
2023-05-27 06:15:13 | INFO | train_inner | epoch 018:   4028 / 6686 loss=4.17, nll_loss=2.549, ppl=5.85, wps=52605.7, ups=0.92, wpb=57129.7, bsz=1485.5, num_updates=117500, lr=0.000184506, gnorm=0.254, clip=100, loss_scale=32, train_wall=105, wall=129308
2023-05-27 06:17:02 | INFO | train_inner | epoch 018:   4128 / 6686 loss=4.175, nll_loss=2.555, ppl=5.88, wps=52536.4, ups=0.92, wpb=57163, bsz=1475.9, num_updates=117600, lr=0.000184428, gnorm=0.255, clip=100, loss_scale=32, train_wall=105, wall=129416
2023-05-27 06:18:51 | INFO | train_inner | epoch 018:   4228 / 6686 loss=4.17, nll_loss=2.55, ppl=5.86, wps=52622, ups=0.92, wpb=57194.3, bsz=1492, num_updates=117700, lr=0.000184349, gnorm=0.254, clip=100, loss_scale=32, train_wall=105, wall=129525
2023-05-27 06:19:56 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 06:20:41 | INFO | train_inner | epoch 018:   4329 / 6686 loss=4.17, nll_loss=2.549, ppl=5.85, wps=52168.3, ups=0.91, wpb=57191.7, bsz=1496.2, num_updates=117800, lr=0.000184271, gnorm=0.254, clip=100, loss_scale=40, train_wall=106, wall=129635
2023-05-27 06:22:29 | INFO | train_inner | epoch 018:   4429 / 6686 loss=4.175, nll_loss=2.555, ppl=5.88, wps=52646.8, ups=0.92, wpb=57266, bsz=1459.9, num_updates=117900, lr=0.000184193, gnorm=0.257, clip=100, loss_scale=32, train_wall=105, wall=129744
2023-05-27 06:24:18 | INFO | train_inner | epoch 018:   4529 / 6686 loss=4.179, nll_loss=2.56, ppl=5.9, wps=52690.1, ups=0.92, wpb=57273.3, bsz=1475.2, num_updates=118000, lr=0.000184115, gnorm=0.255, clip=100, loss_scale=32, train_wall=105, wall=129852
2023-05-27 06:26:07 | INFO | train_inner | epoch 018:   4629 / 6686 loss=4.166, nll_loss=2.545, ppl=5.84, wps=52718.5, ups=0.92, wpb=57231, bsz=1481.8, num_updates=118100, lr=0.000184037, gnorm=0.258, clip=100, loss_scale=32, train_wall=105, wall=129961
2023-05-27 06:27:05 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 06:27:57 | INFO | train_inner | epoch 018:   4730 / 6686 loss=4.172, nll_loss=2.552, ppl=5.86, wps=51830.6, ups=0.91, wpb=57093.7, bsz=1482.6, num_updates=118200, lr=0.000183959, gnorm=0.258, clip=100, loss_scale=24, train_wall=106, wall=130071
2023-05-27 06:29:46 | INFO | train_inner | epoch 018:   4830 / 6686 loss=4.174, nll_loss=2.554, ppl=5.87, wps=52578.3, ups=0.92, wpb=57212, bsz=1477, num_updates=118300, lr=0.000183881, gnorm=0.259, clip=100, loss_scale=16, train_wall=105, wall=130180
2023-05-27 06:31:35 | INFO | train_inner | epoch 018:   4930 / 6686 loss=4.165, nll_loss=2.544, ppl=5.83, wps=52147.1, ups=0.91, wpb=57019.4, bsz=1490.2, num_updates=118400, lr=0.000183804, gnorm=0.256, clip=100, loss_scale=16, train_wall=105, wall=130289
2023-05-27 06:33:24 | INFO | train_inner | epoch 018:   5030 / 6686 loss=4.176, nll_loss=2.557, ppl=5.88, wps=52691.8, ups=0.92, wpb=57231.8, bsz=1483.4, num_updates=118500, lr=0.000183726, gnorm=0.256, clip=100, loss_scale=16, train_wall=105, wall=130398
2023-05-27 06:35:12 | INFO | train_inner | epoch 018:   5130 / 6686 loss=4.166, nll_loss=2.545, ppl=5.84, wps=52769.7, ups=0.92, wpb=57452.7, bsz=1475.6, num_updates=118600, lr=0.000183649, gnorm=0.256, clip=100, loss_scale=16, train_wall=105, wall=130507
2023-05-27 06:37:02 | INFO | train_inner | epoch 018:   5230 / 6686 loss=4.185, nll_loss=2.567, ppl=5.93, wps=52516, ups=0.92, wpb=57259.1, bsz=1455, num_updates=118700, lr=0.000183571, gnorm=0.256, clip=100, loss_scale=22, train_wall=105, wall=130616
2023-05-27 06:38:50 | INFO | train_inner | epoch 018:   5330 / 6686 loss=4.178, nll_loss=2.559, ppl=5.89, wps=52655.3, ups=0.92, wpb=57114.5, bsz=1495, num_updates=118800, lr=0.000183494, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=130724
2023-05-27 06:40:39 | INFO | train_inner | epoch 018:   5430 / 6686 loss=4.186, nll_loss=2.568, ppl=5.93, wps=52550.6, ups=0.92, wpb=57165.1, bsz=1465.8, num_updates=118900, lr=0.000183417, gnorm=0.255, clip=100, loss_scale=32, train_wall=105, wall=130833
2023-05-27 06:42:28 | INFO | train_inner | epoch 018:   5530 / 6686 loss=4.163, nll_loss=2.541, ppl=5.82, wps=52676.4, ups=0.92, wpb=57301.6, bsz=1504.7, num_updates=119000, lr=0.00018334, gnorm=0.258, clip=100, loss_scale=32, train_wall=105, wall=130942
2023-05-27 06:44:16 | INFO | train_inner | epoch 018:   5630 / 6686 loss=4.176, nll_loss=2.556, ppl=5.88, wps=52747, ups=0.92, wpb=57163.7, bsz=1457.8, num_updates=119100, lr=0.000183263, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=131050
2023-05-27 06:45:43 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 06:46:06 | INFO | train_inner | epoch 018:   5731 / 6686 loss=4.178, nll_loss=2.559, ppl=5.89, wps=52134, ups=0.91, wpb=57160.5, bsz=1461, num_updates=119200, lr=0.000183186, gnorm=0.256, clip=100, loss_scale=33, train_wall=106, wall=131160
2023-05-27 06:47:54 | INFO | train_inner | epoch 018:   5831 / 6686 loss=4.182, nll_loss=2.564, ppl=5.91, wps=52524.8, ups=0.92, wpb=57131.8, bsz=1490.4, num_updates=119300, lr=0.000183109, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=131268
2023-05-27 06:49:43 | INFO | train_inner | epoch 018:   5931 / 6686 loss=4.186, nll_loss=2.568, ppl=5.93, wps=52669.9, ups=0.92, wpb=57156.6, bsz=1446.2, num_updates=119400, lr=0.000183032, gnorm=0.258, clip=100, loss_scale=32, train_wall=105, wall=131377
2023-05-27 06:51:32 | INFO | train_inner | epoch 018:   6031 / 6686 loss=4.179, nll_loss=2.56, ppl=5.9, wps=52453.9, ups=0.91, wpb=57392.3, bsz=1478.7, num_updates=119500, lr=0.000182956, gnorm=0.253, clip=100, loss_scale=32, train_wall=106, wall=131486
2023-05-27 06:53:21 | INFO | train_inner | epoch 018:   6131 / 6686 loss=4.175, nll_loss=2.556, ppl=5.88, wps=52597.6, ups=0.92, wpb=57189.2, bsz=1468.2, num_updates=119600, lr=0.000182879, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=131595
2023-05-27 06:55:10 | INFO | train_inner | epoch 018:   6231 / 6686 loss=4.168, nll_loss=2.548, ppl=5.85, wps=52670.3, ups=0.92, wpb=57279.4, bsz=1491.1, num_updates=119700, lr=0.000182803, gnorm=0.255, clip=100, loss_scale=35, train_wall=105, wall=131704
2023-05-27 06:56:02 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 06:57:00 | INFO | train_inner | epoch 018:   6332 / 6686 loss=4.156, nll_loss=2.534, ppl=5.79, wps=52055.5, ups=0.91, wpb=57266.3, bsz=1480.1, num_updates=119800, lr=0.000182727, gnorm=0.255, clip=100, loss_scale=47, train_wall=106, wall=131814
2023-05-27 06:58:49 | INFO | train_inner | epoch 018:   6432 / 6686 loss=4.181, nll_loss=2.563, ppl=5.91, wps=52571.1, ups=0.92, wpb=57190.6, bsz=1452.2, num_updates=119900, lr=0.00018265, gnorm=0.255, clip=100, loss_scale=32, train_wall=105, wall=131923
2023-05-27 07:00:37 | INFO | train_inner | epoch 018:   6532 / 6686 loss=4.166, nll_loss=2.545, ppl=5.84, wps=52606.2, ups=0.92, wpb=57209.3, bsz=1514.9, num_updates=120000, lr=0.000182574, gnorm=0.257, clip=100, loss_scale=32, train_wall=105, wall=132031
2023-05-27 07:02:26 | INFO | train_inner | epoch 018:   6632 / 6686 loss=4.173, nll_loss=2.554, ppl=5.87, wps=52689.3, ups=0.92, wpb=57275.7, bsz=1494.4, num_updates=120100, lr=0.000182498, gnorm=0.255, clip=100, loss_scale=32, train_wall=105, wall=132140
2023-05-27 07:03:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-27 07:03:30 | INFO | fairseq.tasks.translation | example hypothesis: Why was that so?
2023-05-27 07:03:30 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-27 07:03:30 | INFO | fairseq.tasks.translation | example hypothesis: I’ll make you lose so badly that not even your pants are left!
2023-05-27 07:03:30 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-27 07:03:31 | INFO | fairseq.tasks.translation | example hypothesis: Just as Shen Liangchuan heaved a sigh of relief, he heard her say, “I’ll call you my roommate!”
2023-05-27 07:03:31 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-27 07:03:31 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved her hand and entered the elevator.
2023-05-27 07:03:31 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-27 07:03:32 | INFO | fairseq.tasks.translation | example hypothesis: She raised her head and saw Song Cheng standing in the distance!
2023-05-27 07:03:32 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-27 07:03:33 | INFO | fairseq.tasks.translation | example hypothesis: Song Cheng patted his chest and said, “You scared me to death! Where’s Wang Chuan?”
2023-05-27 07:03:33 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-27 07:03:34 | INFO | fairseq.tasks.translation | example hypothesis: I said, “No, I can’t eat it.”
2023-05-27 07:03:34 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-27 07:03:34 | INFO | fairseq.tasks.translation | example hypothesis: At first, no one believed him, but Wang Wenhao insisted that he was the one who supported the public opinion.
2023-05-27 07:03:34 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-27 07:03:35 | INFO | fairseq.tasks.translation | example hypothesis: With his identity, coming here like this, Baili Hongzhuang had to be treated even if she did not have to!
2023-05-27 07:03:35 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-27 07:03:36 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian: “Mr. Shen, I, I have kept too much blood and my brain is lacking oxygen. I can’t think of anything. Why don’t you give me a hint?”
2023-05-27 07:03:36 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-27 07:03:37 | INFO | fairseq.tasks.translation | example hypothesis: He didn’t know why so many people had heard about it. Since he couldn’t hide it anymore, he might as well tell them.
2023-05-27 07:03:37 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-27 07:03:38 | INFO | fairseq.tasks.translation | example hypothesis: Her deliberately lowered voice could not hide the viciousness and viciousness in her voice.
2023-05-27 07:03:38 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-27 07:03:39 | INFO | fairseq.tasks.translation | example hypothesis: A beast pet of different ranks was different in strength, but a beast pet was precious and rare. It was impossible for an ordinary person to possess it, and even an official’s son would not be able to possess it.
2023-05-27 07:03:39 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-27 07:03:40 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chixia gritted her teeth and cursed.
2023-05-27 07:03:40 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-27 07:03:41 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang hid it very well, Di Chen still saw the waves in her eyes and felt a little warm.
2023-05-27 07:03:41 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-27 07:03:42 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia walked in, she didn’t even see a few waiters, let alone the guests.
2023-05-27 07:03:42 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-27 07:03:43 | INFO | fairseq.tasks.translation | example hypothesis: This person was the fourth young miss of the Ye Family, Ye Qing Ling.
2023-05-27 07:03:43 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-27 07:03:44 | INFO | fairseq.tasks.translation | example hypothesis: Because at this moment, she felt as if her chin was about to shatter.
2023-05-27 07:03:44 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-27 07:03:45 | INFO | fairseq.tasks.translation | example hypothesis: “Mu Zi, help me. If it wasn't for you, that old man wouldn't have set his eyes on me.”
2023-05-27 07:03:45 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-27 07:03:46 | INFO | fairseq.tasks.translation | example hypothesis: Bai Li Yu Yan was even more excited. She was the one who was in charge of this matter. Previously, Bai Li Hong Zhuang had treated her like this. This time, she would definitely make Bai Li Hong Zhuang suffer too.
2023-05-27 07:03:46 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-27 07:03:47 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How could that be? They also have four mages on their side, of course they wouldn’t surrender so easily. After arguing for a long time, they decided on what method to obtain control over the Kingdom of Allthan in the future.”
2023-05-27 07:03:47 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-27 07:03:49 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed. He had always been looking for reasons for Li Yuyue not being able to participate in the Imperial Family’s hunting competition.
2023-05-27 07:03:49 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-27 07:03:50 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my level good enough? They’re all the most outstanding talents in the country, how can my magic be so weak?”
2023-05-27 07:03:50 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-27 07:03:52 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yibei’s words meant that if Fang Chixia didn’t want to go, then there was no need to go.
2023-05-27 07:03:52 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-27 07:03:54 | INFO | fairseq.tasks.translation | example hypothesis: She tilted her head and saw that the five palm prints on her face were very eye-catching. They swelled up at a speed visible to the naked eye. When she reached out to touch them, she could not help but let out a hissing sound.
2023-05-27 07:03:54 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-27 07:03:55 | INFO | fairseq.tasks.translation | example hypothesis: This... How could this be the kind of charm that a waste of trash could emit?
2023-05-27 07:03:55 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-27 07:03:56 | INFO | fairseq.tasks.translation | example hypothesis: How could Wang Wenhao have found the newspaper agency? The chief editor should have called her to tell her not to come to the newspaper agency. However, these three people... had schemed against her!
2023-05-27 07:03:56 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-27 07:03:59 | INFO | fairseq.tasks.translation | example hypothesis: Hearing Teacher Di’s praise, I was delighted. I retracted the energy ball with my left hand, and a light sword shot out from my right hand towards Teacher Zhen. The light sword actually managed to hit its target smoothly. I was shocked, and upon closer inspection, I discovered that it was only an afterimage. Teacher Zhen had already moved behind me, and shouted, “Berserk Space
2023-05-27 07:03:59 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-27 07:04:01 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Originally, we proposed three rounds and two wins, but they said it wasn’t fair, because we had Teacher Di and Teacher Zhen. They said they wanted to win three out of five rounds. Since we proposed the competition, we could only listen to them in the end. Three days later, we’ll compete in secret in the Royal Colosseum. We’ll be competing in the Royal Colosseum.”
2023-05-27 07:04:01 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-27 07:04:03 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Di used the light-type rank 7 spell, Light Thunder Burst. I didn’t use this spell very often, because I didn’t have a very good control over it. Teacher Di released nine light lightning bolts to surround me, forming a simple formation, making it impossible for me to escape in a short distance. After that, all the light lightning bolts exploded to form a powerful attack.
2023-05-27 07:04:03 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-27 07:04:06 | INFO | fairseq.tasks.translation | example hypothesis: As soon as Mark and the two teachers walked to the other side, Teacher Zhen immediately sent out a Lesser Dimensional Slash at me. As expected of the continent’s number one Magician. The gravitational force of the Lesser Dimensional Slash was actually much stronger than the one I sent out. A small spatial crack appeared beside me, and a powerful suction force immediately swept towards me.
2023-05-27 07:04:06 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-27 07:04:07 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 4.158 | nll_loss 2.517 | ppl 5.72 | bleu 21.81 | wps 1976.1 | wpb 2420.8 | bsz 84.5 | num_updates 120154 | best_bleu 21.81
2023-05-27 07:04:07 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-27 07:04:11 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/concat-1-1-0.2-sf[zh-en]/checkpoint18.pt (epoch 18 @ 120154 updates, score 21.81) (writing took 4.252965968102217 seconds)
2023-05-27 07:04:11 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-05-27 07:04:11 | INFO | train | epoch 018 | loss 4.168 | nll_loss 2.547 | ppl 5.84 | wps 51955.8 | ups 0.91 | wpb 57190.8 | bsz 1477.5 | num_updates 120154 | lr 0.000182457 | gnorm 0.256 | clip 100 | loss_scale 29 | train_wall 7026 | wall 132245
2023-05-27 07:04:11 | INFO | fairseq.trainer | begin training epoch 19
2023-05-27 07:05:22 | INFO | train_inner | epoch 019:     46 / 6686 loss=4.156, nll_loss=2.534, ppl=5.79, wps=32275.7, ups=0.57, wpb=56751.7, bsz=1465.5, num_updates=120200, lr=0.000182422, gnorm=0.261, clip=100, loss_scale=32, train_wall=107, wall=132316
2023-05-27 07:06:36 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 07:07:20 | INFO | train_inner | epoch 019:    147 / 6686 loss=4.153, nll_loss=2.53, ppl=5.78, wps=48562.1, ups=0.85, wpb=57128.8, bsz=1474.6, num_updates=120300, lr=0.000182346, gnorm=0.258, clip=100, loss_scale=33, train_wall=108, wall=132434
2023-05-27 07:09:12 | INFO | train_inner | epoch 019:    247 / 6686 loss=4.16, nll_loss=2.538, ppl=5.81, wps=50907.2, ups=0.89, wpb=57203.2, bsz=1469.5, num_updates=120400, lr=0.000182271, gnorm=0.254, clip=100, loss_scale=32, train_wall=106, wall=132546
2023-05-27 07:11:02 | INFO | train_inner | epoch 019:    347 / 6686 loss=4.149, nll_loss=2.526, ppl=5.76, wps=52136.1, ups=0.91, wpb=57187.4, bsz=1465.3, num_updates=120500, lr=0.000182195, gnorm=0.259, clip=100, loss_scale=32, train_wall=106, wall=132656
2023-05-27 07:12:50 | INFO | train_inner | epoch 019:    447 / 6686 loss=4.143, nll_loss=2.519, ppl=5.73, wps=52552.8, ups=0.92, wpb=57168.7, bsz=1492.8, num_updates=120600, lr=0.000182119, gnorm=0.259, clip=100, loss_scale=32, train_wall=105, wall=132764
2023-05-27 07:14:39 | INFO | train_inner | epoch 019:    547 / 6686 loss=4.143, nll_loss=2.519, ppl=5.73, wps=52532.7, ups=0.92, wpb=57240.2, bsz=1459.2, num_updates=120700, lr=0.000182044, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=132873
2023-05-27 07:16:28 | INFO | train_inner | epoch 019:    647 / 6686 loss=4.149, nll_loss=2.526, ppl=5.76, wps=52599.7, ups=0.92, wpb=57180.2, bsz=1492.2, num_updates=120800, lr=0.000181969, gnorm=0.258, clip=100, loss_scale=41, train_wall=105, wall=132982
2023-05-27 07:16:31 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 07:18:18 | INFO | train_inner | epoch 019:    748 / 6686 loss=4.152, nll_loss=2.529, ppl=5.77, wps=52103.6, ups=0.91, wpb=57185.2, bsz=1495.6, num_updates=120900, lr=0.000181893, gnorm=0.263, clip=100, loss_scale=33, train_wall=106, wall=133092
2023-05-27 07:20:07 | INFO | train_inner | epoch 019:    848 / 6686 loss=4.162, nll_loss=2.54, ppl=5.82, wps=52585.6, ups=0.92, wpb=57244.1, bsz=1457.5, num_updates=121000, lr=0.000181818, gnorm=0.253, clip=100, loss_scale=32, train_wall=105, wall=133201
2023-05-27 07:21:55 | INFO | train_inner | epoch 019:    948 / 6686 loss=4.163, nll_loss=2.541, ppl=5.82, wps=52683.7, ups=0.92, wpb=57156.3, bsz=1460.3, num_updates=121100, lr=0.000181743, gnorm=0.257, clip=100, loss_scale=32, train_wall=105, wall=133309
2023-05-27 07:23:44 | INFO | train_inner | epoch 019:   1048 / 6686 loss=4.151, nll_loss=2.528, ppl=5.77, wps=52881.4, ups=0.92, wpb=57379, bsz=1493.7, num_updates=121200, lr=0.000181668, gnorm=0.255, clip=100, loss_scale=32, train_wall=105, wall=133418
2023-05-27 07:25:32 | INFO | train_inner | epoch 019:   1148 / 6686 loss=4.158, nll_loss=2.536, ppl=5.8, wps=52667.4, ups=0.92, wpb=57294.6, bsz=1481.4, num_updates=121300, lr=0.000181593, gnorm=0.257, clip=100, loss_scale=32, train_wall=105, wall=133527
2023-05-27 07:25:59 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 07:27:23 | INFO | train_inner | epoch 019:   1249 / 6686 loss=4.161, nll_loss=2.54, ppl=5.82, wps=52002, ups=0.91, wpb=57236.9, bsz=1484.2, num_updates=121400, lr=0.000181518, gnorm=0.257, clip=100, loss_scale=35, train_wall=106, wall=133637
2023-05-27 07:29:12 | INFO | train_inner | epoch 019:   1349 / 6686 loss=4.156, nll_loss=2.534, ppl=5.79, wps=52442.2, ups=0.92, wpb=57223.9, bsz=1480.1, num_updates=121500, lr=0.000181444, gnorm=0.259, clip=100, loss_scale=32, train_wall=105, wall=133746
2023-05-27 07:31:01 | INFO | train_inner | epoch 019:   1449 / 6686 loss=4.156, nll_loss=2.534, ppl=5.79, wps=52597.3, ups=0.92, wpb=57363.6, bsz=1474.4, num_updates=121600, lr=0.000181369, gnorm=0.258, clip=100, loss_scale=32, train_wall=105, wall=133855
2023-05-27 07:32:49 | INFO | train_inner | epoch 019:   1549 / 6686 loss=4.155, nll_loss=2.533, ppl=5.79, wps=52600.3, ups=0.92, wpb=57212.6, bsz=1482.9, num_updates=121700, lr=0.000181295, gnorm=0.258, clip=100, loss_scale=32, train_wall=105, wall=133964
2023-05-27 07:34:38 | INFO | train_inner | epoch 019:   1649 / 6686 loss=4.159, nll_loss=2.537, ppl=5.81, wps=52592.3, ups=0.92, wpb=57045.9, bsz=1465.8, num_updates=121800, lr=0.00018122, gnorm=0.255, clip=100, loss_scale=32, train_wall=105, wall=134072
2023-05-27 07:35:56 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 07:36:28 | INFO | train_inner | epoch 019:   1750 / 6686 loss=4.166, nll_loss=2.545, ppl=5.83, wps=51950.3, ups=0.91, wpb=57264.5, bsz=1464.8, num_updates=121900, lr=0.000181146, gnorm=0.256, clip=100, loss_scale=43, train_wall=106, wall=134182
2023-05-27 07:38:17 | INFO | train_inner | epoch 019:   1850 / 6686 loss=4.16, nll_loss=2.538, ppl=5.81, wps=52643.5, ups=0.92, wpb=57082.9, bsz=1477, num_updates=122000, lr=0.000181071, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=134291
2023-05-27 07:40:06 | INFO | train_inner | epoch 019:   1950 / 6686 loss=4.161, nll_loss=2.539, ppl=5.81, wps=52123.1, ups=0.91, wpb=57079.8, bsz=1468.2, num_updates=122100, lr=0.000180997, gnorm=0.257, clip=100, loss_scale=32, train_wall=106, wall=134400
2023-05-27 07:41:55 | INFO | train_inner | epoch 019:   2050 / 6686 loss=4.151, nll_loss=2.528, ppl=5.77, wps=52427.6, ups=0.92, wpb=57220.1, bsz=1521.6, num_updates=122200, lr=0.000180923, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=134509
2023-05-27 07:43:43 | INFO | train_inner | epoch 019:   2150 / 6686 loss=4.175, nll_loss=2.555, ppl=5.88, wps=52837.3, ups=0.92, wpb=57146.6, bsz=1463.7, num_updates=122300, lr=0.000180849, gnorm=0.259, clip=100, loss_scale=32, train_wall=104, wall=134618
2023-05-27 07:45:32 | INFO | train_inner | epoch 019:   2250 / 6686 loss=4.152, nll_loss=2.53, ppl=5.78, wps=52503, ups=0.92, wpb=57158.3, bsz=1505.7, num_updates=122400, lr=0.000180775, gnorm=0.258, clip=100, loss_scale=38, train_wall=105, wall=134726
2023-05-27 07:45:37 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 07:45:51 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 07:47:23 | INFO | train_inner | epoch 019:   2352 / 6686 loss=4.149, nll_loss=2.526, ppl=5.76, wps=51489.3, ups=0.9, wpb=57119.9, bsz=1473, num_updates=122500, lr=0.000180702, gnorm=0.259, clip=100, loss_scale=19, train_wall=107, wall=134837
2023-05-27 07:49:12 | INFO | train_inner | epoch 019:   2452 / 6686 loss=4.168, nll_loss=2.548, ppl=5.85, wps=52451.6, ups=0.92, wpb=57065.1, bsz=1454, num_updates=122600, lr=0.000180628, gnorm=0.261, clip=100, loss_scale=16, train_wall=105, wall=134946
2023-05-27 07:51:01 | INFO | train_inner | epoch 019:   2552 / 6686 loss=4.172, nll_loss=2.552, ppl=5.86, wps=52555, ups=0.92, wpb=57125.9, bsz=1452.2, num_updates=122700, lr=0.000180554, gnorm=0.26, clip=100, loss_scale=16, train_wall=105, wall=135055
2023-05-27 07:52:50 | INFO | train_inner | epoch 019:   2652 / 6686 loss=4.154, nll_loss=2.532, ppl=5.78, wps=52510.2, ups=0.92, wpb=57112.8, bsz=1482, num_updates=122800, lr=0.000180481, gnorm=0.259, clip=100, loss_scale=16, train_wall=105, wall=135164
2023-05-27 07:54:38 | INFO | train_inner | epoch 019:   2752 / 6686 loss=4.159, nll_loss=2.538, ppl=5.81, wps=52604.1, ups=0.92, wpb=57254.3, bsz=1500.8, num_updates=122900, lr=0.000180407, gnorm=0.255, clip=100, loss_scale=16, train_wall=105, wall=135272
2023-05-27 07:56:27 | INFO | train_inner | epoch 019:   2852 / 6686 loss=4.165, nll_loss=2.545, ppl=5.83, wps=52612.5, ups=0.92, wpb=57305, bsz=1475.3, num_updates=123000, lr=0.000180334, gnorm=0.259, clip=100, loss_scale=28, train_wall=105, wall=135381
2023-05-27 07:58:16 | INFO | train_inner | epoch 019:   2952 / 6686 loss=4.165, nll_loss=2.544, ppl=5.83, wps=52625.5, ups=0.92, wpb=57134.6, bsz=1456.6, num_updates=123100, lr=0.000180261, gnorm=0.258, clip=100, loss_scale=32, train_wall=105, wall=135490
2023-05-27 08:00:05 | INFO | train_inner | epoch 019:   3052 / 6686 loss=4.161, nll_loss=2.54, ppl=5.82, wps=52375.4, ups=0.92, wpb=57071.6, bsz=1466.2, num_updates=123200, lr=0.000180187, gnorm=0.257, clip=100, loss_scale=32, train_wall=105, wall=135599
2023-05-27 08:01:53 | INFO | train_inner | epoch 019:   3152 / 6686 loss=4.162, nll_loss=2.541, ppl=5.82, wps=52688.5, ups=0.92, wpb=57231.2, bsz=1476.7, num_updates=123300, lr=0.000180114, gnorm=0.258, clip=100, loss_scale=32, train_wall=105, wall=135708
2023-05-27 08:03:42 | INFO | train_inner | epoch 019:   3252 / 6686 loss=4.167, nll_loss=2.547, ppl=5.84, wps=52456.7, ups=0.92, wpb=57131.3, bsz=1475.2, num_updates=123400, lr=0.000180041, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=135817
2023-05-27 08:04:39 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 08:05:32 | INFO | train_inner | epoch 019:   3353 / 6686 loss=4.163, nll_loss=2.542, ppl=5.83, wps=52080.3, ups=0.91, wpb=57256.3, bsz=1476, num_updates=123500, lr=0.000179969, gnorm=0.256, clip=100, loss_scale=36, train_wall=106, wall=135926
2023-05-27 08:07:21 | INFO | train_inner | epoch 019:   3453 / 6686 loss=4.168, nll_loss=2.548, ppl=5.85, wps=52545.6, ups=0.92, wpb=57212.7, bsz=1462.5, num_updates=123600, lr=0.000179896, gnorm=0.257, clip=100, loss_scale=32, train_wall=105, wall=136035
2023-05-27 08:09:10 | INFO | train_inner | epoch 019:   3553 / 6686 loss=4.164, nll_loss=2.543, ppl=5.83, wps=52609.9, ups=0.92, wpb=57221.8, bsz=1483.5, num_updates=123700, lr=0.000179823, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=136144
2023-05-27 08:09:50 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 08:11:00 | INFO | train_inner | epoch 019:   3654 / 6686 loss=4.16, nll_loss=2.538, ppl=5.81, wps=52136.1, ups=0.91, wpb=57201.7, bsz=1466.3, num_updates=123800, lr=0.00017975, gnorm=0.255, clip=100, loss_scale=22, train_wall=106, wall=136254
2023-05-27 08:12:48 | INFO | train_inner | epoch 019:   3754 / 6686 loss=4.168, nll_loss=2.548, ppl=5.85, wps=52786.3, ups=0.92, wpb=57221, bsz=1465.6, num_updates=123900, lr=0.000179678, gnorm=0.257, clip=100, loss_scale=16, train_wall=105, wall=136362
2023-05-27 08:14:37 | INFO | train_inner | epoch 019:   3854 / 6686 loss=4.169, nll_loss=2.549, ppl=5.85, wps=52715.7, ups=0.92, wpb=57211.9, bsz=1504.6, num_updates=124000, lr=0.000179605, gnorm=0.26, clip=100, loss_scale=16, train_wall=105, wall=136471
2023-05-27 08:16:26 | INFO | train_inner | epoch 019:   3954 / 6686 loss=4.173, nll_loss=2.553, ppl=5.87, wps=52519.6, ups=0.92, wpb=57200.6, bsz=1468.6, num_updates=124100, lr=0.000179533, gnorm=0.256, clip=100, loss_scale=16, train_wall=105, wall=136580
2023-05-27 08:18:14 | INFO | train_inner | epoch 019:   4054 / 6686 loss=4.158, nll_loss=2.536, ppl=5.8, wps=52471.3, ups=0.92, wpb=57126.2, bsz=1482.9, num_updates=124200, lr=0.000179461, gnorm=0.259, clip=100, loss_scale=16, train_wall=105, wall=136689
2023-05-27 08:20:03 | INFO | train_inner | epoch 019:   4154 / 6686 loss=4.172, nll_loss=2.552, ppl=5.87, wps=52741.6, ups=0.92, wpb=57244.6, bsz=1465.1, num_updates=124300, lr=0.000179388, gnorm=0.257, clip=100, loss_scale=24, train_wall=105, wall=136797
2023-05-27 08:21:52 | INFO | train_inner | epoch 019:   4254 / 6686 loss=4.175, nll_loss=2.556, ppl=5.88, wps=52740.3, ups=0.92, wpb=57306.4, bsz=1493.5, num_updates=124400, lr=0.000179316, gnorm=0.257, clip=100, loss_scale=32, train_wall=105, wall=136906
2023-05-27 08:23:40 | INFO | train_inner | epoch 019:   4354 / 6686 loss=4.163, nll_loss=2.542, ppl=5.82, wps=52765.6, ups=0.92, wpb=57128.6, bsz=1471.7, num_updates=124500, lr=0.000179244, gnorm=0.259, clip=100, loss_scale=32, train_wall=104, wall=137014
2023-05-27 08:25:28 | INFO | train_inner | epoch 019:   4454 / 6686 loss=4.156, nll_loss=2.534, ppl=5.79, wps=52755.2, ups=0.92, wpb=57206.1, bsz=1514.7, num_updates=124600, lr=0.000179172, gnorm=0.257, clip=100, loss_scale=32, train_wall=105, wall=137122
2023-05-27 08:26:27 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 08:27:18 | INFO | train_inner | epoch 019:   4555 / 6686 loss=4.155, nll_loss=2.533, ppl=5.79, wps=51999.6, ups=0.91, wpb=57228.7, bsz=1471.7, num_updates=124700, lr=0.0001791, gnorm=0.259, clip=100, loss_scale=24, train_wall=106, wall=137233
2023-05-27 08:29:07 | INFO | train_inner | epoch 019:   4655 / 6686 loss=4.165, nll_loss=2.545, ppl=5.84, wps=52710.1, ups=0.92, wpb=57274.2, bsz=1480.2, num_updates=124800, lr=0.000179029, gnorm=0.258, clip=100, loss_scale=16, train_wall=105, wall=137341
2023-05-27 08:30:56 | INFO | train_inner | epoch 019:   4755 / 6686 loss=4.155, nll_loss=2.533, ppl=5.79, wps=52796, ups=0.92, wpb=57249.7, bsz=1485.3, num_updates=124900, lr=0.000178957, gnorm=0.254, clip=100, loss_scale=16, train_wall=105, wall=137450
2023-05-27 08:32:44 | INFO | train_inner | epoch 019:   4855 / 6686 loss=4.176, nll_loss=2.557, ppl=5.89, wps=52547.6, ups=0.92, wpb=57122.4, bsz=1456.9, num_updates=125000, lr=0.000178885, gnorm=0.258, clip=100, loss_scale=16, train_wall=105, wall=137558
2023-05-27 08:34:33 | INFO | train_inner | epoch 019:   4955 / 6686 loss=4.169, nll_loss=2.549, ppl=5.85, wps=52810.8, ups=0.92, wpb=57414.3, bsz=1500.6, num_updates=125100, lr=0.000178814, gnorm=0.257, clip=100, loss_scale=16, train_wall=105, wall=137667
2023-05-27 08:36:22 | INFO | train_inner | epoch 019:   5055 / 6686 loss=4.168, nll_loss=2.547, ppl=5.85, wps=52612.2, ups=0.92, wpb=57417.4, bsz=1495.2, num_updates=125200, lr=0.000178743, gnorm=0.259, clip=100, loss_scale=22, train_wall=105, wall=137776
2023-05-27 08:38:11 | INFO | train_inner | epoch 019:   5155 / 6686 loss=4.175, nll_loss=2.555, ppl=5.88, wps=52415.5, ups=0.92, wpb=57094.5, bsz=1473.3, num_updates=125300, lr=0.000178671, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=137885
2023-05-27 08:39:59 | INFO | train_inner | epoch 019:   5255 / 6686 loss=4.161, nll_loss=2.54, ppl=5.82, wps=52791.9, ups=0.92, wpb=57129.7, bsz=1478.6, num_updates=125400, lr=0.0001786, gnorm=0.258, clip=100, loss_scale=32, train_wall=104, wall=137993
2023-05-27 08:41:48 | INFO | train_inner | epoch 019:   5355 / 6686 loss=4.164, nll_loss=2.544, ppl=5.83, wps=52703.3, ups=0.92, wpb=57066.9, bsz=1479.8, num_updates=125500, lr=0.000178529, gnorm=0.259, clip=100, loss_scale=32, train_wall=104, wall=138102
2023-05-27 08:43:36 | INFO | train_inner | epoch 019:   5455 / 6686 loss=4.167, nll_loss=2.546, ppl=5.84, wps=52795, ups=0.92, wpb=57324.4, bsz=1466.1, num_updates=125600, lr=0.000178458, gnorm=0.257, clip=100, loss_scale=32, train_wall=105, wall=138210
2023-05-27 08:45:04 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 08:45:26 | INFO | train_inner | epoch 019:   5556 / 6686 loss=4.162, nll_loss=2.541, ppl=5.82, wps=52210.6, ups=0.91, wpb=57248.2, bsz=1500.5, num_updates=125700, lr=0.000178387, gnorm=0.26, clip=100, loss_scale=33, train_wall=106, wall=138320
2023-05-27 08:47:15 | INFO | train_inner | epoch 019:   5656 / 6686 loss=4.168, nll_loss=2.548, ppl=5.85, wps=52581.1, ups=0.92, wpb=57241.7, bsz=1455, num_updates=125800, lr=0.000178316, gnorm=0.258, clip=100, loss_scale=32, train_wall=105, wall=138429
2023-05-27 08:49:03 | INFO | train_inner | epoch 019:   5756 / 6686 loss=4.17, nll_loss=2.55, ppl=5.86, wps=52736.5, ups=0.92, wpb=57195, bsz=1475.6, num_updates=125900, lr=0.000178245, gnorm=0.26, clip=100, loss_scale=32, train_wall=105, wall=138537
2023-05-27 08:49:50 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 08:50:53 | INFO | train_inner | epoch 019:   5857 / 6686 loss=4.165, nll_loss=2.544, ppl=5.83, wps=52201.5, ups=0.91, wpb=57173.3, bsz=1459.7, num_updates=126000, lr=0.000178174, gnorm=0.258, clip=100, loss_scale=23, train_wall=106, wall=138647
2023-05-27 08:52:41 | INFO | train_inner | epoch 019:   5957 / 6686 loss=4.163, nll_loss=2.543, ppl=5.83, wps=52781, ups=0.92, wpb=57252.4, bsz=1471.3, num_updates=126100, lr=0.000178103, gnorm=0.255, clip=100, loss_scale=16, train_wall=105, wall=138755
2023-05-27 08:54:29 | INFO | train_inner | epoch 019:   6057 / 6686 loss=4.162, nll_loss=2.542, ppl=5.82, wps=52799.6, ups=0.92, wpb=57232.3, bsz=1487.5, num_updates=126200, lr=0.000178033, gnorm=0.258, clip=100, loss_scale=16, train_wall=105, wall=138864
2023-05-27 08:56:19 | INFO | train_inner | epoch 019:   6157 / 6686 loss=4.157, nll_loss=2.536, ppl=5.8, wps=52534.6, ups=0.92, wpb=57295.7, bsz=1489.5, num_updates=126300, lr=0.000177962, gnorm=0.257, clip=100, loss_scale=16, train_wall=105, wall=138973
2023-05-27 08:58:07 | INFO | train_inner | epoch 019:   6257 / 6686 loss=4.182, nll_loss=2.563, ppl=5.91, wps=52502.7, ups=0.92, wpb=57061.1, bsz=1473.8, num_updates=126400, lr=0.000177892, gnorm=0.262, clip=100, loss_scale=16, train_wall=105, wall=139081
2023-05-27 08:59:56 | INFO | train_inner | epoch 019:   6357 / 6686 loss=4.174, nll_loss=2.555, ppl=5.88, wps=52657.7, ups=0.92, wpb=57176.9, bsz=1508.7, num_updates=126500, lr=0.000177822, gnorm=0.259, clip=100, loss_scale=24, train_wall=105, wall=139190
2023-05-27 09:01:44 | INFO | train_inner | epoch 019:   6457 / 6686 loss=4.172, nll_loss=2.553, ppl=5.87, wps=52625.1, ups=0.92, wpb=57134.4, bsz=1467.5, num_updates=126600, lr=0.000177751, gnorm=0.258, clip=100, loss_scale=32, train_wall=105, wall=139299
2023-05-27 09:03:33 | INFO | train_inner | epoch 019:   6557 / 6686 loss=4.17, nll_loss=2.55, ppl=5.86, wps=52658, ups=0.92, wpb=56950.3, bsz=1464.3, num_updates=126700, lr=0.000177681, gnorm=0.257, clip=100, loss_scale=32, train_wall=104, wall=139407
2023-05-27 09:04:19 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 09:05:22 | INFO | train_inner | epoch 019:   6658 / 6686 loss=4.167, nll_loss=2.547, ppl=5.84, wps=52177.9, ups=0.91, wpb=57189.7, bsz=1474.9, num_updates=126800, lr=0.000177611, gnorm=0.258, clip=100, loss_scale=23, train_wall=106, wall=139516
2023-05-27 09:05:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-27 09:05:58 | INFO | fairseq.tasks.translation | example hypothesis: Why was that?
2023-05-27 09:05:58 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-27 09:05:59 | INFO | fairseq.tasks.translation | example hypothesis: I’ll make you lose so badly that you don’t even have your pants left!
2023-05-27 09:05:59 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-27 09:05:59 | INFO | fairseq.tasks.translation | example hypothesis: Shen Liangchuan had just let out a sigh of relief when he heard her say, “I’ll call for you to stay in the same room!”
2023-05-27 09:05:59 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-27 09:06:00 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved her hand and entered the elevator.
2023-05-27 09:06:00 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-27 09:06:01 | INFO | fairseq.tasks.translation | example hypothesis: She raised her head and saw Song Cheng standing in the distance!
2023-05-27 09:06:01 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-27 09:06:01 | INFO | fairseq.tasks.translation | example hypothesis: Song Cheng patted his chest. “You scared me to death! Where’s Wang Chuan?”
2023-05-27 09:06:01 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-27 09:06:02 | INFO | fairseq.tasks.translation | example hypothesis: I said, “No, I can’t eat it.”
2023-05-27 09:06:02 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-27 09:06:03 | INFO | fairseq.tasks.translation | example hypothesis: Everyone didn’t believe it at first, but Wang Wenhao insisted on him, making the public opinion lean towards Wang Wenhao.
2023-05-27 09:06:03 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-27 09:06:04 | INFO | fairseq.tasks.translation | example hypothesis: Coming here like this with his identity, Baili Hongzhuang had to be treated even if she did not want to!
2023-05-27 09:06:04 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-27 09:06:05 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian said, “Mr. Shen, I, I’ve left too much blood and my brain lacks oxygen. I can’t think of anything. Why don’t you give me a hint?”
2023-05-27 09:06:05 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-27 09:06:06 | INFO | fairseq.tasks.translation | example hypothesis: He didn’t know why so many people had heard about it. Since he couldn’t hide it any longer, he might as well tell them.
2023-05-27 09:06:06 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-27 09:06:07 | INFO | fairseq.tasks.translation | example hypothesis: Her deliberately suppressed voice was unable to conceal the hostility and ruthlessness in her voice.
2023-05-27 09:06:07 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-27 09:06:07 | INFO | fairseq.tasks.translation | example hypothesis: Beast pets of different levels were different in strength, but beast pets were precious and rare. It was impossible for an ordinary person to have one, even for the descendants of officials.
2023-05-27 09:06:07 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-27 09:06:08 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chixia gritted his teeth and cursed in a low voice.
2023-05-27 09:06:08 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-27 09:06:09 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang had concealed it very well, Di Beichen could still see the ripples in her eyes, and his eyes were filled with warmth.
2023-05-27 09:06:09 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-27 09:06:10 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia walked in, he didn't even see a few waiters, let alone guests.
2023-05-27 09:06:10 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-27 09:06:11 | INFO | fairseq.tasks.translation | example hypothesis: This person was the fourth young miss of the Ye Family, Ye Qing Ling.
2023-05-27 09:06:11 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-27 09:06:13 | INFO | fairseq.tasks.translation | example hypothesis: Because at this moment, she felt as if her chin was about to break.
2023-05-27 09:06:13 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-27 09:06:14 | INFO | fairseq.tasks.translation | example hypothesis: “Good Mu Zi, help me. If it wasn’t for you, that old man wouldn’t have targeted me.”
2023-05-27 09:06:14 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-27 09:06:15 | INFO | fairseq.tasks.translation | example hypothesis: Bai Li Yu Yan was even more excited. She was the one who was responsible for this. Earlier, Bai Li Hong Zhuang had treated her like this. This time around, she would definitely make it difficult for Bai Li Hong Zhuang.
2023-05-27 09:06:15 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-27 09:06:16 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How could that be? There are also four mages on their side, of course they won’t surrender so easily. After arguing for a long time, they finally decided on how to obtain control of the Kingdom of Exia through the competition.”
2023-05-27 09:06:16 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-27 09:06:18 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a little. He had always been looking for a reason for Li Yuyue not being able to participate in the Imperial Family Hunting Competition.
2023-05-27 09:06:18 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-27 09:06:19 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my level good enough? They’re all the best talents in the country, how can my magic be so weak?”
2023-05-27 09:06:19 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-27 09:06:21 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yibei’s words meant that if Fang Chixia didn’t want to go, then there was no need to go.
2023-05-27 09:06:21 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-27 09:06:22 | INFO | fairseq.tasks.translation | example hypothesis: She tilted her head and saw that the five palm prints on her cheek were very eye-catching. They were swelling at a speed visible to the naked eye. When she reached out to touch them, she couldn’t help but let out a hiss.
2023-05-27 09:06:22 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-27 09:06:24 | INFO | fairseq.tasks.translation | example hypothesis: This... how could this be the charm that that trash could give off?
2023-05-27 09:06:24 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-27 09:06:25 | INFO | fairseq.tasks.translation | example hypothesis: How could Wang Wenhao have found the newspaper firm? The chief editor should have called to tell her not to come to the newspaper firm, but these three people... had plotted against her!
2023-05-27 09:06:25 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-27 09:06:27 | INFO | fairseq.tasks.translation | example hypothesis: Hearing Teacher Di’s praise, I was delighted. I put away the energy ball with my left hand and shot out a light sword with my right hand towards Teacher Zhen. The light sword actually hit its target smoothly. I was shocked, and upon closer inspection, I discovered that it was just an afterimage. Teacher Zhen had already moved behind me and shouted, “Berserk Space!”
2023-05-27 09:06:27 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-27 09:06:30 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Initially, we proposed a two out of three competition, but they said it wasn’t fair, because we have Teacher Di and Teacher Zhen, ranked higher than them, and they proposed a three out of five competition. Since we were the ones who proposed the competition, we can only listen to them in the end. In three days’ time, we will compete in secret in the Royal Coliseum, and the competition will be held in the Royal Coliseum.”
2023-05-27 09:06:30 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-27 09:06:32 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Di used a seventh level light spell, Light Thunder Chain Burst. I rarely used this spell, because my control over it wasn’t ideal. Teacher Di cast nine lightning bolts and surrounded me, forming a simple spell formation. It prevented me from escaping in a short distance, and then each lightning bolt exploded to form a powerful attack.
2023-05-27 09:06:32 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-27 09:06:35 | INFO | fairseq.tasks.translation | example hypothesis: As soon as Ma Ke and the two teachers walked to the other side, Teacher Zhen cast a Lesser Dimensional Slash at me. As expected of the continent’s number one Magician. The suction force of the Lesser Dimensional Slash was much stronger than the one I cast. A small spatial crack appeared beside me, and a powerful suction force swept towards me.
2023-05-27 09:06:35 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-27 09:06:36 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 4.151 | nll_loss 2.51 | ppl 5.7 | bleu 21.72 | wps 1957.9 | wpb 2420.8 | bsz 84.5 | num_updates 126828 | best_bleu 21.81
2023-05-27 09:06:36 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-27 09:06:44 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/concat-1-1-0.2-sf[zh-en]/checkpoint19.pt (epoch 19 @ 126828 updates, score 21.72) (writing took 8.958613088354468 seconds)
2023-05-27 09:06:45 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-05-27 09:06:45 | INFO | train | epoch 019 | loss 4.162 | nll_loss 2.541 | ppl 5.82 | wps 51905.7 | ups 0.91 | wpb 57190.1 | bsz 1477.4 | num_updates 126828 | lr 0.000177592 | gnorm 0.258 | clip 100 | loss_scale 27 | train_wall 7021 | wall 139599
2023-05-27 09:06:45 | INFO | fairseq.trainer | begin training epoch 20
2023-05-27 09:08:28 | INFO | train_inner | epoch 020:     72 / 6686 loss=4.145, nll_loss=2.522, ppl=5.74, wps=30576, ups=0.54, wpb=56808, bsz=1490.2, num_updates=126900, lr=0.000177541, gnorm=0.261, clip=100, loss_scale=16, train_wall=107, wall=139702
2023-05-27 09:10:25 | INFO | train_inner | epoch 020:    172 / 6686 loss=4.133, nll_loss=2.508, ppl=5.69, wps=49170.7, ups=0.86, wpb=57307.4, bsz=1503.7, num_updates=127000, lr=0.000177471, gnorm=0.256, clip=100, loss_scale=16, train_wall=108, wall=139819
2023-05-27 09:12:15 | INFO | train_inner | epoch 020:    272 / 6686 loss=4.143, nll_loss=2.519, ppl=5.73, wps=51783.7, ups=0.9, wpb=57256.4, bsz=1472.1, num_updates=127100, lr=0.000177401, gnorm=0.258, clip=100, loss_scale=16, train_wall=106, wall=139929
2023-05-27 09:14:04 | INFO | train_inner | epoch 020:    372 / 6686 loss=4.153, nll_loss=2.53, ppl=5.78, wps=52571.1, ups=0.92, wpb=57244.3, bsz=1479.4, num_updates=127200, lr=0.000177332, gnorm=0.259, clip=100, loss_scale=16, train_wall=105, wall=140038
2023-05-27 09:15:53 | INFO | train_inner | epoch 020:    472 / 6686 loss=4.144, nll_loss=2.52, ppl=5.74, wps=52451.3, ups=0.92, wpb=57294.3, bsz=1483, num_updates=127300, lr=0.000177262, gnorm=0.262, clip=100, loss_scale=24, train_wall=105, wall=140147
2023-05-27 09:17:42 | INFO | train_inner | epoch 020:    572 / 6686 loss=4.153, nll_loss=2.53, ppl=5.78, wps=52475.5, ups=0.92, wpb=57051.7, bsz=1468.4, num_updates=127400, lr=0.000177192, gnorm=0.26, clip=100, loss_scale=32, train_wall=105, wall=140256
2023-05-27 09:19:31 | INFO | train_inner | epoch 020:    672 / 6686 loss=4.147, nll_loss=2.524, ppl=5.75, wps=52671.9, ups=0.92, wpb=57228.1, bsz=1486.1, num_updates=127500, lr=0.000177123, gnorm=0.259, clip=100, loss_scale=32, train_wall=105, wall=140365
2023-05-27 09:21:19 | INFO | train_inner | epoch 020:    772 / 6686 loss=4.17, nll_loss=2.55, ppl=5.86, wps=52685, ups=0.92, wpb=57098.5, bsz=1451, num_updates=127600, lr=0.000177054, gnorm=0.259, clip=100, loss_scale=32, train_wall=105, wall=140473
2023-05-27 09:23:08 | INFO | train_inner | epoch 020:    872 / 6686 loss=4.144, nll_loss=2.52, ppl=5.74, wps=52679.9, ups=0.92, wpb=57243.2, bsz=1480.5, num_updates=127700, lr=0.000176984, gnorm=0.258, clip=100, loss_scale=32, train_wall=105, wall=140582
2023-05-27 09:24:29 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 09:24:58 | INFO | train_inner | epoch 020:    973 / 6686 loss=4.15, nll_loss=2.527, ppl=5.77, wps=52035.1, ups=0.91, wpb=57212.2, bsz=1465.7, num_updates=127800, lr=0.000176915, gnorm=0.261, clip=100, loss_scale=35, train_wall=106, wall=140692
2023-05-27 09:26:47 | INFO | train_inner | epoch 020:   1073 / 6686 loss=4.154, nll_loss=2.531, ppl=5.78, wps=52364.3, ups=0.92, wpb=57149.6, bsz=1471.8, num_updates=127900, lr=0.000176846, gnorm=0.261, clip=100, loss_scale=32, train_wall=105, wall=140801
2023-05-27 09:28:36 | INFO | train_inner | epoch 020:   1173 / 6686 loss=4.143, nll_loss=2.519, ppl=5.73, wps=52542.1, ups=0.92, wpb=57341.5, bsz=1494.6, num_updates=128000, lr=0.000176777, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=140910
2023-05-27 09:30:24 | INFO | train_inner | epoch 020:   1273 / 6686 loss=4.139, nll_loss=2.515, ppl=5.72, wps=52783.2, ups=0.92, wpb=57276.4, bsz=1481.9, num_updates=128100, lr=0.000176708, gnorm=0.255, clip=100, loss_scale=32, train_wall=105, wall=141019
2023-05-27 09:32:13 | INFO | train_inner | epoch 020:   1373 / 6686 loss=4.156, nll_loss=2.534, ppl=5.79, wps=52456.6, ups=0.92, wpb=56961.2, bsz=1457.2, num_updates=128200, lr=0.000176639, gnorm=0.261, clip=100, loss_scale=32, train_wall=105, wall=141127
2023-05-27 09:34:00 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 09:34:03 | INFO | train_inner | epoch 020:   1474 / 6686 loss=4.151, nll_loss=2.529, ppl=5.77, wps=52013, ups=0.91, wpb=57025.1, bsz=1482.6, num_updates=128300, lr=0.00017657, gnorm=0.261, clip=100, loss_scale=36, train_wall=106, wall=141237
2023-05-27 09:35:52 | INFO | train_inner | epoch 020:   1574 / 6686 loss=4.148, nll_loss=2.524, ppl=5.75, wps=52447.5, ups=0.92, wpb=57184.8, bsz=1498.3, num_updates=128400, lr=0.000176501, gnorm=0.257, clip=100, loss_scale=32, train_wall=105, wall=141346
2023-05-27 09:37:40 | INFO | train_inner | epoch 020:   1674 / 6686 loss=4.147, nll_loss=2.524, ppl=5.75, wps=52517, ups=0.92, wpb=57124.9, bsz=1483, num_updates=128500, lr=0.000176432, gnorm=0.26, clip=100, loss_scale=32, train_wall=105, wall=141455
2023-05-27 09:39:29 | INFO | train_inner | epoch 020:   1774 / 6686 loss=4.146, nll_loss=2.523, ppl=5.75, wps=52713.4, ups=0.92, wpb=57175.1, bsz=1495.9, num_updates=128600, lr=0.000176364, gnorm=0.26, clip=100, loss_scale=32, train_wall=105, wall=141563
2023-05-27 09:41:18 | INFO | train_inner | epoch 020:   1874 / 6686 loss=4.155, nll_loss=2.533, ppl=5.79, wps=52601.2, ups=0.92, wpb=57259.7, bsz=1491.2, num_updates=128700, lr=0.000176295, gnorm=0.261, clip=100, loss_scale=32, train_wall=105, wall=141672
2023-05-27 09:43:07 | INFO | train_inner | epoch 020:   1974 / 6686 loss=4.161, nll_loss=2.539, ppl=5.81, wps=52503.1, ups=0.92, wpb=57224.6, bsz=1475.8, num_updates=128800, lr=0.000176227, gnorm=0.26, clip=100, loss_scale=32, train_wall=105, wall=141781
2023-05-27 09:43:36 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 09:43:53 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 09:44:58 | INFO | train_inner | epoch 020:   2076 / 6686 loss=4.16, nll_loss=2.538, ppl=5.81, wps=51681.4, ups=0.9, wpb=57382.9, bsz=1463.4, num_updates=128900, lr=0.000176158, gnorm=0.258, clip=100, loss_scale=28, train_wall=107, wall=141892
2023-05-27 09:46:47 | INFO | train_inner | epoch 020:   2176 / 6686 loss=4.152, nll_loss=2.53, ppl=5.77, wps=52231.4, ups=0.91, wpb=57296.9, bsz=1475.3, num_updates=129000, lr=0.00017609, gnorm=0.26, clip=100, loss_scale=16, train_wall=106, wall=142002
2023-05-27 09:48:36 | INFO | train_inner | epoch 020:   2276 / 6686 loss=4.154, nll_loss=2.531, ppl=5.78, wps=52546.1, ups=0.92, wpb=57274, bsz=1469.9, num_updates=129100, lr=0.000176022, gnorm=0.259, clip=100, loss_scale=16, train_wall=105, wall=142111
2023-05-27 09:50:25 | INFO | train_inner | epoch 020:   2376 / 6686 loss=4.159, nll_loss=2.537, ppl=5.8, wps=52612.6, ups=0.92, wpb=57207.7, bsz=1461.1, num_updates=129200, lr=0.000175954, gnorm=0.26, clip=100, loss_scale=16, train_wall=105, wall=142219
2023-05-27 09:52:14 | INFO | train_inner | epoch 020:   2476 / 6686 loss=4.14, nll_loss=2.516, ppl=5.72, wps=52579.7, ups=0.92, wpb=57369.3, bsz=1503, num_updates=129300, lr=0.000175886, gnorm=0.257, clip=100, loss_scale=16, train_wall=105, wall=142328
2023-05-27 09:54:03 | INFO | train_inner | epoch 020:   2576 / 6686 loss=4.148, nll_loss=2.524, ppl=5.75, wps=52652.2, ups=0.92, wpb=57379.3, bsz=1497.9, num_updates=129400, lr=0.000175818, gnorm=0.258, clip=100, loss_scale=24, train_wall=105, wall=142437
2023-05-27 09:55:52 | INFO | train_inner | epoch 020:   2676 / 6686 loss=4.153, nll_loss=2.531, ppl=5.78, wps=52442.4, ups=0.92, wpb=57176.6, bsz=1457.8, num_updates=129500, lr=0.00017575, gnorm=0.261, clip=100, loss_scale=32, train_wall=105, wall=142546
2023-05-27 09:57:41 | INFO | train_inner | epoch 020:   2776 / 6686 loss=4.177, nll_loss=2.558, ppl=5.89, wps=52598.5, ups=0.92, wpb=57148.7, bsz=1447.8, num_updates=129600, lr=0.000175682, gnorm=0.258, clip=100, loss_scale=32, train_wall=105, wall=142655
2023-05-27 09:59:30 | INFO | train_inner | epoch 020:   2876 / 6686 loss=4.165, nll_loss=2.545, ppl=5.83, wps=52563.6, ups=0.92, wpb=57118, bsz=1456.6, num_updates=129700, lr=0.000175614, gnorm=0.259, clip=100, loss_scale=32, train_wall=105, wall=142764
2023-05-27 10:01:18 | INFO | train_inner | epoch 020:   2976 / 6686 loss=4.156, nll_loss=2.534, ppl=5.79, wps=52766.8, ups=0.92, wpb=57331.9, bsz=1443.5, num_updates=129800, lr=0.000175547, gnorm=0.261, clip=100, loss_scale=32, train_wall=105, wall=142872
2023-05-27 10:02:41 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 10:03:08 | INFO | train_inner | epoch 020:   3077 / 6686 loss=4.156, nll_loss=2.534, ppl=5.79, wps=52151.3, ups=0.91, wpb=57140.3, bsz=1478, num_updates=129900, lr=0.000175479, gnorm=0.259, clip=100, loss_scale=35, train_wall=106, wall=142982
2023-05-27 10:04:38 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 10:04:58 | INFO | train_inner | epoch 020:   3178 / 6686 loss=4.165, nll_loss=2.544, ppl=5.83, wps=51973, ups=0.91, wpb=57291.4, bsz=1466.2, num_updates=130000, lr=0.000175412, gnorm=0.257, clip=100, loss_scale=29, train_wall=106, wall=143092
2023-05-27 10:06:47 | INFO | train_inner | epoch 020:   3278 / 6686 loss=4.161, nll_loss=2.54, ppl=5.82, wps=52549.3, ups=0.92, wpb=57134.6, bsz=1473.4, num_updates=130100, lr=0.000175344, gnorm=0.258, clip=100, loss_scale=16, train_wall=105, wall=143201
2023-05-27 10:08:35 | INFO | train_inner | epoch 020:   3378 / 6686 loss=4.173, nll_loss=2.554, ppl=5.87, wps=52823.1, ups=0.92, wpb=57307.7, bsz=1479.2, num_updates=130200, lr=0.000175277, gnorm=0.26, clip=100, loss_scale=16, train_wall=105, wall=143309
2023-05-27 10:10:24 | INFO | train_inner | epoch 020:   3478 / 6686 loss=4.16, nll_loss=2.538, ppl=5.81, wps=52557.1, ups=0.92, wpb=57227.6, bsz=1480.6, num_updates=130300, lr=0.00017521, gnorm=0.26, clip=100, loss_scale=16, train_wall=105, wall=143418
2023-05-27 10:12:13 | INFO | train_inner | epoch 020:   3578 / 6686 loss=4.155, nll_loss=2.533, ppl=5.79, wps=52492.8, ups=0.92, wpb=57230.2, bsz=1506.5, num_updates=130400, lr=0.000175142, gnorm=0.261, clip=100, loss_scale=16, train_wall=105, wall=143527
2023-05-27 10:14:02 | INFO | train_inner | epoch 020:   3678 / 6686 loss=4.162, nll_loss=2.541, ppl=5.82, wps=52600.7, ups=0.92, wpb=57154.8, bsz=1461.9, num_updates=130500, lr=0.000175075, gnorm=0.259, clip=100, loss_scale=17, train_wall=105, wall=143636
2023-05-27 10:15:51 | INFO | train_inner | epoch 020:   3778 / 6686 loss=4.154, nll_loss=2.532, ppl=5.78, wps=52701, ups=0.92, wpb=57274.5, bsz=1479.8, num_updates=130600, lr=0.000175008, gnorm=0.259, clip=100, loss_scale=32, train_wall=105, wall=143745
2023-05-27 10:17:40 | INFO | train_inner | epoch 020:   3878 / 6686 loss=4.166, nll_loss=2.546, ppl=5.84, wps=52236.1, ups=0.91, wpb=57100.8, bsz=1486.4, num_updates=130700, lr=0.000174941, gnorm=0.262, clip=100, loss_scale=32, train_wall=105, wall=143854
2023-05-27 10:19:29 | INFO | train_inner | epoch 020:   3978 / 6686 loss=4.152, nll_loss=2.53, ppl=5.78, wps=52651.8, ups=0.92, wpb=57267.8, bsz=1480.3, num_updates=130800, lr=0.000174874, gnorm=0.259, clip=100, loss_scale=32, train_wall=105, wall=143963
2023-05-27 10:20:44 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 10:21:19 | INFO | train_inner | epoch 020:   4079 / 6686 loss=4.147, nll_loss=2.524, ppl=5.75, wps=52157.4, ups=0.91, wpb=57284.1, bsz=1503.8, num_updates=130900, lr=0.000174808, gnorm=0.26, clip=100, loss_scale=27, train_wall=106, wall=144073
2023-05-27 10:23:07 | INFO | train_inner | epoch 020:   4179 / 6686 loss=4.161, nll_loss=2.541, ppl=5.82, wps=52853, ups=0.92, wpb=57231.6, bsz=1480.6, num_updates=131000, lr=0.000174741, gnorm=0.26, clip=100, loss_scale=16, train_wall=104, wall=144181
2023-05-27 10:24:56 | INFO | train_inner | epoch 020:   4279 / 6686 loss=4.162, nll_loss=2.542, ppl=5.82, wps=52480.3, ups=0.92, wpb=57209.2, bsz=1491.4, num_updates=131100, lr=0.000174674, gnorm=0.26, clip=100, loss_scale=16, train_wall=105, wall=144290
2023-05-27 10:26:45 | INFO | train_inner | epoch 020:   4379 / 6686 loss=4.16, nll_loss=2.539, ppl=5.81, wps=52356.3, ups=0.92, wpb=57015, bsz=1456.8, num_updates=131200, lr=0.000174608, gnorm=0.26, clip=100, loss_scale=16, train_wall=105, wall=144399
2023-05-27 10:28:33 | INFO | train_inner | epoch 020:   4479 / 6686 loss=4.155, nll_loss=2.533, ppl=5.79, wps=52831.2, ups=0.92, wpb=57288.2, bsz=1479, num_updates=131300, lr=0.000174541, gnorm=0.258, clip=100, loss_scale=16, train_wall=105, wall=144507
2023-05-27 10:30:22 | INFO | train_inner | epoch 020:   4579 / 6686 loss=4.159, nll_loss=2.538, ppl=5.81, wps=52424.2, ups=0.92, wpb=57009.2, bsz=1483.6, num_updates=131400, lr=0.000174475, gnorm=0.259, clip=100, loss_scale=19, train_wall=105, wall=144616
2023-05-27 10:32:11 | INFO | train_inner | epoch 020:   4679 / 6686 loss=4.184, nll_loss=2.565, ppl=5.92, wps=52554.2, ups=0.92, wpb=57179.5, bsz=1455, num_updates=131500, lr=0.000174408, gnorm=0.26, clip=100, loss_scale=32, train_wall=105, wall=144725
2023-05-27 10:33:59 | INFO | train_inner | epoch 020:   4779 / 6686 loss=4.164, nll_loss=2.544, ppl=5.83, wps=52570.6, ups=0.92, wpb=57005.5, bsz=1479.3, num_updates=131600, lr=0.000174342, gnorm=0.261, clip=100, loss_scale=32, train_wall=105, wall=144833
2023-05-27 10:35:48 | INFO | train_inner | epoch 020:   4879 / 6686 loss=4.15, nll_loss=2.527, ppl=5.77, wps=52509.9, ups=0.92, wpb=57350.5, bsz=1490.9, num_updates=131700, lr=0.000174276, gnorm=0.256, clip=100, loss_scale=32, train_wall=105, wall=144943
2023-05-27 10:37:37 | INFO | train_inner | epoch 020:   4979 / 6686 loss=4.165, nll_loss=2.545, ppl=5.84, wps=52523.8, ups=0.92, wpb=57223.7, bsz=1472.4, num_updates=131800, lr=0.00017421, gnorm=0.261, clip=100, loss_scale=32, train_wall=105, wall=145051
2023-05-27 10:38:56 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 10:39:27 | INFO | train_inner | epoch 020:   5080 / 6686 loss=4.159, nll_loss=2.538, ppl=5.81, wps=51934.3, ups=0.91, wpb=57033.6, bsz=1493.2, num_updates=131900, lr=0.000174144, gnorm=0.258, clip=100, loss_scale=27, train_wall=106, wall=145161
2023-05-27 10:41:16 | INFO | train_inner | epoch 020:   5180 / 6686 loss=4.166, nll_loss=2.545, ppl=5.84, wps=52565.8, ups=0.92, wpb=57101.1, bsz=1476.7, num_updates=132000, lr=0.000174078, gnorm=0.262, clip=100, loss_scale=16, train_wall=105, wall=145270
2023-05-27 10:43:05 | INFO | train_inner | epoch 020:   5280 / 6686 loss=4.155, nll_loss=2.533, ppl=5.79, wps=52626, ups=0.92, wpb=57240.1, bsz=1479.7, num_updates=132100, lr=0.000174012, gnorm=0.262, clip=100, loss_scale=16, train_wall=105, wall=145379
2023-05-27 10:44:53 | INFO | train_inner | epoch 020:   5380 / 6686 loss=4.16, nll_loss=2.539, ppl=5.81, wps=52445.5, ups=0.92, wpb=57126, bsz=1474.2, num_updates=132200, lr=0.000173946, gnorm=0.258, clip=100, loss_scale=16, train_wall=105, wall=145488
2023-05-27 10:46:42 | INFO | train_inner | epoch 020:   5480 / 6686 loss=4.165, nll_loss=2.545, ppl=5.84, wps=52555.2, ups=0.92, wpb=57204.2, bsz=1468.1, num_updates=132300, lr=0.00017388, gnorm=0.257, clip=100, loss_scale=16, train_wall=105, wall=145596
2023-05-27 10:48:31 | INFO | train_inner | epoch 020:   5580 / 6686 loss=4.17, nll_loss=2.55, ppl=5.86, wps=52672, ups=0.92, wpb=57135.8, bsz=1475.6, num_updates=132400, lr=0.000173814, gnorm=0.263, clip=100, loss_scale=19, train_wall=105, wall=145705
2023-05-27 10:48:59 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 10:49:13 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 10:50:22 | INFO | train_inner | epoch 020:   5682 / 6686 loss=4.157, nll_loss=2.536, ppl=5.8, wps=51733.1, ups=0.9, wpb=57264.9, bsz=1470.6, num_updates=132500, lr=0.000173749, gnorm=0.26, clip=100, loss_scale=15, train_wall=107, wall=145816
2023-05-27 10:52:10 | INFO | train_inner | epoch 020:   5782 / 6686 loss=4.181, nll_loss=2.563, ppl=5.91, wps=52602.7, ups=0.92, wpb=57159.3, bsz=1471.7, num_updates=132600, lr=0.000173683, gnorm=0.262, clip=100, loss_scale=8, train_wall=105, wall=145924
2023-05-27 10:53:59 | INFO | train_inner | epoch 020:   5882 / 6686 loss=4.166, nll_loss=2.546, ppl=5.84, wps=52573.4, ups=0.92, wpb=57132.8, bsz=1494.4, num_updates=132700, lr=0.000173618, gnorm=0.256, clip=100, loss_scale=8, train_wall=105, wall=146033
2023-05-27 10:55:48 | INFO | train_inner | epoch 020:   5982 / 6686 loss=4.169, nll_loss=2.55, ppl=5.85, wps=52564.1, ups=0.92, wpb=57263.8, bsz=1462.5, num_updates=132800, lr=0.000173553, gnorm=0.261, clip=100, loss_scale=8, train_wall=105, wall=146142
2023-05-27 10:57:37 | INFO | train_inner | epoch 020:   6082 / 6686 loss=4.169, nll_loss=2.549, ppl=5.85, wps=52550.6, ups=0.92, wpb=57143.9, bsz=1476.5, num_updates=132900, lr=0.000173487, gnorm=0.262, clip=100, loss_scale=8, train_wall=105, wall=146251
2023-05-27 10:59:25 | INFO | train_inner | epoch 020:   6182 / 6686 loss=4.159, nll_loss=2.538, ppl=5.81, wps=52595.8, ups=0.92, wpb=57198.2, bsz=1492.6, num_updates=133000, lr=0.000173422, gnorm=0.26, clip=100, loss_scale=12, train_wall=105, wall=146359
2023-05-27 11:01:14 | INFO | train_inner | epoch 020:   6282 / 6686 loss=4.16, nll_loss=2.539, ppl=5.81, wps=52703.2, ups=0.92, wpb=57187.2, bsz=1480.9, num_updates=133100, lr=0.000173357, gnorm=0.257, clip=100, loss_scale=16, train_wall=105, wall=146468
2023-05-27 11:03:02 | INFO | train_inner | epoch 020:   6382 / 6686 loss=4.174, nll_loss=2.555, ppl=5.88, wps=52469.1, ups=0.92, wpb=56969.5, bsz=1459.9, num_updates=133200, lr=0.000173292, gnorm=0.261, clip=100, loss_scale=16, train_wall=105, wall=146577
2023-05-27 11:04:51 | INFO | train_inner | epoch 020:   6482 / 6686 loss=4.157, nll_loss=2.536, ppl=5.8, wps=52471.6, ups=0.92, wpb=57204, bsz=1470.9, num_updates=133300, lr=0.000173227, gnorm=0.259, clip=100, loss_scale=16, train_wall=105, wall=146686
2023-05-27 11:06:40 | INFO | train_inner | epoch 020:   6582 / 6686 loss=4.16, nll_loss=2.539, ppl=5.81, wps=52470.6, ups=0.92, wpb=57198.4, bsz=1483.2, num_updates=133400, lr=0.000173162, gnorm=0.256, clip=100, loss_scale=16, train_wall=105, wall=146795
2023-05-27 11:08:29 | INFO | train_inner | epoch 020:   6682 / 6686 loss=4.164, nll_loss=2.544, ppl=5.83, wps=52762.6, ups=0.92, wpb=57207.9, bsz=1491.8, num_updates=133500, lr=0.000173097, gnorm=0.257, clip=100, loss_scale=22, train_wall=105, wall=146903
2023-05-27 11:08:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-27 11:08:39 | INFO | fairseq.tasks.translation | example hypothesis: Why was that?
2023-05-27 11:08:39 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-27 11:08:40 | INFO | fairseq.tasks.translation | example hypothesis: I’ll make you lose so badly that you don’t even have your pants left!
2023-05-27 11:08:40 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-27 11:08:40 | INFO | fairseq.tasks.translation | example hypothesis: Just as Shen Liangchuan heaved a sigh of relief, he heard her say, “I’ll call you to stay in the same room!”
2023-05-27 11:08:40 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-27 11:08:41 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved her hand and entered the elevator.
2023-05-27 11:08:41 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-27 11:08:42 | INFO | fairseq.tasks.translation | example hypothesis: She raised her head and saw Song Cheng standing in the distance!
2023-05-27 11:08:42 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-27 11:08:43 | INFO | fairseq.tasks.translation | example hypothesis: Song Cheng patted his chest. “You scared me to death! Where’s Wang Chuan?”
2023-05-27 11:08:43 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-27 11:08:43 | INFO | fairseq.tasks.translation | example hypothesis: I said, “No, I can’t eat it.”
2023-05-27 11:08:43 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-27 11:08:44 | INFO | fairseq.tasks.translation | example hypothesis: At first, no one believed him, but Wang Wenhao insisted on him, making the public opinion lean towards Wang Wenhao.
2023-05-27 11:08:44 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-27 11:08:45 | INFO | fairseq.tasks.translation | example hypothesis: Coming here like this with his status, Baili Hongzhuang had to be treated even if she did not treat it!
2023-05-27 11:08:45 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-27 11:08:46 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian said, “Mr. Shen, I, I’ve kept too much blood and my brain lacks oxygen. I can’t think of anything. Why don’t you give me a hint?”
2023-05-27 11:08:46 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-27 11:08:47 | INFO | fairseq.tasks.translation | example hypothesis: He didn’t know why so many people had heard about it. Since he couldn’t hide it any longer, he might as well tell them.
2023-05-27 11:08:47 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-27 11:08:48 | INFO | fairseq.tasks.translation | example hypothesis: She deliberately lowered her voice, but she could not hide the viciousness and ruthlessness in her tone.
2023-05-27 11:08:48 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-27 11:08:49 | INFO | fairseq.tasks.translation | example hypothesis: The strength of a different rank of a beast pet was different, but a beast pet was precious and rare. It was impossible for ordinary people to possess it, and even the descendants of officials would not be able to possess it.
2023-05-27 11:08:49 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-27 11:08:50 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chi Xia gritted her teeth and cursed.
2023-05-27 11:08:50 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-27 11:08:51 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang had concealed it very well, Di Beichen could still see the waves in her eyes and a hint of warmth filled his eyes.
2023-05-27 11:08:51 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-27 11:08:52 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia walked in, not to mention the guests, she didn't even see a few waiters.
2023-05-27 11:08:52 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-27 11:08:53 | INFO | fairseq.tasks.translation | example hypothesis: This person was the Ye Family's fourth young miss, Ye Qing Ling.
2023-05-27 11:08:53 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-27 11:08:54 | INFO | fairseq.tasks.translation | example hypothesis: Because at this moment, she felt as if her chin was about to shatter.
2023-05-27 11:08:54 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-27 11:08:55 | INFO | fairseq.tasks.translation | example hypothesis: “Good Mu Zi, help me. If it wasn’t for you, that old man wouldn’t have set his eyes on me.”
2023-05-27 11:08:55 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-27 11:08:56 | INFO | fairseq.tasks.translation | example hypothesis: Baili Yuyan was even more excited. This matter was completely directed by her. Earlier, when Baili Hongzhuang treated her like this, she would definitely make things difficult for Baili Hongzhuang.
2023-05-27 11:08:56 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-27 11:08:58 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How could that be? They have four mages on their side, of course they won’t surrender so easily. After arguing for a long time, they decided to decide how to obtain control of the Kingdom of Axia through the competition.”
2023-05-27 11:08:58 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-27 11:08:59 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed. He had been looking for a reason for Li Yuyue’s inability to participate in the Imperial Family’s hunting competition.
2023-05-27 11:08:59 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-27 11:09:00 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my standard good? They’re all the most outstanding talents in the country, how can my magic be so weak?”
2023-05-27 11:09:00 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-27 11:09:02 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yi Bei’s words meant that if Fang Chi Xia didn’t want to go, then she didn’t need to go.
2023-05-27 11:09:02 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-27 11:09:04 | INFO | fairseq.tasks.translation | example hypothesis: She tilted her head and saw that the five palm prints on her cheek were very eye-catching. They swelled up at a speed visible to the naked eye. Reaching out to touch them, she couldn’t help but hiss.
2023-05-27 11:09:04 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-27 11:09:05 | INFO | fairseq.tasks.translation | example hypothesis: This... how could this be the kind of charm that a piece of trash could emit?
2023-05-27 11:09:05 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-27 11:09:06 | INFO | fairseq.tasks.translation | example hypothesis: How could Wang Wenhao have found the newspaper? The chief editor should have called her to tell her not to come to the newspaper, but these three people... had plotted against her!
2023-05-27 11:09:06 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-27 11:09:09 | INFO | fairseq.tasks.translation | example hypothesis: Hearing Teacher Di’s praise, I was delighted. I withdrew the energy ball with my left hand and shot a beam of light towards Teacher Zhen. The beam of light actually managed to land on me. I was shocked. After taking a closer look, I realized that it was just an afterimage. Teacher Zhen had already moved to my back and shouted, “Berserk Space!”
2023-05-27 11:09:09 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-27 11:09:12 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Initially, we proposed a two out of three competition, but they said it wasn’t fair, because we have Teacher Di and Teacher Zhen, who are ranked higher than them, and they proposed five out of three. Since we were the ones who proposed the competition, we can only listen to them in the end. Three days later, we will secretly compete in the Royal Colosseum, and the competition will be held in the Royal Colosseum.”
2023-05-27 11:09:12 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-27 11:09:14 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Di used the seventh grade light spell, Light Thunder Burst. I didn’t use much of this spell because my control over it wasn’t ideal. Teacher Di released nine lightning bolts to surround me, forming a simple spell formation. It prevented me from escaping in a short distance, and then the lightning bolts exploded one after another to form a powerful attack.
2023-05-27 11:09:14 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-27 11:09:17 | INFO | fairseq.tasks.translation | example hypothesis: As soon as Mark and the two teachers walked to the other side of the courtyard, Teacher Zhen launched a Lesser Dimensional Slash at me. He was indeed worthy of being the continent’s number one magician. The suction force of the Lesser Dimensional Slash was actually much stronger than the one I released. A small spatial crack appeared beside me, and a powerful suction force immediately swept towards me.
2023-05-27 11:09:17 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-27 11:09:17 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 4.152 | nll_loss 2.514 | ppl 5.71 | bleu 21.92 | wps 1940.8 | wpb 2420.8 | bsz 84.5 | num_updates 133504 | best_bleu 21.92
2023-05-27 11:09:17 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-27 11:09:25 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/concat-1-1-0.2-sf[zh-en]/checkpoint20.pt (epoch 20 @ 133504 updates, score 21.92) (writing took 8.003345004282892 seconds)
2023-05-27 11:09:25 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-05-27 11:09:25 | INFO | train | epoch 020 | loss 4.157 | nll_loss 2.536 | ppl 5.8 | wps 51870.4 | ups 0.91 | wpb 57190.8 | bsz 1477.5 | num_updates 133504 | lr 0.000173094 | gnorm 0.259 | clip 100 | loss_scale 23 | train_wall 7024 | wall 146959
2023-05-27 11:09:25 | INFO | fairseq.trainer | begin training epoch 21
2023-05-27 11:11:29 | INFO | train_inner | epoch 021:     96 / 6686 loss=4.143, nll_loss=2.52, ppl=5.74, wps=31560.9, ups=0.56, wpb=56697.7, bsz=1452.3, num_updates=133600, lr=0.000173032, gnorm=0.26, clip=100, loss_scale=32, train_wall=106, wall=147083
2023-05-27 11:13:24 | INFO | train_inner | epoch 021:    196 / 6686 loss=4.149, nll_loss=2.526, ppl=5.76, wps=49455.7, ups=0.87, wpb=57009.6, bsz=1466.2, num_updates=133700, lr=0.000172967, gnorm=0.26, clip=100, loss_scale=32, train_wall=107, wall=147198
2023-05-27 11:15:15 | INFO | train_inner | epoch 021:    296 / 6686 loss=4.145, nll_loss=2.521, ppl=5.74, wps=51382.7, ups=0.9, wpb=57125.8, bsz=1467.1, num_updates=133800, lr=0.000172903, gnorm=0.259, clip=100, loss_scale=32, train_wall=106, wall=147309
2023-05-27 11:17:04 | INFO | train_inner | epoch 021:    396 / 6686 loss=4.142, nll_loss=2.519, ppl=5.73, wps=52397, ups=0.92, wpb=57155.8, bsz=1473.5, num_updates=133900, lr=0.000172838, gnorm=0.261, clip=100, loss_scale=32, train_wall=105, wall=147418
2023-05-27 11:18:52 | INFO | train_inner | epoch 021:    496 / 6686 loss=4.148, nll_loss=2.525, ppl=5.75, wps=52691.5, ups=0.92, wpb=57099.2, bsz=1484.2, num_updates=134000, lr=0.000172774, gnorm=0.261, clip=100, loss_scale=41, train_wall=105, wall=147527
2023-05-27 11:19:03 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 11:20:43 | INFO | train_inner | epoch 021:    597 / 6686 loss=4.147, nll_loss=2.524, ppl=5.75, wps=51900.6, ups=0.9, wpb=57368.3, bsz=1481.7, num_updates=134100, lr=0.000172709, gnorm=0.257, clip=100, loss_scale=35, train_wall=106, wall=147637
2023-05-27 11:22:32 | INFO | train_inner | epoch 021:    697 / 6686 loss=4.146, nll_loss=2.523, ppl=5.75, wps=52547.2, ups=0.92, wpb=57253.7, bsz=1466.9, num_updates=134200, lr=0.000172645, gnorm=0.257, clip=100, loss_scale=32, train_wall=105, wall=147746
2023-05-27 11:24:21 | INFO | train_inner | epoch 021:    797 / 6686 loss=4.148, nll_loss=2.525, ppl=5.76, wps=52627.6, ups=0.92, wpb=57309.8, bsz=1462, num_updates=134300, lr=0.000172581, gnorm=0.26, clip=100, loss_scale=32, train_wall=105, wall=147855
2023-05-27 11:26:10 | INFO | train_inner | epoch 021:    897 / 6686 loss=4.149, nll_loss=2.526, ppl=5.76, wps=52512.8, ups=0.92, wpb=57185.6, bsz=1474.8, num_updates=134400, lr=0.000172516, gnorm=0.262, clip=100, loss_scale=32, train_wall=105, wall=147964
2023-05-27 11:27:47 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 11:27:59 | INFO | train_inner | epoch 021:    998 / 6686 loss=4.157, nll_loss=2.535, ppl=5.8, wps=52168.4, ups=0.91, wpb=57036.3, bsz=1467.7, num_updates=134500, lr=0.000172452, gnorm=0.262, clip=100, loss_scale=30, train_wall=106, wall=148073
2023-05-27 11:29:48 | INFO | train_inner | epoch 021:   1098 / 6686 loss=4.151, nll_loss=2.529, ppl=5.77, wps=52502.8, ups=0.92, wpb=57124, bsz=1476.2, num_updates=134600, lr=0.000172388, gnorm=0.262, clip=100, loss_scale=16, train_wall=105, wall=148182
2023-05-27 11:31:36 | INFO | train_inner | epoch 021:   1198 / 6686 loss=4.138, nll_loss=2.514, ppl=5.71, wps=52711.6, ups=0.92, wpb=57142.9, bsz=1473.4, num_updates=134700, lr=0.000172324, gnorm=0.258, clip=100, loss_scale=16, train_wall=105, wall=148290
2023-05-27 11:33:25 | INFO | train_inner | epoch 021:   1298 / 6686 loss=4.15, nll_loss=2.528, ppl=5.77, wps=52569.1, ups=0.92, wpb=57229.9, bsz=1491.6, num_updates=134800, lr=0.00017226, gnorm=0.261, clip=100, loss_scale=16, train_wall=105, wall=148399
2023-05-27 11:35:14 | INFO | train_inner | epoch 021:   1398 / 6686 loss=4.143, nll_loss=2.519, ppl=5.73, wps=52509.5, ups=0.92, wpb=57325.4, bsz=1487.8, num_updates=134900, lr=0.000172196, gnorm=0.259, clip=100, loss_scale=16, train_wall=105, wall=148508
2023-05-27 11:37:04 | INFO | train_inner | epoch 021:   1498 / 6686 loss=4.137, nll_loss=2.512, ppl=5.7, wps=52540.2, ups=0.92, wpb=57371.6, bsz=1504.2, num_updates=135000, lr=0.000172133, gnorm=0.26, clip=100, loss_scale=16, train_wall=105, wall=148618
2023-05-27 11:38:53 | INFO | train_inner | epoch 021:   1598 / 6686 loss=4.146, nll_loss=2.523, ppl=5.75, wps=52484.1, ups=0.92, wpb=57204.5, bsz=1486.8, num_updates=135100, lr=0.000172069, gnorm=0.264, clip=100, loss_scale=32, train_wall=105, wall=148727
2023-05-27 11:40:41 | INFO | train_inner | epoch 021:   1698 / 6686 loss=4.156, nll_loss=2.534, ppl=5.79, wps=52630.2, ups=0.92, wpb=57121.1, bsz=1481.5, num_updates=135200, lr=0.000172005, gnorm=0.258, clip=100, loss_scale=32, train_wall=105, wall=148835
2023-05-27 11:42:30 | INFO | train_inner | epoch 021:   1798 / 6686 loss=4.148, nll_loss=2.525, ppl=5.76, wps=52526.3, ups=0.92, wpb=57315.8, bsz=1482.8, num_updates=135300, lr=0.000171942, gnorm=0.261, clip=100, loss_scale=32, train_wall=105, wall=148944
2023-05-27 11:42:37 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 11:44:20 | INFO | train_inner | epoch 021:   1899 / 6686 loss=4.148, nll_loss=2.525, ppl=5.75, wps=51891.8, ups=0.91, wpb=57114.8, bsz=1485.1, num_updates=135400, lr=0.000171878, gnorm=0.258, clip=100, loss_scale=17, train_wall=106, wall=149054
2023-05-27 11:46:09 | INFO | train_inner | epoch 021:   1999 / 6686 loss=4.161, nll_loss=2.54, ppl=5.82, wps=52519.1, ups=0.92, wpb=57198.8, bsz=1449.7, num_updates=135500, lr=0.000171815, gnorm=0.266, clip=100, loss_scale=16, train_wall=105, wall=149163
2023-05-27 11:47:58 | INFO | train_inner | epoch 021:   2099 / 6686 loss=4.155, nll_loss=2.533, ppl=5.79, wps=52663.7, ups=0.92, wpb=57174.8, bsz=1495.7, num_updates=135600, lr=0.000171751, gnorm=0.262, clip=100, loss_scale=16, train_wall=105, wall=149272
2023-05-27 11:49:46 | INFO | train_inner | epoch 021:   2199 / 6686 loss=4.149, nll_loss=2.527, ppl=5.76, wps=52700.9, ups=0.92, wpb=57171.1, bsz=1466.3, num_updates=135700, lr=0.000171688, gnorm=0.262, clip=100, loss_scale=16, train_wall=105, wall=149380
2023-05-27 11:51:35 | INFO | train_inner | epoch 021:   2299 / 6686 loss=4.152, nll_loss=2.529, ppl=5.77, wps=52649.4, ups=0.92, wpb=57200.2, bsz=1480.6, num_updates=135800, lr=0.000171625, gnorm=0.261, clip=100, loss_scale=16, train_wall=105, wall=149489
2023-05-27 11:52:33 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 11:53:25 | INFO | train_inner | epoch 021:   2400 / 6686 loss=4.148, nll_loss=2.526, ppl=5.76, wps=52025.5, ups=0.91, wpb=57125.5, bsz=1492.3, num_updates=135900, lr=0.000171562, gnorm=0.261, clip=100, loss_scale=22, train_wall=106, wall=149599
2023-05-27 11:55:13 | INFO | train_inner | epoch 021:   2500 / 6686 loss=4.159, nll_loss=2.538, ppl=5.81, wps=52560.4, ups=0.92, wpb=57195.7, bsz=1468.5, num_updates=136000, lr=0.000171499, gnorm=0.258, clip=100, loss_scale=16, train_wall=105, wall=149708
2023-05-27 11:57:03 | INFO | train_inner | epoch 021:   2600 / 6686 loss=4.144, nll_loss=2.521, ppl=5.74, wps=52468.1, ups=0.92, wpb=57276.1, bsz=1476, num_updates=136100, lr=0.000171436, gnorm=0.26, clip=100, loss_scale=16, train_wall=105, wall=149817
2023-05-27 11:58:52 | INFO | train_inner | epoch 021:   2700 / 6686 loss=4.15, nll_loss=2.527, ppl=5.77, wps=52680.8, ups=0.92, wpb=57361.1, bsz=1484.7, num_updates=136200, lr=0.000171373, gnorm=0.263, clip=100, loss_scale=16, train_wall=105, wall=149926
2023-05-27 12:00:40 | INFO | train_inner | epoch 021:   2800 / 6686 loss=4.161, nll_loss=2.54, ppl=5.82, wps=52549.7, ups=0.92, wpb=57065.7, bsz=1455.2, num_updates=136300, lr=0.00017131, gnorm=0.258, clip=100, loss_scale=16, train_wall=105, wall=150034
2023-05-27 12:02:29 | INFO | train_inner | epoch 021:   2900 / 6686 loss=4.133, nll_loss=2.509, ppl=5.69, wps=52531.4, ups=0.92, wpb=56989.2, bsz=1484.4, num_updates=136400, lr=0.000171247, gnorm=0.257, clip=100, loss_scale=22, train_wall=105, wall=150143
2023-05-27 12:04:18 | INFO | train_inner | epoch 021:   3000 / 6686 loss=4.15, nll_loss=2.527, ppl=5.76, wps=52331, ups=0.92, wpb=57149.3, bsz=1457.9, num_updates=136500, lr=0.000171184, gnorm=0.256, clip=100, loss_scale=32, train_wall=106, wall=150252
2023-05-27 12:06:07 | INFO | train_inner | epoch 021:   3100 / 6686 loss=4.161, nll_loss=2.54, ppl=5.82, wps=52414.1, ups=0.92, wpb=57173.6, bsz=1463, num_updates=136600, lr=0.000171122, gnorm=0.261, clip=100, loss_scale=32, train_wall=105, wall=150361
2023-05-27 12:07:55 | INFO | train_inner | epoch 021:   3200 / 6686 loss=4.15, nll_loss=2.527, ppl=5.77, wps=52617.6, ups=0.92, wpb=56989, bsz=1477.3, num_updates=136700, lr=0.000171059, gnorm=0.264, clip=100, loss_scale=32, train_wall=104, wall=150469
2023-05-27 12:09:44 | INFO | train_inner | epoch 021:   3300 / 6686 loss=4.167, nll_loss=2.547, ppl=5.84, wps=52522.5, ups=0.92, wpb=57108.8, bsz=1439.8, num_updates=136800, lr=0.000170996, gnorm=0.263, clip=100, loss_scale=32, train_wall=105, wall=150578
2023-05-27 12:10:48 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 12:11:34 | INFO | train_inner | epoch 021:   3401 / 6686 loss=4.159, nll_loss=2.538, ppl=5.81, wps=52178.4, ups=0.91, wpb=57215.9, bsz=1472, num_updates=136900, lr=0.000170934, gnorm=0.26, clip=100, loss_scale=25, train_wall=106, wall=150688
2023-05-27 12:13:23 | INFO | train_inner | epoch 021:   3501 / 6686 loss=4.158, nll_loss=2.537, ppl=5.8, wps=52599.8, ups=0.92, wpb=57316.7, bsz=1479.4, num_updates=137000, lr=0.000170872, gnorm=0.258, clip=100, loss_scale=16, train_wall=105, wall=150797
2023-05-27 12:15:11 | INFO | train_inner | epoch 021:   3601 / 6686 loss=4.154, nll_loss=2.532, ppl=5.78, wps=52699.3, ups=0.92, wpb=57226, bsz=1475.6, num_updates=137100, lr=0.000170809, gnorm=0.261, clip=100, loss_scale=16, train_wall=105, wall=150905
2023-05-27 12:17:00 | INFO | train_inner | epoch 021:   3701 / 6686 loss=4.151, nll_loss=2.529, ppl=5.77, wps=52569.6, ups=0.92, wpb=57195.2, bsz=1481.4, num_updates=137200, lr=0.000170747, gnorm=0.262, clip=100, loss_scale=16, train_wall=105, wall=151014
2023-05-27 12:18:48 | INFO | train_inner | epoch 021:   3801 / 6686 loss=4.161, nll_loss=2.541, ppl=5.82, wps=52621.5, ups=0.92, wpb=57078.2, bsz=1456.2, num_updates=137300, lr=0.000170685, gnorm=0.26, clip=100, loss_scale=16, train_wall=105, wall=151123
2023-05-27 12:20:37 | INFO | train_inner | epoch 021:   3901 / 6686 loss=4.16, nll_loss=2.539, ppl=5.81, wps=52637, ups=0.92, wpb=57312, bsz=1475.5, num_updates=137400, lr=0.000170623, gnorm=0.261, clip=100, loss_scale=21, train_wall=105, wall=151231
2023-05-27 12:22:26 | INFO | train_inner | epoch 021:   4001 / 6686 loss=4.166, nll_loss=2.546, ppl=5.84, wps=52511.3, ups=0.92, wpb=57207.6, bsz=1473.8, num_updates=137500, lr=0.000170561, gnorm=0.262, clip=100, loss_scale=32, train_wall=105, wall=151340
2023-05-27 12:24:16 | INFO | train_inner | epoch 021:   4101 / 6686 loss=4.155, nll_loss=2.534, ppl=5.79, wps=52433.1, ups=0.92, wpb=57296.2, bsz=1465.8, num_updates=137600, lr=0.000170499, gnorm=0.261, clip=100, loss_scale=32, train_wall=106, wall=151450
2023-05-27 12:26:04 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 12:26:06 | INFO | train_inner | epoch 021:   4202 / 6686 loss=4.167, nll_loss=2.547, ppl=5.84, wps=51930.4, ups=0.91, wpb=57110.2, bsz=1457.5, num_updates=137700, lr=0.000170437, gnorm=0.261, clip=100, loss_scale=32, train_wall=106, wall=151560
2023-05-27 12:27:54 | INFO | train_inner | epoch 021:   4302 / 6686 loss=4.157, nll_loss=2.536, ppl=5.8, wps=52763.9, ups=0.92, wpb=57157.2, bsz=1464.2, num_updates=137800, lr=0.000170375, gnorm=0.258, clip=100, loss_scale=16, train_wall=105, wall=151668
2023-05-27 12:29:43 | INFO | train_inner | epoch 021:   4402 / 6686 loss=4.165, nll_loss=2.544, ppl=5.83, wps=52400.9, ups=0.92, wpb=57050.3, bsz=1457, num_updates=137900, lr=0.000170313, gnorm=0.262, clip=100, loss_scale=16, train_wall=105, wall=151777
2023-05-27 12:31:31 | INFO | train_inner | epoch 021:   4502 / 6686 loss=4.153, nll_loss=2.531, ppl=5.78, wps=52637.4, ups=0.92, wpb=57234.3, bsz=1485.5, num_updates=138000, lr=0.000170251, gnorm=0.26, clip=100, loss_scale=16, train_wall=105, wall=151886
2023-05-27 12:33:20 | INFO | train_inner | epoch 021:   4602 / 6686 loss=4.144, nll_loss=2.521, ppl=5.74, wps=52619.9, ups=0.92, wpb=57249.5, bsz=1487.1, num_updates=138100, lr=0.00017019, gnorm=0.259, clip=100, loss_scale=16, train_wall=105, wall=151994
2023-05-27 12:35:09 | INFO | train_inner | epoch 021:   4702 / 6686 loss=4.144, nll_loss=2.522, ppl=5.74, wps=52619.6, ups=0.92, wpb=57398.8, bsz=1484.1, num_updates=138200, lr=0.000170128, gnorm=0.26, clip=100, loss_scale=16, train_wall=105, wall=152104
2023-05-27 12:36:58 | INFO | train_inner | epoch 021:   4802 / 6686 loss=4.157, nll_loss=2.536, ppl=5.8, wps=52542.5, ups=0.92, wpb=57316.8, bsz=1473.3, num_updates=138300, lr=0.000170067, gnorm=0.259, clip=100, loss_scale=30, train_wall=105, wall=152213
2023-05-27 12:38:47 | INFO | train_inner | epoch 021:   4902 / 6686 loss=4.159, nll_loss=2.538, ppl=5.81, wps=52486.4, ups=0.92, wpb=57033.9, bsz=1492.2, num_updates=138400, lr=0.000170005, gnorm=0.264, clip=100, loss_scale=32, train_wall=105, wall=152321
2023-05-27 12:40:36 | INFO | train_inner | epoch 021:   5002 / 6686 loss=4.154, nll_loss=2.532, ppl=5.78, wps=52614.2, ups=0.92, wpb=57084.8, bsz=1495, num_updates=138500, lr=0.000169944, gnorm=0.26, clip=100, loss_scale=32, train_wall=105, wall=152430
2023-05-27 12:42:24 | INFO | train_inner | epoch 021:   5102 / 6686 loss=4.169, nll_loss=2.549, ppl=5.85, wps=52739.4, ups=0.92, wpb=57231.8, bsz=1463, num_updates=138600, lr=0.000169882, gnorm=0.262, clip=100, loss_scale=32, train_wall=105, wall=152538
2023-05-27 12:44:14 | INFO | train_inner | epoch 021:   5202 / 6686 loss=4.156, nll_loss=2.535, ppl=5.79, wps=52386.8, ups=0.91, wpb=57350.5, bsz=1510.7, num_updates=138700, lr=0.000169821, gnorm=0.261, clip=100, loss_scale=32, train_wall=105, wall=152648
2023-05-27 12:45:16 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 12:46:04 | INFO | train_inner | epoch 021:   5303 / 6686 loss=4.142, nll_loss=2.519, ppl=5.73, wps=51864.6, ups=0.91, wpb=57169.9, bsz=1503.7, num_updates=138800, lr=0.00016976, gnorm=0.259, clip=100, loss_scale=43, train_wall=106, wall=152758
2023-05-27 12:47:53 | INFO | train_inner | epoch 021:   5403 / 6686 loss=4.15, nll_loss=2.528, ppl=5.77, wps=52770.1, ups=0.92, wpb=57391.7, bsz=1475.7, num_updates=138900, lr=0.000169699, gnorm=0.258, clip=100, loss_scale=32, train_wall=105, wall=152867
2023-05-27 12:49:41 | INFO | train_inner | epoch 021:   5503 / 6686 loss=4.17, nll_loss=2.551, ppl=5.86, wps=52583.7, ups=0.92, wpb=56974.4, bsz=1469.8, num_updates=139000, lr=0.000169638, gnorm=0.266, clip=100, loss_scale=32, train_wall=105, wall=152975
2023-05-27 12:51:30 | INFO | train_inner | epoch 021:   5603 / 6686 loss=4.158, nll_loss=2.536, ppl=5.8, wps=52558, ups=0.92, wpb=57130.1, bsz=1481.9, num_updates=139100, lr=0.000169577, gnorm=0.26, clip=100, loss_scale=32, train_wall=105, wall=153084
2023-05-27 12:51:45 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 12:53:20 | INFO | train_inner | epoch 021:   5704 / 6686 loss=4.141, nll_loss=2.518, ppl=5.73, wps=52024, ups=0.91, wpb=57169.9, bsz=1491.3, num_updates=139200, lr=0.000169516, gnorm=0.259, clip=100, loss_scale=18, train_wall=106, wall=153194
2023-05-27 12:55:09 | INFO | train_inner | epoch 021:   5804 / 6686 loss=4.156, nll_loss=2.534, ppl=5.79, wps=52513.2, ups=0.92, wpb=57223.6, bsz=1495.7, num_updates=139300, lr=0.000169455, gnorm=0.263, clip=100, loss_scale=16, train_wall=105, wall=153303
2023-05-27 12:56:57 | INFO | train_inner | epoch 021:   5904 / 6686 loss=4.146, nll_loss=2.524, ppl=5.75, wps=52581.8, ups=0.92, wpb=57265.9, bsz=1477, num_updates=139400, lr=0.000169394, gnorm=0.258, clip=100, loss_scale=16, train_wall=105, wall=153412
2023-05-27 12:58:46 | INFO | train_inner | epoch 021:   6004 / 6686 loss=4.158, nll_loss=2.537, ppl=5.8, wps=52729.5, ups=0.92, wpb=57316.2, bsz=1489.1, num_updates=139500, lr=0.000169334, gnorm=0.259, clip=100, loss_scale=16, train_wall=105, wall=153520
2023-05-27 13:00:35 | INFO | train_inner | epoch 021:   6104 / 6686 loss=4.154, nll_loss=2.533, ppl=5.79, wps=52740.9, ups=0.92, wpb=57175.5, bsz=1477.7, num_updates=139600, lr=0.000169273, gnorm=0.26, clip=100, loss_scale=16, train_wall=105, wall=153629
2023-05-27 13:01:11 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 13:02:24 | INFO | train_inner | epoch 021:   6205 / 6686 loss=4.159, nll_loss=2.538, ppl=5.81, wps=52233.8, ups=0.91, wpb=57176.6, bsz=1480.7, num_updates=139700, lr=0.000169212, gnorm=0.262, clip=100, loss_scale=17, train_wall=106, wall=153738
2023-05-27 13:04:13 | INFO | train_inner | epoch 021:   6305 / 6686 loss=4.147, nll_loss=2.524, ppl=5.75, wps=52664.4, ups=0.92, wpb=57235.8, bsz=1492.9, num_updates=139800, lr=0.000169152, gnorm=0.262, clip=100, loss_scale=16, train_wall=105, wall=153847
2023-05-27 13:06:01 | INFO | train_inner | epoch 021:   6405 / 6686 loss=4.152, nll_loss=2.53, ppl=5.78, wps=52591.5, ups=0.92, wpb=57178, bsz=1491.8, num_updates=139900, lr=0.000169091, gnorm=0.257, clip=100, loss_scale=16, train_wall=105, wall=153956
2023-05-27 13:07:50 | INFO | train_inner | epoch 021:   6505 / 6686 loss=4.166, nll_loss=2.546, ppl=5.84, wps=52739.3, ups=0.92, wpb=57344.5, bsz=1507.1, num_updates=140000, lr=0.000169031, gnorm=0.263, clip=100, loss_scale=16, train_wall=105, wall=154064
2023-05-27 13:09:39 | INFO | train_inner | epoch 021:   6605 / 6686 loss=4.141, nll_loss=2.518, ppl=5.73, wps=52699.2, ups=0.92, wpb=57182.4, bsz=1483.1, num_updates=140100, lr=0.000168971, gnorm=0.26, clip=100, loss_scale=16, train_wall=105, wall=154173
2023-05-27 13:11:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-27 13:11:13 | INFO | fairseq.tasks.translation | example hypothesis: Why was that?
2023-05-27 13:11:13 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-27 13:11:13 | INFO | fairseq.tasks.translation | example hypothesis: I’ll make you lose so much that you don’t even have pants left!
2023-05-27 13:11:13 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-27 13:11:14 | INFO | fairseq.tasks.translation | example hypothesis: Just as Shen Liangchuan heaved a sigh of relief, he heard her say, “I’ll call for you to stay in the same room!”
2023-05-27 13:11:14 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-27 13:11:14 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved her hand and entered the elevator.
2023-05-27 13:11:14 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-27 13:11:15 | INFO | fairseq.tasks.translation | example hypothesis: She raised her head and saw Song Cheng standing in the distance!
2023-05-27 13:11:15 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-27 13:11:16 | INFO | fairseq.tasks.translation | example hypothesis: Song Cheng patted his chest. “You scared me to death! Where’s Wang Chuan?”
2023-05-27 13:11:16 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-27 13:11:17 | INFO | fairseq.tasks.translation | example hypothesis: “No, I can’t eat it,” I said.
2023-05-27 13:11:17 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-27 13:11:17 | INFO | fairseq.tasks.translation | example hypothesis: At first, everyone didn’t believe him, but Wang Wenhao insisted that he would make the public opinion lean towards him.
2023-05-27 13:11:17 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-27 13:11:18 | INFO | fairseq.tasks.translation | example hypothesis: Coming here like this with his identity, Baili Hongzhuang had to be treated even if she did not want to!
2023-05-27 13:11:18 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-27 13:11:19 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian: “Mr. Shen, I, I’ve kept too much blood and my brain is short of oxygen. I can’t think of anything. Why don’t you give me a hint?”
2023-05-27 13:11:19 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-27 13:11:20 | INFO | fairseq.tasks.translation | example hypothesis: He didn’t know why so many people heard about it. Since he couldn’t hide it anymore, he might as well tell them.
2023-05-27 13:11:20 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-27 13:11:21 | INFO | fairseq.tasks.translation | example hypothesis: She deliberately lowered her voice, but it could not hide the viciousness and ruthlessness in her tone.
2023-05-27 13:11:21 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-27 13:11:22 | INFO | fairseq.tasks.translation | example hypothesis: Beast pets of different levels were different in strength, but beast pets were precious and rare. It was impossible for ordinary people to possess them, and even the descendants of officials were unable to possess them.
2023-05-27 13:11:22 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-27 13:11:23 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chixia clenched her teeth and cursed in a low voice.
2023-05-27 13:11:23 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-27 13:11:24 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang concealed it very well, Di Beichen could still see a flash of warmth in her eyes.
2023-05-27 13:11:24 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-27 13:11:25 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia walked in, not to mention the guests, not even a few waiters could be seen.
2023-05-27 13:11:25 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-27 13:11:26 | INFO | fairseq.tasks.translation | example hypothesis: This person was the fourth young miss of the Ye Family, Ye Qing Ling.
2023-05-27 13:11:26 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-27 13:11:27 | INFO | fairseq.tasks.translation | example hypothesis: Because at this moment, she felt as if her chin was about to break.
2023-05-27 13:11:27 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-27 13:11:29 | INFO | fairseq.tasks.translation | example hypothesis: “Good Mu Zi, help me. If it wasn't for you, that old man wouldn't have set his eyes on me.”
2023-05-27 13:11:29 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-27 13:11:30 | INFO | fairseq.tasks.translation | example hypothesis: Baili Yuyan was even more excited. She was the one in charge of this matter. She had treated Baili Hongzhuang like that before. This time, she would definitely make Baili Hongzhuang suffer.
2023-05-27 13:11:30 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-27 13:11:31 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How could that be? They’re also four mages, of course they won’t surrender so easily. After arguing for a long time, they finally decided on how to obtain control of the Kingdom of Alluring Summer through the competition.”
2023-05-27 13:11:31 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-27 13:11:32 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a bit. He had always been looking for a reason for Li Yuyue to not participate in the Imperial Family Hunting Competition.
2023-05-27 13:11:32 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-27 13:11:33 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my standard good enough? They’re all the most outstanding talents in the country, how can my magic be so weak?”
2023-05-27 13:11:33 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-27 13:11:35 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yibei’s words meant that if Fang Chixia didn’t want to go, then there was no need to go.
2023-05-27 13:11:35 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-27 13:11:37 | INFO | fairseq.tasks.translation | example hypothesis: Turning her head to the side, she saw that the five palm prints on her cheeks were very eye-catching. It was visible to the naked eye that they were swollen. Reaching out to touch them, she could not help but let out a hiss.
2023-05-27 13:11:37 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-27 13:11:38 | INFO | fairseq.tasks.translation | example hypothesis: This......how could this be the charm that that trash could emit?
2023-05-27 13:11:38 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-27 13:11:39 | INFO | fairseq.tasks.translation | example hypothesis: How could Wang Wenhao have found the news agency? The chief editor should have called her to tell her not to come to the news agency. However, these three people... had plotted against her!
2023-05-27 13:11:39 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-27 13:11:42 | INFO | fairseq.tasks.translation | example hypothesis: Hearing Teacher Di’s praise, I was delighted. I withdrew the energy ball with my left hand, and a beam of light shot out from my right hand towards Teacher Zhen. The beam of light was actually able to land on me smoothly. I was startled, and upon closer inspection, I realized that it was just an afterimage. Teacher Zhen had already moved to my back, and shouted,
2023-05-27 13:11:42 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-27 13:11:45 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Originally, our side proposed a two out of three competition, but they said that it’s unfair, because we have Teacher Di and Teacher Zhen, who are ranked higher than them, and they proposed five out of five wins. Since we proposed the competition, we can only listen to them in the end. Three days later, we will compete in secret in the Royal Colosseum, and the competition will be held in the Royal Colosseum.”
2023-05-27 13:11:45 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-27 13:11:47 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Di used the seventh grade light element spell, Light Thunder Burst. I didn’t use much of this spell, because my control over it was not ideal. Teacher Di released nine Light Thunder Bursts to surround me, forming a simple spell formation, preventing me from escaping in a short distance. Then, the various Light Thunder Bursts exploded one after another, forming a powerful attack power.
2023-05-27 13:11:47 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-27 13:11:50 | INFO | fairseq.tasks.translation | example hypothesis: As soon as Mark and the two teachers walked to the other side of the courtyard, Teacher Zhen shot a small Dimensional Slash at me. As expected of the continent’s number one Magician. The suction force of the small Dimensional Slash was actually much stronger than the one I sent out. A small spatial crack appeared beside me, and a powerful suction force immediately swept towards me.
2023-05-27 13:11:50 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-27 13:11:50 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 4.151 | nll_loss 2.508 | ppl 5.69 | bleu 21.87 | wps 1939.6 | wpb 2420.8 | bsz 84.5 | num_updates 140181 | best_bleu 21.92
2023-05-27 13:11:50 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-27 13:11:54 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/concat-1-1-0.2-sf[zh-en]/checkpoint21.pt (epoch 21 @ 140181 updates, score 21.87) (writing took 3.8298751953989267 seconds)
2023-05-27 13:11:54 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-05-27 13:11:54 | INFO | train | epoch 021 | loss 4.153 | nll_loss 2.53 | ppl 5.78 | wps 51960.6 | ups 0.91 | wpb 57190.2 | bsz 1477.5 | num_updates 140181 | lr 0.000168922 | gnorm 0.26 | clip 100 | loss_scale 24 | train_wall 7026 | wall 154308
2023-05-27 13:11:54 | INFO | fairseq.trainer | begin training epoch 22
2023-05-27 13:12:33 | INFO | train_inner | epoch 022:     19 / 6686 loss=4.162, nll_loss=2.541, ppl=5.82, wps=32623.2, ups=0.57, wpb=56882.3, bsz=1441.8, num_updates=140200, lr=0.00016891, gnorm=0.264, clip=100, loss_scale=25, train_wall=106, wall=154347
2023-05-27 13:14:34 | INFO | train_inner | epoch 022:    119 / 6686 loss=4.122, nll_loss=2.495, ppl=5.64, wps=47418, ups=0.83, wpb=57234.3, bsz=1479.4, num_updates=140300, lr=0.00016885, gnorm=0.258, clip=100, loss_scale=32, train_wall=108, wall=154468
2023-05-27 13:16:29 | INFO | train_inner | epoch 022:    219 / 6686 loss=4.134, nll_loss=2.509, ppl=5.69, wps=49463.3, ups=0.87, wpb=57098.5, bsz=1465.2, num_updates=140400, lr=0.00016879, gnorm=0.26, clip=100, loss_scale=32, train_wall=107, wall=154583
2023-05-27 13:17:53 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 13:18:20 | INFO | train_inner | epoch 022:    320 / 6686 loss=4.139, nll_loss=2.515, ppl=5.72, wps=51573.4, ups=0.9, wpb=57294.3, bsz=1501.6, num_updates=140500, lr=0.00016873, gnorm=0.26, clip=100, loss_scale=28, train_wall=107, wall=154694
2023-05-27 13:20:10 | INFO | train_inner | epoch 022:    420 / 6686 loss=4.134, nll_loss=2.509, ppl=5.69, wps=52449.8, ups=0.92, wpb=57258.2, bsz=1483.6, num_updates=140600, lr=0.00016867, gnorm=0.258, clip=100, loss_scale=16, train_wall=105, wall=154804
2023-05-27 13:21:59 | INFO | train_inner | epoch 022:    520 / 6686 loss=4.148, nll_loss=2.525, ppl=5.75, wps=52392.1, ups=0.92, wpb=57120.3, bsz=1455.8, num_updates=140700, lr=0.00016861, gnorm=0.26, clip=100, loss_scale=16, train_wall=105, wall=154913
2023-05-27 13:23:47 | INFO | train_inner | epoch 022:    620 / 6686 loss=4.141, nll_loss=2.517, ppl=5.72, wps=52545.2, ups=0.92, wpb=57200.3, bsz=1472.7, num_updates=140800, lr=0.00016855, gnorm=0.262, clip=100, loss_scale=16, train_wall=105, wall=155022
2023-05-27 13:25:36 | INFO | train_inner | epoch 022:    720 / 6686 loss=4.144, nll_loss=2.521, ppl=5.74, wps=52532.6, ups=0.92, wpb=57203, bsz=1466.2, num_updates=140900, lr=0.00016849, gnorm=0.26, clip=100, loss_scale=16, train_wall=105, wall=155130
2023-05-27 13:27:25 | INFO | train_inner | epoch 022:    820 / 6686 loss=4.138, nll_loss=2.514, ppl=5.71, wps=52803.6, ups=0.92, wpb=57376.1, bsz=1485.8, num_updates=141000, lr=0.00016843, gnorm=0.26, clip=100, loss_scale=18, train_wall=105, wall=155239
2023-05-27 13:29:13 | INFO | train_inner | epoch 022:    920 / 6686 loss=4.136, nll_loss=2.512, ppl=5.7, wps=52649.3, ups=0.92, wpb=57077.5, bsz=1473.4, num_updates=141100, lr=0.000168371, gnorm=0.259, clip=100, loss_scale=32, train_wall=105, wall=155348
2023-05-27 13:31:02 | INFO | train_inner | epoch 022:   1020 / 6686 loss=4.137, nll_loss=2.513, ppl=5.71, wps=52650, ups=0.92, wpb=57251.1, bsz=1511.7, num_updates=141200, lr=0.000168311, gnorm=0.264, clip=100, loss_scale=32, train_wall=105, wall=155456
2023-05-27 13:32:51 | INFO | train_inner | epoch 022:   1120 / 6686 loss=4.133, nll_loss=2.508, ppl=5.69, wps=52675.1, ups=0.92, wpb=57293.1, bsz=1480.9, num_updates=141300, lr=0.000168251, gnorm=0.263, clip=100, loss_scale=32, train_wall=105, wall=155565
2023-05-27 13:34:40 | INFO | train_inner | epoch 022:   1220 / 6686 loss=4.144, nll_loss=2.521, ppl=5.74, wps=52381.2, ups=0.91, wpb=57340.9, bsz=1453, num_updates=141400, lr=0.000168192, gnorm=0.261, clip=100, loss_scale=32, train_wall=105, wall=155674
2023-05-27 13:36:29 | INFO | train_inner | epoch 022:   1320 / 6686 loss=4.142, nll_loss=2.518, ppl=5.73, wps=52450.5, ups=0.92, wpb=56967.4, bsz=1479.5, num_updates=141500, lr=0.000168133, gnorm=0.262, clip=100, loss_scale=33, train_wall=105, wall=155783
2023-05-27 13:36:37 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 13:38:19 | INFO | train_inner | epoch 022:   1421 / 6686 loss=4.145, nll_loss=2.522, ppl=5.74, wps=52244.8, ups=0.91, wpb=57277.2, bsz=1500.4, num_updates=141600, lr=0.000168073, gnorm=0.261, clip=100, loss_scale=34, train_wall=106, wall=155893
2023-05-27 13:40:07 | INFO | train_inner | epoch 022:   1521 / 6686 loss=4.155, nll_loss=2.533, ppl=5.79, wps=52717.6, ups=0.92, wpb=57259.4, bsz=1488, num_updates=141700, lr=0.000168014, gnorm=0.26, clip=100, loss_scale=32, train_wall=105, wall=156001
2023-05-27 13:41:56 | INFO | train_inner | epoch 022:   1621 / 6686 loss=4.14, nll_loss=2.516, ppl=5.72, wps=52668.8, ups=0.92, wpb=57249.3, bsz=1465.4, num_updates=141800, lr=0.000167955, gnorm=0.262, clip=100, loss_scale=32, train_wall=105, wall=156110
2023-05-27 13:43:45 | INFO | train_inner | epoch 022:   1721 / 6686 loss=4.147, nll_loss=2.524, ppl=5.75, wps=52520.6, ups=0.92, wpb=57070.6, bsz=1469.4, num_updates=141900, lr=0.000167895, gnorm=0.266, clip=100, loss_scale=32, train_wall=105, wall=156219
2023-05-27 13:45:33 | INFO | train_inner | epoch 022:   1821 / 6686 loss=4.152, nll_loss=2.53, ppl=5.77, wps=52744.6, ups=0.92, wpb=57284.1, bsz=1482.4, num_updates=142000, lr=0.000167836, gnorm=0.259, clip=100, loss_scale=32, train_wall=105, wall=156327
2023-05-27 13:46:00 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 13:47:23 | INFO | train_inner | epoch 022:   1922 / 6686 loss=4.146, nll_loss=2.523, ppl=5.75, wps=52162.1, ups=0.91, wpb=57304.8, bsz=1479.8, num_updates=142100, lr=0.000167777, gnorm=0.261, clip=100, loss_scale=34, train_wall=106, wall=156437
2023-05-27 13:49:12 | INFO | train_inner | epoch 022:   2022 / 6686 loss=4.147, nll_loss=2.525, ppl=5.75, wps=52571.8, ups=0.92, wpb=57236.5, bsz=1463.8, num_updates=142200, lr=0.000167718, gnorm=0.26, clip=100, loss_scale=32, train_wall=105, wall=156546
2023-05-27 13:51:00 | INFO | train_inner | epoch 022:   2122 / 6686 loss=4.152, nll_loss=2.53, ppl=5.78, wps=52573.9, ups=0.92, wpb=57002.2, bsz=1469, num_updates=142300, lr=0.000167659, gnorm=0.26, clip=100, loss_scale=32, train_wall=105, wall=156654
2023-05-27 13:52:48 | INFO | train_inner | epoch 022:   2222 / 6686 loss=4.155, nll_loss=2.534, ppl=5.79, wps=52766.6, ups=0.92, wpb=57045.5, bsz=1478.4, num_updates=142400, lr=0.0001676, gnorm=0.261, clip=100, loss_scale=32, train_wall=104, wall=156763
2023-05-27 13:54:37 | INFO | train_inner | epoch 022:   2322 / 6686 loss=4.143, nll_loss=2.52, ppl=5.74, wps=52656.7, ups=0.92, wpb=57317.8, bsz=1485, num_updates=142500, lr=0.000167542, gnorm=0.259, clip=100, loss_scale=32, train_wall=105, wall=156871
2023-05-27 13:55:37 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 13:56:27 | INFO | train_inner | epoch 022:   2423 / 6686 loss=4.142, nll_loss=2.518, ppl=5.73, wps=52122, ups=0.91, wpb=57233.1, bsz=1466.2, num_updates=142600, lr=0.000167483, gnorm=0.26, clip=100, loss_scale=38, train_wall=106, wall=156981
2023-05-27 13:58:16 | INFO | train_inner | epoch 022:   2523 / 6686 loss=4.152, nll_loss=2.529, ppl=5.77, wps=52591.6, ups=0.92, wpb=57149.4, bsz=1461.7, num_updates=142700, lr=0.000167424, gnorm=0.261, clip=100, loss_scale=32, train_wall=105, wall=157090
2023-05-27 14:00:05 | INFO | train_inner | epoch 022:   2623 / 6686 loss=4.137, nll_loss=2.513, ppl=5.71, wps=52474.1, ups=0.92, wpb=57133.3, bsz=1501.1, num_updates=142800, lr=0.000167365, gnorm=0.261, clip=100, loss_scale=32, train_wall=105, wall=157199
2023-05-27 14:01:53 | INFO | train_inner | epoch 022:   2723 / 6686 loss=4.148, nll_loss=2.525, ppl=5.76, wps=52762.1, ups=0.92, wpb=57312, bsz=1474.8, num_updates=142900, lr=0.000167307, gnorm=0.26, clip=100, loss_scale=32, train_wall=105, wall=157307
2023-05-27 14:03:42 | INFO | train_inner | epoch 022:   2823 / 6686 loss=4.142, nll_loss=2.519, ppl=5.73, wps=52574.7, ups=0.92, wpb=57258.1, bsz=1508.4, num_updates=143000, lr=0.000167248, gnorm=0.263, clip=100, loss_scale=32, train_wall=105, wall=157416
2023-05-27 14:05:13 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 14:05:32 | INFO | train_inner | epoch 022:   2924 / 6686 loss=4.15, nll_loss=2.528, ppl=5.77, wps=52069.5, ups=0.91, wpb=57125.5, bsz=1485.1, num_updates=143100, lr=0.00016719, gnorm=0.261, clip=100, loss_scale=38, train_wall=106, wall=157526
2023-05-27 14:05:36 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 14:07:22 | INFO | train_inner | epoch 022:   3025 / 6686 loss=4.15, nll_loss=2.527, ppl=5.77, wps=52310, ups=0.91, wpb=57392.8, bsz=1471.8, num_updates=143200, lr=0.000167132, gnorm=0.26, clip=100, loss_scale=16, train_wall=106, wall=157636
2023-05-27 14:09:10 | INFO | train_inner | epoch 022:   3125 / 6686 loss=4.14, nll_loss=2.516, ppl=5.72, wps=52609.1, ups=0.92, wpb=57095.5, bsz=1476.8, num_updates=143300, lr=0.000167073, gnorm=0.262, clip=100, loss_scale=16, train_wall=105, wall=157744
2023-05-27 14:10:59 | INFO | train_inner | epoch 022:   3225 / 6686 loss=4.159, nll_loss=2.537, ppl=5.81, wps=52619.5, ups=0.92, wpb=57200.6, bsz=1457.8, num_updates=143400, lr=0.000167015, gnorm=0.263, clip=100, loss_scale=16, train_wall=105, wall=157853
2023-05-27 14:12:47 | INFO | train_inner | epoch 022:   3325 / 6686 loss=4.147, nll_loss=2.524, ppl=5.75, wps=52774.7, ups=0.93, wpb=57049.5, bsz=1484.2, num_updates=143500, lr=0.000166957, gnorm=0.269, clip=100, loss_scale=16, train_wall=104, wall=157961
2023-05-27 14:14:36 | INFO | train_inner | epoch 022:   3425 / 6686 loss=4.152, nll_loss=2.529, ppl=5.77, wps=52664.5, ups=0.92, wpb=57294.6, bsz=1454.5, num_updates=143600, lr=0.000166899, gnorm=0.26, clip=100, loss_scale=16, train_wall=105, wall=158070
2023-05-27 14:16:25 | INFO | train_inner | epoch 022:   3525 / 6686 loss=4.147, nll_loss=2.524, ppl=5.75, wps=52541.5, ups=0.92, wpb=57174.2, bsz=1503.6, num_updates=143700, lr=0.000166841, gnorm=0.26, clip=100, loss_scale=30, train_wall=105, wall=158179
2023-05-27 14:18:13 | INFO | train_inner | epoch 022:   3625 / 6686 loss=4.145, nll_loss=2.522, ppl=5.75, wps=52698.1, ups=0.92, wpb=57185.1, bsz=1468.8, num_updates=143800, lr=0.000166783, gnorm=0.262, clip=100, loss_scale=32, train_wall=105, wall=158287
2023-05-27 14:20:01 | INFO | train_inner | epoch 022:   3725 / 6686 loss=4.147, nll_loss=2.525, ppl=5.76, wps=52891.9, ups=0.92, wpb=57208.7, bsz=1488.6, num_updates=143900, lr=0.000166725, gnorm=0.26, clip=100, loss_scale=32, train_wall=104, wall=158395
2023-05-27 14:21:50 | INFO | train_inner | epoch 022:   3825 / 6686 loss=4.157, nll_loss=2.535, ppl=5.8, wps=52708.1, ups=0.92, wpb=57128.5, bsz=1451.4, num_updates=144000, lr=0.000166667, gnorm=0.261, clip=100, loss_scale=32, train_wall=105, wall=158504
2023-05-27 14:23:38 | INFO | train_inner | epoch 022:   3925 / 6686 loss=4.149, nll_loss=2.527, ppl=5.76, wps=52698.9, ups=0.92, wpb=57304.7, bsz=1483.1, num_updates=144100, lr=0.000166609, gnorm=0.263, clip=100, loss_scale=32, train_wall=105, wall=158613
2023-05-27 14:24:11 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 14:25:28 | INFO | train_inner | epoch 022:   4026 / 6686 loss=4.149, nll_loss=2.526, ppl=5.76, wps=52031.4, ups=0.91, wpb=57141, bsz=1455.1, num_updates=144200, lr=0.000166551, gnorm=0.263, clip=100, loss_scale=33, train_wall=106, wall=158722
2023-05-27 14:26:21 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 14:27:18 | INFO | train_inner | epoch 022:   4127 / 6686 loss=4.146, nll_loss=2.524, ppl=5.75, wps=51989.3, ups=0.91, wpb=57276.5, bsz=1505.8, num_updates=144300, lr=0.000166493, gnorm=0.265, clip=100, loss_scale=23, train_wall=106, wall=158833
2023-05-27 14:29:07 | INFO | train_inner | epoch 022:   4227 / 6686 loss=4.147, nll_loss=2.524, ppl=5.75, wps=52627, ups=0.92, wpb=57123.6, bsz=1497.4, num_updates=144400, lr=0.000166436, gnorm=0.26, clip=100, loss_scale=16, train_wall=105, wall=158941
2023-05-27 14:30:55 | INFO | train_inner | epoch 022:   4327 / 6686 loss=4.167, nll_loss=2.547, ppl=5.84, wps=52508.7, ups=0.92, wpb=56971.6, bsz=1448.8, num_updates=144500, lr=0.000166378, gnorm=0.263, clip=100, loss_scale=16, train_wall=105, wall=159050
2023-05-27 14:31:42 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2023-05-27 14:32:45 | INFO | train_inner | epoch 022:   4428 / 6686 loss=4.159, nll_loss=2.538, ppl=5.81, wps=52198.5, ups=0.91, wpb=57287.6, bsz=1495.9, num_updates=144600, lr=0.000166321, gnorm=0.259, clip=100, loss_scale=11, train_wall=106, wall=159159
2023-05-27 14:34:34 | INFO | train_inner | epoch 022:   4528 / 6686 loss=4.149, nll_loss=2.526, ppl=5.76, wps=52431.6, ups=0.92, wpb=57176.8, bsz=1477.1, num_updates=144700, lr=0.000166263, gnorm=0.26, clip=100, loss_scale=8, train_wall=105, wall=159268
2023-05-27 14:36:24 | INFO | train_inner | epoch 022:   4628 / 6686 loss=4.154, nll_loss=2.533, ppl=5.79, wps=52246.3, ups=0.92, wpb=57076, bsz=1471.8, num_updates=144800, lr=0.000166206, gnorm=0.261, clip=100, loss_scale=8, train_wall=106, wall=159378
2023-05-27 14:38:12 | INFO | train_inner | epoch 022:   4728 / 6686 loss=4.157, nll_loss=2.535, ppl=5.8, wps=52607.6, ups=0.92, wpb=57215.7, bsz=1488.2, num_updates=144900, lr=0.000166148, gnorm=0.262, clip=100, loss_scale=8, train_wall=105, wall=159486
2023-05-27 14:40:01 | INFO | train_inner | epoch 022:   4828 / 6686 loss=4.157, nll_loss=2.536, ppl=5.8, wps=52728, ups=0.92, wpb=57207.7, bsz=1475.8, num_updates=145000, lr=0.000166091, gnorm=0.265, clip=100, loss_scale=8, train_wall=105, wall=159595
2023-05-27 14:41:49 | INFO | train_inner | epoch 022:   4928 / 6686 loss=4.151, nll_loss=2.529, ppl=5.77, wps=52535, ups=0.92, wpb=56940.2, bsz=1455.1, num_updates=145100, lr=0.000166034, gnorm=0.264, clip=100, loss_scale=12, train_wall=105, wall=159703
2023-05-27 14:43:38 | INFO | train_inner | epoch 022:   5028 / 6686 loss=4.152, nll_loss=2.53, ppl=5.77, wps=52428.4, ups=0.92, wpb=57294.6, bsz=1466.3, num_updates=145200, lr=0.000165977, gnorm=0.264, clip=100, loss_scale=16, train_wall=105, wall=159813
2023-05-27 14:45:27 | INFO | train_inner | epoch 022:   5128 / 6686 loss=4.147, nll_loss=2.525, ppl=5.75, wps=52655.5, ups=0.92, wpb=57120.4, bsz=1497, num_updates=145300, lr=0.000165919, gnorm=0.26, clip=100, loss_scale=16, train_wall=105, wall=159921
2023-05-27 14:47:16 | INFO | train_inner | epoch 022:   5228 / 6686 loss=4.158, nll_loss=2.537, ppl=5.8, wps=52424.8, ups=0.92, wpb=57114.8, bsz=1463.5, num_updates=145400, lr=0.000165862, gnorm=0.265, clip=100, loss_scale=16, train_wall=105, wall=160030
2023-05-27 14:49:04 | INFO | train_inner | epoch 022:   5328 / 6686 loss=4.151, nll_loss=2.529, ppl=5.77, wps=52791.2, ups=0.92, wpb=57207.1, bsz=1489.3, num_updates=145500, lr=0.000165805, gnorm=0.262, clip=100, loss_scale=16, train_wall=105, wall=160138
2023-05-27 14:50:53 | INFO | train_inner | epoch 022:   5428 / 6686 loss=4.147, nll_loss=2.525, ppl=5.75, wps=52527.1, ups=0.92, wpb=57255.3, bsz=1498.6, num_updates=145600, lr=0.000165748, gnorm=0.262, clip=100, loss_scale=22, train_wall=105, wall=160247
2023-05-27 14:52:42 | INFO | train_inner | epoch 022:   5528 / 6686 loss=4.153, nll_loss=2.532, ppl=5.78, wps=52659.2, ups=0.92, wpb=57272.9, bsz=1482.6, num_updates=145700, lr=0.000165691, gnorm=0.262, clip=100, loss_scale=32, train_wall=105, wall=160356
2023-05-27 14:54:31 | INFO | train_inner | epoch 022:   5628 / 6686 loss=4.155, nll_loss=2.533, ppl=5.79, wps=52711.2, ups=0.92, wpb=57175.3, bsz=1464.8, num_updates=145800, lr=0.000165635, gnorm=0.263, clip=100, loss_scale=32, train_wall=105, wall=160465
2023-05-27 14:56:20 | INFO | train_inner | epoch 022:   5728 / 6686 loss=4.15, nll_loss=2.528, ppl=5.77, wps=52523.1, ups=0.92, wpb=57356.2, bsz=1475.9, num_updates=145900, lr=0.000165578, gnorm=0.262, clip=100, loss_scale=32, train_wall=105, wall=160574
2023-05-27 14:58:08 | INFO | train_inner | epoch 022:   5828 / 6686 loss=4.157, nll_loss=2.537, ppl=5.8, wps=52666.5, ups=0.92, wpb=57187.6, bsz=1477.5, num_updates=146000, lr=0.000165521, gnorm=0.262, clip=100, loss_scale=32, train_wall=105, wall=160682
2023-05-27 14:59:57 | INFO | train_inner | epoch 022:   5928 / 6686 loss=4.153, nll_loss=2.532, ppl=5.78, wps=52811.7, ups=0.92, wpb=57328.4, bsz=1502.1, num_updates=146100, lr=0.000165465, gnorm=0.259, clip=100, loss_scale=39, train_wall=105, wall=160791
2023-05-27 15:00:48 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 15:01:46 | INFO | train_inner | epoch 022:   6029 / 6686 loss=4.158, nll_loss=2.537, ppl=5.8, wps=52188.9, ups=0.91, wpb=57171.9, bsz=1480.6, num_updates=146200, lr=0.000165408, gnorm=0.26, clip=100, loss_scale=47, train_wall=106, wall=160901
2023-05-27 15:03:35 | INFO | train_inner | epoch 022:   6129 / 6686 loss=4.157, nll_loss=2.536, ppl=5.8, wps=52482.5, ups=0.92, wpb=57208.3, bsz=1488.4, num_updates=146300, lr=0.000165351, gnorm=0.262, clip=100, loss_scale=32, train_wall=105, wall=161010
2023-05-27 15:05:24 | INFO | train_inner | epoch 022:   6229 / 6686 loss=4.156, nll_loss=2.535, ppl=5.8, wps=52717.5, ups=0.92, wpb=57246.7, bsz=1461.4, num_updates=146400, lr=0.000165295, gnorm=0.262, clip=100, loss_scale=32, train_wall=105, wall=161118
2023-05-27 15:07:12 | INFO | train_inner | epoch 022:   6329 / 6686 loss=4.159, nll_loss=2.538, ppl=5.81, wps=52597.8, ups=0.92, wpb=57057.5, bsz=1471.7, num_updates=146500, lr=0.000165238, gnorm=0.261, clip=100, loss_scale=32, train_wall=105, wall=161227
2023-05-27 15:09:01 | INFO | train_inner | epoch 022:   6429 / 6686 loss=4.153, nll_loss=2.531, ppl=5.78, wps=52653.8, ups=0.92, wpb=57205.9, bsz=1467.9, num_updates=146600, lr=0.000165182, gnorm=0.262, clip=100, loss_scale=32, train_wall=105, wall=161335
2023-05-27 15:10:06 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 15:10:51 | INFO | train_inner | epoch 022:   6530 / 6686 loss=4.156, nll_loss=2.535, ppl=5.8, wps=52193.5, ups=0.91, wpb=57116, bsz=1473.6, num_updates=146700, lr=0.000165126, gnorm=0.265, clip=100, loss_scale=33, train_wall=106, wall=161445
2023-05-27 15:12:39 | INFO | train_inner | epoch 022:   6630 / 6686 loss=4.148, nll_loss=2.526, ppl=5.76, wps=52675.3, ups=0.92, wpb=57210.8, bsz=1474.9, num_updates=146800, lr=0.00016507, gnorm=0.26, clip=100, loss_scale=32, train_wall=105, wall=161553
2023-05-27 15:13:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-27 15:13:46 | INFO | fairseq.tasks.translation | example hypothesis: Why was that?
2023-05-27 15:13:46 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-27 15:13:46 | INFO | fairseq.tasks.translation | example hypothesis: I’ll make you lose so badly that you don’t even have any pants left!
2023-05-27 15:13:46 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-27 15:13:47 | INFO | fairseq.tasks.translation | example hypothesis: Just as Shen Liangchuan heaved a sigh of relief, he heard her say, “I’ll call for you to stay in the same room!”
2023-05-27 15:13:47 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-27 15:13:48 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved her hand and entered the elevator.
2023-05-27 15:13:48 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-27 15:13:48 | INFO | fairseq.tasks.translation | example hypothesis: She looked up and saw Song Cheng standing in the distance!
2023-05-27 15:13:48 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-27 15:13:49 | INFO | fairseq.tasks.translation | example hypothesis: Only then did Song Cheng pat his chest. “You scared me to death! Where’s Wang Chuan?”
2023-05-27 15:13:49 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-27 15:13:50 | INFO | fairseq.tasks.translation | example hypothesis: I said, “No, I can’t eat it.”
2023-05-27 15:13:50 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-27 15:13:50 | INFO | fairseq.tasks.translation | example hypothesis: At first, everyone didn’t believe it, but Wang Wenhao insisted that he was biased towards Wang Wenhao.
2023-05-27 15:13:50 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-27 15:13:51 | INFO | fairseq.tasks.translation | example hypothesis: With his status, coming here like this, Baili Hongzhuang had to be treated even if she did not want to!
2023-05-27 15:13:51 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-27 15:13:52 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian said, “Mr. Shen, I, I left too much blood and my brain is lacking oxygen. I can’t think of anything. Why don’t you give me a hint?”
2023-05-27 15:13:52 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-27 15:13:53 | INFO | fairseq.tasks.translation | example hypothesis: He didn’t know why so many people heard about this matter. Since he couldn’t hide it anymore, he might as well tell them.
2023-05-27 15:13:53 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-27 15:13:54 | INFO | fairseq.tasks.translation | example hypothesis: She deliberately lowered her voice, but it could not hide the viciousness and viciousness in her tone.
2023-05-27 15:13:54 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-27 15:13:55 | INFO | fairseq.tasks.translation | example hypothesis: Beast pets of different levels had different strengths, but beast pets were precious and hard to come by. It was impossible for ordinary people to have one, even for the children of officials.
2023-05-27 15:13:55 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-27 15:13:56 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chixia gritted his teeth and cursed in a low voice.
2023-05-27 15:13:56 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-27 15:13:57 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang had concealed it very well, Di Beichen could still see the ripples in her eyes and felt a little warmth in them.
2023-05-27 15:13:57 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-27 15:13:58 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia walked in, she didn’t even see a few waiters, let alone guests.
2023-05-27 15:13:58 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-27 15:13:59 | INFO | fairseq.tasks.translation | example hypothesis: This person was the Ye Family’s fourth young miss, Ye Qingling.
2023-05-27 15:13:59 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-27 15:14:00 | INFO | fairseq.tasks.translation | example hypothesis: Because at this moment, she felt as if her chin was about to break.
2023-05-27 15:14:00 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-27 15:14:02 | INFO | fairseq.tasks.translation | example hypothesis: “Alright, Mu Zi, help me. If it weren’t for you, that old man wouldn’t have set his eyes on me.”
2023-05-27 15:14:02 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-27 15:14:03 | INFO | fairseq.tasks.translation | example hypothesis: Baili Yuyan was even more excited. This matter was completely directed by her. Earlier, when Baili Hongzhuang treated her like this, she would definitely make things difficult for Baili Hongzhuang.
2023-05-27 15:14:03 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-27 15:14:04 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How could that be? They are also four grand mages, of course they won’t surrender so easily. After arguing for a long time, they finally decided on how to obtain control of the Kingdom of Axia through the competition.”
2023-05-27 15:14:04 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-27 15:14:05 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a bit. He had been looking for a reason for Li Yuyue not being able to participate in the royal hunting competition.
2023-05-27 15:14:05 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-27 15:14:07 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my level good? They’re all the most outstanding people in the country, how can my magic be so weak?”
2023-05-27 15:14:07 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-27 15:14:09 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yibei’s words meant that if Fang Chi Xia didn’t want to go, then there was no need to go.
2023-05-27 15:14:09 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-27 15:14:10 | INFO | fairseq.tasks.translation | example hypothesis: She tilted her head and saw that the five palm prints on her cheek were very eye-catching. They were swelling at a speed visible to the naked eye. Reaching out to touch them, she could not help but let out a hiss.
2023-05-27 15:14:10 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-27 15:14:12 | INFO | fairseq.tasks.translation | example hypothesis: This... how could this be the charm emitted by that piece of trash?
2023-05-27 15:14:12 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-27 15:14:13 | INFO | fairseq.tasks.translation | example hypothesis: How could Wang Wenhao have found the newspaper? The chief editor should have called her to tell her not to come to the newspaper, but these three people... had plotted against her!
2023-05-27 15:14:13 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-27 15:14:15 | INFO | fairseq.tasks.translation | example hypothesis: Hearing Teacher Di’s praise, I was delighted. I put away the energy ball with my left hand, and a light sword appeared in my right hand, slashing towards Teacher Zhen. The light sword actually managed to land smoothly. I was startled, and upon a closer look, I discovered that it was only an afterimage. Teacher Zhen had already moved behind me, and shouted, “Berserk
2023-05-27 15:14:15 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-27 15:14:18 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Originally, we proposed three rounds and two wins, but they said it wasn’t fair, because we have Teacher Di and Teacher Zhen, who are ranked higher than them, so they proposed five rounds and three wins. Since we proposed the competition, we can only listen to them in the end. Three days from now, we will compete in secret in the Royal Colosseum. If we don’t compete in the Royal Colosseum, then we will be
2023-05-27 15:14:18 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-27 15:14:20 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Zhen used a light magic of the seventh rank, Light Thunder Burst. I didn’t use much of this spell, because I didn’t have a good control over it. Teacher Zhen released nine Light Thunder Bursts to surround me, forming a simple formation, preventing me from escaping in a short distance. Then all the Light Thunder Bursts exploded one after another to form a powerful attack.
2023-05-27 15:14:20 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-27 15:14:23 | INFO | fairseq.tasks.translation | example hypothesis: As soon as Mark and the two teachers walked to the other side, Teacher Zhen sent out a small Dimensional Slash towards me. As expected of the continent’s number one Magician. The strong suction force of his small Dimensional Slash was actually much stronger than mine. A small spatial crack appeared beside me, and a strong suction force immediately swept towards me.
2023-05-27 15:14:23 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-27 15:14:23 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 4.158 | nll_loss 2.517 | ppl 5.72 | bleu 21.74 | wps 1956.5 | wpb 2420.8 | bsz 84.5 | num_updates 146856 | best_bleu 21.92
2023-05-27 15:14:23 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-27 15:14:27 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/concat-1-1-0.2-sf[zh-en]/checkpoint22.pt (epoch 22 @ 146856 updates, score 21.74) (writing took 3.8973854295909405 seconds)
2023-05-27 15:14:27 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-05-27 15:14:27 | INFO | train | epoch 022 | loss 4.148 | nll_loss 2.526 | ppl 5.76 | wps 51916.2 | ups 0.91 | wpb 57190 | bsz 1477.5 | num_updates 146856 | lr 0.000165038 | gnorm 0.262 | clip 100 | loss_scale 26 | train_wall 7024 | wall 161662
2023-05-27 15:14:27 | INFO | fairseq.trainer | begin training epoch 23
2023-05-27 15:15:36 | INFO | train_inner | epoch 023:     44 / 6686 loss=4.153, nll_loss=2.532, ppl=5.78, wps=32021.9, ups=0.56, wpb=56719.9, bsz=1462, num_updates=146900, lr=0.000165013, gnorm=0.267, clip=100, loss_scale=32, train_wall=107, wall=161730
2023-05-27 15:17:33 | INFO | train_inner | epoch 023:    144 / 6686 loss=4.136, nll_loss=2.512, ppl=5.7, wps=49017.3, ups=0.86, wpb=57016.9, bsz=1469.6, num_updates=147000, lr=0.000164957, gnorm=0.262, clip=100, loss_scale=32, train_wall=107, wall=161847
2023-05-27 15:19:25 | INFO | train_inner | epoch 023:    244 / 6686 loss=4.143, nll_loss=2.519, ppl=5.73, wps=51095, ups=0.89, wpb=57290.8, bsz=1487.8, num_updates=147100, lr=0.000164901, gnorm=0.26, clip=100, loss_scale=32, train_wall=106, wall=161959
2023-05-27 15:20:56 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 15:21:15 | INFO | train_inner | epoch 023:    345 / 6686 loss=4.126, nll_loss=2.501, ppl=5.66, wps=51750.8, ups=0.91, wpb=57113.5, bsz=1480.1, num_updates=147200, lr=0.000164845, gnorm=0.259, clip=100, loss_scale=36, train_wall=106, wall=162069
2023-05-27 15:23:04 | INFO | train_inner | epoch 023:    445 / 6686 loss=4.133, nll_loss=2.508, ppl=5.69, wps=52758.3, ups=0.92, wpb=57322.2, bsz=1469.4, num_updates=147300, lr=0.000164789, gnorm=0.26, clip=100, loss_scale=32, train_wall=105, wall=162178
2023-05-27 15:24:53 | INFO | train_inner | epoch 023:    545 / 6686 loss=4.133, nll_loss=2.508, ppl=5.69, wps=52587.2, ups=0.91, wpb=57482.8, bsz=1472.2, num_updates=147400, lr=0.000164733, gnorm=0.261, clip=100, loss_scale=32, train_wall=106, wall=162287
2023-05-27 15:26:42 | INFO | train_inner | epoch 023:    645 / 6686 loss=4.125, nll_loss=2.499, ppl=5.65, wps=52339.3, ups=0.92, wpb=57166.2, bsz=1493.6, num_updates=147500, lr=0.000164677, gnorm=0.26, clip=100, loss_scale=32, train_wall=105, wall=162396
2023-05-27 15:28:26 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 15:28:32 | INFO | train_inner | epoch 023:    746 / 6686 loss=4.133, nll_loss=2.508, ppl=5.69, wps=52042.8, ups=0.91, wpb=57286.2, bsz=1479.4, num_updates=147600, lr=0.000164622, gnorm=0.263, clip=100, loss_scale=31, train_wall=106, wall=162507
2023-05-27 15:30:21 | INFO | train_inner | epoch 023:    846 / 6686 loss=4.136, nll_loss=2.512, ppl=5.7, wps=52777.5, ups=0.92, wpb=57252.4, bsz=1462.9, num_updates=147700, lr=0.000164566, gnorm=0.262, clip=100, loss_scale=16, train_wall=105, wall=162615
2023-05-27 15:32:10 | INFO | train_inner | epoch 023:    946 / 6686 loss=4.141, nll_loss=2.517, ppl=5.72, wps=52673.9, ups=0.92, wpb=57281, bsz=1465, num_updates=147800, lr=0.00016451, gnorm=0.263, clip=100, loss_scale=16, train_wall=105, wall=162724
2023-05-27 15:33:58 | INFO | train_inner | epoch 023:   1046 / 6686 loss=4.14, nll_loss=2.516, ppl=5.72, wps=52727.4, ups=0.92, wpb=57244.5, bsz=1487.8, num_updates=147900, lr=0.000164455, gnorm=0.262, clip=100, loss_scale=16, train_wall=105, wall=162832
2023-05-27 15:35:47 | INFO | train_inner | epoch 023:   1146 / 6686 loss=4.142, nll_loss=2.519, ppl=5.73, wps=52731.7, ups=0.92, wpb=57140.8, bsz=1471.4, num_updates=148000, lr=0.000164399, gnorm=0.263, clip=100, loss_scale=16, train_wall=105, wall=162941
2023-05-27 15:37:36 | INFO | train_inner | epoch 023:   1246 / 6686 loss=4.14, nll_loss=2.516, ppl=5.72, wps=52511.8, ups=0.92, wpb=57201.5, bsz=1468.6, num_updates=148100, lr=0.000164343, gnorm=0.264, clip=100, loss_scale=16, train_wall=105, wall=163050
2023-05-27 15:39:24 | INFO | train_inner | epoch 023:   1346 / 6686 loss=4.13, nll_loss=2.505, ppl=5.68, wps=52838.8, ups=0.92, wpb=57259.6, bsz=1479, num_updates=148200, lr=0.000164288, gnorm=0.263, clip=100, loss_scale=31, train_wall=105, wall=163158
2023-05-27 15:39:51 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 15:41:14 | INFO | train_inner | epoch 023:   1447 / 6686 loss=4.138, nll_loss=2.514, ppl=5.71, wps=52251.1, ups=0.91, wpb=57281.1, bsz=1480.9, num_updates=148300, lr=0.000164233, gnorm=0.262, clip=100, loss_scale=20, train_wall=106, wall=163268
2023-05-27 15:43:03 | INFO | train_inner | epoch 023:   1547 / 6686 loss=4.143, nll_loss=2.52, ppl=5.73, wps=52481.2, ups=0.92, wpb=57195.7, bsz=1473.4, num_updates=148400, lr=0.000164177, gnorm=0.263, clip=100, loss_scale=16, train_wall=105, wall=163377
2023-05-27 15:44:51 | INFO | train_inner | epoch 023:   1647 / 6686 loss=4.141, nll_loss=2.518, ppl=5.73, wps=52932.2, ups=0.92, wpb=57423.7, bsz=1504.3, num_updates=148500, lr=0.000164122, gnorm=0.266, clip=100, loss_scale=16, train_wall=105, wall=163485
2023-05-27 15:46:40 | INFO | train_inner | epoch 023:   1747 / 6686 loss=4.143, nll_loss=2.52, ppl=5.74, wps=52700, ups=0.92, wpb=57230.3, bsz=1462.3, num_updates=148600, lr=0.000164067, gnorm=0.264, clip=100, loss_scale=16, train_wall=105, wall=163594
2023-05-27 15:48:28 | INFO | train_inner | epoch 023:   1847 / 6686 loss=4.141, nll_loss=2.517, ppl=5.73, wps=52794.2, ups=0.92, wpb=57342, bsz=1471.4, num_updates=148700, lr=0.000164012, gnorm=0.259, clip=100, loss_scale=16, train_wall=105, wall=163702
2023-05-27 15:50:17 | INFO | train_inner | epoch 023:   1947 / 6686 loss=4.136, nll_loss=2.512, ppl=5.71, wps=52583.9, ups=0.92, wpb=57099.5, bsz=1465, num_updates=148800, lr=0.000163956, gnorm=0.263, clip=100, loss_scale=26, train_wall=105, wall=163811
2023-05-27 15:52:06 | INFO | train_inner | epoch 023:   2047 / 6686 loss=4.145, nll_loss=2.522, ppl=5.74, wps=52652.2, ups=0.92, wpb=57229.2, bsz=1481.4, num_updates=148900, lr=0.000163901, gnorm=0.264, clip=100, loss_scale=32, train_wall=105, wall=163920
2023-05-27 15:53:54 | INFO | train_inner | epoch 023:   2147 / 6686 loss=4.135, nll_loss=2.51, ppl=5.7, wps=52574.6, ups=0.92, wpb=57172.8, bsz=1491, num_updates=149000, lr=0.000163846, gnorm=0.263, clip=100, loss_scale=32, train_wall=105, wall=164028
2023-05-27 15:55:43 | INFO | train_inner | epoch 023:   2247 / 6686 loss=4.136, nll_loss=2.512, ppl=5.71, wps=52677.3, ups=0.92, wpb=57108.7, bsz=1488.6, num_updates=149100, lr=0.000163791, gnorm=0.263, clip=100, loss_scale=32, train_wall=105, wall=164137
2023-05-27 15:57:32 | INFO | train_inner | epoch 023:   2347 / 6686 loss=4.152, nll_loss=2.53, ppl=5.78, wps=52650.9, ups=0.92, wpb=57303.1, bsz=1472.6, num_updates=149200, lr=0.000163737, gnorm=0.263, clip=100, loss_scale=32, train_wall=105, wall=164246
2023-05-27 15:58:49 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 15:59:21 | INFO | train_inner | epoch 023:   2448 / 6686 loss=4.159, nll_loss=2.538, ppl=5.81, wps=51877.2, ups=0.91, wpb=57038.8, bsz=1447.4, num_updates=149300, lr=0.000163682, gnorm=0.265, clip=100, loss_scale=39, train_wall=106, wall=164356
2023-05-27 16:01:10 | INFO | train_inner | epoch 023:   2548 / 6686 loss=4.147, nll_loss=2.525, ppl=5.75, wps=52593.6, ups=0.92, wpb=57135.2, bsz=1466.8, num_updates=149400, lr=0.000163627, gnorm=0.266, clip=100, loss_scale=32, train_wall=105, wall=164464
2023-05-27 16:02:59 | INFO | train_inner | epoch 023:   2648 / 6686 loss=4.137, nll_loss=2.513, ppl=5.71, wps=52657.6, ups=0.92, wpb=57084.1, bsz=1476.9, num_updates=149500, lr=0.000163572, gnorm=0.263, clip=100, loss_scale=32, train_wall=105, wall=164573
2023-05-27 16:04:47 | INFO | train_inner | epoch 023:   2748 / 6686 loss=4.134, nll_loss=2.51, ppl=5.7, wps=52657.7, ups=0.92, wpb=57356.6, bsz=1494.2, num_updates=149600, lr=0.000163517, gnorm=0.262, clip=100, loss_scale=32, train_wall=105, wall=164682
2023-05-27 16:06:37 | INFO | train_inner | epoch 023:   2848 / 6686 loss=4.14, nll_loss=2.517, ppl=5.72, wps=52459.4, ups=0.92, wpb=57220.5, bsz=1486.1, num_updates=149700, lr=0.000163463, gnorm=0.262, clip=100, loss_scale=32, train_wall=105, wall=164791
2023-05-27 16:08:23 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 16:08:26 | INFO | train_inner | epoch 023:   2949 / 6686 loss=4.159, nll_loss=2.538, ppl=5.81, wps=52216.2, ups=0.91, wpb=57243.1, bsz=1482.8, num_updates=149800, lr=0.000163408, gnorm=0.264, clip=100, loss_scale=37, train_wall=106, wall=164900
2023-05-27 16:10:03 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 16:10:16 | INFO | train_inner | epoch 023:   3050 / 6686 loss=4.142, nll_loss=2.519, ppl=5.73, wps=52017.5, ups=0.91, wpb=57016.5, bsz=1484.9, num_updates=149900, lr=0.000163354, gnorm=0.262, clip=100, loss_scale=30, train_wall=106, wall=165010
2023-05-27 16:12:04 | INFO | train_inner | epoch 023:   3150 / 6686 loss=4.15, nll_loss=2.527, ppl=5.77, wps=52654.9, ups=0.92, wpb=57067.1, bsz=1474.6, num_updates=150000, lr=0.000163299, gnorm=0.264, clip=100, loss_scale=16, train_wall=105, wall=165118
2023-05-27 16:13:53 | INFO | train_inner | epoch 023:   3250 / 6686 loss=4.144, nll_loss=2.521, ppl=5.74, wps=52325.3, ups=0.92, wpb=57016.5, bsz=1471, num_updates=150100, lr=0.000163245, gnorm=0.261, clip=100, loss_scale=16, train_wall=105, wall=165227
2023-05-27 16:15:42 | INFO | train_inner | epoch 023:   3350 / 6686 loss=4.144, nll_loss=2.521, ppl=5.74, wps=52784.3, ups=0.92, wpb=57262.5, bsz=1471.9, num_updates=150200, lr=0.000163191, gnorm=0.263, clip=100, loss_scale=16, train_wall=105, wall=165336
2023-05-27 16:17:30 | INFO | train_inner | epoch 023:   3450 / 6686 loss=4.144, nll_loss=2.521, ppl=5.74, wps=52544.3, ups=0.92, wpb=57131.5, bsz=1487, num_updates=150300, lr=0.000163136, gnorm=0.267, clip=100, loss_scale=16, train_wall=105, wall=165445
2023-05-27 16:19:19 | INFO | train_inner | epoch 023:   3550 / 6686 loss=4.137, nll_loss=2.513, ppl=5.71, wps=52644.9, ups=0.92, wpb=57257.9, bsz=1473.9, num_updates=150400, lr=0.000163082, gnorm=0.263, clip=100, loss_scale=16, train_wall=105, wall=165553
2023-05-27 16:21:08 | INFO | train_inner | epoch 023:   3650 / 6686 loss=4.147, nll_loss=2.525, ppl=5.76, wps=52745.8, ups=0.92, wpb=57356.7, bsz=1479.6, num_updates=150500, lr=0.000163028, gnorm=0.264, clip=100, loss_scale=32, train_wall=105, wall=165662
2023-05-27 16:22:56 | INFO | train_inner | epoch 023:   3750 / 6686 loss=4.155, nll_loss=2.534, ppl=5.79, wps=52648.5, ups=0.92, wpb=57125.4, bsz=1457, num_updates=150600, lr=0.000162974, gnorm=0.263, clip=100, loss_scale=32, train_wall=105, wall=165771
2023-05-27 16:24:45 | INFO | train_inner | epoch 023:   3850 / 6686 loss=4.156, nll_loss=2.535, ppl=5.8, wps=52666.1, ups=0.92, wpb=57255, bsz=1470.6, num_updates=150700, lr=0.00016292, gnorm=0.261, clip=100, loss_scale=32, train_wall=105, wall=165879
2023-05-27 16:26:34 | INFO | train_inner | epoch 023:   3950 / 6686 loss=4.146, nll_loss=2.523, ppl=5.75, wps=52731, ups=0.92, wpb=57280.3, bsz=1501, num_updates=150800, lr=0.000162866, gnorm=0.264, clip=100, loss_scale=32, train_wall=105, wall=165988
2023-05-27 16:28:22 | INFO | train_inner | epoch 023:   4050 / 6686 loss=4.151, nll_loss=2.529, ppl=5.77, wps=52673.9, ups=0.92, wpb=57219.6, bsz=1487, num_updates=150900, lr=0.000162812, gnorm=0.264, clip=100, loss_scale=32, train_wall=105, wall=166097
2023-05-27 16:29:06 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 16:30:12 | INFO | train_inner | epoch 023:   4151 / 6686 loss=4.148, nll_loss=2.526, ppl=5.76, wps=52072.6, ups=0.91, wpb=57114.9, bsz=1480.2, num_updates=151000, lr=0.000162758, gnorm=0.262, clip=100, loss_scale=41, train_wall=106, wall=166206
2023-05-27 16:32:01 | INFO | train_inner | epoch 023:   4251 / 6686 loss=4.15, nll_loss=2.527, ppl=5.77, wps=52761.3, ups=0.92, wpb=57213.5, bsz=1484.2, num_updates=151100, lr=0.000162704, gnorm=0.263, clip=100, loss_scale=32, train_wall=105, wall=166315
2023-05-27 16:33:49 | INFO | train_inner | epoch 023:   4351 / 6686 loss=4.151, nll_loss=2.529, ppl=5.77, wps=52695.6, ups=0.92, wpb=57197.9, bsz=1475.2, num_updates=151200, lr=0.00016265, gnorm=0.264, clip=100, loss_scale=32, train_wall=105, wall=166423
2023-05-27 16:33:59 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 16:35:39 | INFO | train_inner | epoch 023:   4452 / 6686 loss=4.145, nll_loss=2.522, ppl=5.74, wps=52092.7, ups=0.91, wpb=57259, bsz=1476, num_updates=151300, lr=0.000162596, gnorm=0.264, clip=100, loss_scale=17, train_wall=106, wall=166533
2023-05-27 16:37:27 | INFO | train_inner | epoch 023:   4552 / 6686 loss=4.149, nll_loss=2.527, ppl=5.77, wps=52546.5, ups=0.92, wpb=57002.7, bsz=1456.8, num_updates=151400, lr=0.000162543, gnorm=0.268, clip=100, loss_scale=16, train_wall=105, wall=166642
2023-05-27 16:39:16 | INFO | train_inner | epoch 023:   4652 / 6686 loss=4.142, nll_loss=2.519, ppl=5.73, wps=52714.3, ups=0.92, wpb=57101, bsz=1487.2, num_updates=151500, lr=0.000162489, gnorm=0.263, clip=100, loss_scale=16, train_wall=105, wall=166750
2023-05-27 16:41:05 | INFO | train_inner | epoch 023:   4752 / 6686 loss=4.133, nll_loss=2.51, ppl=5.69, wps=52688.2, ups=0.92, wpb=57373.2, bsz=1510.1, num_updates=151600, lr=0.000162435, gnorm=0.261, clip=100, loss_scale=16, train_wall=105, wall=166859
2023-05-27 16:42:53 | INFO | train_inner | epoch 023:   4852 / 6686 loss=4.159, nll_loss=2.538, ppl=5.81, wps=52890.9, ups=0.93, wpb=57153.2, bsz=1471.9, num_updates=151700, lr=0.000162382, gnorm=0.266, clip=100, loss_scale=16, train_wall=104, wall=166967
2023-05-27 16:44:42 | INFO | train_inner | epoch 023:   4952 / 6686 loss=4.151, nll_loss=2.529, ppl=5.77, wps=52393.7, ups=0.92, wpb=57008.4, bsz=1479.8, num_updates=151800, lr=0.000162328, gnorm=0.266, clip=100, loss_scale=29, train_wall=105, wall=167076
2023-05-27 16:46:30 | INFO | train_inner | epoch 023:   5052 / 6686 loss=4.151, nll_loss=2.53, ppl=5.77, wps=52666.8, ups=0.92, wpb=57315.6, bsz=1486.9, num_updates=151900, lr=0.000162275, gnorm=0.264, clip=100, loss_scale=32, train_wall=105, wall=167185
2023-05-27 16:48:19 | INFO | train_inner | epoch 023:   5152 / 6686 loss=4.142, nll_loss=2.519, ppl=5.73, wps=52745, ups=0.92, wpb=57275.2, bsz=1486.7, num_updates=152000, lr=0.000162221, gnorm=0.262, clip=100, loss_scale=32, train_wall=105, wall=167293
2023-05-27 16:50:07 | INFO | train_inner | epoch 023:   5252 / 6686 loss=4.136, nll_loss=2.513, ppl=5.71, wps=52679.3, ups=0.92, wpb=57153.5, bsz=1517.8, num_updates=152100, lr=0.000162168, gnorm=0.262, clip=100, loss_scale=32, train_wall=105, wall=167402
2023-05-27 16:51:56 | INFO | train_inner | epoch 023:   5352 / 6686 loss=4.149, nll_loss=2.527, ppl=5.76, wps=52766.2, ups=0.92, wpb=57269.1, bsz=1452.9, num_updates=152200, lr=0.000162115, gnorm=0.263, clip=100, loss_scale=32, train_wall=105, wall=167510
2023-05-27 16:52:37 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 16:53:46 | INFO | train_inner | epoch 023:   5453 / 6686 loss=4.145, nll_loss=2.523, ppl=5.75, wps=52249.8, ups=0.91, wpb=57323.9, bsz=1484.4, num_updates=152300, lr=0.000162062, gnorm=0.261, clip=100, loss_scale=34, train_wall=106, wall=167620
2023-05-27 16:55:07 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 16:55:35 | INFO | train_inner | epoch 023:   5554 / 6686 loss=4.14, nll_loss=2.517, ppl=5.72, wps=52391.2, ups=0.92, wpb=57233.2, bsz=1468.3, num_updates=152400, lr=0.000162008, gnorm=0.261, clip=100, loss_scale=28, train_wall=105, wall=167729
2023-05-27 16:57:24 | INFO | train_inner | epoch 023:   5654 / 6686 loss=4.154, nll_loss=2.533, ppl=5.79, wps=52432.2, ups=0.92, wpb=57116.6, bsz=1486.5, num_updates=152500, lr=0.000161955, gnorm=0.263, clip=100, loss_scale=16, train_wall=105, wall=167838
2023-05-27 16:59:13 | INFO | train_inner | epoch 023:   5754 / 6686 loss=4.138, nll_loss=2.514, ppl=5.71, wps=52755.8, ups=0.92, wpb=57335.9, bsz=1494.6, num_updates=152600, lr=0.000161902, gnorm=0.261, clip=100, loss_scale=16, train_wall=105, wall=167947
2023-05-27 17:01:01 | INFO | train_inner | epoch 023:   5854 / 6686 loss=4.156, nll_loss=2.534, ppl=5.79, wps=52688.7, ups=0.92, wpb=57285.3, bsz=1457.4, num_updates=152700, lr=0.000161849, gnorm=0.263, clip=100, loss_scale=16, train_wall=105, wall=168055
2023-05-27 17:02:50 | INFO | train_inner | epoch 023:   5954 / 6686 loss=4.142, nll_loss=2.519, ppl=5.73, wps=52522.3, ups=0.92, wpb=57023.4, bsz=1494.5, num_updates=152800, lr=0.000161796, gnorm=0.263, clip=100, loss_scale=16, train_wall=105, wall=168164
2023-05-27 17:04:39 | INFO | train_inner | epoch 023:   6054 / 6686 loss=4.15, nll_loss=2.529, ppl=5.77, wps=52626.5, ups=0.92, wpb=57173.6, bsz=1479.7, num_updates=152900, lr=0.000161743, gnorm=0.265, clip=100, loss_scale=18, train_wall=105, wall=168273
2023-05-27 17:06:28 | INFO | train_inner | epoch 023:   6154 / 6686 loss=4.149, nll_loss=2.527, ppl=5.76, wps=52387.1, ups=0.92, wpb=57109.2, bsz=1455.4, num_updates=153000, lr=0.00016169, gnorm=0.266, clip=100, loss_scale=32, train_wall=105, wall=168382
2023-05-27 17:07:55 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 17:08:17 | INFO | train_inner | epoch 023:   6255 / 6686 loss=4.152, nll_loss=2.53, ppl=5.78, wps=52106.5, ups=0.92, wpb=56934.7, bsz=1459.5, num_updates=153100, lr=0.000161638, gnorm=0.265, clip=100, loss_scale=29, train_wall=105, wall=168491
2023-05-27 17:10:06 | INFO | train_inner | epoch 023:   6355 / 6686 loss=4.147, nll_loss=2.525, ppl=5.76, wps=52632.7, ups=0.92, wpb=57284.4, bsz=1493.4, num_updates=153200, lr=0.000161585, gnorm=0.265, clip=100, loss_scale=16, train_wall=105, wall=168600
2023-05-27 17:11:55 | INFO | train_inner | epoch 023:   6455 / 6686 loss=4.149, nll_loss=2.527, ppl=5.76, wps=52392.2, ups=0.92, wpb=57117.7, bsz=1463.2, num_updates=153300, lr=0.000161532, gnorm=0.264, clip=100, loss_scale=16, train_wall=105, wall=168709
2023-05-27 17:13:43 | INFO | train_inner | epoch 023:   6555 / 6686 loss=4.163, nll_loss=2.543, ppl=5.83, wps=52652.4, ups=0.92, wpb=57036.6, bsz=1464.2, num_updates=153400, lr=0.000161479, gnorm=0.267, clip=100, loss_scale=16, train_wall=105, wall=168817
2023-05-27 17:15:32 | INFO | train_inner | epoch 023:   6655 / 6686 loss=4.149, nll_loss=2.528, ppl=5.77, wps=52639.8, ups=0.92, wpb=57207.8, bsz=1486, num_updates=153500, lr=0.000161427, gnorm=0.263, clip=100, loss_scale=16, train_wall=105, wall=168926
2023-05-27 17:16:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-05-27 17:16:11 | INFO | fairseq.tasks.translation | example hypothesis: Why was that?
2023-05-27 17:16:11 | INFO | fairseq.tasks.translation | example reference: Why?
2023-05-27 17:16:11 | INFO | fairseq.tasks.translation | example hypothesis: I’ll make you lose so badly that not even your pants are left!
2023-05-27 17:16:11 | INFO | fairseq.tasks.translation | example reference: Later on, you will lose everything, even the pants you are wearing!
2023-05-27 17:16:12 | INFO | fairseq.tasks.translation | example hypothesis: Just as Shen Liangchuan heaved a sigh of relief, he heard her say, “I’ll call for you to stay in the same room!”
2023-05-27 17:16:12 | INFO | fairseq.tasks.translation | example reference: Just as Shen Liangchuan breathed a sigh of relief, she claimed, “I should call you ‘roommate’!”
2023-05-27 17:16:13 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian waved her hand and entered the elevator.
2023-05-27 17:16:13 | INFO | fairseq.tasks.translation | example reference: Qiao Lian waved her hand and entered the elevator.
2023-05-27 17:16:13 | INFO | fairseq.tasks.translation | example hypothesis: She raised her head and saw Song Cheng standing in the distance!
2023-05-27 17:16:13 | INFO | fairseq.tasks.translation | example reference: When she lifted her head, she saw Song Cheng, who was standing in the distance.
2023-05-27 17:16:14 | INFO | fairseq.tasks.translation | example hypothesis: Then, Song Cheng patted his chest. “You scared me to death! Where’s Wang Chuan?”
2023-05-27 17:16:14 | INFO | fairseq.tasks.translation | example reference: Song Cheng then patted his chest and exclaimed, “You gave me a shock! Where’s Wang Chuan?”
2023-05-27 17:16:15 | INFO | fairseq.tasks.translation | example hypothesis: I said, “I’m not going, I can’t eat it.”
2023-05-27 17:16:15 | INFO | fairseq.tasks.translation | example reference: I relented and said, “Fine, then we’ll go eat at noon.”
2023-05-27 17:16:15 | INFO | fairseq.tasks.translation | example hypothesis: At first, everyone didn’t believe it, but Wang Wenhao insisted that he would make public opinion favor Wang Wenhao.
2023-05-27 17:16:15 | INFO | fairseq.tasks.translation | example reference: At first, everyone was in disbelieve. Yet, as Wang Wenhao insisted that Shen Liangchuan had been taking drugs, the public opinion took Wang Wenhao’s side.
2023-05-27 17:16:16 | INFO | fairseq.tasks.translation | example hypothesis: Coming here like this with his identity, Baili Hongzhuang had to be treated even if she did not want to!
2023-05-27 17:16:16 | INFO | fairseq.tasks.translation | example reference: Coming here with his identity, Baili Hongzhuang wouldn’t dare refuse!
2023-05-27 17:16:17 | INFO | fairseq.tasks.translation | example hypothesis: Qiao Lian: “Mr. Shen, I, I left too much blood and my brain lacks oxygen. I can’t figure it out. Why don’t you give me a hint?”
2023-05-27 17:16:17 | INFO | fairseq.tasks.translation | example reference: Qiao Lian said, “Mr. Shen, I, I have lost too much blood and my head is feeling woozy. I can’t think anymore, so can you give me a hint?”
2023-05-27 17:16:18 | INFO | fairseq.tasks.translation | example hypothesis: He didn’t know why so many people had heard about it. Since he couldn’t hide it anymore, he might as well tell them.
2023-05-27 17:16:18 | INFO | fairseq.tasks.translation | example reference: He didn’t know how so many people already knew of this, but right now, it was better to just say it instead of hiding it.
2023-05-27 17:16:19 | INFO | fairseq.tasks.translation | example hypothesis: She deliberately lowered her voice, but it could not hide the viciousness and ruthlessness in her voice.
2023-05-27 17:16:19 | INFO | fairseq.tasks.translation | example reference: She has deliberately suppressed her voice, but it was still unable to conceal the anguish in her tone.
2023-05-27 17:16:20 | INFO | fairseq.tasks.translation | example hypothesis: Different levels of beast pets had different strengths, but beast pets were precious and hard to come by. It was impossible for normal people to possess them, and even the children of officials wouldn’t be able to possess them.
2023-05-27 17:16:20 | INFO | fairseq.tasks.translation | example reference: Beast pets had different levels of strength, but they were all very rare and precious. They were something common people simply couldn’t have. Even the sons and daughters of government officials couldn’t afford them.
2023-05-27 17:16:21 | INFO | fairseq.tasks.translation | example hypothesis: Fang Chixia gritted his teeth and cursed in a low voice.
2023-05-27 17:16:21 | INFO | fairseq.tasks.translation | example reference: “Rogue!” Fang Chixia whispered.
2023-05-27 17:16:22 | INFO | fairseq.tasks.translation | example hypothesis: Even though Baili Hongzhuang had concealed it very well, Di Beichen could still see the ripples in her eyes and a hint of warmth appeared in them.
2023-05-27 17:16:22 | INFO | fairseq.tasks.translation | example reference: Even though Baili Hongzhuang hid her feelings extremely well, Dibei Chen still managed to see through to the turmoil in her heart. His eyes turned a little warm.
2023-05-27 17:16:23 | INFO | fairseq.tasks.translation | example hypothesis: After Fang Chi Xia walked in, she didn’t even see a few waiters or guests.
2023-05-27 17:16:23 | INFO | fairseq.tasks.translation | example reference: From the moment Fang Chixia walked down, not to mention other guests, not even a waiter was in sight.
2023-05-27 17:16:24 | INFO | fairseq.tasks.translation | example hypothesis: This person was the Ye Family’s fourth young miss, Ye Qing Ling.
2023-05-27 17:16:24 | INFO | fairseq.tasks.translation | example reference: This person was the fourth Miss of the Ye Family- Ye Qing Ling.
2023-05-27 17:16:25 | INFO | fairseq.tasks.translation | example hypothesis: Because at this moment, she felt as though her chin was about to break into pieces.
2023-05-27 17:16:25 | INFO | fairseq.tasks.translation | example reference: At this moment, she felt as though her jaw was about to be shattered.
2023-05-27 17:16:27 | INFO | fairseq.tasks.translation | example hypothesis: “Alright, Mu Zi, help me. If it wasn’t for you, that old man wouldn’t have set his eyes on me.”
2023-05-27 17:16:27 | INFO | fairseq.tasks.translation | example reference: “Mu Zi, you are a good person! Please help me! If it wasn’t for you, that old man would have never pick on me.”
2023-05-27 17:16:28 | INFO | fairseq.tasks.translation | example hypothesis: Bai Li Yu Yan was even more excited. She was the one who was in charge of this. Bai Li Hongzhuang had treated her like this before. This time, she would definitely make Bai Li Hongzhuang suffer.
2023-05-27 17:16:28 | INFO | fairseq.tasks.translation | example reference: Baili Yuyan was even more excited. This entire play was staged by her. Before, Baili Hongzhuang treated her like that, this time, she’ll let Baili Hongzhuang suffer.
2023-05-27 17:16:29 | INFO | fairseq.tasks.translation | example hypothesis: “Surrender? How could that be? They also have four mages on their side, of course they won’t surrender so easily. After arguing for a long time, they finally decided on how to obtain control over the Kingdom of Axia in the future.”
2023-05-27 17:16:29 | INFO | fairseq.tasks.translation | example reference: Why would they do that? They have four Magisters as do we; it isn’t easy to make them surrender. After negotiating for half a day, we finally decided to compete against each other. The winner will have the right to control the kingdom of Aixia.”
2023-05-27 17:16:30 | INFO | fairseq.tasks.translation | example hypothesis: Li Chengqian’s expression changed a bit. He had always been looking for an excuse for Li Yuyue not being able to participate in the Royal Family’s hunting competition.
2023-05-27 17:16:30 | INFO | fairseq.tasks.translation | example reference: Li Chengqian’s face changed slightly, his brain continually thinking of excuses why Li Yuyue couldn’t come to the royal hunting competition
2023-05-27 17:16:32 | INFO | fairseq.tasks.translation | example hypothesis: “Teacher Xiu, is my level good enough? They’re all the most outstanding people in the country, how can my magic be that weak?”
2023-05-27 17:16:32 | INFO | fairseq.tasks.translation | example reference: “Teacher Xiu, how could my level be compared the kingdom’s most talented people with such weak magic?” I immediately tried to shirk this.
2023-05-27 17:16:34 | INFO | fairseq.tasks.translation | example hypothesis: Luo Yibei’s words meant that if Fang Chixia didn’t want to go, then there was no need to go.
2023-05-27 17:16:34 | INFO | fairseq.tasks.translation | example reference: Luo Yibei meant that Fang Chixia need not go if she wasn’t willing to.
2023-05-27 17:16:36 | INFO | fairseq.tasks.translation | example hypothesis: She tilted her head and saw that the five palm marks on her cheek were very eye-catching. They were swelling at a speed visible to the naked eye. Reaching out to touch them, she couldn’t help but let out a hiss.
2023-05-27 17:16:36 | INFO | fairseq.tasks.translation | example reference: She tilted her head and saw that the imprint of the slap was still visible on her cheek. As she examined her cheek, it started to swell. She reached out her hand to touch it, and she could not help but wince in pain.
2023-05-27 17:16:37 | INFO | fairseq.tasks.translation | example hypothesis: This... how could this be the charm that that trash could emit?
2023-05-27 17:16:37 | INFO | fairseq.tasks.translation | example reference: How could that waste have so much charm?
2023-05-27 17:16:38 | INFO | fairseq.tasks.translation | example hypothesis: How could Wang Wenhao have found the newspaper agency? The chief editor should have called her to warn her not to come to the newspaper agency, but these three people... had schemed against her!
2023-05-27 17:16:38 | INFO | fairseq.tasks.translation | example reference: When Wang Wenhao found his way to the news agency, the chief editor should have called her to inform her that the correct choice for her was not tp come to the agency building. However, these three people... had instead schemed against her!
2023-05-27 17:16:41 | INFO | fairseq.tasks.translation | example hypothesis: Hearing Teacher Di’s praise, I was delighted. I put away the energy ball with my left hand and released a beam of light from my right hand towards Teacher Zhen. The beam of light actually managed to hit the target. I was startled, and upon closer inspection, I realized it was just an afterimage. Teacher Zhen had already moved to my back and shouted, “Berserk Space!”
2023-05-27 17:16:41 | INFO | fairseq.tasks.translation | example reference: Hearing Teacher Di’s praise, I was elated. I dissipated the light ball in my left hand and cast a light blade at Teacher Zhen with my right hand. The light blade actually hit him. I was in shock! However, after I took a second look, I realized that what I had hit was just an afterimage. Teacher Zhen had already teleported behind me and shouted, “
2023-05-27 17:16:43 | INFO | fairseq.tasks.translation | example hypothesis: Ma Ke said, “Initially, we proposed a two out of three competition, but they said it wasn’t fair, because we have Teacher Di and Teacher Zhen, who are ranked higher than them, and they proposed five out of five wins. Since we proposed the competition, we can only listen to them in the end. In three days, we’ll compete in secret in the Royal Family’s arena, and we’ll see if we can win or not.”
2023-05-27 17:16:43 | INFO | fairseq.tasks.translation | example reference: Ma Ke explained. “Initially, our side suggested that the winner of three matches wins. However, they said it was unfair as we have Teacher Di and Teacher Zhen, whose ranks are higher than their magisters’, so they suggested best of five matches instead. Since we brought up the competition, we could only agree to their request. After three days, we’ll secretly compete at the palace. Teacher Di told me to tell you that after asking for a leave of absence from the academy tomorrow, you need to go find him so you can train for a while and increase our chances of winning.”
2023-05-27 17:16:45 | INFO | fairseq.tasks.translation | example hypothesis: Teacher Di used a seventh ranked spell, Light Burst, Light Burst. I didn’t use much of this spell, because I didn’t have a good control over it. Teacher Di released nine lightning bolts to surround me, forming a simple formation, preventing me from escaping in a short distance. After that, all the lightning bolts exploded one after another, forming a powerful offensive power.
2023-05-27 17:16:45 | INFO | fairseq.tasks.translation | example reference: Teacher Di used the rank 7 spell, Lightning Array Burst. I rarely used that spell as it was difficult to control. Teacher Di cast nine bolts of lightning to surround me; forming a simple array. This would result in me being unable to dodge his spell by using the short distance teleportation spell so every lightning held strong offensive powers.
2023-05-27 17:16:48 | INFO | fairseq.tasks.translation | example hypothesis: Just as Mark and the two teachers walked to the other side, Teacher Zhen sent out a Small Dimensional Slash towards me. He was indeed worthy of being the continent’s number one magician. The Small Dimensional Slash’s suction force was actually much stronger than mine. A small spatial crack appeared beside me, and a powerful suction force immediately swept towards me.
2023-05-27 17:16:48 | INFO | fairseq.tasks.translation | example reference: Just as Ma Ke and his teachers walked towards their designated area, Teacher Zhen suddenly shot a small dimensional slash at me. As expected of the first ranked Magister; a very strong attraction force surged from the small dimensional slash, one much stronger than mine. A small spatial crack appeared beside me and a strong attraction force instantaneously surged out from inside it.
2023-05-27 17:16:49 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 4.152 | nll_loss 2.51 | ppl 5.7 | bleu 21.85 | wps 1936.1 | wpb 2420.8 | bsz 84.5 | num_updates 153531 | best_bleu 21.92
2023-05-27 17:16:49 | INFO | fairseq_cli.train | begin save checkpoint
2023-05-27 17:16:54 | INFO | fairseq.checkpoint_utils | saved checkpoint /project/jonmay_231/linghaoj/reproduce/ckpt/concat-1-1-0.2-sf[zh-en]/checkpoint23.pt (epoch 23 @ 153531 updates, score 21.85) (writing took 5.195360353216529 seconds)
2023-05-27 17:16:54 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-05-27 17:16:54 | INFO | train | epoch 023 | loss 4.144 | nll_loss 2.521 | ppl 5.74 | wps 51961.6 | ups 0.91 | wpb 57189.8 | bsz 1477.4 | num_updates 153531 | lr 0.000161411 | gnorm 0.263 | clip 100 | loss_scale 25 | train_wall 7021 | wall 169008
2023-05-27 17:16:54 | INFO | fairseq.trainer | begin training epoch 24
2023-05-27 17:18:28 | INFO | train_inner | epoch 024:     69 / 6686 loss=4.146, nll_loss=2.523, ppl=5.75, wps=32117.1, ups=0.57, wpb=56666, bsz=1443.4, num_updates=153600, lr=0.000161374, gnorm=0.269, clip=100, loss_scale=17, train_wall=107, wall=169102
2023-05-27 17:20:23 | INFO | train_inner | epoch 024:    169 / 6686 loss=4.138, nll_loss=2.514, ppl=5.71, wps=49910.2, ups=0.87, wpb=57202.5, bsz=1462.2, num_updates=153700, lr=0.000161322, gnorm=0.263, clip=100, loss_scale=32, train_wall=107, wall=169217
2023-05-27 17:22:15 | INFO | train_inner | epoch 024:    269 / 6686 loss=4.128, nll_loss=2.503, ppl=5.67, wps=51080.5, ups=0.89, wpb=57318.8, bsz=1482.6, num_updates=153800, lr=0.000161269, gnorm=0.264, clip=100, loss_scale=32, train_wall=106, wall=169329
2023-05-27 17:24:05 | INFO | train_inner | epoch 024:    369 / 6686 loss=4.134, nll_loss=2.51, ppl=5.7, wps=52031.9, ups=0.91, wpb=57045.4, bsz=1476.3, num_updates=153900, lr=0.000161217, gnorm=0.264, clip=100, loss_scale=32, train_wall=106, wall=169439
2023-05-27 17:25:54 | INFO | train_inner | epoch 024:    469 / 6686 loss=4.124, nll_loss=2.498, ppl=5.65, wps=52325.4, ups=0.92, wpb=57064, bsz=1494, num_updates=154000, lr=0.000161165, gnorm=0.266, clip=100, loss_scale=32, train_wall=105, wall=169548
2023-05-27 17:27:42 | INFO | train_inner | epoch 024:    569 / 6686 loss=4.132, nll_loss=2.507, ppl=5.68, wps=52766.1, ups=0.92, wpb=57186.2, bsz=1461, num_updates=154100, lr=0.000161112, gnorm=0.266, clip=100, loss_scale=32, train_wall=105, wall=169656
2023-05-27 17:28:39 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 17:29:00 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 17:29:33 | INFO | train_inner | epoch 024:    671 / 6686 loss=4.125, nll_loss=2.499, ppl=5.65, wps=51627.8, ups=0.9, wpb=57337.5, bsz=1481.7, num_updates=154200, lr=0.00016106, gnorm=0.261, clip=100, loss_scale=42, train_wall=107, wall=169767
2023-05-27 17:31:22 | INFO | train_inner | epoch 024:    771 / 6686 loss=4.126, nll_loss=2.501, ppl=5.66, wps=52802.3, ups=0.92, wpb=57331.9, bsz=1485.1, num_updates=154300, lr=0.000161008, gnorm=0.261, clip=100, loss_scale=16, train_wall=105, wall=169876
2023-05-27 17:33:11 | INFO | train_inner | epoch 024:    871 / 6686 loss=4.14, nll_loss=2.516, ppl=5.72, wps=52527.3, ups=0.92, wpb=57135, bsz=1462.7, num_updates=154400, lr=0.000160956, gnorm=0.263, clip=100, loss_scale=16, train_wall=105, wall=169985
2023-05-27 17:34:59 | INFO | train_inner | epoch 024:    971 / 6686 loss=4.126, nll_loss=2.5, ppl=5.66, wps=52524.4, ups=0.92, wpb=57237.3, bsz=1505.8, num_updates=154500, lr=0.000160904, gnorm=0.265, clip=100, loss_scale=16, train_wall=105, wall=170094
2023-05-27 17:36:48 | INFO | train_inner | epoch 024:   1071 / 6686 loss=4.143, nll_loss=2.52, ppl=5.74, wps=52660.2, ups=0.92, wpb=57098.1, bsz=1458.6, num_updates=154600, lr=0.000160852, gnorm=0.264, clip=100, loss_scale=16, train_wall=105, wall=170202
2023-05-27 17:38:37 | INFO | train_inner | epoch 024:   1171 / 6686 loss=4.131, nll_loss=2.507, ppl=5.68, wps=52591.8, ups=0.92, wpb=57228.8, bsz=1479.9, num_updates=154700, lr=0.0001608, gnorm=0.267, clip=100, loss_scale=19, train_wall=105, wall=170311
2023-05-27 17:38:46 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 17:40:26 | INFO | train_inner | epoch 024:   1272 / 6686 loss=4.136, nll_loss=2.512, ppl=5.7, wps=52129.6, ups=0.91, wpb=57193.9, bsz=1484.4, num_updates=154800, lr=0.000160748, gnorm=0.261, clip=100, loss_scale=17, train_wall=106, wall=170421
2023-05-27 17:42:15 | INFO | train_inner | epoch 024:   1372 / 6686 loss=4.128, nll_loss=2.503, ppl=5.67, wps=52853.2, ups=0.92, wpb=57345.5, bsz=1501.2, num_updates=154900, lr=0.000160696, gnorm=0.263, clip=100, loss_scale=16, train_wall=105, wall=170529
2023-05-27 17:44:03 | INFO | train_inner | epoch 024:   1472 / 6686 loss=4.142, nll_loss=2.519, ppl=5.73, wps=52694.3, ups=0.92, wpb=57109.1, bsz=1480, num_updates=155000, lr=0.000160644, gnorm=0.263, clip=100, loss_scale=16, train_wall=105, wall=170637
2023-05-27 17:45:52 | INFO | train_inner | epoch 024:   1572 / 6686 loss=4.138, nll_loss=2.514, ppl=5.71, wps=52489.1, ups=0.92, wpb=57143.1, bsz=1471.7, num_updates=155100, lr=0.000160592, gnorm=0.265, clip=100, loss_scale=16, train_wall=105, wall=170746
2023-05-27 17:47:41 | INFO | train_inner | epoch 024:   1672 / 6686 loss=4.133, nll_loss=2.509, ppl=5.69, wps=52890.9, ups=0.92, wpb=57344.7, bsz=1473.8, num_updates=155200, lr=0.00016054, gnorm=0.263, clip=100, loss_scale=16, train_wall=105, wall=170855
2023-05-27 17:49:29 | INFO | train_inner | epoch 024:   1772 / 6686 loss=4.138, nll_loss=2.515, ppl=5.72, wps=52518.2, ups=0.92, wpb=57067.4, bsz=1461.6, num_updates=155300, lr=0.000160489, gnorm=0.264, clip=100, loss_scale=29, train_wall=105, wall=170963
2023-05-27 17:51:18 | INFO | train_inner | epoch 024:   1872 / 6686 loss=4.132, nll_loss=2.508, ppl=5.69, wps=52778.8, ups=0.92, wpb=57381.3, bsz=1488.6, num_updates=155400, lr=0.000160437, gnorm=0.265, clip=100, loss_scale=32, train_wall=105, wall=171072
2023-05-27 17:53:07 | INFO | train_inner | epoch 024:   1972 / 6686 loss=4.142, nll_loss=2.519, ppl=5.73, wps=52547, ups=0.92, wpb=57066.8, bsz=1466.5, num_updates=155500, lr=0.000160385, gnorm=0.264, clip=100, loss_scale=32, train_wall=105, wall=171181
2023-05-27 17:54:56 | INFO | train_inner | epoch 024:   2072 / 6686 loss=4.137, nll_loss=2.513, ppl=5.71, wps=52488.6, ups=0.92, wpb=57171.7, bsz=1458.5, num_updates=155600, lr=0.000160334, gnorm=0.263, clip=100, loss_scale=32, train_wall=105, wall=171290
2023-05-27 17:56:44 | INFO | train_inner | epoch 024:   2172 / 6686 loss=4.145, nll_loss=2.523, ppl=5.75, wps=52733.2, ups=0.92, wpb=57236.7, bsz=1495.1, num_updates=155700, lr=0.000160282, gnorm=0.266, clip=100, loss_scale=32, train_wall=105, wall=171398
2023-05-27 17:57:45 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 17:58:34 | INFO | train_inner | epoch 024:   2273 / 6686 loss=4.15, nll_loss=2.527, ppl=5.77, wps=52364, ups=0.91, wpb=57390.1, bsz=1492.6, num_updates=155800, lr=0.000160231, gnorm=0.266, clip=100, loss_scale=40, train_wall=106, wall=171508
2023-05-27 18:00:22 | INFO | train_inner | epoch 024:   2373 / 6686 loss=4.149, nll_loss=2.526, ppl=5.76, wps=52432.3, ups=0.92, wpb=56966.9, bsz=1472.2, num_updates=155900, lr=0.00016018, gnorm=0.265, clip=100, loss_scale=32, train_wall=105, wall=171616
2023-05-27 18:02:11 | INFO | train_inner | epoch 024:   2473 / 6686 loss=4.13, nll_loss=2.506, ppl=5.68, wps=52761.6, ups=0.92, wpb=57270.1, bsz=1500.3, num_updates=156000, lr=0.000160128, gnorm=0.265, clip=100, loss_scale=32, train_wall=105, wall=171725
2023-05-27 18:04:00 | INFO | train_inner | epoch 024:   2573 / 6686 loss=4.129, nll_loss=2.505, ppl=5.67, wps=52584.6, ups=0.92, wpb=57140.4, bsz=1485.8, num_updates=156100, lr=0.000160077, gnorm=0.266, clip=100, loss_scale=32, train_wall=105, wall=171834
2023-05-27 18:05:49 | INFO | train_inner | epoch 024:   2673 / 6686 loss=4.147, nll_loss=2.525, ppl=5.75, wps=52281.6, ups=0.92, wpb=57128.5, bsz=1470.6, num_updates=156200, lr=0.000160026, gnorm=0.266, clip=100, loss_scale=32, train_wall=106, wall=171943
2023-05-27 18:07:08 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2023-05-27 18:07:38 | INFO | train_inner | epoch 024:   2774 / 6686 loss=4.142, nll_loss=2.518, ppl=5.73, wps=52301.6, ups=0.91, wpb=57214.5, bsz=1484.4, num_updates=156300, lr=0.000159974, gnorm=0.267, clip=100, loss_scale=34, train_wall=106, wall=172052
2023-05-27 18:09:27 | INFO | train_inner | epoch 024:   2874 / 6686 loss=4.143, nll_loss=2.52, ppl=5.74, wps=52611.3, ups=0.92, wpb=57238.7, bsz=1479.1, num_updates=156400, lr=0.000159923, gnorm=0.264, clip=100, loss_scale=32, train_wall=105, wall=172161
2023-05-27 18:11:15 | INFO | train_inner | epoch 024:   2974 / 6686 loss=4.142, nll_loss=2.519, ppl=5.73, wps=52839.4, ups=0.92, wpb=57182.3, bsz=1459.8, num_updates=156500, lr=0.000159872, gnorm=0.264, clip=100, loss_scale=32, train_wall=105, wall=172269
2023-05-27 18:13:04 | INFO | train_inner | epoch 024:   3074 / 6686 loss=4.131, nll_loss=2.507, ppl=5.68, wps=52465.1, ups=0.92, wpb=57210.2, bsz=1497.9, num_updates=156600, lr=0.000159821, gnorm=0.265, clip=100, loss_scale=32, train_wall=105, wall=172378
2023-05-27 18:13:45 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2023-05-27 18:14:54 | INFO | train_inner | epoch 024:   3175 / 6686 loss=4.15, nll_loss=2.528, ppl=5.77, wps=51921.9, ups=0.91, wpb=57095.5, bsz=1465.4, num_updates=156700, lr=0.00015977, gnorm=0.265, clip=100, loss_scale=22, train_wall=106, wall=172488
2023-05-27 18:16:43 | INFO | train_inner | epoch 024:   3275 / 6686 loss=4.142, nll_loss=2.519, ppl=5.73, wps=52606.7, ups=0.92, wpb=57227.8, bsz=1477.4, num_updates=156800, lr=0.000159719, gnorm=0.265, clip=100, loss_scale=16, train_wall=105, wall=172597
